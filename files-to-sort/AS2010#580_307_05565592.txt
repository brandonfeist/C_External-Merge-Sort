An Improved Hebbian Neural Network with 
Dynamic Neuronal Life and Relations 
  
Cornelia Gy?rödi1, Robert Gy?rödi1, George Pecherle3, Livia Bandici2, Mihai Dersidan4 
1professor Phd. Eng Department of Computer Science 
2Associate professor Phd. Eng Department of Electrical Engineering 
3Phd student Department of Computer Science 
4 Student Department of Computer Science 
Faculty of Electrical Engineering and Information Technology, University of Oradea 
Str. Universitatii 1, 410087 
Oradea, Romania 
cgyorodi@uoradea.ro, rgyorodi@uoradea.ro, gpecherle@uoradea.com, lbandici@uoradea.ro, m_dersidan@yahoo.com 
 
 
Abstract- In the last years, artificial intelligence has been an 
important field as the environments in which human-made 
devices have to operate become more and more complex, and 
designing a new algorithm for each environment can be very 
time and resources consuming. Neural networks have been 
successful in a lot of applications, since the same basic 
implementation can be used in a virtually unlimited number of 
situations, by modifying the structure of the network and the 
tests that are used for constructing it. In this paper we present 
an improved hebbian neural network that has the capability of 
adding new neurons to it and can connect neurons using an 
association rule. Since the main problem in neural network 
design is the actual construction of the inter-neuronal relations, 
we try to solve this issue at least partially by allowing the 
network to modify itself depending on its response to different 
stimuli.   
I. INTRODUCTION  
In complex and highly dynamic environments, controlled 
by a large number of state variables, normal human-designed 
algorithms are usually either ineffective, or very hard and 
time-consuming to build. Artificial intelligence tries to 
overpass these difficulties by creating computer-based 
structures and algorithms that imitate at a small level some 
aspects of the human behavior. Neural networks are a special 
type of structures that try to imitate the human brain in order 
to create a structure that is self-built (under the control of a 
feedback algorithm) in the environment where it is supposed 
to run. After it has been built, it remains unmodified and is 
used as is.  
The process of designing the structure of the neural 
network and of building it with the optimal environment 
conditions is more of an art than a science, since the number 
of possible environments is theoretically infinite, and the 
possible state variables might occur with different frequencies 
in the environment. However, neural networks have been 
used successfully in performing several simple tasks. 
In the rest of the paper, we will define the problem (what 
the Hebbian theory is), we will describe our modifications 
and implementation for a more advanced Hebbian Neural 
Network, then we will describe some experimental results we 
have obtained using our method, and some final conclusions.  
 
II. PROBLEM DEFINITION 
The Hebbian theory describes a mechanism by which the 
repeated and persistent stimulation of the postsynaptic cell 
results in an increase in synaptic efficacy. This theory was 
introduced by Donald Hebb, therefore the theory took his 
name (the Hebbian theory). Other names for this theory are 
also: Hebb’s rule, Hebb’s postulate and cell assembly theory. 
This theory says the following: 
We assume the following situation takes place: an axon of 
cell X is near enough to excite another cell Y and it fires it in 
a persistent and repeated way. In this case, a metabolic 
change or growth change takes place in either one or both 
cells. The efficiency of cell X is consequently increased [1]. 
This theory could be summarized as cells that fire 
together. This is somehow similar to the nervous system, as 
an oversimplification of it. This theory explains the process of 
associative learning. In this process, the simultaneous 
activation of cells leads to produce increases in synaptic 
strength [2], also called Hebbian learning. 
Since the rules of hebbian learning are simple, they can be 
easily encoded in a computer neural network, in a very easy 
weight-selection program. However, because of this 
simplicity, hebbian neural networks (HNN) can be used in a 
limited range of applications [3]. 
 
III. OUR MODIFICATIONS AND IMPLEMENTATION 
The purpose of this paper is to create a more advanced 
HNN that uses the advantages of this kind of association 
learning, but also adds some complexity to the neural 
interactions, allowing these networks to be used in a wider 
range of applications [7]. We are also trying to build a more 
dynamic network, that adds new neurons and new 
connections to itself. While this capacity does not bring many 
significant improvements, it is interesting to observe the 
ª*&&& 233
transformations that appear in the network, to be able to 
further improve this self-transformation. 
The changes appear in several parts of the network design. 
First of all, an arbiter is used to offer feedback to the 
network, depending on its output (see Fig. 1). This arbiter is 
only active during initial training and, depending on the 
inputs, the outputs of the HNN and the optimal outputs, the 
arbiter returns a real number in the [-1; 1] interval. From now 
on, we will call this number alpha. The function used to 
determine this feedback number is built such as a maximum 
value -1 is returned when the highest one-space distance 
appears between the two output values: the one returned by 
the HNN, and the optimal one. A value of 1 is returned when 
the two outputs are equal, and a 0 when the HNN’s output is 
neutral (neither bad, nor good). Tests with different feedbacks 
have been performed, by using non-linear functions that were 
stricter or more relaxed, but in average, the linear function 
worked without any problems. 
Depending on the feedback from the arbiter, the network 
updates its connections (change, creation, deletion) depending 
on the activation states of each neuron [6]. 
During the execution of the network, each neuron has an 
activation value in the interval [0; 1] (neuron’s state). The 
threshold is set at 0.5: above this value the neuron is active, 
below it, it is inactive. The threshold is thus only used during 
the running of the HNN. The activation value however is 
going to be used when updating the weights of the 
connections. 
 
 
 
Fig. 1. Schematic representation of the feedback circuit 
 
 
The updating function is run for each pair of neurons that 
are connected, and it depends on the feedback value, on the 
activation values of both neurons and on the learning speed 
(this can be used as a variable and be set higher when the 
current learning set has a higher priority) which is constant. 
This function is also run when the HNN has produced a 
good output (alpha > goodOutputThreshold, where 
goodOutputThreshold is a constant set at 0.5 – remember that 
alpha has a range of [-1; 1], with values for good outputs in 
[0; 1]) between pairs of unconnected neurons that have 
activated at the same time. The value returned by the function 
is multiplied with a probability constant, probNewConnection 
and the resulting number is used as the probability of creating 
a new connection between the two neurons. If a connection is 
added between the two neurons, its initial weight is set to the 
value returned by the updating function. 
The inter-neuronal connections are deleted when they 
reach a critical lower value, killConnectionThreshold. This 
value has been set at 0.0012. 
The updating function is given in the following algorithm: 
 
TABLE I  
UPDATING FUNCTION 
LINE OBSERVATIONS 
If (alpha > 0) Correct output 
 If  (state1 > 0.5 OR state2 > 0.5)  
  Return alpha * (state1-0.5) * (state2-0.5) * K  
  Else  
  Return -alpha * (state1-0.5) * (state2-0.5) * K  
Else Incorrect output 
  If (state1 > 0.5 OR state2 > 0.5)  
    Return alpha * (state1-0.5) * (state2-0.5) * K  
    Else  
    Return -alpha * (state1-0.5) * (state2-0.5) * K  
 
Where: 
- state1, state2 are the activation states of the neurons 
(values between 0 and 1 inclusive),  
- K is a constant representing the learning speed.  
Analyzing all of the cases, if the feedback is positive: 
• If both neurons activated, a positive value is returned, 
proportional with the value of the feedback, and the activation 
values of the neurons (state1, state2). Since the states are 
greater than 0.5 (as the neurons activated) the total product 
will be a positive value. 
• If just one neuron activated, a negative value is 
returned, since one of the terms state1-0.5, state2-0.5 will be 
negative, and the other positive. Since the neurons activated 
differently, the strength of the connection must decrease. 
• If neither neuron activated, a negative value is 
returned, reinforcing their behavior (non activation). 
Likewise, if the feedback is negative (bad outputs): 
• If both the neurons activated, the strength of their 
connection is decreased (a negative number is returned). 
• If just one of the neurons activated, a positive value is 
returned, reinforcing the communication between neurons with 
different activation states. 
• If neither of the neurons activated, a positive value is 
returned. 
40'"tUI*OUFSOBUJPOBM8PSLTIPQPO4PGU$PNQVUJOH"QQMJDBUJPOTto+VMZo"SBE3PNBOJB
234
On each run, depending on the number of the neurons, on 
the absolute value of the feedback and on a probability 
constant, a new neuron might be constructed, adding to it 
some weak connections to the most active (positive feedback) 
or most inactive neurons (negative feedback) [4] [8]. 
In the following algorithm, P(x) represents a probability 
function, where x is an expression whose value is between 0 
and 100. P returns a Boolean value, which will be true in x out 
of 100 cases, and false in the other 100-x cases. 
|x| represents the absolute value of x. 
If ( P( |feedback| * probNewNeuron * networkSize ) ) 
 addNewNeuron 
 for ( each neuron in HNN ) 
       if (  ( stateNeuron-0.5 ) * alpha >= 0 AND 
             P( | stateNeuron-0.5 | * probNewConnection ) 
     connectNeurons( current, new ) 
             end if 
       end for 
end if 
The network is run as a normal neural network, and the 
input and output neurons cannot be killed. They are connected 
to the external world, so they cannot be changed. A visual 
representation of this aspect is shown below, with the 
input/output neurons fixed, and the internal neurons and 
inner-connections dynamic. 
 
 
Fig. 2. The input and output neurons are fixed and can’t be removed. The rest 
of the network is dynamic 
 
 
IV. EXPERIMENTAL RESULTS 
A number of tests have been designed for testing the 
functionality of the network and several networks with 
different initial structures and numbers of neurons were used 
for each test. The tests and their results are presented below: 
1. The networks had to compute the function XOR 
between three input variables. The output was given on four 
output neurons: the XOR between the three pairs formed by 
the input variables, and the total XOR. The reason for using 
four outputs instead of just one was to allow the arbiter to 
return a wider range of numbers, instead of just +/-1. The 
weights of the output neurons were: +/- 0.5 for the total XOR, 
and +/- 0.1(6) for the other three outputs and the sum of these 
weights gives the feedback from the arbiter. 10 different 
initial networks were used, with the first two being built with 
a hierarchical structure- after a structure was set for 
computing the XOR between two variables it was repeated 
for computing the intermediary XORs, and the final one. 
After different runs of the networks, 6 out of 10 (including the 
two networks with the pre-designed structure) produced the 
correct results, and the other 4 had a correctness average of 
74%. 
2. Another set of tests was designed using randomly-built 
polynoms of the 3rd degree, with the coefficients being 
selected to be smaller than 15. For each polynom, 30 neural 
networks with 15 hidden (neither input, nor internal) neurons 
were built with random connections between the neurons. The 
inputs and outputs of the network were encoded in binary 
code. The total number of input and output neurons was 
selected such that, if the largest value of the polynom (with X 
in the [1; 30] interval) was N, log(N)+1 output neurons were 
present. The same principle was used for the input (since the 
largest input value was 30, 5 input neurons were present). The 
arbiter returned after each run a feedback value that depended 
linearly on the response of the network, the value of the 
polynom for the current X, and the maximum distance in the 
direction of the neuron’s output of the polynom in the [1; 30] 
interval. For example, for an output of 12 from the network, a 
correct value of 6, and a maximum value of 34, the arbiter 
returned the value 8/14: a 1 would be returned for 6, -1 for 34. 
Drawing a line in the XoY plane between these points, the 
intersection with X=12 would be at 8/14. After multiple runs, 
an average correctness of 68% was obtained for this test. 
3. The third and final test was a practical implementation 
of the neural network on a simple line-following robot that 
received information from two light sensors, each encoded on 
8 bits. The output of the network was encoded on 6+6 bits, 
each representing the speed of the engine from the respective 
side (with stop at 0 and maximum speed at 63). After 
developing a program for this line-following robot, its output 
was used by the arbiter to compute the feedback value. This 
feedback value depended on angle difference between the two 
directions (the one chosen by the robot’s program, and the 
one suggested by the neural network). The robot was 
controlled only by its program during the building of the 
network. After the end of the building period, the control was 
given to the neural network. Different tests were made on this 
robot, with different reduction values for the two engines, to 
control the maximum speed of the robot mechanically. At 
slow and medium speeds, the network was able to keep the 
robot on the track, but at higher speeds, after 6-7 seconds, it 
got off tracks. Another test was made, when the arbiter 

$(Z?SÚEJFUBMt"O*NQSPWFE)FCCJBO/FVSBM/FUXPSLXJUI%ZOBNJD/FVSPOBM-JGFBOE3FMBUJPOT
235
remained active during the period when the network was 
controlling the robot. No significant improvement was 
observed in the behavior of the robot. 
 
 
 
V. CONCLUSIONS 
Our neural network is an improved version by allowing 
the possibility to add new neurons to it. Also, our network can 
connect neurons using an association rule.  
Another advantage is the fact that we allow our network to 
modify itself depending on its response to different stimuli. 
This solves a problem in neural network design, more exactly 
the construction of the inter-neuronal relations. 
This type of network can further be improved by adding a 
sub graph based analysis of the neuronal connections, and 
updating the weights depending on the activity in each sub 
graph. In choosing these sub graphs, a good technique could 
be to select the dense sub graphs that are isolated from the 
rest of the network (working separately), and by using a more 
advanced arbiter, a feedback could be generated for the 
respective sub graph. 
Another improvement can be the inclusion of genetic 
algorithms in the building of the networks. The genetic 
algorithm will be used to modify the different parameters that 
appear in the network self-construction (the probabilities for 
creating new neurons, new connections etc.), or to change the 
function of the arbiter for each network, thus controlling the 
curve of the positive-negative response to a non-linear one. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
REFERENCES  
[1] Hebbian theory (http://en.wikipedia.org/wiki/Hebbian) 
[2] Neural Networks and Learning Machines (3rd Edition) - Simon Haykin, 
McMaster University, Canada, 2008, Prentice Hall 
[3] Artificial Intelligence-A Modern Approach (3rd Edition) - Stuart 
Russell, 2009, Prentice Hall 
[4] Pattern Recognition and Machine Learning (Information Science and 
Statistics) - Christopher M. Bishop, 2007, Springer 
[5] Practical Genetic Algorithms - Randy L. Haupt, Wiley-Interscience, 
2004  
[6] "A self-organising network that grows when required" - Stephen 
Marsland, Jonathan Shapiro, Ulrich Nehmzow - Neural Networks, 
Volume 15, Issue 8-9 (October 2002), pp. 1041-1058, ISSN: 0893-6080  
[7] "A Very Fast Learning Method for Neural Networks Based on 
Sensitivity Analysis" - Enrique Castillo, Bertha Guijarro-Berdiñas, 
Oscar Fontenla-Romero, Amparo Alonso-Betanzos - The Journal of 
Machine Learning Research - Volume 7 (December 2006), pp. 1159 - 
1182, ISSN: 1532-4435  
[8] Pattern Recognition and Neural Networks - Brian D. Ripley - 
Cambridge University Press, 1st edition (January 28, 2008) 
 
 
 
 
 
 
 
40'"tUI*OUFSOBUJPOBM8PSLTIPQPO4PGU$PNQVUJOH"QQMJDBUJPOTto+VMZo"SBE3PNBOJB
236
