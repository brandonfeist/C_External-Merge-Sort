 Distributed Mining of Association Rules Based on 
Privacy-Preserved Method  
 
Hua-jin Wang and Chun-an Hu 
 School of Information Engineering 
 Jiangxi University of Science and Technology 
Ganzhou, China 
wanghj128@163.com 
Jian-sheng Liu 
 School of Science 
 Jiangxi University of Science and Technology 
Ganzhou, China 
jxgzjscn@126.com 
 
 
Abstract—With the rapid development of social information, 
the application of distributed database system is increasing. 
Distributed data mining will play an important role in data 
mining. As one of the well-known distributed association rules 
mining algorithm, the FDM algorithm is very fast and efficient, 
however, the cost of this algorithm is very great because it is 
designed under the condition of non-shared resource. 
Moreover, the important information at every site is exposed to 
other sites, which is not accord to the nowadays trend of 
attaching importance to privacy preserving increasingly. In 
this paper, we propose an improved algorithm based on the 
FDM algorithm. In the process, it computes the total support 
count with the privacy-preserved method, meanwhile ensures 
the source of every local large item-set and local support count 
is covered, so it reduces the time spent on communication and 
preserves the privacy of the data distributed at each site. The 
experimental evaluations show that the proposed algorithm is 
efficient and rather suitable for the practical application fields. 
FDM; privacy preserving; association rules; data mining 
I.  INTRODUCTION 
Association rules mining is an important research area in 
data mining, which indicates relations among item sets in 
database, With the accumulation of the data, association rule 
mining in large data set attracts more and more attention, 
distributed mining algorithms are effective methods to solve 
this problem. At present, researchers have proposed some 
distributed algorithms to mining association rules such as 
PDM, CD, FDM, DMA, FPM, DDDM, Grid based method 
and parallel FP-Growth et al. Among these algorithms, 
FDM[1] is classical which is proposed by Cheung D.W. based 
on the CD[2] algorithm. The time cost of each iteration can be 
reduced by decreasing the communicating cost and the 
number of candidates in each site. 
In each site, the FDM algorithm finds the local support 
counts and prunes all infrequent local candidate sets. After 
completing local pruning, each site broadcasts messages 
containing all the remaining candidate sets to all other sites 
to request for their support counts. It then decides whether 
large item sets are globally frequent and generates the 
candidate item sets from those globally frequent item sets. 
This process continues until no globally frequent item sets is 
generated or no candidate set is produced.  
To reduce message communication, it uses polling site 
method. In this method every itemset is assign to one local 
site and this site must calculate support count of it. So if a 
site need support count of any itemset, ask from its polling 
site. This idea reduces communications between processes. 
FDM’s main advantage over CD is that it reduces the 
communication overhead. 
However, the FDM algorithm was designed under the 
condition of non-shared-resource. In the paper[3], the 
network condition of topology is formed between all sites 
and local large candidate item sets are broadcasted to all sites 
that results into the exposure of important information of 
every site in the distributed system and unable to privacy 
preserving.  
Therefore, based on the FDM algorithm, an improved 
algorithm which named PPFDM is proposed. In the process, 
it computes the total support count with the privacy-
preserved method, meanwhile ensures the source of every 
local large item-set and local support count is covered. The 
experimental result shows that it reduces the time spent on 
communication and preserves the privacy of data distributed 
on each site. 
II. PROBLEM  DESCRIPTION   
With the increasing development of information 
technology, people appeal to privacy preserving urgently. In 
the paper[4], singularly high privacy preserving is required 
in some fields of data mining, especially in the field of 
finance, medical treatment etc. For example, to analyze the 
incidence of one disease, it needs for several hospitals to 
integrate and analyze the information held by their own, but 
in practice, the hospitals are unwilling to share the 
information for the reason of protecting privacy of patients 
or for other reasons. Thus, in some fields, privacy preserving 
becomes the important factor to evaluate the performance of 
distributed data mining. In the paper[5], As far as the defect 
of FDM algorithm concerned, since it was designed under 
the condition of non-shared-resource, the topology of 
network causes one site to expose its own information to 
other sites. Consequently, we improve the classical FDM 
Third International Symposium on Information Science and Engineering
978-0-7695-4360-4/10 $26.00 © 2010 IEEE
DOI 10.1109/ISISE.2010.125
4984
algorithm in order to prevent revealing important data and 
improve the performance of the algorithm. 
Distributed mining of association rules can be classified 
into two kinds: horizontally partitioned and vertically 
partitioned. In [6-8] , Accordingly FDM algorithm is on the 
base of horizontally partitioned data and correspondingly the 
theory of privacy preserving in horizontally partitioned data 
mining is to ensure local candidate item-sets are accessible to 
local sites but inaccessible to other sites. Hereby the motive 
of introducing privacy preserving in this paper, namely the 
problems need to be solved is as follows: 
1) Ensuring that the local large itemset and local support 
count is covered to other sites. 
2) Computing the global support count. 
Firstly, secure set union is proposed to adopt by means of 
encrypting, re-encrypting and permuting encrypted items at 
every site, so that the local large item-set and local support 
count could be transferred between sites and the tracing of 
source of original data could be prevented well. 
Secondly, secure sum could be adopted to solve the 
second problem. In detail, we set up a site called home site, 
then it is proposed to compute a certain function from the 
home site to other sites with the privacy input into this 
function, return the ultimate function value to the home site, 
decrypt the returned function value at the home site 
according to the original privacy input, and obtain the secure 
sum finally, that is global support count. 
III.  PRIVACY-PRESERVED METHOD 
As is known that in classical FDM algorithm, the local 
large item sets need to be broadcasted to other sites after the 
local pruning so that the global support count of these local 
large item-sets could be computed. In order to ensure the 
information of local site such as local large item-sets and 
local support count could not be aware to other sites, we  
introduce the secure set union here.  
Secure set union is a method of privacy preserving in 
data mining, through which the information of local site such 
as rules, local large item-sets etc. can be broadcasted in the 
distribution system, but owners of broadcasted information 
can’t be exposed. Theoretically, secure set union executes its 
function basing on the thought of permuting encrypt item. 
Figure 1 shows the principle to set up secure set union. 
 
 
))(( 32 CEE  
))(( 32 DEE                             )(1 CE  
 
                                                C  
                    )(3 CE                  D  
)(3 DE  
 
)))((( 132 CEEE                                                               ))(( 13 CEE  
 
 
 
Figure 1.  Determining the union of itemsets 
If given key 1,... nK K K? , for any permutation ,i j , the 
following two equations hold:  
1 1
(... ( )...) (... ( )...)
i in j jnK K K K
E E M E E M=                (1)  
1 2 1 2, ,M M M M M? ? ? , given arbitrary 1, 2kk ? < , s.t 
1 11 2
( (... ( )...) (... ( )...))
i in j jnr K K K K
P E E M E E M ?= <       (2) 
 
By introducing the secure set union, each site encrypts 
the local data and transfers it to other sites, then each site 
reencrypt data received from other sites. Accordingly to 
equation 1 and equation 2, duplicates in the original items 
will be duplicated in the encrypted items, and can be deleted. 
In addition, the decryption can occur in any order. Thus, by 
permuting the encrypted items, it is prevented that each site 
tracks the source item-sets. 
Obviously, through this method of secure set union, 
each site could transfer the information of local large 
itemsets and local support count etc., without revealing that 
information from which site. However during the process of 
transferring data, the number of local large item-sets is 
revealed which exist in two sites. For example, if K site 
have a local large item-set, it will be duplicated k times. 
Although the item-set itself is not revealed, the true secure 
computation could not reveal this information. In practice, 
allowing innocuous information leakage in an algorithm 
means lower cost than the algorithm with fully secure 
computation. 
On the other hand, we would like to compute the global 
support counts and ensure the local supports of each site 
could not revealed to other sites as well. This can be easily 
fulfilled by the method of secure sum.   
If given sites1, 2,...s , first a home site(site No.1) must to 
be determined; and site No.1 randomly produces a 
randomR which ranges in [1, ]n  and will be added the local 
support count of site No.1, then transfers 1 modR v n+  to site 
No.2; asR is a random ranging in[1, ]n , site No.2 could not 
obtain the real value of 1v  after receiving the information of 
1 modR v n+ ; similar mode to compute the function will be 
set up in remainder sites No. l  ( 2... 1l s= ? ) and now the 
received function value in site No. l  is 
1
1
mod
l
j
j
V R v n
?
=
= + ?  , 
which will be added R  (that 
is
1
mod ( ) mod
l
j j
j
R v n v V n
=
+ = +? ) and transferred to site 
No. 1l + ; …; similarly the last site (site No. s ) computes the 
function and returns the function value to site No.1 where 
decryption will be implemented according to the value of 
cryptically R , global support count will be acquired and 
local support counts of other sites can’t be revealed. Figure 2 
shows the principle to compute secure sum. 
Obviously, the method of secure sum will be confronted 
with problem if sites collude. For instance, site No. 1l ?  and 
site No. 1l +  could collude, then could confirm the real   
2 
D 
3 
C 
1 
C 
4995
 
                               712 +  
                                                  
                                    19                                                                                
                                                                                                                   
                                                                    !219 =? R  
 
17=R  
                                                   
517 ?                              
 
0+R  
Figure 2. The principle to compute secure sum 
value of lv  by comparing the function values that they sent 
out and received. However one site could be threatened on 
privacy secure, unless all the other sites colluded. This 
makes it possible for secure sum to be used in our proposed 
method. 
IV. EXPERIMENTAL  EVALUATION 
The proposed improved algorithm (PPFDM) is evaluated 
on some UCI datasets[9], and the distributed system in the 
experiment is made of four computers which are deployed 
with the following hardware and software: CPU: 
Pentium(R) D CPU 2.60GHZ; Memory: 1024MB; Operation 
System: Windows XP. Java was adopted as the 
programming language in the experiment.  
The front 1400 records of dataset named Contraceptive 
Method Choice in UCI datasets are used in the experiment. 
We first discretize an attribute named Wife's age, the original 
values of which are integers and range in [20, 50] (the value 
of other attributes is discretized originally and need not be 
scattered). We suppose the data distributes symmetrically in 
each computer, namely the numbers of the data distributed in 
each site are approximately equal. Our scheme is described 
as: symmetrically distributing 1400 discrete records to each 
site, just 350 records per site. Table I describes some samples 
with records. 
Among the above attributes, firstly, attribute A denotes 
wife’s age: 2 for 20~29 years old, 3 for 30~39 years old, 4 
for 40~49 years old; secondly, attribute B denotes wife’s 
education level which ranges from low to high as: 1, 2, 3, 4; 
thirdly, attribute C denotes husband’s education level which 
ranges from low to high as: 1, 2, 3, 4; and attribute D is the 
statistic of number of children ever born; attribute E shows 
wife’s religion: 0 for non-Islam and 1 for Islam; attribute F 
figures whether wife is now working: 0 for working and 1 
for not working; attribute G denotes husband’s occupation 
level which ranges from low to high as: 1, 2, 3, 4; in 
addition, attribute H denotes standard of living index which 
ranges from low to high as: 1, 2, 3, 4; and attribute I shows 
media exposure: 0 for good and 1 for not good. Finally, 
attribute J shows way to contracept: 1 for never use, 2 for 
long-time use and 3 for short-time use. 
Given min_sup=20%, min_conf=70%. In the testing on 
effectiveness, we got the average time of 10 times tested on 
experimented dataset respectively by classic FDM algorithm 
and improved algorithm, and the experimental results are 
showed in Table II. 
TABLE I.  SOME SAMPLES 
Code of 
attribute 
  
          No. of 
            record 
Name                
of  attribute 
? ? ? ? ? 
A Wife’s age 2 4 4 4 3 
B Wife’s  education 2 1 2 3 3 
C Husband’s education 3 3 3 2 3 
D 
Number of 
children ever 
born 
3 10 7 9 8 
E Wife’s religion 1 1 1 1 1 
F Wife’s now working? 1 1 1 1 1 
G Husband’s occupation 2 3 3 3 3 
H Standard of living index 3 4 4 3 2 
I Media exposure 0 0 0 0 0 
J Contraceptive method used 1 1 1 1 1 
TABLE II.  EXPERIMENTAL RESULTS ON EFFECTIVENESS TESTING 
 FDM Algorithm PPFDM Algorithm 
the Result 
of Large 
Association 
Rules 
301,111 JIEJFE ????  301,111 JIEJFE ????  
Time 
Spent 2246ms 2019ms 
 
As is shown that in Table II the proposed improved 
PPFDM algorithm is more effective than the FDM algorithm,  
At the same time, we have got the same large association 
rules by the improved algorithm. Furthermore, we have 
compared the efficiency of the improved algorithm with the 
classical one. The proposed algorithm reduces the 
computation time because secure sum has been used in the 
improved strategy and the new communication mode has 
decreased the time which spent on communication with the 
set up of home site. Besides, privacy of each site has been 
also preserved well. 
V. CONCLUSIONS 
In this study, we propose an improved algorithm 
(PPFDM) based on the FDM algorithm and the computation 
method of privacy preserving. In the process, this algorithm 
computes the total support count with the privacy-preserved 
method, meanwhile ensures the source of every local large 
item-set and local support count is covered, so it reduces the 
time which spent on communication and preserves the 
privacy of the data distributed at each site. The experimental 
evaluation proves that the improved algorithm is efficient 
and rather suitable for the practical application fields, 
Site No.3 
7 
Site No.2 
-5 
Site No.1 
0 
500496
particularly those fields which require preserving privacy in 
the mining process. 
ACKNOWLEDGMENT 
The authors acknowledge the support from Jiangxi 
University of Science and Technology and the research 
grants provided by the Youth Science Fund of Education 
Office of Jiangxi Province (No.GJJ09522).  
REFERENCES 
[1] D.W. Cheung,  et al., 1996. A Fast Distributed Algorithm for Mining 
Association Rules. In Proc. Parallel and Distributed Information 
Systems, IEEE CS Press, pp: 31-42.  
[2] R. Agrawal and J. Shafer, 1996. Parallel mining of association rules. 
IEEE Transaction on Knowledge and Data Engineering, 8(6): 962-
969. 
[3] Huang Xianying, Wang Keke, Fan Wei. Distributed Ming of 
Association Rules Based on Network of Start Model [J].Science of 
Computer, 2004(12): 180-188.  
[4] Huang Yiqun, Lu Zhengding, Hu heping, Li Ruixuan. Algorithm of 
Privacy-preserved Association Rules Mining in Distributed System 
[J].Computer Engineering, 2006(13): 12-14. 
[5] R.Agrawal and R.Srikant. Privacy-preserving Data Mining. In 
Proceedings of 2000 ACM SIGMOD Conference on Management of 
Data, Dallas, TX, 2000: 439-450. 
[6] S.C.Pohlig and M.E.Hellman. An improved algorithm for computing 
logarithms over GF(p) and its cryptographic significance. IT-24: 
1978.106-110.  
[7] Zhang Guorong. Problem of privacy preserving in Distributed Data 
Ming [J].Knowledge and Technology of Computer, 2006(08):30-212.   
[8] B.Schneier. Applied Cryptography. John Wiley & Sons. 1995. 
[9] UCI Repository of Machine Learning Databases. 
http://archive.ics.uci.edu/ml/.
 
501497
