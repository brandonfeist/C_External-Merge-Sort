A Novel Fuzzy Positive and Negative Association Rules Algorithm 
HU Kai 
China ship Development & Design Center 
Wuhan, China 
iamhukai@gmail.com 
 
Abstract—According to the existing mining algorithm of fuzzy 
association rules, a novel fuzzy positive and negative 
association rules algorithm will be proposed in this paper. We 
focus on the membership function of fuzzy set and minimum 
support parameters of positive and negative association rules 
and adopt a method that selects parameters automatically 
which is based on the k-means clustering. Besides, multi-level 
fuzzy support and correlation coefficient are chosen to restrain 
the quantity and quality of rules generated by the algorithm. 
Finally the validity and accuracy of the algorithm are proved 
by an experiment. 
Keywords- data mining; fuzzy association rules; membership 
function; multi-level fuzzy support; correlation coefficient 
I. INTRODUCTION 
Association rules mining, which aims to discover 
relevant valuable knowledge describing interrelation 
between data items from huge numbers of data, is a 
extremely important research subject of data mining 
domain.  Since it was first proposed in 1993 by Rakesh 
Agrawal etc[1], association rules extraction has received 
widespread concern and in-depth research both in 
algorithms and efficiency[2-3]. For numeric databases, 
quantitative association rules mining [4-5] is a significant 
branch. Since the fuzzy association rules mining technology 
was put forward combined with fuzzy set theory [6], this 
field has got more and more attention. However, the 
selection of membership functions, a key issue of the fuzzy 
association rules mining technology, gets little research. In 
most cases, the methods developed by experts are adopted 
by making use of a priori knowledge, but there is a certain 
blindness, which will cause an influence on the accuracy 
and efficiency of the final rules extraction. In addition, most 
studies focus on the extraction of positive association rules 
such as X ? Y no matter in the traditional Boolean 
association rules mining or quantitative association rules 
mining and many mature algorithms come into being. 
Negative association rules in the form of X?¬Y, ¬X?Y or 
¬X?¬Y have been received widespread concern[7-8], but 
such issues as the parameter selection of support degree etc. 
call for further study. Negative association rules stand for a 
negative correlation knowledge of things and they also plays 
a very important role compared with the positive association 
rules. 
According to current research status, a new fuzzy 
positive and negative association rules mining algorithm is 
proposed, which determines the membership functions 
based on k-means clustering method. And its advantage lies 
in discovering the cluster center of data set guidelessly in 
the absence of sufficient prior knowledge, thereby 
identifying the membership functions reasonably and 
avoiding wrong mining results caused by false parameter 
selection of the membership functions. Meanwhile, it adopts 
the multiple fuzzy supports in the fuzzy association rules for 
the first time and introduces the correlation coefficient 
criterion, controlling the quality of rules effectively and 
ensuring the accuracy and efficiency of algorithms. 
The remainder of this paper is organized as follows: An 
introduction of positive and negative association rules and 
multiple support degree theories are given in Section 2. In 
Section 3, the fuzzy association rules and the selection of 
membership functions are introduced. In Section 4, the new 
fuzzy positive and negative association rules mining 
algorithm is presented. After that, Section 5 introduces an 
experimental simulation of the proposed algorithm. Finally, 
some conclusions are drawn in Section 6. 
II. MULTI-SUPPORT POSITIVE AND NEGATIVE 
ASSOCIATION RULES 
Suppose that I={i1, i2,…, im} is a set of binary attributes, 
and T={t1,t2,…,tn} is a set of n data records, where ti ? I, 
namely, each record in T can be viewed as a subset of I. The 
association rule (AR) is the logical implication of such form 
as X?Y, where X ? I, Y ? I, and X?Y=?. When the 
support degree and the confidence degree of the rule are 
greater than a given minimum support and minimum 
confidence threshold separately, then it is considered as a 
correct one. And its support degree is supp(X ?
Y)=|TX?Y|/|T|, while the confidence degree is conf(X?
Y)=|TX?Y|/|TX|, where |TX| represents the count of 
transactions containing X in T. When a considered thing 
does not happen, that is to say, ¬X shows that itemset X 
does not occur, bringing about such negative rules as X?
¬Y, ¬X? Y and ¬X? ¬Y. The support degree and 
confidence degree can be counted by the corresponding 
positive item sets: 
s(¬X)=1-s(X); 
s(X?¬Y)=s(X)-s(X?Y); 
s(¬X?Y)=s(Y)-s(X?Y); 
s(¬X?¬Y)=1-s(X)-s(Y)+s(X?Y); 
c(X?¬Y)=1–c(X?Y); 
2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science
Unrecognized Copyright Information
DOI 10.1109/DCABES.2010.163
623
c(¬X?Y)=
s(X)-1
Y)()( ?? XsYs ; 
c(¬X?¬Y)=
)(1
)()()(1
Xs
YXsYsXs
?
?+?? =1-c(¬X?Y) 
In fact, negative association rules exist not only in 
infrequent itemSets (inFS), but also exists in the frequent 
itemSets (FS), so negative rules need to be mined in inFS, 
while in FS, both positive and negative rules need to be 
mined. In theory, inFS can be regarded as a complement of 
FS, but, in practice use, it is often very large, generating 
plenty of negative rules, which are not all meaningful. The 
size of inFS can be restraint by 2-level Supports[9] and 
multiple level minimum supports(MLMS)[10], in which the 
later establishes different minimum supports for those 
candidate itemsets which have different lengths, 
ms(1)?ms(2)?...?ms(n)?ms>0, where ms represents the 
threshold of inFrequent itemSets and ms( k) stands for the 
minimum support of frequent K-itemsets. If s(X)?ms(k) 
then X is a frequent itemset. But if s(X)<ms(k) and 
s(X)>ms, then X is an inFrequent itemset. This model 
MLMS can control the number of the frequent and 
inFrequent itemSets by establishing different m(k). 
The correlation between the preceding paragraph X and 
consequent paragraph Y of association rules can be 
measured as follows: 
)()(
)(
, YsXs
YXscorr yx
?
= . If corrx,y>1, then 
X and Y are positively correlated, that is, the occurrence of 
X will promote the occurrence of Y. But if corrx,y=1, then X 
and Y are independent, that is, the occurrence of X and Y 
has nothing to do with each other. If corrx,y<1, then X and Y 
are negatively correlated, that is, the occurrence of X 
conflicts with the occurrence of Y. The correlation between 
negative itemsets can be counted by corresponding positive 
itemsets. 
When corrx,y>1, )( YXs ? > )()( YsXs , 
so )()()()()( YsXsYsYXsYs ?<?? , 
while )()()( YXsYXsYs ?¬=?? , 
)()()](1)[()()()( XsYsXsYsYsXsYs ¬=?=? ’ 
hence, )()()( YXsYsXs ?¬>¬ ’ 
thus,
1
)()(
)(
, <
¬
?¬
=
YsXs
YXscorr yx
, 
And in the same way, we can infer that corrx,¬y<1, 
corr¬x,¬y>1. 
When corrx,y>1, Certainly, the greater corrx,y, the stronger 
the positive correlation between X and Y. While when 
corrx,y<1, the closer corrx,y comes to zero, the stronger the 
negative correlation between X and Y. 
III. FUZZY ASSOCIATION RULES 
When datasets containing continuous numeric attributes 
emerge during association rules mining, the method 
discretizing data is usually adopted. As to a specified 
continuous numeric attribute Q, it will be divided into p 
intervals, and then the new generated attributes Q1, Q2, ..., 
Qp are used to replace the original attribute Q. However, a 
simple division of continuous attributes into several 
intervals may lead to so-called "hard boundary" issues, such 
as the record "Those who are 31 years old age 31 spend 6 
hours online per day” does not support the rule: 
Age[20,30]?Average daily online duration[5,10]. However, 
in fact there is little age difference between 31 and 30, in 
other words, such fuzzy association rules as "young adults 
are more likely to spend a long time online" seem more 
correct and more instructive [11-12]. 
For the continuous numeric dataset T=(t1, t2, ..., tn), and 
I=(i1, i2, ..., im), the set containing all the attributes of T, 
each continuous attribute ik has a corresponding fuzzy set 
},...,,{ 21 liiii kkkk fffF = , where 
j
ik
f  represents the j-th fuzzy 
set. For example, the continuous attribute "income" has 
three fuzzy sets: high, middle and low, so it can be 
expressed as "F Income = {high, middle, low}". 
The form ????? BYAX ,,  is a fuzzy association rule, 
which means that when attribute X is A, then it can inferred 
that attribute Y is B. Where X ? I and Y ? I are the sets of 
attributes, A and B are corresponding with the fuzzy sets of 
attributes which belong to X and Y respectively. The 
standards for valid fuzzy rules are the same as traditional 
Boolean rules. Namely, fuzzy support and fuzzy confidence 
of the fuzzy rules should be greater than the given 
thresholds of minimum fuzzy support and minimum fuzzy 
confidence respectively. However, the calculation of fuzzy 
support and fuzzy confidence is different from that of 
traditional Boolean rules. In the mining of traditional 
Boolean association rules and quantitative association rules, 
the transaction of a record either appears or not, and the 
degree of transaction support a property can be counted by 
the times which the attribute appears in all the transactions. 
While in the mining of fuzzy association rules, fuzzy 
support can be counted by the membership of data items to 
each attribute, and described by the form of probability. 
The support of ?? AX ,  is calculated as follow: 
||
])}[({
, T
xt
S
jiaXxTt
AX
jji? ? ??
?? =
?
, 
Where ti[xj] represents the value of the j-th attribute in the i-th 
record, ])[( jia xtj?  stands for such fuzzy support of ti[xj] 
that attribute xj is equal to aj, and ? ? ])}[({ jiaXx xtjj ?  
represents the result which is multiplied by the  fuzzy support 
of each attribute xj. Here, T-mode TP(x,y)=x*y is adopted 
instead of other T-modes, such as TM(x,y)=min(x,y); 
TW(x,y)=max(x+y-1,0) etc, for the reason that operation ? 
not only considers the membership of all attributes, but also 
the convenient calculation of the algorithm 
The fuzzy confidence of ????? BYAX ,,  is calculated 
as follows: 
624
? ?
? ?
??
??
??
??
?????? == ])}[({
])}[({
,
,
,,,
jicXxTt
kicZzTt
AX
CZ
BYAX zt
zt
S
S
C
kji
kki
?
?
, 
Where ?? CZ ,  is the frequent fuzzy item set, ZX ? , 
Y=Z-X, CA ? , B=C-A. 
How to determine a Membership function (MF) of the 
sample data is a key issue of fuzzy association rules. So the 
determination of the parameters of MF is particularly 
important. This paper adopts the method based on k-means 
clustering, which identifies the cluster center of data sets by 
self-learning, and hence, determines the parameters of MF. 
As to the data set T, first of all, cluster p continuous 
numeric attributes that need discretization into specified q 
clusters by k-means, and generate a p * q cluster center 
matrix C, where the j-th center point of the i-th attribute can 
be represented by Ci,j. Then, combine with MF of triangle to 
find out the fuzzy MF of each attribute. Attribute ik has q 
cluster centers described as },...,,{ ,2,1, qiii kkk CCC , the fuzzy 
set MF of which is shown as .Figure 1. 
1 
Cik,qCik,2 Cik,1  
Fig.1  MF of ik determined by the clustering center 
The ik attribute’s fuzzy set },...,,{ 21 qiiii kkkk fffF = , where 
,1
,21
,1 ,2
,1 ,2 ,2 ,1
,2
1                                          
     
0                                         
k
k
k k k
k k k k
k
k i
ik
i i k i
i i i i
i k
i C
Cif C i C
C C C C
C i
? ???
= + < ??
? ??? <?
; 
,1
,1 ,2
,2 ,1 ,1 ,2
,32
,2 ,3
,2 ,3 ,3 ,2
,3 ,1
     
     
0                                          or 
k
k k
k k k k
k
k kk
k k k k
k k
ik
i k i
i i i i
ik
i k ii
i i i i
i k k i
Ci
C i C
C C C C
Ci
C i Cf
C C C C
C i i C
?
+ ? ??
? ????
+ < ?= ?
? ????
< <??
; 
, 1
, 1
, 1 ,
, , 1 , 1 ,
,
0                                              
     
1                                               
k
k
k k k
k k k k
k
i q k
i qq k
i i q k i q
i q i q i q i q
k i q
C i
Cif C i C
C C C C
i C
?
?
?
? ?
? ???
= + < ??
? ??? ??
 
IV. FUZZY POSITIVE AND NEGATIVE 
ASSOCIATION RULES ALGORITHM 
This paper proposes a new mining fuzzy positive and 
negative association rules algorithm, which can be divided 
into two steps. Firstly, adopt k-means clustering algorithm 
to process continuous numeric attributes of data sets, and 
determine the MF of each attribute by cluster center points. 
Secondly, convert original data set T into fuzzy data set T’ 
according to the generated MFs. This step can be viewed as 
a pre-processing stage. The algorithm is shown as follows:  
Input: original data set -T, the number of clusters -K 
Call k-means to cluster data set T, and get k 
cluster centers {C1, C2,…,Ck}. 
For each attribute Ai do 
Determine Mi, the MF of attribute Ai, by 
{C1,C2,…,Ck}. 
End for 
For each record ti?T 
Make the record ti fuzzy by Mi  
End for 
Output: fuzzy data set T’ 
MS_FPNAR is adopted in the second step. Multi-level 
Fuzzy support is used to generate Frequent Fuzzy itemSet 
and infrequent Fuzzy itemSet in the fuzzy data set T’. Then, 
fuzzy positive and negative association rules, which are 
greater than the minimum fuzzy confidence, are mined in 
frequent fuzzy itemsets and fuzzy negative association rules 
are mined in infrequent fuzzy itemsets combined with 
correlation coefficient corrx,y constraints. The algorithms for 
generating frequent fuzzy itemsets and infrequent fuzzy 
itemsets are shown as follows: 
Input: fuzzy data set T’, Multi-level minimum Fuzzy 
Support mfs(k), Infrequent fuzzy itemset threshold mfs. 
C1=a fuzzy itemset which has a support ? mfs 
FFS1= a fuzzy itemset which has a support 
? mfs(1) in C1 
inFFS1=C1-FFS1; 
For (k=2;Ck-1!=NULL;k++) 
Ck=apriori_gen(Ck-1, mfs); 
For each c?Ck 
If c contains multiple fuzzy sets in the 
same attribute then delete c from Ck 
Ct=subset(Ck,t); 
Calculate the support of each c?Ct 
End for 
Ck= a fuzzy itemset which has a support ? ms 
in Ct; 
FFSk=a fuzzy k itemset which has a 
support ? mfs(k) in Ck; 
inFFSk=Ck-FFSk; 
add FFSk into FFS, and add inFFSk into inFFS 
End for 
Output: frequent fuzzy itemset FFS, infrequent fuzzy 
itemset inFFS 
625
The algorithm which is mining fuzzy positive and 
negative association rules in FFS and inFFS as follows: 
Input: frequent fuzzy sets - FFS, infrequent fuzzy sets - 
inFFS, minimum fuzzy confidence - mfc, minimum 
correlation information number- min_corr 
For each fuzzy set ?? CZ ,  in FFS 
Calculate the correlation coefficient 
of ???? BYAX ,, ? When X ? Y=Z, A ? B=C and X ? Y= ? , 
A ? B= ? ; 
If the correlation coefficient 
of ???? BYAX ,, ? >min_coor 
If the fuzzy confidence 
),,( ????? BYAXc ? mfc then add ?? CZ ,  into FPAR 
If the fuzzy confidence 
),,( ??¬???¬ BYAXc ? mfc then add ?? CZ ,  into FNAR 
If the correlation coefficient 
of ???? BYAX ,, ? <1/min_corr 
If the fuzzy 
confidence ),,( ??¬??? BYAXc ? mfc then add ?? CZ ,  into 
FNAR 
If the fuzzy confidence 
),,( ?????¬ BYAXc ? mfc then add ?? CZ ,  into FNAR 
End for 
For each fuzzy set ?? CZ ,  in inFFS 
Calculate the correlation coefficient 
of ???? BYAX ,, ? When X ? Y=Z, A ? B=C and X ? Y= ? , 
A ? B= ? ; 
If the correlation coefficient of 
???? BYAX ,, ? >min_coor 
If the fuzzy confidence 
),,( ??¬???¬ BYAXc ? mfc then add ?? CZ ,  into FNAR 
If the correlation coefficient of 
???? BYAX ,, ? <1/min_corr 
If the fuzzy confidence 
),,( ??¬??? BYAXc ? mfc then add ?? CZ ,  into FNAR 
If the fuzzy confidence 
),,( ?????¬ BYAXc ? mfc then add ?? CZ ,  into FNAR 
End for 
Output?fuzzy positive association rules -PAR, fuzzy 
negative association rules -NAR 
V. EXPERIMENTAL RESULTS 
A standard data set consisting of 150 samples, which 
belongs to three different kinds of rocks separately and 
contains data with four oxide components, is used in the 
experiment. Moreover, each sample has a six-dimensional 
attribute, where the first one represents the sample number, 
and the second to the fifth one represents the content of 
SiO2, Al2O3, MgO, Fe2O3 respectively, while the sixth 
stands for the rock class number which the sample belongs 
to. Besides, the second to the fifth dimension attribute are 
continuous numeric variables. The boundary points of 
which are decided by the domain experts based on the prior 
knowledge before the modeling of association rules mining. 
However, due to the diversity, variability and complexity of 
the geological phenomena and conditions, there is plenty of 
uncertainty and imprecision. The inaccuracy in choosing 
boundaries may directly affect the quality of extracting 
rules.  
According to the proposed algorithm, the second to fifth 
dimension of the original data set are firstly clustered with 
k-means, and discretized to two-dimensional fuzzy attribute: 
{high, low}. As a result, Two cluster center points are 
generated: 
 center1={50.0566,33.6981,15.6038,2.9057}; 
 center2={63.0103,28.8660,49.5876,16.9588}. 
The membership functions of the content of SiO2, 
Al2O3, MgO, Fe2O3 are shown respectively as figure 2 to 
figure 5. According to these MFs, a new fuzzy sets T’ will 
be generated if the value of each attribute of every sample in 
the original data set T is changed into a form of a fuzzy set. 
63.0103 50.0566 
1
SiO2 
33.6981 28.8660 
1
Al2O3 
 
Fig.2 the MF of SiO2  Fig.3 the MF of Al2O3 
49.5876 15.6038 
1
MgO 
16.9588 2.9057 
1
Fe2O3 
 
Fig.4 the MF of MgO  Fig.5 the MF of Fe2O3 
In the following, a comparison will be done to T’, the 
generated fuzzy set, with traditional fuzzy association rules 
algorithm and   MS_FPNAR algorithm proposed in the 
paper respectively, the results of which are shown as figure 
1 to figure 10 and table 6 to table 7, where the multi-level 
fuzzy support vector is expressed by 
mfs(k)=[mfs(1),mfs(2),mfs(3),mfs(4),mfs(5),mfs] and the 
minimum fuzzy confidence is expressed as mfc. The 
minimum correlation coefficient is stated as min_corr. The 
number of the fuzzy positive association rule is expressed in 
PAR. The number of the negative association rules is 
expressed in two different variables: NAR1 and NAR2. The 
difference between the variables is the expressions. NAR1 is 
expressed as ??¬??? BYAX ,, and ?????¬ BYAX ,, , 
while NAR2 is expressed as ??¬???¬ BYAX ,, . 
Rules_num is stated as the total number of the positive and 
negative association rules. 
626
Mine the fuzzy association rules by the traditional fuzzy 
association rules algorithm at first. Then set mfc = 0.6 and 
min_corr = 1.Use the uniform minimum mfs and set mfs 
equal to 0.3, 0.2, 0.16, 0.12, 0.10 and 0.08 respectively. It 
can be seen that, when mfs gets a larger value, as shown in 
Table 1, the number of the rules extracted from the frequent 
itemsets is limited. Take for example, while mfs(k) = 0.3, 
small amounts of frequent fuzzy two itemsets, three itemsets 
and four itemsets are generated. Some meaningful rules, 
especially some longer rules fail to be mined for their higher 
supports. However, in order to mine more long rules, 
turning more four itemsets and five itemsets into the 
frequent fuzzy itemsets to get smaller fuzzy supports, which 
turns out the other way. Take Table 6 for example, when 
mfs = 0.08, moderate frequent fuzzy five itemsets are 
generated, but amounts of frequent fuzzy two itemsets and 
three itemsets are extracted and the number of mined fuzzy 
rules which may contain lots of redundant and meaningless 
rules is multiple. The relation between the value of the mfs 
in traditional fuzzy association algorithm and the rule 
number of fuzzy association is shown in figure 6. Thus the 
uniform mfs used in the traditional algorithm has a great 
effect on the accuracy of the final rule mining if its value is 
either too big or small. How to find a more moderate fuzzy 
support threshold is a common problem. 
To solve this problem effectively, a method based on 
multiple minimum fuzzy supports is adopted. Suppose mfs 
(k) = [0.3, 0.2, 0.16, 0.12, 0.1, 0.1]. As shown in table 7, 
each layer has the same rules as the corresponding layer 
from table 2 to table 5 when k=2,3,4,5 respectively. In this 
way, not only the large number of meaningless rules is 
avoided, but some meaningful rules also cannot be removed. 
However, it doesn’t take into account the negative 
association rules generated in the infrequent itemsets. By 
comparison of table 7 and table 8, certain infrequent itemsets 
(inFFS), in which some meaningful negative rules could be 
generated, can be produced by setting the threshold of the 
infrequent fuzzy itemsets. But it does not mean that the 
lower the threshold, the better. Comparing table 8 with table 
9, we can see that plenty of fuzzy negative rules, most of 
which are meaningless and redundant, will be generated 
when inFFS is the complement of FFS. It is clearly 
inadvisable. 
TABLE I.  FPNAR WHEN MFS(K)=0.3 
mfs(k)=[0.3,0.3,0.3,0.3,0.3,0.3];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 14 0 25 0 25 50 
k=3 9 0 43 0 46 89 
k=4 1 0 9 0 10 19 
k=5 0 0 0 0 0 0 
Total 24 0 77 0 81 158 
TABLE II.  FPNAR WHEN MFS(K)=0.2 
mfs(k)=[0.2,0.2,0.2,0.2,0.2,0.2];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 25 0 38 2 40 80 
k=3 22 0 98 0 114 212 
k=4 9 0 93 0 114 207 
k=5 1 0 26 0 30 56 
Total 57 0 255 2 298 555 
TABLE III.  FPNAR WHEN MFS(K)=0.16 
mfs(k)=[0.16,0.16,0.16,0.16,0.16,0.16];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 26 0 38 4 40 82 
k=3 26 0 106 0 127 233 
k=4 11 0 104 0 135 239 
k=5 2 0 40 0 55 95 
Total 65 0 288 4 357 649 
TABLE IV.  FPNAR WHEN MFS(K)=0.12 
mfs(k)=[0.12,0.12,0.12,0.12,0.12,0.12];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 30 0 38 20 40 98 
k=3 29 0 112 7 133 252 
k=4 15 0 122 4 167 293 
k=5 2 0 40 0 55 95 
Total 76 0 312 31 395 738 
TABLE V.  FPNAR WHEN MFS(K)=0.1 
mfs(k)=[0.1,0.1,0.1,0.1,0.1,0.1];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 34 0 38 32 40 110 
k=3 36 0 121 27 154 302 
k=4 18 0 138 10 194 342 
k=5 4 0 60 4 97 161 
Total 92 0 357 73 485 915 
TABLE VI.  FPNAR WHEN MFS(K)=0.08 
mfs(k)=[0.08,0.08,0.08,0.08,0.08,0.08];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 36 0 38 38 40 116 
k=3 40 0 126 32 164 322 
k=4 19 0 142 13 206 361 
k=5 4 0 60 4 97 161 
Total 99 0 366 87 507 960 
TABLE VII.  FPNAR WHEN USE MULTI-LEVEL FUZZY SUPPORT 
mfs(k)=[0.3,0.2,0.16,0.12,0.1,0.1];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 25 0 38 2 40 80 
k=3 26 0 106 0 127 233 
k=4 15 0 122 4 167 293 
k=5 4 0 60 4 97 161 
Total 70 0 326 10 431 767 
TABLE VIII.  FPNAR WHEN USE MS_FPNAR 
mfs(k)=[0.3,0.2,0.16,0.12,0.1,0.08];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 25 11 38 38 40 110 
k=3 26 14 106 32 164 302 
k=4 15 4 122 13 206 342 
k=5 4 0 60 4 97 161 
Total 70 29 326 97 507 930 
TABLE IX.  FPNAR WHEN MFS=0 
mfs(k)=[0.3,0.2,0.16,0.12,0.1,0];mfc=0.6;min_corr=1 
 FFS inFFS PAR NAR1 NAR2 Rules_num 
k=2 25 23 38 78 40 156 
k=3 26 77 106 378 235 719 
k=4 15 92 122 819 564 1505 
k=5 4 39 60 702 486 1248 
Total 70 231 326 1977 1325 3628 
627
 Fu
zz
y 
ru
le
s
Fu
zz
y 
ru
le
s
mfs
Fu
zz
y 
ru
le
s
Fu
zz
y 
ru
le
s
 
Fig.6  mfs and Fuzzy rules in Traditional algorithms 
Table 10 and Figure 7 reflect the relationship between 
the minimum correlation coefficient (min_corr) and fuzzy 
positive and negative association rules (FPNAR) where the 
former is used to remove those frequent fuzzy itemsets of 
weak correlation. Table 10 presents the number of fuzzy 
positive and negative association rules, which are generated 
with min_corr varying from 1 to 2.8 under such pre-
conditions as mfs = [0.3, 0.2, 0.16, 0.12, 0.1, 0.08] and mfc 
= 0.6.As can be seen from Figure 7, with the min_corr 
increasing, the number of fuzzy association rules attained 
shows an obvious decreasing trend, as the minimum 
correlation coefficient can eliminate the rules which are 
generated by frequent itemsets of weak correlation, leaving 
more meaningful rules. So, the minimum correlation 
coefficient can effectively remove those meaningless or less 
meaningful rules to ensure that the final mined fuzzy rules 
are meaningful. 
TABLE X.  RELATIONSHIP BETWEEN MIN_CORR AND FPNAR 
mfs(k)=[0.3,0.2,0.16,0.12,0.1,0.08];mfc=0.6 
min_corr= 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.8 
PAR 326 292 249 192 133 106 72 44 
NAR 604 522 435 322 193 130 80 48 
TotalRules 930 814 684 514 326 236 152 92 
 
Fig.7  relationship between min_corr and FPNAR 
According to the above analysis, the algorithm is adopted 
to mine rules from the rock sample data set. If correlation 
coefficient constraints min_corr = 2, and multiple minimum 
fuzzy support mfs (k) = [0.3, 0.2, 0.16, 0.12, 0.1, 0.08], then 
326 fuzzy rules, including 133 fuzzy positive rules and 193 
fuzzy negative rules, are generated after mining. Compared 
with the traditional fuzzy association rules mining 
algorithm, this algorithm solves the problem about the 
selection of fuzzy support, and generates more accurate and 
effective fuzzy positive and negative association rules. 
VI. CONCLUSION 
There are broad development space and prospects for the 
mining fuzzy positive and negative association rules, 
however, there are still many drawbacks in the selection of 
the membership function and minimum support, and the 
accuracy of selected parameters directly affects the result of 
the final mining rules. This paper proposes a novel fuzzy 
positive and negative association rules algorithm for the first 
time, and utilize k-means clustering method to determine the 
membership function, avoiding uncertainty problems which 
may be brought about in current existed related algorithms 
that need to identify the membership function subjectively. 
Meanwhile, the multi-level fuzzy support and the 
correlation coefficient criterion are introduced based on 
fuzzy positive and negative association rules. In the end, the 
proposed algorithm is proved to be more effective and 
accurate in comparison with the traditional algorithm 
through an experiment. 
REFERENCES 
[1] R. Agrawal, T. Imielinski and A. Swami, “Mining association rules 
between sets of items in large database”, Proceeding of the 1993 
ACM SIGMOD International Conference on Management of Data, 
New York: ACM Press, 1993, pp.207-216. 
[2] R. Agrawal, R. Srikant, “Fast algorithms for mining association rules 
in large database”, Proceedings of the 1994 International Conference 
on VLDB, San Francisco: Morgan Kaufmann Publishers, 1994, 
pp.487-499. 
[3] J. Han, J. Pei, Y. Yin, et al, “Mining Frequent Patterns without 
Candidate Generation: a Frequent-Pattern Tree Approach”, Data 
Mining and Knowledge Discovery, Vol. 8, 2004, pp. 53-87. 
[4] R. Srikant, R. Agrawal, “Mining Quantitative Association Rules in 
Large Relational Tables”, In Proc. 1996 ACM–SIGMOD Int. Conf. 
Management of Data, Montreal, Canada: ACM Press, 1996, pp. 1-12. 
[5] B. Lent, A. Swami, J. “Widow. Clustering association rules”, In Proc. 
1997 Int. Conf. Data Engineering, Birmingham, England: ACM 
Press, Apr. 1997, pp. 220-231. 
[6] T.P. Hong, J.B. Chen, “Processing individual fuzzy attributes for 
fuzzy rule induction”, Fuzzy Sets Syst, 2000, pp. 127-140. 
[7] S. Brin, R. Motwani, C. Silverstein, “Beyond Market: Generalizing 
Association Rules to Correlations”, Processing of the ACM SIGMOD 
Conference, Tucson, AZ: ACM Press, 1997, pp. 265-276. 
[8] X. Wu, C. Zhang, S. Zhang, “Efficient Mining of Both Positive and 
Negative Association Rules”, ACM Trans. On Information Systems, 
Vol.22, 2004, , pp. 381-405. 
[9] X.J. Dong, S.J. Wang, H.T. Song, “Approach for Mining Positive & 
Negative Association Rules Based on 2-level Support”, Computer 
Engineering, Vol.31, 2005, pp. 16-18. 
[10] X.J. Dong, Z.D. Niu, X.L. Shi, et al, “Mining Both Positive and 
Negative Association Rules from Frequent and Infrequent Itemsets”, 
ADMA 2007. Harbin, China: Spring-Verlag, 2007, pp. 122-133. 
628
