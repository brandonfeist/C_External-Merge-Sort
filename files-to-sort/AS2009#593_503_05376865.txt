Performance Analysis of Parallel Apriori on 
Heterogeneous Nodes
Ketan D. Shah 
Asst. Professor, Information Technology Department 
MPSTME, SVKM’s NMIMS University 
Vile-Parle(west), Mumbai, India 
ketanshah@nmims.edu  
Dr. (Mrs.) Sunita Mahajan 
(Principal), MCA, 
Institute of Computer Science, M.E.T., 
Bandra(west), Mumbai, India 
sunita_ics@met.edu 
 
 
Abstract – The paper analyzes the performance of parallel 
Apriori Algorithm on heterogeneous nodes with different 
datasets and over n processors on a commodity cluster of 
machines. In the Apriori Algorithm all processes need to 
synchronize after every pass. If any process is assigned more load 
than other processes in the system, the slowest process will dictate 
the speed of the program. It is therefore important to ensure that 
load is equally balanced among all processes. Memory, speed of 
the processor and cache play a significant role in the processing 
capacity of the system. The experiments show that nodes with 
different configurations affect the performance of the parallel 
apriori algorithm. In order to maximize the efficiency it is 
required to balance the data set based on the processing speed of 
the various nodes present in the cluster. 
Keywords - Data Mining, Association Rules, Parallel Mining, 
Apriori Algorithm,  Load Balancing, Commodity Cluster. 
I.  INTRODUCTION 
Data Mining is the efficient discovery of previously 
unknown patterns in large databases. One of the most 
important problems in data mining [1] is discovering 
association rules. There has been considerable research in 
designing parallel algorithms for mining association rules [2] 
[3] [4]. One of the key features of all the previous algorithms 
is that they require multiple passes over the database. For disk 
resident databases, this requires reading the database 
completely for each pass resulting in a large number of disk 
I/Os. The effort spent in performing just the I/O would be 
considerable for large databases and would result in poor 
response times. Efficiency Improvement[6] over the serial 
Apriori algorithm [1] [2] and the parallel CD algorithm [3] to 
generate all significant association rules based on the 
reduction in the time spent on scanning elements in the data 
set have been worked on. In this paper, we analyze the 
performance of the algorithm over n processors on a 
commodity cluster of machines. The extensive experiments 
carried out show that the parallel algorithm scales well to the 
number of processors and also improves on the efficiency by 
effective load balancing. 
A. Problem Decomposition 
The problem of discovering all association rules can be 
decomposed into two sub-problems [1]: 
1. Find all sets of items (item-sets) that have transaction 
support above minimum support. The support for an item-set 
is the number of transactions that contain the item-set. Item-
sets with minimum support are called large item-sets, and all 
others, small item-sets. 
2. Use the large item-sets to generate the desired rules. Here is 
a straightforward algorithm for this task. For every large item-
set l, find all non-empty subsets of l. for every such subset a, 
output a rule of the form aÎ (l-a) if the ratio of support(l) to 
support(a) is at least minconf. Consider all subsets of l to 
generate rules with multiple consequents. 
II. DISCOVERING LARGE ITEM-SETS 
Algorithms for discovering large item-sets make multiple 
passes over the data [1] [2]. In the first pass, support of 
individual items are counted and it is determined which of 
them are large, i.e., has minimum support. Every subsequent 
pass starts with a seed set of item-sets that are found to be 
large in the previous pass. Use this seed set for generating new 
potentially large item-sets, called candidate item-sets, and 
count the actual support for these candidate item-sets during 
the pass over the data. At the end of the pass, determine which 
of the candidate item-sets are actually large, and they become 
the seed for the next pass. This process continues until no new 
large item-sets are found. 
A. Apriori Algorithm 
Figure 1 gives an overview of the Apriori Algorithm [1] 
[2], using the notation in Table 1. The first pass of the 
algorithm simply counts item occurrences to determine the 
large 1-item-sets. A subsequent pass, say pass k, consists of 
two phases. First, the large item-sets Lk-1 found in the (k-1)th 
pass are used to generate the candidate item-sets Ck. Next, the 
dataset is scanned and the support of candidates in Ck is 
counted. For fast counting, it is required to efficiently 
determine the candidates in Ck that are contained in a given 
transaction t. 
 
TABLE1. NOTATIONS 
k-item-set An item-set having k items. 
Lk Set of frequent k-item-sets(those with 
minimum support). 
Ck Set of candidate k-item-sets (potentially 
frequent item-sets) 
2009 International Conference on Advances in Computing, Control, and Telecommunication Technologies
978-0-7695-3915-7/09 $26.00 © 2009 IEEE
DOI 10.1109/ACT.2009.20
42
Pi Processor with id i 
Di The dataset local to the processor Pi 
Cki The candidate set maintained with the 
Processor Pi during the kth Pass 
 
1) L1 = { Large 1-item-sets}; 
2) k =2; // k represents the pass number 
3) while ( Lk-1 <> 0 ) do 
4) begin 
5)         Ck = new candidates of size k generated from Lk-1; 
6)        forall transactions t ? D do 
7)             Increment the count of all candidates in Ck that are 
contained in t; 
8)        Lk = All candidates in Ck with minimum support; 
9)       k = k +1; 
10) end 
11) Answer = UkLk; 
Figure 1: Apriori Algorithm 
B. Parallel CD Algorithm 
The CD Algorithm [3] uses a simple principle of allowing 
“redundant computations in parallel on otherwise idle 
processors to avoid communication”. The first pass is special. 
For all other passes k >1, the algorithm works as follows: 
1. Each processor Pi generates the complete Ck, using the 
complete frequent item-set Lk-1 created at the end of pass k-1.  
2. Processor Pi makes a pass over its data partition Di and 
develops local support counts for candidates in Ck. 
3. Processor Pi exchanges local Ck counts with all other 
processors to develop global Ck counts. Processors are forced 
to synchronize at this step. 
4. Each Processor Pi now computes Lk from Ck.  
5. Each Processor Pi independently makes the decision to 
terminate or continue to the next pass. 
In the first pass, each Processor Pi dynamically generates its 
local candidate item-set C1i depending on the items actually 
present in its local data partition Di. Hence candidates counted 
by different processors may not be identical and care must be 
taken in exchanging the local counts to determine the global 
C1. 
C. Performance Consideration 
Each Processor Pi makes a pass over its data partition Di 
reading one tuple at a time and builds Cki. Since in every pass 
each Processor has to go through all the items in every 
transaction, this becomes a compute intensive step. After 
every pass, processes need to synchronize by exchanging 
counts. This implies that the slowest process will dictate the 
speed of the algorithm. Hence the data should be divided in 
such a way that every processor gets equal amount of work so 
that the efficiency of the parallel algorithm is maximized. 
III. PERFORMANCE ANALYSIS 
In the serial Apriori and the parallel CD algorithm, for every 
pass made by a Processor Pi, it requires a scan of all the 
elements of individual transaction read from the data partition. 
This affects the scalability of the algorithm as there can be 
cases where a transaction does not contain frequent k-item-set 
in the k+1 pass. If such transactions can be identified then the 
algorithms would not read the transaction and move ahead 
with the next transaction. This would save considerable 
amount of processor time. 
The proposed formulation identifies the transactions that 
contain frequent k-item-sets in the 1st scan and checks 
whether a transaction should be scanned when reading the 
database for subsequent scans. The overhead required is that 
one has to keep track of the transactions that probably would 
contain frequent item-sets. But the advantage of saving the 
transaction scan time would outperform the overhead as the 
database size increases.  
To maximize the efficiency of the parallel algorithm the 
data is divided equally among the number of processes in the 
system so that each process can be utilized to its maximum. 
IV. EXPERIMENTAL RESULTS 
To conduct experiments, a pseudo-random data generator 
has been developed that generates transactions of random 
length and elements are also randomly generated within a 
given range. Data set containing 10 million transactions 
generated using the above software has been used for the 
experiments. Each transaction contained data items of variable 
length from 1 to 15 from an item-set {1…25}. The parallel 
versions were implemented using the MPICH2 library 
functions under windows environment. A commodity cluster 
was created with 4 machines with varying processor speed, 
random access memory and cache. Table 2 lists the 
configuration of the system in the commodity cluster.  
Figure 2 shows the experimental result of the time taken to 
generate k-frequent item-sets on homogeneous nodes running 
1 and 2 processes in parallel. The results show the scalability 
of the parallel Apriori Algorithm on homogeneous nodes. In 
Figure 3 shows the time taken by 4 processes on homogeneous 
system consisting of 2 dual core machines with the same 
configuration and compares it with the time taken by the 
algorithm on 4 processes in the commodity cluster of 
heterogeneous nodes. All the experiments were performed 
with a support of 15%. As the data was generated using a 
pseudo-random data generator, the support was taken to be 
low so that there could be at-least 3 to 4 frequent-item sets 
generated.  
It is observed from the results of Figure 3 that with 
heterogeneous nodes the performance of the algorithm is 
dictated by the slowest node on the system. The load needs to 
be balanced taking into consideration the processing capacity 
of the system.  
 
TABLE2. CLUSTER SPECIFICATION 
System Processor Speed RAM Cache 
CORE 2 Duo 
E4800 2997 MHz 2037 MB 6144 K 
CORE 2 Duo 
E4800 2997 MHz 2037 MB 6144 K 
CORE 2 CPU 
4300 1794 MHz 1014 MB 2048K 
Pentium D 
CPU 2793 MHz 502 MB 1024K 
43
  
Figure 2: Parallel Apriori on Homogeneous nodes 
 
 
Figure 3: Parallel Apriori on Commodity Cluster with 4 processes 
V. CONCLUSION 
The parallel Apriori algorithm works efficiently with 
homogeneous nodes by making sure that load is equally 
balanced among nodes. When the algorithm runs on a 
commodity cluster with each node having different processor 
speed, memory and cache, the performance of the algorithm is 
affected. The processor with slowest processing capacity in 
the cluster dictates the speed of the algorithm. Performance of 
the algorithm can be improved by re-distributing the load in 
such a way that the utilization of every processor is maximized 
as per its capability. We are working on a model that will note 
the processing capability of every node in the commodity 
cluster and then balance out the workload for better 
performance. 
REFERENCES 
[1] Rakesh Agarwal, Thomas Imielinski, and Arun Swami.1993. Mining 
association rules between sets of items in large databases. In 
Proceedings of the ACM SIGMOD Conference on Management of Data, 
Washington, D.C., 207-216. 
[2] R. Agarwal and R. Srikant. 1994. Fast Algorithms for mining association 
rules in large databases. In Proceedings of the 20th International 
Conference on very Large Databases, Santiago, Chile, August 29 – 
September 1, 1994.  
[3] Rakesh Agrawal and John C. Shafer. 1996. Parallel Mining of 
Association Rules: Design Implementation, and experience. In IBM 
Research Report, 1996. 
[4] D.W.Cheung, J. Han, V.T.Ng, A.W.Fu. 1996. Efficient Mining of 
Association rules. In Proceedings of 4th Int. Conference on Parallel and 
Distributed Information Systems, Miami Beach, Florida, December, 
1996, 31- 43. 
[5] J.S.Park, M.S.Chen, and P.S.Yu. 1995. An Efficient hash-based 
algorithm for mining Association Rules. In Proc. 1995 ACM-SIGMOD 
Int. Conf. Management of Data, San Jose, CA, 175-186. 
[6] Ketan Shah, Sunita Mahajan. 2009. A new efficient formulation for 
frequent item-set generation. In Proceedings of the International 
Conference on Advances in Computing, Communication and Control, 
Mumbai, India, January 23-24, 2009. 
 
44
