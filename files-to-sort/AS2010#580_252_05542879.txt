Application Research of Association Analysis with 
Clementine 
Yu-Chen Song, Yi-Feng Fang 
Center for Inner Mongolia Industry Informationization and Innovation, 
Department of Mining Information System, Laboratory for Data Engineering,  
Inner Mongolia University of Science and Technology, Baotou, China. 014010 
songyuchen@imust.edu.cn,  qdfyf@163.com  
 
 
Abstract—After introduce briefly about the basic concept and 
methods of association rules in data mining, we take borrowing 
records in library as example to describe the whole process of 
how to find association with the application of Apriori algorithm 
in Clementine.The mining outcome shows that some books and 
books have stronger association strength. According to the 
association between books, we can do book recommendation. 
That is to say, when reader borrows a book, the library can 
recommend the book which has strong association strength with 
it to the reader; we can rearrange the distribution of books in 
library by putting books with strong association strength close to 
each other to save time for readers in choosing books. 
Keywords-data mining; association rules; borrowing record ; 
apriori  algorithm
I.  INTRODUCTION 
The association rules in data mining attach importance to 
the association among different areas of data and finding out 
the dependant relation among different areas in given 
conditions. The prospect of application of association rules is 
extremely bright. Retail trade analysts use association rule to 
analyze a great amount of sales figures. They find out customer 
purchasing pattern and trend to improve their service quality. 
Association rules are also widely applied in risk analysis in 
insurance industry, market predicting in financial investment, 
and relevant areas about telecommunication industry. 
Nowadays, the prevalent mining tools in the market are 
Enterprise Miner developed by SAS, Intelligent Miner 
developed by IBM and Clementine developed by SPSS. This 
paper takes Clementine12.0 as example to introduce the 
application of data mining. 
II. ASSOCIATION RULES MINING THEORY AND 
ALGORITHM STUDY 
Association rule is the most active research method in data 
mining. It was firstly put forward in 1993 by Agrawal, etc. The 
original motivation of putting forward it aimed at market 
basket analysis and the goal is to find out the association rules 
among different merchandise in trading database. These rules 
describe consumer buying behavior model and they can be 
used to instruct merchant to arrange scientifically about 
purchases, inventory and designing of goods shelf, etc. 
A. The Definition of Association Rules and Associative 
Processes 
Association Rules refer to rules that describe the potential 
association among data items (attribute, variable). Using data 
mining techniques of Association Ruleswe can find out a 
large amount of unknown dependant relations among data. 
We define Association Rules as follows: Let I={i1, i2, …, 
im}be the set of all items in a market basket data and T={t1, 
t2, …, tn} be the set of all transactions. Each transaction ti 
contains a subset of itemset. If an itemset contains k items, it is 
called a k-itemset. A transaction tj is said to contain an itemset 
X if X is a subset of tj. An association rule is an implication 
expression of the form X=>Y, where X and Y are disjoint 
itemsets, and XY =. The Strength of an association rule 
can be measured in terms of its support and confidence. The 
formal definitions of these metrics are: 
  NYXSupport    (1)
   XYXConfidence   (2)
We assume that minsup is the minimum support and minconf  
is the minimum confidence. If the rule satisfies both minsup 
and minconf, it is the strong association rule. 
Mining for Association Rules has two steps.The first step 
is to find out the group of the frequent itemsetAccording to 
the definition, the frequency of appearance of these itemsets is 
at least the same with the number of the pre-defined minsup. 
The second step is to generate the strong association rules from 
the frequent itemset. According to the definition, these rules 
must satisfy both minsup and minconf. 
B. The Ccategory  of Association Rules 
According to the type of the attribute value in dealing with 
the rule, Association Rules can be divided into Boolean 
association rule and Quantitative association rule. 
Identify applicable sponsor/s here. (sponsors)
445
Boolean association rule concerns the association about 
whether the classification attribute value exists or not.For 
example,we get a rule by market basket analysis: 
buys("beer")=>buys("Diapers") [sup=20%,conf=60%]. 
The classical algorithm,Apriori algorithm, is the most 
influential algorithm in mining for frequent itemset of Boolean 
association rule.The main idea is using the method of layer-
by-layer search to find out the frequently appeared itemsets in 
database. The main processes of the algorithm are as follows: 
The first step is to generate frequent itemset L1, then scan the 
database D, each database appearing in D forms an candidate 
itemset C1, and count the frequency of each data item's 
appearance, the set in which the frequency is bigger than the 
minsup is the frequent itemset L1; the step k is to generate the 
frequent itemset Lk, using the frequent itemset generated by the 
previous step associated with itself to generate the candidate 
itemset Ck, then scan the database transaction set, count the 
frequency of each member of Ck, delete the candidate item 
which is smaller than the minsup, then the frequent itemset k 
comes out at last. 
Quantitative association rule describes the association 
among the quantitative attributes. For example: 
age(30,35)=>income(12k,14k)[sup=20%,conf=60%]. 
Quantitative association rule separates the quantitative 
attributes according to the data distribution and then use the 
classical algorithm to mine. E.g., income attribute is divided 
into equal districts as "0k...20k", "21k...30k", "31k...40k", etc. 
Then substitute the value of the original attribute, stock it in the 
relation table. Then revise Apriori algorithm to find out all 
frequent predicate (i.e. to search all the relevant attributes, not 
only one attribute as "buys"). At last, generate the association 
rule which satisfies both minsup and minconf. 
C. Brief Introduction of Clementine Association 
There is much of software of data mining, the paper focuses 
on the usage of Clementine association. Clementine is a 
platform for data mining tools developed by ISL (Integral 
Solutions Limited). SPSS acquired ISL in 1999. They 
reintegrated and developed the production of Clementine.  
Clementine is widely used special software in data mining 
at present, and it integrates different kinds of data mining 
techniques as cluster, decision tree, neural network and 
association rules, etc to a intuitional visible graphical interface. 
The association module is very useful in protecting different 
outcomes. As for the association which can be found out by 
manual movement, Association rule algorithm can find it 
automatically through visible technique (e.g., the Web node). 
The advantage of Association rule algorithm over decision tree 
algorithm is that it can find out the association among all the 
attributes. Decision trees algorithm only use mono-conclusion 
to construct rules while Association rule algorithm tries to find 
out more rules and each rule has different conclusion. 
Clementine offers 3 kinds of Association rule algorithms: 
Apriori, GRI and CARMA algorithm. We study the Apriori 
algorithm.  
III. THE APPLICATION OF CLEMENTINE ASSOCIATION 
MINING 
College library generates a large amount of books currency 
data. These data record reader's personal information and are 
used to do the regular service data statistics. The potential 
value of using these data has not been mined and used 
reasonably. Using cluster technique of data mining to mine for 
the relevant data in library, through designing and testing 
CADD cluster algorithm, we make a cluster application of 
library data and get a good outcome. The problem of whether 
the Association rule mining method can be applied to the 
analysis of books currency data to mine and discover the 
implied rules in the borrow behavior of readers to instruct the 
work of the library deserves study. 
We study the data of the library borrowing system, using 
Clementine to mine for the association among books to offer 
service for recommendation and library shelf arrangement. 
Readers have similarity in borrowing books, i.e., they 
borrow another book soon after borrowing one book. For 
example, after borrowing Advanced Mathematics, we usually 
will borrow Exercises on Advanced Mathematics. 
A. Data Preparation 
We use borrowing data (2006.9-2008.9) of library system 
to mine for association of books. Our college library uses 
General Library Integrated System (GLIS8.0) at present, which 
is an application system for library network. 
At first, we study the particular borrowing details and select 
the top 50 books according to the number of borrowing times 
to do experiment about association. The statistics attributes 
include: control number (book's MAC), title, author, publishing 
house, publishing data and borrowing times. We check the 
particular borrowing details by looking for the bar code 
according to the control number. In the experiment, we select 
15 books as analyzing objects. These books are <<Mechanical 
Parts Design Manual>>, <<Cherry tree>>, << Peking 
University Students Mei-wen>>, <<Spicy Lovers Amber 
tears>>, <<Legal Report: China's legal Lunch >>, << Even 
Ling >>, <<Elapsed beauty>>and <<The story of Zhou 
Enlai>>, etc. The relevant information about these books is 
showed as TABLE I.  
 
446
TABLE I. THE TOP 15 BOOKS 
 
According to the analysis of the borrowing records, 488 
readers have borrowed these books. Then we refer to the 
borrowing records of these readers, deleting each reader's 
repetition borrowing record of each book, and then we get a 
Transaction database for discovering association rules as 
TABLE II. ID refers to the number of transactions; the actual 
data refer to the reader's certificate number; ITEM refers to the 
itemset of transaction and its actual meaning is the set of the 
reader's borrowing books. The combining meaning of the 
letters and numbers is call number of books. 
TABLE II. TRANSACTION DATABASE 
ID ITEM
0610127114 O13-44/2,O13/43,Z228/8,I247.5/38,TP312C/146,… 
0710100331 78.213/5090,TH13-39/6 
2003041212 TP312C/73,78.213/5090,I247.57/88,I545.73/2,… 
2003041235A K827=52/8,H316/5,I207.411-53/1,C913.2/22,… 
2003041540 TB301-43/2,TB301/19,71.221/1249,TB301/16,… 
2003041644 TG506/3,78.29/1111,X734.201/3,X756.03/1,… 
? ? 
 
B. The Processes of Clementine Data Mining 
1) Creating the data stream 
The data mining processes are described by stream in 
Clementine. Stream is a set of Nodes and it represents the 
processes of data moving from Source Node to Processing 
Node and then to the Output Node. User can edit the stream in 
steam editor. To create stream as follows: select “File” from 
"Menu", then click "New Stream". 
2) Adding and editing the data source node 
Editing stream in stream editor, we firstly should add data 
source node and then attach it to the data for mining. In 
Clementine, Database, Fixed File, SPSS File, SAS File, Excel, 
User Input are data source nodes. Data used in this paper are 
stored in Excel. Therefore, we select Sources tab, double click 
Excel node in node module, adding Excel node to stream editor 
window. Then we edit it in editor window and select the data 
file we need. 
3) Importing Data 
Double click Type node, click Read value in a pop-up 
dialog box to import data. 
4) Adding data mining model node 
Clementine offers algorithm models as nerve network, 
decision tree, cluster, sequence, regression, association, etc. As 
this thesis describing the application processes of association, 
we should construct association data mining model. 
Clementine offers association models as GRI, Apriori, Carma, 
Sequence, etc. This thesis uses the Apriori model so we add 
stream by selecting Apriori in model tab. 
5) Executing the mining model 
After model setup, we set the pre-piece and the post-piece, 
and click "Execute". After execution, a new icon will appear in 
manager. We can see the execution outcome by right clicking 
the icon and clicking "Browse". 
6) Making mining outcome visible 
If you want to make the final mining outcome visible, you 
can add a certain graphic node to data stream and execute it. 
An integrated data stream is showed as Fig. 1. 
 
 
Figure 1. Data Stream 
 
C. The Description of Data MiningRresult 
We can get different mining outcomes by selecting 
different minsup and minconf as is showed in TABLE III. 
ID
Con-
trol 
Num
-ber 
Title Author Publish-er
Public-
ation 
Date 
Borro-
wed 
Times
1 
zyk0
0358
63  
Mechani-
cal Parts 
Design 
Manual 
Northeas-
tern 
Universi-
ty of 
Technol-
ogy 
Metallur-
gy 
Industry 
Press  
1980 748 
2 
zyk0
0689
08  
Cherry 
tree 
(Japan) 
Watana- 
be 
Culture 
and Arts 
Publishi-
ng House 
2005 442 
3 
zyk0
0706
47 
Spicy 
Lovers   
Amber 
tears 
Mu Mao 
New  
World 
Press 
2005 422 
? ? ? ? ? ? ? 
447
TABLE III. ASSOCIATION RESULT 
Result Minsup(%) Minconf(%) Rules 
Result 1 4 50 48 
Result 2 5 50 16 
Result 3 6 55 4 
 
In TABLE III, there are 48 association rules in the first 
outcome where minsup is 4% and minconf is 50%; there are 16 
association rules in the second outcome where minsup is 5% 
and minconf is 50%; there are 4 association rules in the third 
outcome where minsup is 6% and minconf is 55%. Then let's 
see the differences among mining outcomes when minsup and 
minconf have different values. 
In the first outcome, there are 48 association rules where 
minsup is 4% and minconf is 50%. Among these 48 rules, the 
minsup is 4.098%; the maxsup is 7.992%; the minconf is 50%; 
the maxconf is 84.615%. Some Association rules strength 
among books are showed in Fig. 2. 
 
 
Figure 2. Association Rules Strength Among Books I 
 
In Fig. 2, the thicker the line between the two books is, the 
stronger the association strength of the two books is. The 
thinner the line is, the weaker the association strength is. Link 
refers to the number of times of the appearance of the pre-piece 
and the post-piece at the same time. As is showed in Fig. 2, 
there are 28 links between 1247.56/9 and 1247.56/6, i.e. 28 
readers borrow the two books at the same time. We define it as 
a strong link when there are more than 30 links between 2 
books; a medium link when the number is between 15 and 30; 
a weak link when the number is under 15. The Fig. 2 is an 
outcome after deleting some weak link. The aim is to see 
clearly that which 2 books have stronger association strength, 
i.e., after borrowing one book, the reader tends to borrow 
another book. 
We change the graph to data showed in TABLE IV. As is 
showed in TABLE IV, when readers borrow I247.56/6 
(<<Ghost Inn>>), I247.7/13(<<Peak Reasoning>>), I247.57/ 
118(<<Latent grass Rapids>>), I712.45/2(<<Honey-moon 
Cry>>), I516.84/2(<<Laura’s Secret>>), I247.56/8(<< Sad 
death>>), I247.57/119(<<Find Murderer>>), I247.57/ 
114(<<Elapsed Beauty>>) and I247.55/6(<<Adventures in 
urban demon>>), they often borrow I247.56/9(<<Even 
Ling>>); when readers borrows I247.55/5(<<FLS Legend (Part 
One)>>), they usually also borrow  I247.56/4(<<Love War 
KGB>>); when readers borrows I247.57/105(<< Sparrow 
Revolute>>), they usually also borrow I247.57/78 (<<Spicy 
Lovers Amber tears>>); when readers borrow 
I247.55/1(<<Soul Wars>>), they often also borrow I247.55/6 
(<<Adventures in urban demon>>). 
There are 16 association rules in the second outcome where 
minsup is 5% and minconf is 50%. Compared with the first 
outcome, it has deleted the rules with sup under 5%. Among 
these 16 rules, minsup is 5.123%, maxsup is 7.992%, minconf 
is 50%, maxconf is 84.615%. The association strength is 
showed in Fig. 3. 
The association strength is showed in detail in Fig. 4. As is 
showed in Figure IV, I247.56/9 and I247.7/13 have the 
strongest association strength, I247.56/9 and I247.45/29 come 
second, and then I247.57/78 and I247.57/78, I247.56/  and 
I247.55/6  at last. 
TABLE IV. ASSOCIATION RULES STRENGTH AMONG BOOKS I 
Post-piece Pre-piece Support Confidence
I247.56/9 = T I247.57/119 = T 5.328 84.615 
I247.56/9 = T I247.56/8 = T 5.943 75.862 
I247.55/6 = T I247.55/1 = T 4.918 75.0 
I247.56/9 = T I247.57/116 = T 4.098 70.0 
I247.56/9 = T I712.45/29 = T 6.762 66.667 
I247.56/9 = T I247.56/6 = T 7.992 64.103 
I247.55/4 = T I247.55/5 = T 4.303 61.905 
I247.55/3 = T I247.55/5 = T 4.303 61.905 
…… …… …… …… 
 
 
Figure 3. Association Rules Strength Among Books II 
448
 Figure 4. Association Rules Strength Among Books III 
 
We change graph to data showed in TABLE V. 
TABLE V. ASSOCIATION RULES STRENGTH AMONG BOOKS II 
 
As is showed in TABLE V: 
 There are 6.672% of readers borrow I247.45/29 
(<<Honeymoon Cry>>) and I247.56/9(<<Even 
Ling>>); 66.667% of the readers who borrow 
I247.45/29(<<Honeymoon Cry>>) will borrow 
I247.56/9 (<< Even Ling >>). 
 7.992% of readers borrow I247.56/6(<<Ghost Inn>>) 
and I247.56/9 (<<Even Ling>>); 64.103% of the 
readers who borrow I247.56/6(<<Ghost Inn>>)   will 
borrow I247.56/9 (<< Even Ling >>). 
 There are 7.172% of readers borrow I247.7/13 
(<<Peak Reasoning>>) and I247.56/9 (<<Even 
Ling>>); 57.143% of the readers who borrow 
I247.7/13 (<<Peak Reasoning>>) will borrow 
I247.56/9 (<< Even Ling >>). 
 6.557% of readers borrow I247.7/43(<<Sky Blue>>) 
and I247.57/78(<<Spicy Lovers Amber tears>>); 
56.25% of the readers who borrow I247.7/43(<<Sky 
Blue>>) will borrow I247.57/78(<<Spicy Lovers 
Amber tears>>). 
IV. CONCLUSOION 
The paper starts with the basic concept of Association rules, 
describing the whole processes of how to find association rules 
by using Clementine through the study of borrowing records 
about the books association. The mining outcome shows that, 
<<Even Ling>> and <<Peak Reasoning>>, << Even 
Ling >>and <<Honeymoon Cry>>, <<Sky Blue>> and 
<<Spicy Lovers Amber tears>>, << Even Ling >> and 
<<Adventures in urban demon>> have stronger association 
strength. According to the association between books, we can 
do book recommendation. That is to say, when reader borrows 
a book, the library can recommend the book which has strong 
association strength with it to the reader; we can rearrange the 
distribution of books in library by putting books with strong 
association strength close to each other to save time for readers 
in choosing books. 
 Clementine has other association algorithms. As for the 
length of the paper, we only study the Apriori algorithm. We 
can use different algorithms of Clementine in a broader area. 
Post-piece Pre-piece Support(%) Confidence(%)
I247.56/9 = T I247.45/29 = T 6.672 66.667 
I247.56/9 = T I247.56/6 = T 7.992 64.103 
I247.56/9 = T I247.7/13 = T 7.172 57.143 
I247.57/78 = T I247.7/43 = T 6.557 56.25 
ACKNOWLEDGMENT 
 The material is based on work supported by National 
Natural Science Foundation of China under Grant No. 
40764002. 
 The material is based on work supported by National 
Social Science Foundation of China under Grant No. 
06XTQ011. 
 
REFERENCES 
 
[1] Yan Wang. Association rules algorithm in data mining. Journal of  
Chengdu University of Information Technology,2004,19(2) 
[2] R Agrawal,T lmielisk,A Swami. Mining Association Rules Between 
Sets of Items in Large DatabaseIn Proceedings of ACM SIGMOD 
International Conference on Management of Data(SIGMOD’93). May 
1993:207-216 
[3] Jiawei Han,Micheline Kamber.Data Mining:Concept and Techniques. 
Beijing:China Machine Press,2001 
[4] Yu-Chen Song. Dynamic and Incremental Clustering Based on Density 
Reachable . IEEE Publishers, Aug-2009 
[5] Yu-Chen Song, Grady M J O, Hare G M P O. Applications of Attributes 
Weighting in Data Mining. In proceedings of IEEE Cybernetic Systems 
Conference,IEEE Publishers,2007: 41-45 
[6] Yu-Chen Song, Hai-Dong Meng. Clustering Algorithms for Arbitrary 
Data Sets[C]. Encyclopedia of Artificial IntelligenceIdea Group Inc, 
Information Science Reference 
[7] Yu-Chen Song,Yi-Feng Fang,Wei Wang,et al. Data Analysis of College 
Library Reading-room Based on Clustering Algorithm[C]. Information 
Technology Application Institute, 2008 
[8] Yu-Chen Song, Hai-Dong Meng, Feiyan Song. Study on Arbitrary 
Distribution in Cluster Analysis. IEEE Publishers, Sep-2009 
 
449
