2010 International Conference on Computer Application and System Modeling (ICCASM 2010) 
IULFP An Efficient incremental updating Algorithm based on LFP-tree for 
Mining Association Rules 
T L· 12 ongyan 1 ' 
Key Laboratory of Broadband Optical Fiber Transmission 
and Communication Networks of Ministry of Education, 
UESTC, Chengdu,6l1731 China 
2. Department of Communication Engineering,Chengdu 
University of Information Technology, Chengdu 
610225,China 
Abstract-Dynamic rules acquisition is a topic of general 
interest in the field of association rules mining. Many existing 
incremental mining algorithms are Apriori-based, which are 
not easily adoptable to mine tree-based frequent patterns. In 
this paper, we provide a novel incremental updating algorithm 
IULFP for mining association rules. We use the layered 
frequent pattern tree based structure to store frequent items. 
Moreover, we propose the definition of "strong frequent 
item sets", which is proved to be a useful method to find all the 
frequent item sets in the updated databases. The experimental 
results show that our approach has higher efficiency than 
other previous works. 
Keywords-association rules mmmg; incremental updating; 
layered frequent pattern tree; strong frequent itemsets 
I. INTRODUCTION 
Association rules mining has recently attracted 
tremendous amount of attention in the data mining research. 
As communication network configurations and demand for 
network resources are highly dynamic, the aim for 
incremental updating mining is to keep track of the frequent 
itemsets as the underlying database changes. Specifically, 
when some old transactions are deleted from an existing 
database D and/or when some new transactions are inserted 
into D, one may need to update the collection of frequent 
patterns. 
Algorithms such as FUP [1], FUP2 [2], UWEP [3] and 
asp [4] were developed to solve this problem. In general, 
these algorithms are based on Apriori algorithm [5-8]. 
Similar to the structure of the Apriori algorithm, that is, they 
have to generate a large number of candidates and rescan the 
database many times. Here we discuss the algorithm asp. 
asp starts by finding all frequent length-I sequences from 
the database. A set of candidate length-2 sequences is then 
generated. The support counts of the candidate sequences are 
then counted by scanning the database once. Those frequent 
length-2 sequences are then used to generate candidate 
sequences of length-3, and so on. In these algorithms 
mentioned before, asp is an efficient algorithm. However, 
the number of database scans it requires is determined by the 
length of the longest frequent sequences. Consequently, if 
there are very long frequent sequences and if the database is 
huge, the I/O cost of asp could be substantial. Although 
Xingming Li 
Key Laboratory of Broadband Optical Fiber Transmission 
and Communication Networks of Ministry of Education, 
UESTC, Chengdu 610054, China 
three incremental algorithms asp+ [9], MFS [10] and MFS+ 
[11] were proposed to improve the mining efficiency, they 
can't overcome the shortcomings of Apriori structure. In 
order to suffer from the problem of multiple scans of 
database, some tree-based incremental mining algorithms 
were recently developed. For example, Cheung and Zaiane 
[12] proposed the FELINE algorithm with the CATS tree, 
whereas Koh and Shieh [13] proposed the AFPIM algorithm. 
The former aims to make the CATS tree (a variant of the FP­
tree) compact, and the FELINE algorithm is well-suited for 
interactive mining where the database remains unchanged 
and only the minimum support threshold gets changed. 
However, these algorithms have too complex structure and 
they require rescanning the entire updated database in order 
to construct the corresponding updated FP-tree. Recently, 
Leung [14-15] proposed a CanTree structure to avoid the 
rescan of the entire updated database or the reconstruction of 
a new tree for incremental updating. In this CanTree, items 
are arranged according to some specific order depending on 
the item properties (e.g., their price values, their validity of 
some constraints). Obviously, CanTree is an efficient method, 
but it may build a large number of conditional pattern trees 
and take a large amount of memory. Moreover, it is 
important to note that CanTree do not necessarily reduce 
computation or time. 
In this paper, we introduce a novel incremental updating 
algorithm based on LFP-tree (Layered Frequent Pattern tree) 
to improve the performance of the mining. Our proposed 
method IULFP (Incremental Updating algorithm based on 
LFP-tree) uses layered structure, which is propitious to store 
and update the frequent items in the dynamic environment. 
In addition, our method makes full use of the previous 
mining results to cut down the cost of finding new patterns in 
an updated database. Comparing with some existing 
incremental updating algorithms, we offer several 
experiments to show that our approach is more efficient. 
The paper is organized as follows. After introducing the 
definitions and lemmas of the mining problem in Sect II, we 
introduce how to construct a LFP-tree in Sect III. Then we 
propose our incremental updating algorithm IULFP in Sect 
IV. In Sect V, we explain experimental results. Finally, we 
conclude this paper in Sect VI. 
978-1-4244-7237-6 /10/$26.00.2010 IEEE V4-426 
2010 International Conference on Computer Application and System Modeling (ICCASM 2010) 
II. DEFINITlON AND LEMMAS 
Let I = g, iz' ... , im} be a set of items in the alarm 
transaction database, D = {tl' tz' ... , tn} , ij (j = 1,2, ... , n) is 
an item which is made of the useful alarm attributes by 
pretreatment. A transaction is a set of weighted items, where 
the weights are made from the neural network method. 
Let j = (I, ... , n) denotes the count of the transaction 
of X in D when tE D and 1 ? t . The support of 1 
describes as support (I) = Support(l) = Support _ Count(l) / T , 
where T is the count of transaction in D. association is 
described as r: IJ => Iz ,where itemsets 11' Iz eland 
IJ n 12 = ¢ 0 The confidence of an association rule 
r shows the conditional probability that a transaction 
contains 12 ,given that it contains 11 : conjidence(r) = 
II{t E D II <;;; t}11 / li t E DII 0 The support of an association 
rule r is defined as: Support(X) = Support _ Count(X) / T . 
The dataset X is defined as a frequent set 
when Support(X) ::> minsup (minsup is the minimum support). 
Let Minconf and Minsup be the thresholds of 
confidence and support specified by the user respectively. 
Association rules mining is to find all the rules whose 
confidences and supports are greater than or equal to 
Minconf and Minsup in the dataset. The association rules 
mining can be broken down to following two sub-problems: 
(1) Finding all the frequent itemsets whose 
supports are no less than Minsup ; 
(2) Generating the association rules derived from 
the frequent itemsets and inspecting their confidences. If the 
confidence is not less than Minconf , the corresponding rule 
is an association rule described as: Iz => IJ -/z l/z C IJ 
Of above two steps, the efficiency of association rules 
mining mainly depends on the first step. After the largest 
frequent itemsets have been produced, the relevant 
association rules can be gained immediately. 
For the incremental update problem, consider D is the 
original database, and d is the new added dataset. In order to 
describe the algorithm clearly, we give the following 
definition and lemmas: 
Definition 1. Strong frequent itemsets Let 1 be the 
itemset, if l'suPD ? s , and l'suPDud ? s ( s is the minimal 
support threshold, and 1'",pJ)ud means the support ratio of I 
in Dud ), we consider I as a strong frequent itemset in D. 
Let SLD denote the strong frequent itemsets in D. 
Lemma1. Let SLJ) and SLd denote the strong frequent 
itemsets in D and d respectively, then LDud = SLD U SLd 
( LJ)Ud denotes all the frequent itemsets in Dud ). 
Proof. First, let X be any frequent itemset in Dud 
as X E LDud, suppose that X E SLD U SLd , then we have 
X'SUPD < s and X'supd < S . Thus, we have X'SUPDUd < S . 
Obviously it contradicts the earlier condition X E LDud , 
then X E SLD U SLd . 
Second, '\IX E SLD U SLd , :J X'SUPDUd ? S , then we 
have X E LJ)Ud . 
When we want to find all the frequent item sets in the 
updated database, we only need to get the strong frequent 
item sets in D and d respectively. In general, we can receive 
the strong frequent itemsets in previous D when d is 
scanned once. Here, our objective is to find the strong 
frequent itemsets in d. 
Lemma2. If I is a strong frequent itemset in D, then any 
subset of 1 is strongly frequent. 
Lemma3. If 1 is infrequent in D, then any superset of 1 is 
infrequent. 
III. LFP-TREE CONSTRUCTION 
TID is the unique identifier of each transaction in the 
database. Itemsets field is filled with the transaction itemsets, 
which are made of {II,I" ... ,I.} .Each node of the layered 
tree is described as a 3-tuple < a, v, t > , in which ' a 'denotes 
the attribute, 'v 'denotes the support count of the item from 
the first layer to the current layer, and' t 'is a flag with the 
value 1 or 0 for deciding whether the item is frequent or not. 
t = 1 means the value of v is no less than Minsup (minimal 
support). On the contrary, t = 0 means the support of this 
item is less than Minsup and the item will be pruned 
subsequently. 
A. LFP-tree construction algorithm 
Input: transaction database D , minimum support minsup. 
Output: LFP-Tree. 
Step 1. Scan the database D , count the support of each item, 
and generate all the frequent l-itemset according to 
the minsup; 
Step2.According to the order 11, • • •  ,/5 , store as 3-
tuple < a, v,t > ; 
Step 3.Scan the database D, generate frequent 2-itemset 
from the beginning of 12, ordered as II" '" 14 and 
store the support of frequent 2-itemsets to the 
corresponding 3-tuple. In this way, start with Ik, we 
can obtain the frequent k -itemsets on the k level 
until the k level only has II item or none, then the 
process is end. If the value of tin 3-tuple is 0, delete 
the corresponding item. Frequent 2-itemsets are made 
of the itemsets which are linked the level 1 to the 
level 2, and frequent k -itemsets are linked from the 
level 1 to the level k . 
Step 4.LFP-Tree has been constructed, and it concludes all 
the frequent patterns. 
V4-427 
2010 International Conference on Computer Application and System Modeling (ICCASM 2010) 
B. An example 
TABLE! TRANSACTION DATABASE 
TID Item sets TID Itemsets 
II Iz 1 3  6 Iz 1 3  1 4 
2 Iz 1 4 7 II 1 3  
3 Iz 1 3  Is 8 II Iz 1 3  Is 
4 II Iz 1 4 9 II Iz 1 3  
5 II 1 3  
level I 
level 2 
level 3 
Figure 1. LFP-tree construction 
Table 1 shows the transaction database and Figure 
shows a LFP-Tree which is created by LFPTDP algorithm 
from this database (We set Minsup at 15%. If support count 
of an itemset is no less than 2, this itemset is frequent). 
IV. PROPOSED IULFP ALGORITHM 
IULFP algorithm requires one scan of the updated 
database to build the updated LFP-tree. New transactions 
are added from the first level to the last level. Based on the 
above lemmas, we need to find the strong frequent itemsets 
in D and d respectively. 
The IULFP algorithm works as follows: 
Step l.Scan the added database d once, count the support of 
l-itemsets, and add the support count of the 
corresponding item to v on the level 1. If the original 
count of t is 1, it turns out that the items are strong 
frequent items, then we turn to the step2, or else we 
should decide whether the updated items are 
frequent or not. If an updated item is infrequent, it 
seems that all supersets of it are infrequent, and then 
mark t with o. 
Step 2.Find all the potential strong k-frequent itemsets in d. 
Step 3.Get the support count of these potential strong k­
frequent itemsets in D, and generate the strong 
frequent item sets in d and D as SLd and SL!) , 
respectively. 
Step 4.Consider the strong frequent itemsets in D as SLD • In 
the updated database, all the frequent itemsets can be 
obtained by SLD u SLd . 
When the database d is scanned once, we can find all the 
strong frequent itemsets in D. Consequently, we need to find 
all the strong frequent itemsets in d. The following lemma 
can help us find the strong frequent itemsets effectively. 
Lemma 4 LetXbe any itemset in d, if Xc SLD andXis 
frequent in d, then X c SLd and X C L/)Ud . 
A. Example 2. 
TABLE II. UPDATED TRANSACTION DATABASE 
TID Itcmscts rID Itcmsets 
I 11 I, 13 
2 I, 14 J 11 I, 14 
3 I, 1, I, 
original 4 11 I, 14 added 
2 11 I, 
database 5 11 I, 
database 
D d 3 11 13 14 I, 6 I, 13 14 
7 11 I, 
8 11 I, I, I, 4 II I, 
9 11 I, I, 
level I 
level 2 
level 3 
Figure 2. the updated LFP-tree 
We consider the original database be the same as 
Example 1. Here, we add the database d to the original 
database, and also set Minsup at 15%. Table 2 shows the 
updated database including D and d. We can see that there 
are 4 itemsets in d and 13 itemsets in Dud . Fig.2. shows 
the updated LFP-tree which is generated by IULFP 
algorithm. From table 2 we can find that SLd = 
{ {II}' {lz}, {l3}' {l4}' {Is}, {I/3} ,{I/4} , {/3/4}, {I/z} , 
{I/s} , {l3Is} , {I/3I4}' {I/3Is} }are all the strong frequent 
itemsets in d. Note that all the strong frequent itemsets in 
original database D are contained as SL/) ( SL/) ={ g} , 
{lz}, {l3}' {l4}' {Is}, {I/z} , {I/3} , {lzI3} , {I/4} , {lzI4} , 
{l3I4} , {I/s} , {lzIs} , {l3IJ, {I/zI3}, {I/3Is} }). After the 
d is inserted, all the frequent itemsets in Dud become 
LDud = SLD u SLd = {{II}' {lz} , {l3} , {l4}' {Is} , {I/z} , 
{I/J ' {lzI3} , {I/4} , {lzI4} , {l3I4} , {I/s} , {lzIs} , 
{l3Is} ,{I/zI3} ,{1 /3/4}, {I/3Is} }). 
B. IULFP algorithm 
Inputs: The original LFP-tree, the two threshold values 
minsup and minco! , the potential strong 1-itemset 
S (the frequent l-itemset in the original database 
D), the added database d. 
Output: A list of interesting rules. 
V4-428 
2010 International Conference on Computer Application and System Modeling (ICCASM 2010) 
Algorithm IULFP: 
1) Make sure that S is in an ascending order for each 
item n; do the following: 
a) Find all the conditional pattern sets C pbsel of 
ni and the maximum length Tmax of all prefix 
paths in n;; 
b) C2 = {n; u C1} ; ( C1 is the potential strong 1-
itemset in C pbsel ); 
c) ( C2, L2) = Checking( C2 ); ( Ck is the 
potential strong k -itemset); 
d) for (k = 3; k < Tmax &the number of Tmax > 1 ; 
k++) ; 
e) Ck = Join (Ck-1 ); 
f) (Ck, SLk) = Checking (Ck); 
g) UpdateCount (Ck); 
h) SL = SL u SLk ( SLk is the strong frequent 
k -itemset, SL is a set of SLk ); 
i) L = SLd uSLn 
2) Rules (minco! , L ). 
The subroutines are outlined as follows: 
(1) Join (Ck_I): join the k -I-itemset Ck_1 to k ­
itemset C k  ' the count of each item in Ck equals 
to the minimum value of the two items linked 
in Ck-1 . The link method is similar to the 
Apriori in [5]. Prune (Ck) will be executed to 
each linked item. 
(2) Checking (Ck): this sub-program will complete 
three functions, the first UpdateCount (Ck) 
updates the support counts of k -itemset, the 
second checking up every item and executing 
Prune (Ck), deleting the itemsets which can 
not make up the potential k -itemset in Ck, at 
last getting the strong frequent k -itemset 
according to its definition. 
(3) UpdateCount (Ck): updating the support count 
of the k -itemset. 
(4) Rules (minco! ,L): the similar to the method in 
[5]. 
V. EXPERIMENTS 
A series of experiments have been done to evaluate the 
performance of our approach. We compare our proposed 
updating algorithm IULFP with the previous updating 
algorithms FUP, MFS+ and CanTree. First, we acquire the 
alarm data from a simulated telecommunication network. In 
our simulation, we assume that 1) Alarms in lower level of 
any node lead to the alarms in upper lever of the same node. 
2) Alarms of the edge node may be transmitted to the center 
node which connects with a probability p. 3) Alarms of the 
center node will be transmitted to one of the edge nodes 
which connect randomly. 4) Alarms of the center node will 
be transmitted to all center nodes which they connect with. 
minimum support threshold: 0.25% 
450,---?--?--?--?--?,---?--,
400 
-+- IULFP 
350 ? CanTree 
--- MFS+ 
300 -+- FUP 
'" 
.? 250 
'" 
c: 
c: 200 c: 
2 
150 
100 
50 
o?????--??--?? 
1000 2000 3000 4000 5000 6000 7000 8000 
alarm data size 
Figure 3. Running time vs. different database sizes 
Fig.3 shows the performance of the four algorithms in 
running time. Minsup is set to 0.25%. We can see that, 
although the running time of the four algorithms changed 
linearly as the number of alarm transactions increases, 
IULFP increases more slowly than the other algorithms. 
Dealing with the same number of alarms, our proposed 
updating algorithm needs less time. When the number of 
alarms is 7000, the mining time of our approach is only 
about 92% of CanTree, 86%of MFS+ and 69% of FUP, 
respectively. This is because IULFP doesn't need to rescan 
the original database any more. It requires finding strong 
frequent itemsets in the original database and changed 
database respectively. However, MFS+ and FUP need to 
rescan the whole databases when some data is added. 
Moreover, Apriori -based FUP also generate large number 
of candidates, which can potentially increase the I/O cost 
and the processing time. In these existing updating methods, 
CanTree needn't to rescan the original database any more, 
therefore, its mining time is less than MFS+ and FUP. 
However, CanTree needs to process a large number of 
conditional pattern trees, so its running time is little more 
than our proposed algorithm IULFP. 
In FigA, we further compare the running time of the four 
algorithms for each minsup. It can be seen that IULFP 
outperforms other algorithms with all support thresholds. 
With low support thresholds, a large number of strong 
frequent itemsets are generated, but only few of them are 
generated from the updated database in IULFP. As the 
support threshold goes down, CanTree has to rescan the 
whole database and rebuild the tree structure. However, 
IULFP only needs to scan the changed part of the database 
to find strong frequent items, so IULFP runs faster than 
Can Tree. From the figure, we can see that MFS+ and FUP 
perform poorly. This is because of their high I/O costs and 
relatively large memory requirements. 
V4-429 
2010 International Conference on Computer Application and System Modeling (ICCASM 2010) 
Q) 
.? 
'" 
c 
. "  
c 
2 
alarm data size:1 ,000,000 
1400 
1200 -+- IULFP 
--& CanTree 
-a- MFS+ 
1000 -+- FUP 
BOO 
600 
400 
200 
0 
0.5 0.6 0.7 O.B 
minimum support threshold (%) 
Figure 4. Running time vs. different minsup 
VI. CONCLUSION 
0.9 
In this paper, we proposed a novel incremental updating 
algorithm called IULFP. This method uses the LFP-tree 
structure to avoid generating large number of candidates and 
conditional pattern trees; it also uses strong frequent 
itemsets generating strategy to avoid rescanning the original 
database. Theoretical analysis and experimental results 
show that IULFP has better performance than the other 
classical updating algorithms, In other word, IULFP has less 
running time and higher efficiency in comparison with other 
updating algorithms. 
REFERENCES 
[I] D.W. Cheung, 1. Han, VT Ng, and CY Wong, "Maintenance of 
discovered association rules in large databases: an incremental 
updating technique," Proc. ICDE, pp.106-114, 1996. 
[2] D.W. Cheung, S.D. Lee, and B. Kao, "A general incremental 
technique for maintaining discovered association rules," Proc. 
DASFAA, pp.185-194, 1997. 
[3] N. F. Ayan, AU Tansel, and E. Arkun, "An efficient algorithm to 
update large itemsets with early pruning," Proc. SIGKDD, pp. 287? 
291,1999. 
[4] R. Srikant, and R. Agrawal, "Mining sequential patterns: 
Generalizations and performance improvements," Proc. the 5th 
Conference on Extending Database Technology, A vignion, France, 
pp.3-17, 1996. 
[5] R. Agrawal, and R. Srikant, "Fast algorithm for mining association 
rules," Proc. the 20th VLDB Conference, pp. 487-499, 1994. 
[6] R. Ng, L. V. S. Lakshmanan, 1. Han, and A. Pang, "Exploratory 
mining and pruning optimizations of constrained association rules," 
Proc. SIGMOD'98, pp.13-24, 1998. 
[7] S. sarawagi, S. Thomas, and R. Agrawal, "Integrating association rule 
mining with relational database system: Alternatives and 
implications," Proc. SIGMOD'98, pp. 343-354, 1998. 
[8] R. Srikant, Q. VU, and R. Agrawal, "Mining association rules with 
item constraints," Proc. KDD'97, pp. 67-73, 1997. 
[9] M.1Zaki, "Efficient enumeration of frequent sequences," 
Proc.CIKM'98, USA, pp.68-75, 1998. 
[10] M. Zhang, B. Kao, CYip, and D. Cheung, "A GSP-based efficient 
algorithm for mining frequent sequences," Proc. IC-AI'200 1, USA, 
pp.497-503,2001. 
[II] M. Zhang, B. Kao, D. Cheung, and CL.Yip, "Efficient algorithms for 
incremental update of frequent sequences," Proc. the sixth Pacific­
Asia Conference on PAKDD, Taiwan, pp.186-197, 2002. 
[12] W Cheung, and O.R Za lane, "Incremental mining of frequent 
patterns without candidate generation or support constraint," Proc. 
IDEAS 2003, pp. III ? 116,2003. 
[13] l-L. Koh, and S.-F. Shieh, "An efficient approach for maintaining 
association rules based on adjusting FP-tree structures," Proc. 
DASFAA 2004, pp. 417?424, 2004. 
[14] CX.-S. Leung, Q.L Khan, and T. Hoque, "CanTree A Tree Structure 
for Efficient incremental Mining of Frequent Patterns," Proc. ICDM, 
pp.274-281,2005. 
[15] CX. Leung, Q. L Khan, and T. Hoque, "CanTree: a canonical-order 
tree for incremental frequent-pattern mining," Knowledge and 
Information Systems, voL II, no.3, pp. 287-311,2007. 
V4-430 
