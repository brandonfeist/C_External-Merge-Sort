 An Improved Design Approach in Spatial Databases 
Using Frequent Association Rule Mining Algorithm  
 
Animesh Tripathy                    
Assistant Professor,                    
School of Computer Engineering,       
KIIT University, Bhubaneswar, INDIA 
Subhalaxmi Das                      
Research Associate,                    
School of Computer Engineering,       
KIIT University, Bhubaneswar, INDIA  
Prashanta Kumar Patra                
Professor, Department of Computer 
Science & Engineering, CET, 
Bhubaneswar, INDIA. 
 
Abstract- Recently Negative Association Rule Mining (NARM) 
has become a focus in the field of spatial data mining. Negative 
association rules are useful in data analysis to identify objects 
that conflict with each other or that complement each other. 
Much effort has been devoted for developing algorithms for 
efficiently discovering relation between objects in space. All the 
traditional association rule mining algorithms were developed to 
find positive associations between objects. By positive correlation 
we refer to associations between frequently occurring objects in 
space such as a city is always located near a river and so on. 
Recently the problem of identifying negative associations (or 
“dissociations”) that is absence of objects has been explored and 
considered relevant. This paper presents an improved design 
approach for mining both positive and negative association rules 
in spatial databases. This approach extends traditional 
association rules to include negative association rules using a 
minimum support count. Experimental results show that this 
approach is efficient on simple and sparse datasets when 
minimum support is high to some degree, and it overcomes some 
limitations of the previous mining methods. The proposed form 
will extend related applications of negative association rules to a 
greater extent.  
Keywords: Association Rule, Data Mining, correlation coefficient, 
Negative Association Rule. 
I. INTRODUCTION 
Database research in the last decade has focused on 
developing support for so-called non-standard applications. 
One important area is the representation of spatial 
information, needed, for example, in Geographic Information 
Systems. Improved geographic data should lead to better 
conclusions and better decisions. In particular, Association 
Rule Mining (ARM) is used to represent the discovered spatial 
relationships and infer additional information based on already 
discovered relationships. Spatial dataset’s integration has been 
widely investigated but unfortunately there exists no 
framework to define this process.  It is more complex when 
the data has spatial attribute than when it has common 
attribute data.  
A. Positive Association Rule 
Association rule mining, as an important problem in data 
mining, was originally proposed in [1]. It is intended to 
discover implicit and interesting associations among data 
items in a dataset.  
Let I = {I1,I2...In} be a set of n distinct objects. Let 
T={T1,T2,…Tn} be a set of transactions, where each 
transaction T is a set of objects. Let A be a set of objects in I. 
Objects of length k are referred to as k-object sets. A 
transaction T is said to contain A if A?T. An association rule 
is an implication of the form AB, where A?I, B?I, and 
AB=. The rule A B has a support (denoted as supp) in T 
if s% of the transactions in T contains A?B.  
supp (AB) =supp (A?B)=P(A?B).                         (1) 
The rule A  B has a measure of its strength called 
confidence (denoted as conf) c if c% of transactions in T that 
contain A also contain B.  
conf (A B) = P (B|A)=supp(A?B)/supp(A).             (2) 
 
B. Negative Association Rule 
The negation of an object set A is indicated by ¬A, which 
means the absence of the object set A. We call a rule of the 
form AB a positive association rule, and rules of the other 
forms (A¬B, ¬AB and ¬A¬B) negative association 
rules. The support is given by the following formulas: 
supp (¬A)=1-supp(A)          (3) 
supp (A?¬B)=supp(A)-supp(A?B)        (4) 
supp (¬A?B)=supp(B)-supp(A?B)        (5) 
supp (¬A?¬B)=1-supp(A)-supp(B)+supp(A?B)       (6) 
 
The confidence is given by the following formulas: 
conf(A¬B)=   
)(sup
)(sup)(sup
Ap
BApAp ??          (7)                    
conf (¬AB) =    
)(sup1
)(sup)(sup
Ap
BApAp
?
??  (8)                     
conf(¬A¬B) =   
)(sup1
)(sup)(sup)(sup1
Ap
BApBpAp
?
?+??      (9) 
Our paper shows that both positive and negative association 
rules can be discovered efficiently from spatial database using 
the improved approach. 
 
II. RELATED WORK DONE 
The research and application of data mining technology are a 
hot spot in database and artificial intelligence in recent years 
as Association Rules Mining introduced by R. Agrawal [4] is 
an important research topic among the various data mining 
404978-1-4244-4791-6/10/$25.00 c©2010 IEEE
problems. Association rules have been extensively studied in 
the literature for their usefulness in many application domains 
such as market basket analysis, recommender systems, 
diagnosis decisions support, telecommunication, intrusion 
detection, and etc. All the traditional association rule mining 
algorithms were developed to find positive associations 
between item sets. Several algorithms have been developed to 
cope with the popular and computationally expensive task of 
association rule mining [5], AIS [2], DHP [3], and Partition 
[4]. With the increasing use and development of data mining 
techniques and tools, much work has recently focused on 
finding negative patterns, which can provide valuable 
information. However, mining negative association rules is a 
difficult task, due to the fact that there are essential differences 
between positive and negative association rule mining. We 
will attack two key problems in negative association rule 
mining: The first one is”How to effectively search for negative 
frequent item sets?” and the second is “How to effectively 
identify negative association rules?” [4].  
 
The frequent pattern tree [3] is a data structure that is used to 
optimize the compression of a database representing data 
transactions by using regular tree structures which make data 
representation efficient. But transaction mapping [6, 7] is an 
efficient approach rather than FP tree for mining data. This 
approach first builds an FP-Tree. After building the FP-Tree, 
an interval list for each item can be done by traveling the FP-
Tree. In the mining phase, the interval lists can determine two 
items are frequent or not by intersection produce. These 
approaches perform well in data mining. But, producing all the 
patterns is time consuming because it consumes too many 
computing resources. A new transaction mapping technique 
approach for FP tree structure is introduced to improve the 
storing of known frequent object sets. But little study is about 
negative association rules, especially weighted negative 
association rules [2] first mentions the negative relationships 
between two frequent items. A correlation method [7] aims to 
solve these mining problems have been proposed. But the user 
can’t control the number of the flexible rules. In this paper, a 
method based on the interest measure is defined. The number 
of rules is restricted making use of the value of the interest 
measure. 
III. PROPOSED WORK 
As per the discussion in the previous sections there exist 
algorithms for generation of association rules such as Apriori, 
Hash Based Technique, Frequent Pattern Tree Approach & 
others. To find valid negative and positive association rules 
there should a threshold of minimum support confidence 
framework. In this section we propose a data structure such as 
Frequent Positive Association Rule (FPAR) and Frequent 
Negative Association Rule (FNAR) to find valid positive and 
negative association rules. The detail of the proposed approach 
is given in fig 1. The Proposed Approach can be described as a 
five step process. In the first step we find frequent positive 
objects. Second step finds negative frequent objects. In the 
third step we sort the objects in order of their frequencies.  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: Proposed FPAR/FNAR Model 
Then we build a FPAR and FNAR Tree during the forth step. 
Finally we generate all possible positive and negative 
association rules. These Association Rules both positive and 
negative are considered to be valid rules. To demonstrate the 
proposed model we consider a set of seven spatial objects in 
Table I. These spatial objects are correlated to each other in 
space. The in Table 2 we consider a sample Spatial 
Transaction Dataset of 10 observations. 
TABLE I. SET OF SPATIAL OBJECTS 
TID Spatial Object 
1 Temple(T) 
2 Water(W) 
3 Park(P) 
4 College(C) 
5 Post Office(PO) 
6 Bank(B) 
7 Restaurant(R) 
 
Let consider a database table with 10 transactions and 07 
spatial objects. Association rules have been mined with 
threshold support of 40% for both antecedent and consequent. 
In order to avoid wasted a lot of computing resources when 
verifying a few frequent objects in database.  An algorithm is 
proposed in figure 2. The first phase of algorithm is to 
building a frequent order list to find out all the frequent 
objects in the transaction table. Then from a transaction table a 
FPAR/FNAR Tree is constructed. A procedure is followed by 
traversing the level of the tree to generate the valid frequent 
patterns which yields positive and negative association rules.  
 
Spatial Data 
Base 
Find Frequent 
Positive Objects 
Negative Frequent 
Ordered Objects 
Positive Frequent 
Ordered Objects 
Find Frequent 
Negative Objects 
FPAR/ 
FNAR  
Tree 
Generate Negative Association Rule 
Generate Positive Association Rule 
2010 IEEE 2nd International Advance Computing Conference 405
Input: Spatial Database (DB), minimum_support  
Output: Valid Frequent Patterns 
 
1. Call Frequent Order List procedure to find out all frequent 
objects. 
2. Call FPAR/FNAR Tree procedure to build a tree. 
3. Call FPAR/FNAR pattern procedure to find out all valid 
frequent patterns. 
Figure 2 The procedure of algorithm 
A. Frequent Order List 
The procedure scans the database fully and the objects which 
are present in the transaction table are inserted into positive 
object list and the objects which are absent inserted into 
negative object list. Then analyze the frequencies of all listed 
objects. If any object does not satisfy the minimum support 
count then it is discarded. Then each transaction is sorted in 
descending order according to the frequency of object. The 
detail is given in Figure 3.  
Input:    Spatial Database (DB), minimum_support 
Output: Orderlist (OL) 
 Procedure: Frequent Order list generates as follows 
Step 1:  Scan DB and consider object[i] from object_list 
Step 2:  Generate Positive and Negative object_list  
             For each transaction T 
             If object[i] ==found in object_list 
             Insert into positive_OL 
             Else 
             Insert into negative_OL 
 Step 3: For each positive_OL & negative_OL 
             Determine the support count for each object 
 Step 4: If (support count(object[i])<min_support)  
            Discard (object[i]) 
            Else   
            Sort (object[i].list) in descending order.  
Figure 3 Procedure for Frequent Order list 
B. FPAR/FNAR Tree Algorithm 
Secondly, each frequent object of current transaction is 
inserted into the tree. If any object of the frequent pattern is 
not present in the existing tree then it creates a new object 
node and assigns one to the frequency. Otherwise the 
frequency of child node adds one. When an object is inserted 
into the tree, a frequent item node can be combined with its 
parent node if and only if the parent is not root. This new node 
has same properties as the current frequent object node and 
can be put on the level of the parent node. The first one is 
using depth first search to build a linking header for each 
object. The header table is an index structure enabling one to 
reach an item quickly. The second is assigning a new 
transaction list for each object. A tree node is comprised of 
one or many items in FPAR/FNAR Tree. Each object of this 
node is appended to the header table. If sub nodes remain in 
this node, then the procedure is processed recursively. On the 
other hand, the next transaction number follows that of the 
current transaction number. At last, the mining procedure 
forms a tree where each known frequent object is combined. 
This procedure stops when no more objects can be mined and 
verify the last object. The figure 4 shows in details. 
Input:     Ordered List (OL) 
Output:  FPAR/FNAR Tree 
Procedure FPAR/FNAR Tree creates as follows 
Step 1:    Generate FPAR/FNAR Tree 
            For each positive_OL & negative_OL                       
             Scan each transaction T in Order_list[i] 
Step 2: For each Order_list[i] 
             Generate Frequent Pattern[j] , such that 
             Pattern[j] contains object[i]>1 &&!=Order_list[i]   
Step 3:  Determine support count for each Pattern[j] 
             For each Pattern[j] 
             If transaction T contains Pattern[j]==found 
             Count[Pattern[j]]++ 
             Else 
             Consider Pattern[j++] 
 Step 4: Build FPAR/FNAR Tree 
             For each Order_list[i] 
             Root==max(Pattern[j])  
             Set counter_value==1 
             Generate leaf nodes for object[i] not in Pattern[j] 
             Set counter_value==1 
 Step 5: For each successive scan of Order_list[i] 
             If(max(Pattern[j] exists) 
             Increment counter_value ++ 
             If leaf nodes exists  
             Increment counter_value++ 
             Else 
             Generate leaf nodes for object[i] not in Pattern[j] 
             Set counter_value==1 
Figure 4. Procedure for FPAR/FNAR Tree generation 
C. FPAR/FNAR Patterns  
The FPAR/FNAR-tree is mined as follows. Start from each 
frequent length-1 pattern (as an initial suffix pattern), 
construct its pattern base (a “sub database,” which consists of 
the set of prefix paths in the FPAR/FNAR-tree co-occurring 
with the suffix pattern), then construct its (pattern) 
FPAR/FNAR-tree, and perform mining recursively on such a 
tree. The pattern growth is achieved by the concatenation of 
the suffix pattern with the valid frequent patterns generated 
from a valid FPAR/FNAR-tree patterns as shown in figure 5.  
 
Input   : FPAR/FNAR Tree, minimum_support 
Output: FPAR/FNAR patterns   
Procedure FPAR/FNAR pattern creates as follows 
Step 1: Generate FPAR/FNAR pattern 
            If leaf node contains a single path p then 
            For each combination (denoted as k) of the nodes in  path p 
Step 2: Generate pattern k?Root with 
 support_count=minimum_support count of nodes in k 
           Else for each object[i] in header of leaf node { 
           Generate pattern k=object[i]?Root with 
 support_count=object[i].support count 
          Construct k’s patterns and then k’s FPAR/FNAR patterns 
          If leaf node?? then 
         Call leaf node++} 
Figure 5 Procedure for FPAR/FNAR pattern generation 
406 2010 IEEE 2nd International Advance Computing Conference
This algorithm when applied gives result of generation of 
association rules. To generate the association rules we 
consider a set of transaction of spatial objects and based on the 
minimum support confidence framework the algorithm 
generates association rules as required. 
IV. EXPERIMENTAL STUDY 
In order to use the proposed approach in our study of spatial 
databases system we use the concept of ordered object sets and 
frequent pattern. In this approach we have considered some 
spatial objects found generally in Map Databases or Spatial 
Databases. The design process has the following steps as per 
the algorithm described in the previous section.  
Step 1: Build Ordered object sets. 
Step 2: Build a Positive Frequent Association Tree 
Step 3: Build a Negative Frequent Association Tree. 
Step 4: Generate the optimized set of association rules. 
TABLE II. SAMPLE SPATIAL DATASETS 
TID Objects (Order)Positive 
Frequent Objects 
(Order)Negative 
Frequent 
Objects 
1 T,W,R  R,T,W  ¬PO,¬B  
2 T,W,P,C,R  C,R,P,T,W  ¬PO,¬B  
3 C,PO,B,R,P  C,R,P  ¬W,¬T  
4 W,P,R  R,P,W  ¬PO,¬B,¬T  
5 C,P,B,R  C,R,P  ¬PO,¬W,¬T  
6 T,W,P,C,R  C,R,P,T,W  ¬PO,¬B  
7 P,C,B,R  C,R,P  ¬PO,¬W,¬T  
8 P,C,PO,R  C,R,P  ¬B,¬W,¬T  
9 T,P,C  C,P,T  ¬PO,¬B,¬W  
10 T,PO,C  C,T  ¬B,¬W  
 
Table II shows an example of a database with 10 transaction 
and 07 objects. Suppose we take min_sup is 4 and the sorted 
frequent objects are College(C), Restaurant(R), Park(P), 
Temple(T), Water(W), Post Office(PO), Bank(B). The 
database is scanned once to find the frequent (positive) 
objects. The negative objects of interest, i.e., negative objects 
having support at least min_sup, can then be found. Each 
transaction can be viewed as being appended with the negative 
objects. For example, in TID (1) {T, W, R} is a frequent 
object set. So the object which is less than the min_sup is 
pruned. Now TID (1) can be viewed as a new transaction {R, 
T,W,¬PO,¬B} if the set of negative objects is 
{¬PO,¬B,¬W,¬T}. Then, each transaction will be used to 
construct the FPAR/FNAR –tree (shown in figure 3 and 4) for 
mining the frequent object sets comprising both positive and 
negative objects. The objects in transaction is sorted by the 
support-decreasing order and then added to the FPAR/FNAR-
tree. Each transaction is gradually inserted into the tree. Let’s 
take TID(2) for constructing the FPAR tree then College(C), 
Restaurant(R) and Park (P) can be combined into one node 
because these are the frequent objects. A new node is inserted 
into the child of the tree root with transaction number as one.   
 
Figure 6. FPAR Tree Example 
 
Figure 7. FNAR Tree Example 
TABLE III. POSITIVE AND NEGATIVE ASSOCIATION RULES 
Rule # Positive Association Rule Negative 
Association Rule 
1 College ^Restaurant  Park  ¬Post office ¬ 
Bank  
2 College Restaurant ^ Park  ¬Water  ¬Temple 
3 College  Temple   
4 Restaurant  Water   
 
When traveling the FPAR-Tree, the transaction number is 
passed into the next recursive procedure. Otherwise, the 
transaction number increases the current frequency of node. At 
the same time, each object of a node is appended to the header 
table. The object C has the largest support and there are two 
nodes CRP {2, 6} and C {9, 2}. This method substantially 
reduces the search costs. From the figure 6 & 7 we build the 
set of positive association rules and negative association rules 
as shown in Table III. For the positive and negative 
association rules in Table III, support, confidence and lift have 
been shown in Table IV. From table IV, the rules # whose lift 
value is greater than “1” implies a strong positive association 
rule. Refer rule #3 where lift value is 1.00 is an independent 
object pattern or there is no correlation between objects. But in 
case of rules #5 and #6 whose lift value is also greater than ‘1’ 
as the rules have already been expressed in negative forms, 
2010 IEEE 2nd International Advance Computing Conference 407
implies actually a strong negative association rule, otherwise it 
is not considered as a negative association rule. Then, for each 
of the association rules with lift less than “1” further 
examination should be done for all possible negative 
association rules.  
TABLE IV. POSITIVE AND NEGATIVE ASSOCIATION RULE WITH 
SUPPORT, CONFIDENCE AND LIFT 
 
The generated set of association rules are known to be the 
optimized set of rules or valid rules. As the generated rules are 
valid rules it requires no pruning process to find invalid rules. 
Thus we get a set of 3 positive association rules and 2 negative 
association rules where each rule satisfy the minimum of 40% 
of support. These negative valid association rules affect the 
decision making process and improve efficiency of spatial 
objects access. 
V. TEST RESULTS 
To assess the performance and efficiency of the proposed 
algorithm, we conducted our experiments on a spatial database 
sample to study the behaviors as compared to the existing 
ones. The experiments were performed in an Intel Core Duo 
T2300 1.66 GHz CPU, 1024MB memory PC running the 
Windows XP. The datasets used were generated from the well-
known IBM synthetic dataset generation program [1]. The 
datasets in the experiments were T10I5R50D10K and 
T5I2.5R100D10K, similar to that used in [7] for mining 
negative association rules. Dataset T10I5R50D10K represents 
1000 transactions of average size 10 (item sets), with 50 items 
and can be viewed as a dense dataset. The other one can be 
characterized as a sparse dataset. The minimum confidence 
and minimum interest are used in a post processing to obtain 
the interesting rules. The results are compared with existing 
PAR/NAR algorithm as shown in Table V using 3D Miner 
Data Mining Tool. The total execution time is dependent on 
the time to mining the frequent item sets, comprising both 
positive and negative items.  Thus, only the results of the 
discovery of frequent item sets are depicted in the following.
 
Figure 8. Par/Sar with changing value of Min_Support 
 
 
 
Figure 9. FNAR/FPAR with changing value of Min_Supp & Min_Conf 
TABLE V. COMPARISON RESULTS FOR PAR/SAR Vs FPAR/FNAR 
Min Sup Min Conf PAR/SAR FPAR/FNAR 
0.15 0.3 54 66 
0.2 0.6 82 89 
0.25 0.9 70 76 
0.3 0.9 70 72 
0.35 0.3 28 73 
0.4 0.6 74 84 
0.45 0.9 38 47 
0.5 0.9 37 46 
 
When min_sup was decreased from 0.5 to 0.15, the total 
execution time for both algorithms increased. FNAR 
outperforms the Apriori-based algorithm for all the 
experiments conducted. The number of frequent items 
including both positive and negative items increases as the 
min_sup decreases, as shown above. The results show that 
FPAR/FNAR approach has good scalability for the different 
parameters. It shows FPAR/FNAR scales up linearly because 
of many known frequent item sets are reducing, the repetition 
of calculation greatly. 
Rule 
# 
Association 
Rule 
 
Antecede
nt 
Support 
%  
Consequ
ent 
Support 
%  
Confid
ence 
%  
Rul
e 
Sup
port 
%  
Lift  
1 College 
^Restaurant 
 Park  
60  80  100  60  2.5  
2 College 
Restaurant 
^ Park  
80  70  75  60  1.07  
3 College  
Temple  
80  50  50  40  1.00  
4 Restaurant 
 Water  
80  40  50  40  1.25  
5 ¬Post office 
¬ Bank 
70  70  71.42  50  1.02  
6 ¬Water  
¬Temple  
60  50  66.67  40  1.34  
408 2010 IEEE 2nd International Advance Computing Conference
VI. CONCLUSION AND FUTURE WORK 
In this paper FPAR/FNAR algorithm constructs a tree that 
compresses and generates a set of generalized strong positive 
and negative association rules. The algorithm predicts useful 
negative rules with respect to existing positive rules by 
employing frequent growth approach. Extending mining to 
negative association rules can assist the recommendations 
more accurately. Although the mining complexity is increased, 
the experiments showed that our approach can be applied to 
discover the patterns of both dense and spare datasets. The 
algorithm also has linear scalability with the number of 
transactions. The algorithm is efficient on simple and sparse 
datasets, and has overcome some limitations of the previous 
methods. The algorithm will definitely enhance the efficiency 
of finding spatial objects in space with respect to their 
correlation analysis. However, some further work needs to be 
done on complex and dense datasets and increase its 
performance. One possible way is to use max-pattern sets or 
closed pattern sets, instead of all frequent pattern sets. 
Secondly, we will extend this to quantitative, multilevel and 
multidimensional forms, and propose the corresponding 
mining methods.  
 
 
 
 
 
 
REFERENCE 
[1] X. Wu, C. Zhang and S. Zhang, “Efficient mining of both 
positive and negative association rules”, ACM Transactions on 
Information Systems, Vol. 22, No. 3, pp.381-405, 2004.  
[2] Dong, X., Niu, Z., Shi, X., Zhang, X., Zhu, D,”Mining both 
Positive and Negative Association Rules from Frequent and 
Infrequent Itemsets”. ADMA 2007, LNAI 4632, Springer-
Verlag Berlin Heidelberg (2007) 122–133. 
[3] R. Agrawal, T. Imielinski, and A. Swami, “Mining association 
rules between sets of items in large databases”, Proceeding of 
the ACM SIGMOD Intl. Conf. on Management of Data, pp. 
207-216, 1993.  
[4] T D.R. Thiruvady and G.I. Webb, “Mining negative rules in 
large databases using GRD”, Proceeding of PAKDD 2004, 
pp.161-165, 2004.  
[5] A. Pietracaprina and D. Zandolin, “Mining frequent itemsets 
using Patricia tries”, Proceeding of IEEE FIMI 2003, 2003.  
[6] M M. Gan, M.-Y. Zhang and S.-W. Wang, “One Extended Form 
for Negative Association Rules and the Corresponding Mining 
Algorithm” Proceedings of the 4th International Conference on 
Machine Learning and Cybernetics, Vol. 3, pp.1716-1721, 2005. 
[7] C. Borgelt, "An Implementation of the FP-growth Algorithm," 
Proceedings of the 1st international workshop on open source 
data mining, 2005, pp. 1-5. 
 
 
 
2010 IEEE 2nd International Advance Computing Conference 409
