BitApriori: An Apriori-Based Frequent Itemsets 
Mining Using Bit Streams 
Le Thi Thanh Nhan 
Department of Computer Science 
Kyunghee University, Global Campus 
Yongin, Gyeonggi 446-701, Korea 
nhanltn@khu.ac.kr 
Nguyen Thi Thanh Thuy 
Department of Computer Science 
Posts and Telecommunications Institute 
Hanoi, Vietnam  
thuyr205@gmail.com  
Chung Tae Chong 
Department of Computer Science 
Kyunghee University, Global Campus 
Yongin, Gyeonggi 446-701, Korea 
tcchung@khu.ac.kr
Abstract— Generating, pruning and counting itemset candidates 
are important steps in Apriori frequent itemsets mining. 
Unfortunately, their computation time is too expensive. In this 
paper, we propose a new method using Bit Stream to improve 
their speed. At the beginning, the 1-itemsets are found out and 
sorted according to the decline of count. By that way, a map of all 
attributes would be created. After that, each attribute will be 
presented by 1 bit. At last, the generating and pruning itemset 
candidates are processed by LOGIC operations which are not 
cost much of computation time. For experiments we compare our 
method with some Apriori-based state of the arts. 
Keywords-component; formatting; Apriori, Association Rules, 
Data Mining, Frequent Itemsets Mining (FIM). 
I. INTRODUCTION
Frequent itemsets mining is a crucial step in association 
rule mining. It plays an important role in many data mining 
tasks including strong rules, correlations and sequential rules. 
One of ordinary algorithms is Apriori [1]. It adopts breadth 
search and finds all frequent itemsets. When the database is 
sparse and the frequent itemsets are short, Apriori and its 
improvements give high performance. However, with dense, 
medium size database, the efficiency of Apriori-based 
algorithms goes down dramatically. There are some main 
reasons: 
• In dense database, the frequent itemsets are long. 
Therefore, the candidate generating dominates the run 
time. 
• If the longest frequent itemset is n, it means each 
transaction have to be scanned n times. In other words, 
the entire database has to be scanned n time. 
• Each m-length candidate is generated from 2m-2 extra 
frequent itemsets. The generation of them costs lot of 
time. 
• The computation cost for counting support of 
candidates is so high. 
In order to solve those shortcomings of Apriori, many 
improvements had been published. It is useful to store the 
candidates in a special data structure and save numerous 
transaction traversals. Firstly, in the ordinary paper [1], hash 
tree had been used to store frequent itemsets and candidate 
frequent itemsets. Only candidate frequent itemsets, whose 
subsets are all frequent, are generated in each database scan. 
Based on the hash tree, candidate frequent itemsets are 
generated and their subsets are tested. Secondly, the trie-based 
Apriori [10] were reported. After that, with independent 
researchs, Borgelt[5], and Bodon [12][14] published the first 
open-source of Apriori algorithm. And then, a parallel Apriori 
algorithm for Frequent Itemsets Mining had been proposed 
[13]. 
In our research, we propose a method which presents all 
candidates, frequent itemsets, and transaction in same-length 
Bit Streams. By that way, the generating candidates, and the 
support counting will be done by LOGIC operations with low 
cost of computation. The rest of this proposal will be organized 
as follow. Section II introduces the description of frequent 
itemsets mining. Section III presents the Apriori property and 
Apriori algorithm. In section IV, we present our algorithm, 
BitApriori. 
II. PROBLEM DESCRIPTION 
Let I = {i1, i2,  ... ,in} be a set of items and D be a multiset of 
transactions, where each transaction T is a set of items such 
that T? I. For any X ? I, we say that a transaction T contains X 
if X ? T. The set X is called an itemset. The count of an itemset 
X is the number of transactions in D that contain X. The 
support of an itemset X is the proportion of transactions in D
that contain X. Thus, if the total number of transactions in D is 
n, then the support of X is the count of X divided by n . 100
percent. An itemset X is called frequent if its support is greater 
than or equal to some given percentage s, where s is the 
minimum support. 
III. ORIGINALLY APRIORI ALGORITHM 
Apriori finds frequent itemsets according to a user-defined 
minimum support. In the first pass of the algorithm, it constructs 
the candidate 1-itemsets. Then the algorithm generates the 
frequent 1-itemsets by pruning some candidate 1-itemsets if 
their support values are lower than the minimum support. After 
the algorithm finds out all the frequent 1-itemsets, it joins the 
frequent 1-itemsets with each other to construct the candidate 2-
itemsets and then prunes some infrequent itemsets from the 
978-1-4244-5943-8/10/$26.00 ©2010 IEEE
candidate 2-itemsets to create the frequent 2-itemsets. This 
process is repeated until no more candidate itemsets can be 
created. Fig. 1 shows original Apriori pseudo code. 
Figure 1. Apriori pseudo code 
The apriori-gen function (Fig.  2) takes Lk-1, the set of all 
large (k-1)-itemsets, as argument. It returns a superset of all k-
itemsets. The function is in following order. Firstly, in the join 
step Lk-1 is joined with itself. Next, in the prune step, all the 
itemsets c ? Ck that some (k-1)-subset of c are not in Lk-1 are 
deleted. 
Figure 2. Candidate generating  pseudo code 
The count function counts support of each itemset in C. If 
an itemset c ? Ck and with every transaction T contains c, 
support of c will be increase 1. Counting process is shown in 
Fig.  3. 
Figure 3. Counting pseudo code 
An example on how Apriori discoveries frequent itemsets is 
shown in Fig. 4. The database in this example denoted D will 
be used in future examples. 
Database D        support = 2  L1
TID Item  Item Support 
1 1 3 4 scan {1} 3 
2 2 3 5  {2} 4 
3 1 2 5  {3} 3 
4 1 2 5   {4} 2 
5 2 3 4  {5} 3 
              C2    L2
Itemset   Itemset Support 
{1 2}   {1 2} 2 
{1 3}   {1 5} 2 
{1 4}   {2 3} 2 
{1 5}  scan {2 5} 3 
{2 3}   {3 4} 2 
{2 4}     
{2 5}     
{3 4}     
{3 5}     
{4 5}     
C3    L3
Itemset   Itemset Support 
{1 2 5}   scan {1 2 5} 2 
{1 2 3}     
{2 3 5}     
{2 3 4}     
Figure 4. An Apriori frequent itemset mining example 
IV. BITAPRIORI ALGORITHM 
A. BitApiori  
BitApriori is an approach in which the input file contains 
numerical data. If the data in the input file are not numerical, 
an index file for all items should to be created. After that, the 
algorithm will work with this file instead of input file. 
All candidates and transactions will be presented by a bit 
stream with same number of bits (same length). The length (by 
bit) of a bit stream is n which the number of frequent items is. 
To implement bitApriori, we use an array of STL library in 
C++ bitset<16> container to present each bit stream, the 
number of elements needs for this array is nE which is the 
smallest, nearest positive integer and greater than n div 16.
Each bit stream also contains 2 other parameters start and 
end which indicate the first and the last non-zero element of bit 
stream. All operations onto every bit stream only work in range 
(end – start + 1) element, instead of nE element. The order of 
bits in a bit stream is presented in Fig. 5.  
Figure 5. An array of bitset<16> has nE elements 
With n=5 on the above example, we only need  
nE = 1 for each bit stream, so bit stream has only 1 element, 
start = end = 0; with n =18, nE = 2. 
B. Map of bit stream creation 
The database will be scannd to create the list of all items. 
After that, non-frequent items are deleted and the list of items 
is sorted by the descent of support count. This list is set of 
frequent items will be used as a map of bit stream for later 
processes. This map presents the order of bits in each bit 
stream. 
C. Database conversion to bit streams 
BitApriori scans the database once more time again. All 
transactions are presented by bit streams. If transaction T 
contain item i which has position p-th in item list, the p-th bit 
of T’s bit stream will be set 1, otherwise will be set 0. 
Assuming that the first transaction {1, 3} contains 2 frequent 
items 1 and 3 which are respectively the 1-st and the 4-th in the 
list. Therefore, it will be presented by bit stream 1001, the 1-st
bit is the most right one. 
D. The 1-length frequent itemset 
Each frequent item at position p-th in the map will be 
shown as a bit stream with p-th bit is 1 and the rest others are 0, 
then start = end. By that way, L1 is created. 
E. Candidate generation 
In original Apriori [1], Ck is generated by joining Lk-1 with 
itself. It leads to many itemsets need to be pruned. There are 
two kinds of these itemsets: 
• Duplicated itemsets 
• Itemsets have more than k items. 
Example L3 = { {1 2 3}, {1 2 4}, {1 2 5},  {1 3 4}, {1 3 5}, 
{1 4 5}, {2 3 4}}, six pairs of itemsets ({1 2 3}, {1 2 4}), ({1 2 
3}, {1 3 4}), ({1 2 3}, {2 3 4}), ({1 2 4}, {1 3 4}), ({1 2 4}, {2 
3 4}), and ({1 3 4}, {2 3 4})  generate itemset {1 2 3 4}. 
Besides, eight other pairs ({1 2 3}, {1 3 5}), ({1 2 3}, {1 4 5}), 
({1 2 4}, {1 3 5}), ({1 2 5}, {1 3 4}), ({1 2 5}, {2 3 4}), ({1 3 
4}, {1 4 5}), ({1 3 5}, {2 3 4}), ({1 4 5}, {2 3 4}) create a 5-
length itemsets {1 2 3 4 5}. Finding and pruning these spare 
itemsets cost too much time. 
To overcome above shortcomings, we propose an 
improvement for candidates generating (Fig. 6) in which 
contains two main rules: 
• In a k-length itemset I = {i1 i2 i3 …ik}, the item ij
(j=1,k) have to be after the item ij-1 in the map of items. 
Therefore, an itemset we have index l only join with 
itemset I1 have index l1>l in Lk-1
• An k-length itemset is only generated by two itemsets 
have the same (k-2) first items. 
Therefore, in above L3, we join L31 = {{1 2 3}, {1 2 4}, {1 
2 5}} and L32 = {{1 3 4}, {1 3 5}} with themselves. 
Figure 6. Candidates generating without duplications. 
Suppose that subset(I) check whether all (k-1)-length 
itemsets of itemset I = {i1, i2, …, ik} are frequent. We see 
easily that itemset I have k (k-1)-length sub-itemsets. (k-1) of 
them begin with item i1 and absent one items ij (j=2,k) and the 
rest one begins with i2, {i2, i3, …, ik}.
F. Support counting 
For counting support for all candidate in Ck, bitApriori 
algorithms does AND operation between candidate ci and 
transaction bit stream bj then compares result with candidate. 
Because the AND operation only shows the common bits from 
2 bit streams, if result bit stream equals to the candidate 
stream ci, the transaction bi contains ci and ci’s support
increases 1. Providing that ci’s support >= minsup, ci wil be 
inserted into Lk.
The details of support counting process are described in 
Fig. 7. 
Figure 7. Support counting process. 
Below is an example which shows how bitApriori finds 
frequent itemsets for database D in Section III. 
Database D     support = 2       Frequent items 
TID Item  Item Support 
1 1 3 4 1st scan 1 3 
2 2 3 5  2 4 
3 1 2 5  3 3 
4 1 2 5   4 2 
5 2 3 4  5 3 
    Map of bit stream  
   (Sorted frequent items) 
Position Item Support   
0 2 4  nE = 1 
1 1 3  Start = end = 1 
2 3 3   
3 5 3   
4 4 2   
With TID = 1, T = {1, 3, 4}, item 1 , item 3 item 4 are at 
positions 1, 2, 4 respectively in map of bit stream, so bit 1-th,
bit 2-th, bit 3-th in bit stream presents for T is 1. bitT = 
0000000000010110, start = end = 1.  
Because D has only 5 frequent items, so each bit stream 
presents one itemset (transaction, candidate, frequent itemset) 
only has 5 value bits. From now, only 5 low bit will be shown 
for each bit stream of this example. 
Database D  Present D by bit streams  
TID Item  TID Bit stream 
1 1 3 4  1 10110 
2 2 3 5  2nd scan 2 01101 
3 1 2 5  3 01011 
4 1 2 5   4 01011 
5 2 3 4  5 10101 
Sorted frequent items   L1 
Position Item Support  Itemset Support 
0 2 4  00001 4 
1 1 3  00010 3 
2 3 3  00100 3 
3 5 3  01000 3 
4 4 2  10000 2 
C2                  L2
Itemset   Items Support 
00011   00011 2 
00101   00101 2 
01001   01001 3 
10001   01010 3 
00110   01100 2 
01010     
10010     
01100     
10100     
11000     
C3    L3
Itemset   Items Support 
00111   01011 2 
01011     
01101     
01110     
Frequent Itemsets 
Itemset Items 
00001 2 
00010 1 
00100 3 
01000 5 
10000 4 
00011 2 1 
00101 2 3 
01001 2 5 
01010 1 5 
01100 3 5 
01011 2 1 5 
Figure 8. An example of bitApriori frequent itemset mining. 
V. EXPERIMENTAL RESULTS 
In our experiments, we used four sets of data. Among 
them, T10I4D100K, T40I10D100K are synthetic data. They 
resemble market basket data with short frequent itemsets. The 
other two datasets, Mushroom and Connect-4 data, are real 
data which are dense in long frequent itemsets. These data sets 
were often used in the previous studies of frequent itemsets 
and asscociation rules mining. We downloaded them from 
http://fimi.cs.helsinki.fi/testdata.html. Some characteristic of 
these datasets are shown in table I. 
TABLE I. THE DATASETS
Data set #Items Avg. Length #Trans Type Size 
T10I4D100K 1000 10 100000 Sparse 3.93 MB
T40I10D100K 1000 40 100000 Sparse 14.8 MB
Mushroom 120 23 8124 Dense 557 KB 
Connect-4 130 43 67557 Dense 8.89 MB
Our algorithm has mainly compared with three popular 
Apriori-based algorithms. Two of them, AprioriTrie [14], depth 
first search Apriori (dfApriori) [15], were downloaded  from 
http://fimi.cs.helsinki.fi/src/ . The rest is the newest Borget’s 
Apriori implementation from http://www.borgelt.net//apriori.html
(version 5.8, 2009.11.13). 
All experiments were performed on a Intel Core 2 Quad 
2.4GHz with 2GB of memory. All times include time for 
outputting all the frequent itemsets. Tables II through V and 
figure 9 through 12 present the results. 
TABLE II. RUN TIME (S) FOR T10I4D100K DATA
Support 
(%) 
AprioriTri
e
Borget's 
Apriori 
Depth 
Apriori bitApriori 
25 2.577 0.5 10.703 0.626 
20 2.75 0.51 10.715 0.632 
15 2.965 0.515 10.71 0.638 
10 3.225 0.558 10.716 0.685 
5 4.218 0.672 10.658 0.798 
0
2
4
6
8
10
12
25 20 15 10 5
Support (%)
Ti
m
e 
(s
)
AprioriTrie
Borget's Apriori
Depth Apriori
bitApriori
Figure 9. Run time (s) for T10I4D100K data 
Table II and Fig. 9 show the performance comparison of 
the compared algorithms on T10T4D100K data. AprioriTrie 
runs fifth faster than Depth Apriori while both bitApriori and 
Borget’s Apriori make a fair comparison and run twice faster 
than AprioriTrie. 
TABLE III. RUN TIME (S) FOR T40I10D100K DATA
Support 
(%) AprioriTrie 
Borget's 
Apriori 
Depth 
Apriori bitApriori 
25 19.869 1.975 40.231 2.305 
20 19.878 2.047 40.032 2.382 
15 20 2.198 40.256 2.521 
10 20.553 2.605 40.436 2.943 
5 20.475 3.438 46.197 4.225 
0
5
10
15
20
25
30
35
40
45
50
25 20 15 10 5
Support (%)
Ti
m
e 
(s
) AprioriTrie
Borget's Apriori
Depth Apriori
bitApriori
Figure 10. Run time (s) for T40I10D100K data 
The comparison results on T40I10D100K data are 
presented by Table III and Fig. 11. While AprioriTrie 
performs twice as Depth Apriori, bitApriori and Borget’s 
Apriori performance are nearly the same and nine times as 
AprioriTrie. 
TABLE IV. RUN TIME (S) FOR MUSHROOM DATA
Support 
(%) 
AprioriTri
e
Borget's 
Apriori 
Depth 
Apriori bitApriori 
25 1.355 0.17 0.656 0.285 
20 6.312 0.37 1.576 0.482 
15 12.264 0.48 1.86 0.605 
10 105.894 4.55 10.34 7.875 
5 571.67 40.16 74.01 52.015 
0
100
200
300
400
500
600
700
25 20 15 10 5
Support (%)
Ti
m
e 
(s
) AprioriTrie
Borget's Apriori
Depth Apriori
bitApriori
Figure 11. Run time (s) for mushroom data 
TABLE V. RUN TIME (S) FOR CONNECT-4 DATA
Support 
(%) AprioriTrie 
Borget's 
Apriori 
Depth 
Apriori bitApriori 
90 13 1.547 1.125 1.672 
80 44.798 2.688 35.876 2.802 
70 334.485 9.628 255.638 10.171 
60 675.695 47.512 585.762 49.205 
50 1387.672 189.548 1201.879 192.235 
0200
400
600
800
1000
1200
1400
1600
90 80 70 60 50
Support (%)
Ti
m
e 
(s
) AprioriTrie
Borget's Apriori
Depth Apriori
bitApriori
Figure 12. Run time (s) for connect-4 data 
VI. CONCLUSION AND FUTURE WORK 
In this paper, we have presented a new approach to Apriori 
frequent itemset mining, bit Apriori, using bit stream as main 
data structures to store database and itemsets. Besides, LOGIC 
operations are used for joining candidates and support 
counting. By that way, instead of checking one item by one 
time, our algorithm checks a group of items at once. 
Therefore, the performance is considerable improved. 
In future, we will improve bitApriori so that it can be fairly 
compare with other frequent itemsets mining. 
REFERENCES
[1] R. Agrawal, T. Imielinski, and A. Swami, “Mining association rules 
between sets of items in large databases”. In P. Buneman and S. Jajodia, 
editors, Proceedings of the 1993 ACM SIGMOD International 
Conference on Management of Data, Washington, DC: ACM Press, 
1993, 207-216.  
[2] R. Agrawal, R. Srikant, “Fast algorithms for mining association rules”. 
In J. B. Bocca, M.Jarke, and C. Zaniolo, editors, Proceedings 20th 
International Conference on Very Large DataBases(VLDB'94), 
Santiago, Chile: Morgan Kaufmann, 1994, 487-499.  
[3] J. Han, J. Pei, and Y. Yin, “Mining frequent patterns without candidate 
generation”. In Proc. 2000 ACM-SIGMOD Int. Conf. Management of 
Data (SIGMOD’00), Dallas, TX: ACM Press, 2000, 1-12. 
[4] http://fimi.cs.helsinki.fi, 2003. 
[5] C. Borgelt, “Efficient Implementations of Apriori and Eclat”, Proc. 
IEEE ICDM Workshop Frequent Itemset Mining Implementations, 
CEUR Workshop Proc., vol. 80, Nov. 2003. 
[6] B. Goethals, “Survey on frequent pattern mining”, University of 
Helsinki, Tech. Rep., 2003. 
[7] G. Grahne, J.F. Zhu, “Fast algorithms for frequent itemset mining using 
FP-trees”, IEEE Transactions on Knowledge and Data Engineering 17 
(10) (2005) 1347–1362. 
[8] F. Bodon,  “A survey on frequent itemset mining”, Budapest, 2006. 
[9] J. Han, “Data mining Concepts and Techniques”, 2006 
[10] Sergey Brin, Rajeev Motwani, Jeffrey D. Ullman, and Shalon Tsur, 
“Dynamic itemset counting and implication rules for market basket 
data”. In Joan Peckham, editor, SIGMOD 1997. Proceedding ACM 
SIGMOD International Conference on Management of Data, May 13-
15, 1997, Tucson, Arizona, USA, pages 255-264. ACM Press, 05/ 1997. 
[11] Salvator Orlando, Paolo Palmerini, and Raffaele Perego. “Enhancing the 
apriori algorithm for frequent set counting”. In DaWak’01: Proceedding 
of the Third International Conference on Data Warehousing and 
Knowledge Discovery, page 71-82, London, UK, 2001. Springer-Verlag. 
[12] F. Bodon and Lajos Rónyai, “Trie: an alternative data structure for data 
mining algorithms”. Hungarian Applied Mathematics and Computer 
Application, October 2003. 
[13] Y. Ye, C. Chiang, “A parallel apriori algorithm for frequent itemsets 
mining”, Proceeddings of the Fourth International Conference on 
Software Engineering Research, Management and Applications 
(SERA’06), 2006 
[14] F. Bodon,” Surprising results of trie-based FIM algorithms”, IEEE 
ICDM Workshop on Frequent Itemset Mining Implementations 
(FIMI'04), in Bart Goethals and Mohammed J. Zaki and Roberto 
Bayardo editors, CEUR Workshop Proceedings, volume 90, Brighton, 
UK, 1. November 2004. 
[15] Walter A. Kosters and Wim Pijls, “Apriori, a depth-first 
implementation”, IEEE ICDM Workshop on Frequent Itemset Mining 
Implementations (FIMI'04), in Bart Goethals and Mohammed J. Zaki 
and Roberto Bayardo editors, CEUR Workshop Proceedings, volume 90, 
Brighton, UK, 1. November 2004. 
