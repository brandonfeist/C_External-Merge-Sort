Laser-Based Tracking of Randomly Moving People in
Crowded Environments
Masafumi Hashimoto Tomoki Konda and Zhitao Bai
Faculty of Engineering and Science Graduate School of Engineering
Doshisha University Doshisha University
Kyotanabe, Kyoto 610-0394 Japan Kyotanabe, Kyoto 610-0394 Japan
mhashimo@mail.doshisha.ac.jp
Kazuhiko Takahashi
Faculty of Engineering and Science
Doshisha University
Kyotanabe, Kyoto 610-0394 Japan
katakaha@mail.doshisha.ac.jp
Abstract - This paper presents a people tracking system with
multiple sensor nodes allocated in an environment. Each sensor
node consists of a two-layered laser range sensor (LRS) that
detects the positions of waists and knees of people. From the laser
images of the people, heuristic-rule-based and global-nearest-
neighbor (GNN)-based data association can identify a large
number of people in crowded environments. The identified
people are tracked via a model-based tracker; the interacting
multiple model (IMM) estimator is applied to track people
moving randomly and flexibly, such as walking, running,
going/stopping suddenly, and turning suddenly. Simulation and
experimental results validate our people tracking method.
Index Terms - People tracking, Laser range sensor,
Interacting multiple model estimator, Data association
I. INTRODUCTION
The tracking (i.e., estimation of motion) of multi-
interacting people is an important issue for surveillance,
security, service robotics, intelligent transport system, and
many other applications. There has been much interest in the
use of stereo vision or laser range sensors (LRSs). In this
paper, we focus on laser-based tracking.
Compared with vision-based tracking systems, laser-
based tracking systems are insensitive to lighting conditions
and require less data processing time. Thus, a number of laser-
based tracking systems have been developed in the past years
[1–10]. In sparse environments, laser-based tracking systems
can provide good accuracy; however, the tracking accuracy
reduces in cluttered and crowded environments, where a lot of
interactions and occlusions of multiple people occur. To
address with this problem, multiple people tracking based on
Bayesian filters, such as the Kalman filter and the Particle
filter, has been achieved [5–10]. In addition, data association
(one-to-one matching of tracked people and laser
measurements), such as the joint probabilistic data association
filter (JPDAF) and the multiple hypothesis tracker (MHT) [14,
15, 18], has been implemented for reliable tracking. However,
the limitations of conventional laser-based people tracking
systems are inherent and evident.
Most laser-based tracking systems use a laser scanning in
a single plane and apply a leg tracking method, where people
are represented by the states of their two legs; namely, a single
augmented state or a high-level track in which two low-level
leg tracks are associated. This approach makes it difficult to
detect multiple people accurately in crowded environments.
Therefore, track lost often occurs. A typical solution to
manage with this problem is to simultaneously detect different
body parts of a person, such as legs and torso, using multi-
layered LRS [11–13]. Moreover, by allocating multi-LRSs as
sensor nodes at different positions in an environment, we can
reduce occlusions of people in cluttered environments and
improve the tracking performance [4, 6, 7].
Most conventional laser-based tracking systems based on
Bayesian filter are built under the assumption that people walk
at almost constant speed. Therefore, when people move
randomly and flexibly, such as walking, running, going or
stopping suddenly, and turning suddenly, the tracking
performance significantly deteriorates. People typically move
and act under the constraints of an environment, making
human behavior strongly dependent on the location. For
randomly moving people, a single model (constant velocity
model) is insufficient to represent the people’s motion. A
multi-model based approach in which different models run in
parallel and describe different aspects of the people’s behavior
is an effective technique to track randomly moving people; in
the aerospace field, one of the typical multi-model based
approaches to track maneuvering targets is the interacting
multiple model (IMM) estimator [16, 17].
This paper presents a laser-based tracking system for
randomly moving people in a crowded environment. Multiple
two-layered LRSs are allocated at different positions in the
environment. This detects different body parts of people
simultaneously, thus allowing a robust detection of people.
The IMM based tracking enables tracking randomly moving
people. This paper is organized as follows: Section II presents
an overview of our experimental system. Sections III and IV
31
 
Proceedings of the 2010 IEEE 
International Conference on Automation and Logistics 
August 16-20 2010, Hong Kong and Macau 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
978-1-4244-8376-1/10/$26.00 ©2010 IEEE  
 
present our tracking method. Section V describes simulation
and experiment to evaluate the tracking method, followed by
our conclusions.
II. EXPERIMENTAL SYSTEM
Figure 1 shows our experimental sensor node. It consists
of two LRSs (LRSH and LRSL). Each LRS captures distance
samples by scanning a single laser beam in a horizontal plane.
Therefore, we construct a two-layered LRS by setting two
LRSs at different heights. LRSH detects people’s waists and
LRSL detects their knees. The view angle of the LRS is 180
deg. In our experiment, we allocate two sensor nodes in the
environment.
Figure 2 shows the sequence of people detection and
tracking. In each sensor node, we extract the distance samples
(laser measurements) related to people on the basis of the
background subtraction method from the laser images from
LRSH and LRSL. The distance samples obtained from the
same object have the same values, while those obtained from
different objects are significantly different. Thus, the distance
samples are clustered by checking the gap between two
adjacent samples. Based on the sample clustering, we group
the laser measurements and obtain the representative point of
each group. We perform the clustering individually using each
LRS.
The distance samples filtered in each sensor nodes are
collected into a computer. Based on the distance samples, we
detect people and identify them via the global-nearest-
neighboring (GNN)-based data association [18]. The
identified people are tracked based on the IMM estimator [16,
17].
III. PEOPLE TRACKING
A. Interacting Multiple Model (IMM) Estimator Based
Tracking
We classify person motion into the following three
patterns:
LRSH
LRSL
Figure 1. Experimental sensor node.
LRSH
Background subtraction
and grouping
People detection
Tracking
Sensor node #1
Background subtraction
and grouping
Sensor node #2
LRSL LRSH LRSL
Data association
Figure 2. Sequence of people detection and tracking.
a) Constant velocity model (Model 1): Person moves at
almost constant speed.
b) Sudden acceleration/deceleration model (Model 2):
Person suddenly increases/decreases the speed and turns.
c) Stop model (Model 3): Person stops.
Motion equation of the three models is given by Eqs. (A.1)
and (A.2) in Appendix. We represent the motion equation of
the n-th model, where n = 1, 2, 3, by the following vector
form:
),( 11
n
t
n
t
nn
t ??? vxfx ? (1)
where Tnnnnnn vyx ),,,,( ?? ??x . ),( nn yx is the person’s
position in a global coordinate frame, and n? is the moving
direction of the person. nv and n?? are the linear and turning
velocities of the person, respectively. Tnnn v ),( ???? ??v is
the disturbance, which is assumed to be zero mean and having
white noise sequence with the variance ),diag( nnv
n qq
??
?Q .
For the Models 1 and 3, we set 1vq ,
1
??
q , 3vq , and
3
??
q at
small values; for the Model 2, we select larger 2vq and
2
??
q
than 1vq and
1
??
q . In our experiments shown in Section V, we
set their variance at
)/srad1.0,/sm1.0diag( 42421 ?Q ,
)/srad100,/sm50diag( 42422 ?Q , and
)/srad1.0,/sm1.0diag( 42423 ?Q .
The LRS measurements give the waist (knee) positions of
the person in the global coordinate frame by Tyx zz ),(?z .
The measurement model related to both LRSH and LRSL is
t
n
tt zHxz ??? (2)
where
?
?
?
?
?
?
?
?
?
00010
00001
H .
z? is the measurement noise, which is assumed to be zero
32
mean and having noise sequence with the variance R. In our
experiments shown in Section V, we set the variance at
)m01.0,m01.0diag( 22?R .
Based on Eqs. (1) and (2), we track the person via the
IMM estimator [16, 17]. To track multiple people, as shown in
Fig. 3, a validation region is set around the predicted position
of each tracked person. The measurement inside the validation
region is considered to come from the tracked person, and it is
applied to the track update with an IMM estimator. As in Fig.
3 (a) and (c), in crowded environments, multiple
measurements exist inside a validation region; multiple
tracked people also compete for measurements. To achieve the
reliable data association (matching of tracked people and
measurements), we apply GNN [18, 19], in which a cost
matrix based on the laser measurements (distance samples
related to the people’s waists and knees) can be minimized.
The methods of setting the validation region and cost matrix
are detailed in Section IV.
In Fig. 3 (b), person #1 matched with the waist
measurement taken by LRSH is updated by the waist
measurement. The person #2 that is not matched with any
waist measurement is updated by the knee measurements
taken by LRSL. In Fig. 3(b) and (d), person #1 matched with
both the waist and knee measurements is updated using only
the waist measurement.
B. Track Management
Moving people always appear in and disappear from the
sensing area of the LRS. They also meet interaction and
occlusion. In order to handle such conditions, we implement a
track management system based on the following rules:
a) Track initiation: As shown in Fig. 3 (a) and (d), the
measurements that are not matched with any tracked people
are considered to come from new people or false alarms,
which disappear soon. Therefore, we tentatively initiate
tracking of the measurements with the IMM estimator. If the
measurements are always visible in more than N1 seconds,
they are considered to come from new people, and the
tracking is continued. If the measurements disappear within N1
seconds, they are considered to be the false alarms, and the
tentative tracking is terminated.
b) Track termination: When the tracked people exit the
sensing area of the LRS or they meet occlusion, no
measurements exist within their validation regions. If no
measurements arise from the temporal occlusion, the
measurements appear again. We thus predict the positions of
the tracked people with the IMM estimator. If the
measurements appear again within N2 seconds, we proceed
with the tracking of objects. Otherwise, we terminate the
tracking.
In our simulation and experiment described in Section V,
we set N1 = 0.7 and N2 =1.2 by trial and error.
Person #1 Person #2
Waist measurement
Person #1 Person #2
(a) Tracked people and (b) Data association with
waist measurements waist measurements
Person #1 Person #2
Knee measurement
Person #1 Person #2
(c) Tracked people and (d) Data association with
knee measurements knee measurements
Figure 3. Data association of tracked people and laser measurements. The
closed circles and open diamonds indicate the tracked people and the
measurements, respectively. The dashed lines in (a) and (c) indicate the
validation region. The red lines in (b) and (d) indicate the result of data
association.
IV. DATA ASSOCIATION
A. Setting of Validation Region
In this subsection, we describe the method of setting the
validation region. Based on the n-th motion model (where n =
1, 2, 3) of the person, the IMM estimator predicts the position
of the tracked person by
)(
ˆˆ
n
t
n
n
t
n
t
f
P
xH
xH
?
?
(3)
where ?
?
?
3
1
ˆ
m
m
t
mnn
t c xx , and
?
?
?
?
? 3
1
1
1
ˆ
ˆ
m
m
t
mn
m
t
mn
mn
T
T
c
?
?
.
Tmn is the probability that the m-th model jumps into the n-th
model, where m = 1, 2, 3 and n = 1, 2, 3. mtxˆ and
m
t 1ˆ ?? are the
state estimate and posterior probability of the m-th model.
As shown in Fig. 4, three circular regions with constant
radius r are set around the predicted positions, 1ˆtP ,
2ˆ
tP , and
3ˆ
tP , of the tracked person, and their union is set as the
validation region for the data association. In the simulation
and experiment in Section V, we set the radius at r = 0.55 m
for LRSH and r = 0.5 m for LRSL .
33
1
ˆ tp
2ˆ tp
3
ˆ tp
Figure 4. Validation region. The red marks indicate the predicted positions of
the tracked person. Orange dotted circles indicate the regions with constant
radius set around the predicted positions. The black dashed lines indicate the
validation region for data association.
B. Calculation of Cost Matrix
In this subsection, we describe the method for calculating
the cost matrix applied for GNN-based data association.
We consider that, in a validation region, I people exist and
J measurements are received, where I is not necessarily equal
to J. The j-th measurements taken by LRSH are denoted by jtz ,
where Jj ,,2,1 ?? ; jtz is the waist position of a tracked
person detected by LRSH, We then define the following cost
matrix D:
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
IJII
J
J
ddd
ddd
ddd
?
????
?
?
21
22221
11211
D (4)
where dij is the Mahalanobis distance when the laser
measurement zjt is matched with the i-th tracked person.
We achieve the data association so that the summed total
distance of D can be minimized [18, 19].
The IMM estimator predicts the n-th model based position
of the i-th tracked person. We therefore obtain the following
distance:
)ˆ()()ˆ( 1 nitjt
n
it
Tn
itjt
n pzSpz ??? ?? (5)
where n = 1, 2, 3. nipˆ is the n-th model based predicted
position of the i-th tracked person. niS is the covariance of the
prediction error )ˆ( nij pz ? .
We define the Mahalanobis distance in Eq. (4) by dij =
minimum ( 321 ,, ??? ).
When the tracked person is invisible by the LRSH, we
determine the Mahalanobis distance based on the knee
measurements by LRSL and achieve the data association.
V. SIMULATION AND EXPERIMENTAL RESULTS
A. Simulation Result of Single Person Tracking
To evaluate the performance of the IMM-based tracking,
we perform a simulation tracking of a person moving at
txt ?sin5.5? [m] and 0?ty [m], where ? is the angular
rate. The person is assumed to be always detected accurately.
The sampling period (scan) is 0.1 seconds. We set the
transition probability matrix at
?
?
?
?
?
?
?
?
?
?
?
9.005.005.0
05.09.005.0
05.005.09.0
T .
For comparison, we perform the Kalman-filter-based
tracking; for the filter, we use only the sudden acceleration/
deceleration model (Model 2) and set the covariance at
)/srad120,/sm50diag( 42422 ?Q . The covariance value is
chosen by trial and error such that it can provide the best
tracking performance in the experiment shown in the
following subsection.
We present Monte Carlo results using 50 simulations. To
evaluate the tracking performance, we calculate the following
normalized position error (NPE) [20]:
?
?
?
?
???
???
? 50
1
22
50
1
22
])()[(
])ˆ()ˆ[(
i
yititxitit
i
itititit
t
zyzx
yyxx
NPE (6)
Here (xi , yi) is the true position of the person in the i-th
simulation, where i = 1–50. (zxi , zyi) are the position of the
person calculated from the sensor measurements. The values
)ˆ,ˆ( ii yx are the filter estimates.
From the definition of the NPE, the values below unity
signify good estimation; the smaller the values become, the
better the tracking performance is. Table 1 shows the result;
the time average and the related standard deviation of NPE in
20 seconds (200 scans). These results clearly indicate that the
IMM-based tracking provides better performance than the
Kalman-filter-based tracking does.
Table 1. Simulation result of normalized position error.
Angular rate [rad/s] IMM-based tracking KF-based tracking
?? 0 0.46 ? 0.04 0.62 ? 0.04
?? 0.01 0.48 ? 0.04 0.63 ? 0.04
?? 0.1 0.58 ? 0.07 0.70 ? 0.07
?? 1.0 0.85 ? 0.10 0.91 ? 0.16
* Average ? Standard deviation
34
B. Experimental Result of Eleven People Tracking
We conducted experiments of tracking eleven people in a
hall environment (8 m ? 6 m) as shown in Fig. 5. The people
move randomly: sudden stop, sudden going, and sudden
turning. Two sensor nodes are set in the environment; a
fisheye camera is equipped with the sensor node #1 to
evaluate the tracking performance.
We tracked the people in 45.3 seconds (453 scans). Figure
6 shows the tracking result. In the experiment, the rate of the
people detection was 95.6%; the number of the track lost was
just one, while misidentification never occurred.
VI. CONCLUSIONS
This paper presented a laser-based people tracking system
for randomly moving people in crowded environments.
Multiple two-layered LRSs allocated at different positions in
the environments allowed reliable detection of people. The
IMM-based tracking algorithm enabled the system to track
people moving randomly and flexibly, such as walking,
running, going or stopping suddenly, and turning suddenly.
Simulation and experimental results validated our tracking
method.
Our method presented in this paper was applied in a
centralized architecture, where people’s images detected by
multiple two-layered LRSs were collected into a computer and
processed by it. Our research effort is directed toward a
decentralized architecture; this provides a degree of scalability
and robustness that cannot be achieved by a centralized
architecture.
APPENDIX
Three models of a motion of a person are given as follows:
? Constant velocity model (Model 1) and sudden acceleration
/deceleration model (Model 2)
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
???
???
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
??
??????
??????
1
1
11
1
2
11
2
111
1
2
11
2
111
cos)
2
1)(
2
1(
2
1
sin)
2
1)(
2
1(
2
1
t
t
tt
tttttt
tttttt
t
t
t
t
t
v
vvy
vvx
v
y
x
?
???
?????????
?????????
?
?
?
?
??
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
???
???
???
??
???
????
????
1
1
2
1
1
2
11
1
2
11
2
1
sin)
2
1(
cos)
2
1(
t
t
t
ttt
ttt
v
vv
vv
?
?
(A.1)
? Stop model (Model 3)
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
??
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
??
??????
??????
???
??
????
????????
????????
?
?
1
1
2
11
1
2
11
4
111
1
2
11
4
111
2
1
sin
2
1cos
8
1
cos
2
1sin
8
1
t
t
tt
tttttt
tttttt
t
t
t
t
t
v
vvy
vvx
v
y
x
?
?
?
?
?
(A.2)
where ),( yx is the person’s position in a global coordinate
frame, and ? is the moving direction of the person. v and ??
are the linear and turning velocities of the person,
respectively. v? and ?? ? are the disturbances. ? is the
sampling period.
REFERENCES
[1] People Detection and Tracking, Proc. of the IEEE ICRA 2009 Workshop,
2009.
[2] E.Prassler, J.Scholz and A.Elfes, “Tracking Multiple Moving Objects for
Real-Time Robot Navigation,” Autonomous Robots, Vol.8, pp.105–116,
2000.
[3] C.Wang, C.Thorpe, and S.Thrun, “Online Simultaneous Localization and
Mapping with Detection and Tracking of Moving Objects: Theory and
Results from a Ground Vehicle in Crowded Urban Areas,” Proc. of Int.
Conf. on Robotics and Automation (ICRA 2003), CD-ROM, 2003.
[4] K.Nakamura, H.Zhao, R.Shibasaki, K.Sakamoto, T.Ooga, and
N.Suzukawa, “Tracking Pedestrians by using Multiple Laser Range
Scanners,” Proc. of ISPRS Congress, Vol. 35, Part B4, pp.1260–1265,
2004.
[5] M. Hashimoto, S. Ogata, F. Oba, and T. Murayama, “A Laser Based
Multi-Target Tracking for Mobile Robot,” Intelligent Autonomous
Systems 9, pp.135–144, 2006.
[6] H. Nishimura, M. Hashimoto, Y. Matsui, and K. Takahashi, “People
Tracking with Multiple Laser Range Sensors,” Proc. of Int. Conf. on
Mechatronics and Information Technology (ICMIT2007), Proc. of SPIE
Vol. 6794 679410-1-6, 2007.
[7] A.Fod, A.Howard, and M.J Mataric, “A Laser-Based People Tracker,”
Proc. of 2002 IEEE Int. Conf. on Robotics & Automation (ICRA 2002),
pp.3024–3029, 2002.
[8] D.Schulz, W.Burgard, D.Fox, and A.B.Cremers, “People Tracking with
Mobile Robot using Sample-based Joint Probabilistic Data Association
Filters,” Int. J. of Robotics Research, pp.99–115, 2003.
[9] O.Frank, J.Nieto, J.Guivant, and S.Scheding, “Multiple Target Tracking
Using Sequential Monte Carlo Methods and Statistical Data
Association,” Proc. of 2003 IEEE Int. Conf. on Robotics & Automation
(ICRA 2003), pp.2718–2723, 2003.
[10] M.Lindstrom and J.-O.Eklundh, “Detecting and Tracking Moving
Objects from a Mobile Platform Using a Laser Range Scanner,” Proc. of
2001 IEEE/RSJ Int. Conf. on Intelligent Robots and Systems
(IROS2001), CD-ROM, 2001.
[11] K.Takagi, S.Ando, and M.Hashimoto, “Pedestrian Detection Using In-
vehicle Multilayer LIDAR,” Proc. of 13th World Congress & Exhibition
on Intelligent Transport Systems and Services, 2006.
[12] S. Gidel, C. Blanc, T. Chateau, P. Checchin, L. Trassoudaine, “A Method
based on Multilayer Laserscanner to Detect and Track Pedestrians in
Urban Environment,” Proc. of IEEE Intelligent Vehicle Symp., pp. 157–
162, 2009.
[13] A. Carballo, A. Ohya, amd S. Yuta, “Fusion of Double Layered Multiple
Laser Range Finders for People Detection from a Mobile Robot,” Proc. of
IEEE Int. Conf. on Multisensor Fusion and Integration for Intelligent
Systems (MFI 2008), pp. 677-682, 2008.
[14] Y.Bar-Shalom and T.E.Fortmann, “Tracking and Data Association,”
Academic Press,Inc., 1988.
35
[15] K.R.Pattipati, R.L.Popp and T.Kirubarajan, ”Survey of Assignment
Techniques for Multitarget Tracking,: Multitarget-Multisensor Tracking:
Applications and Advances volume III (Edited by Y.Bar-Shalom and
W.D. Blair),” Artech House, Inc., pp.77–159, 2000.
[16] H.A.P.Blom, and Y.Bar-Shalom, “The Interacting Multiple Model
Algorithm for Systems with Markovian Switching Coefficient,” IEEE
Trans. on Automatic Control, Vol.33, No.8, pp.780–783, 1988.
[17] E. Mazor, A. Averbuch, Y. Bar-Shalom, and J. Dayan, “Interacting
Multiple Model Methods in Target Tracking: A Survey,” IEEE Trans. on
Aerospace and Electronic Systems, Vol.34, No.1, pp.103–123, 1998.
[18] P. Konstantinova, A. Udvarev, and T. Semerdjiev, “A Study of a Target
Tracking Algorithm Using Global Nearest Neighbor Approach,” Proc. of
Int. Conf. on Systems and Technologies, 2003.
[19] H.W. Kuhn, “The Hungarian Method for the Assignment Problem,”
Naval Research Logistics Quarterly, Vol. 2, No.1–2, pp.83–98, 1955.
[20] S. McGinnity, and G. W. Irwin, “Maneuvering Target Tracking Using a
Multiple-Model Bootstrap Filter,” Sequential Monte Carlo Methods in
Practice (A. Doucet, N. D. Freitas, and N. Gordon, Eds), New York:
Springer-Verlag, 2001, pp. 479–497.
Sensor
node #1
Sensor
node #2
8 [m]
6 [m]
Figure 5. Experiment setup.
(a) Snapshot at 19.7 s. (b) Tracking result at 19.7 s.
(c) Snapshot at 38.6 s. (d) Tracking result at 38.6 s.
Figure 6. Experimental results. (a) and (c) show the snapshots taken by a fisheye camera at different times. (b) and (d) show the tracking results. Here, the orange,
red, and blue symbols indicate people states (constant velocity motion, sudden acceleration/deceleration motion, and stop, respectively), estimated with IMM-
based tracker; the green triangles indicate the sensor nodes; the cyan and magenta dots indicate laser images taken by the sensor nodes.
36
