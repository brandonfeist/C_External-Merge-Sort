Mining Efficacious Association Rules under Length-Decreasing Support Constraint 
 
Lingwei Yan 
Department of Physics 
Dalian Jiaotong University 
Dalian, China 
Email: yanlingwei791@163.com 
Weiguo Yi 
Software Institute 
Dalian Jiaotong University 
Dalian, China 
Email: jiekexun98@163.com
 
 
Abstract—In mining association rules, Itemsets with high-
length usually has lower support, but still have potential value. 
To mine efficacious association rules under long-pattern, a new 
mining method of efficacious association rules is proposed 
under length-decreasing support constraint. Compare to other 
mining methods of association rules, the new method can mine 
more efficacious long-patterns and improve correlation 
between the antecedent and the consequent of the rules.  
Keywords-association rules, correlation, length-decreasing 
support, match 
I.  INTRODUCTION 
Data Mining is an active research area and one of the 
most popular approaches is discovering association rules. At 
present, the main research work about association rules 
includes efficiency analysis and correlation analysis. In the 
aspect of improving the efficiency of mining frequent 
itemsets, since R.Agrawal et al firstly introduced the 
association rules mining algorithm Apriori [1], many 
researches have done to make corresponding improvements 
according to the shortage of Apriori. FP-growth [2] is an 
improved mining method which doesn’t generate candidate 
itemsets and has higher efficiency. But it has several 
disadvantages, such as the constructed FP-tree is too large, 
the algorithm is too complex and the generated FP-tree 
doesn’t certainly fit into the main memory at a time. 
Frequent closed itemsets mining algorithms, such as A-Close 
[3], CLOSET [4], CHARM [5], CLOSET+ [6] and FPClose [7] 
etc can reduce the redundant in the frequent patterns. The 
difficulty of frequent closed itemsets mining algorithms is to 
check whether itemsets are closed. Frequent closed itemsets 
mining algorithms generate a relatively smaller result set, so 
the algorithms have better expansibility and intelligibility. 
Aim at the correlation of the generated rules. In order to 
make the rules more interesting, researchers have put 
forward a number of metrics of interestingness. In [8] three 
types of metrics (any-confidence, all-confidence, and bond) 
are proposed to take place of support. In [9] a new metric of 
interestingness by using the information of classification is 
proposed. It gives a definition of interestingness: the support 
of rule is R times more than expected, or the confidence is R 
times more than expected. R is a constant specified by user. 
In [10] an improvement is made based on interestingness in 
[9]. It took account of generalization as well as 
specialization. In [11] a measure of interestingness is derived 
from the correlation of statistics and it is defined as 
P(AB)/sqrt(P(A)P(B)) . It contains two important factors: 
interest factor and support. In [12] a significance measure for 
association is proposed by making use of 2?  correlation test. 
Its interestingness is defined as IS=P(AB)/(P(A)P(B)) . 
Because of the shortcomings of symmetric interestingness in 
[12], in [13] Certainty: P(A) P(?B)/P(A??B) is proposed. 
But it is anti-symmetric for the rules. In [14] a framework 
based on correlation is proposed. In this framework, it uses 
residual analysis to determine whether two items are 
independent. In [15] a method based on linear regression and 
reverse authentication is presented to verify the correlation of 
the association rules. The method is based on the analysis of 
the correlation of the incident and verifies the generated rules 
through the selected time period. Therefore, how to select the 
size of time period will become an issue which is worth 
exploring. 
The existing association rules mining algorithms are 
mostly studying on the efficiency and correlation analysis. 
So it is hard to mine the long itemsets with low support. 
Therefore, this paper did some corresponding analysis and 
proposed a length-decreasing support constraint to mine long 
itemets, then combined the effective association rules mining 
method to mine the association rules. 
II. THE BASIC PROBLEM 
Given a transaction set D, mining association rules is to 
find the rules whose support and confidence are respectively 
larger than or equal to the minimum support threshold 
( minsup ) and minimum confidence threshold ( minconf ) 
given by user. Therefore the association rule mining can be 
divided into two sub-problems as follows: 
Find out all the itemsets, the support and confidence of 
which are larger than or equal to the minsup  required by the 
customers. The itemsets with minsup  are called frequent 
sets. 
Set up association rules through frequent sets. Finding 
out all M’s non-empty subsets ms to each frequent set M. 
Association rule m (M-m)?  can be obtained 
if support(M)/support(m) minconf? . 
support(M)/support(m)  is defined as the confidence of the 
rule m (M-m)?  where m  is the antecedent of the rule and 
M m?  is the consequent of the rule.  
2010 International Conference on Artificial Intelligence and Computational Intelligence
978-0-7695-4225-6/10 $26.00 © 2010 IEEE
DOI 10.1109/AICI.2010.269
144
The traditional association rules mining uses fixed 
minimum support threshold, thus it is unable to extract the 
frequent patterns with low support and it can’t reflect the 
changing of the minimum support of itemsets with different 
length. Besides, the traditional association rules mining 
adopts confidence threshold. Confidence can denote the 
probability that some itemset’ emergence will lead to others’ 
occurrence. But we notice that the confidence of association 
rule F=>E only considers the possibility of the case when E 
and F will occur simultaneously, without considering the 
possibility of the case when only E occur and the case 
whether E and F are correlated. Then many association rules 
obtained are ineffective. 
III. LENGTH-DECREASING SUPPORT CONSTRAINT 
A. The Formula of Length-Decreasing Support 
According to the above-mentioned problems, this paper 
proposes a new length-decreasing support constraint to mine 
those long patterns which have low support but have 
potential value. Considering that the changing of the support 
can not only reflect the requirement of the minimum support 
for different long itemsets, but also can aim at datasets from 
different fields, the correlation coefficient is need to be 
capable of adjustment. Therefore, we define the calculation 
function as follows. 
-2 2a k+b+c 1-d k (k<max_length)f(k)=
s (k max_length)
?? × ×?
???
     (1) 
where k is the length of the itemset, a, b, c and d are 
coefficients (a<0,b>0,0<c?1, d>0), s is a constant, and 
max_length denotes the maximum length. When the length 
of the itemset reaches the threshold given by experts, the 
corresponding minimum support will get the value s and no 
longer reduce. The maximum support threshold is f(1), that 
is, it is the support threshold of itemsets whose length is 1, 
f(1)= -2a+b+c 1-d× <1. The minimum support threshold is 
f( max_length )=s>0. So the range of f(k) is [s, f(1)]. 
z How to determine the parameters 
For example, when ( )f k  is selected as the elliptic 
function curve, we can use the following value to compute 
the parameters. 
2f(1)=c 1 d ?× ?                                  (2) 
( (max_-2 2f max_length)=c 1-d length) s× =          (3) 
z The significance of the formula 
The formula contains linear function and elliptic function 
so as to do corresponding adjustment according to datasets 
from different fields. When the minimum support of frequent 
itemsets with different length decrease linearly, we can set 
the parameter c to zero; when meet elliptic diminishing 
relations, we can set both a  and b  to zero; when adjusting 
the minimum support curve with different length, we can 
respectively set the corresponding coefficients and obtain a 
combination of linear function and elliptic function. Fig. 1 
shows the relationship between ( )f k  and k. 
 
B. related properties 
Property 1 x y? ? , then ( ) ( )support x support y> . 
Property 2 Any itemset whose length is k satisfies: 
f(1)?f(k)?f(k+1), then f(k) is called a length-deceasing 
support constraint to the transaction database. 
Property 3 Any itemset x whose length is kx satisfies: 
xsupport(x) f(k )? , then x is called a frequent itemset that 
satisfies a length-deceasing support constraint. 
Property 4 The property of smallest valid extension 
(SVE): Assume itemset x and itemset y, their length are kx 
and yk  respectively and x y? , support(x)<f(kx). Then the 
necessary condition that y is a frequent itemset to ( )yf k  is 
yk ?
-1f (support(x)) . 
In our problem, an itemsets can be frequent even if its 
subsets are infrequent. So the traditional way to mine 
association rules loses effectiveness in removing the 
candidate itemsets. Therefore, we mainly use Property 4 and 
the constant s to discard non-frequent itemsets.  
IV. EFFICACIOUS ASSOCIATION RULES 
According to the problems discussed above, this paper 
considered the correlation between the antecedent and 
consequent of the generated rules, and then applied the 
framework of support-match to produce association rules by 
combining the existing the research results [16]. Match is 
defined as follows: 
Assume P(A) denotes the probability that A occurs, P(B) 
denotes the probability that B occurs, P(AB) denotes the 
probability that A and B occur simultaneously, P( AB ) 
denotes the probability that A  and B occur simultaneously, 
P( A ) denotes the probability that A doesn’t occurs. Then, 
we define the match of rule A B?  as match = (the 
confidence of A B? )-(the confidence of A B? ), that is:  
P(AB) P( A B)match= -
P(A) P( A )
                          (4) 
To facilitate the understanding and calculation of the 
formula, the above formula can be transformed as:  
Figure 1.  the curve of minimum support function 
Length of 
itemsets 
linear 
elliptic 
max-length 1
1
 
f(1) 
f(max-length)
145
P(AB)-P(A) P(B)match=
P(A) (1-P(A))
×
×
                    (5) 
We make the declaration that an itemset is unrelated to 
any other itemset when its support is 1, in which case we can 
overlook the match of this item set with other item sets. 
Consequently, the probability for any itemset A’s occurrence 
is 0< ( )P A <1. The range of match is [-1, 1] because 
0< ( ) / ( )P AB P A ?1, 0< ( ) / ( )P AB P A ?1. If match>0, we 
have ( ) ( ) ( )P AB P A P B> , which proves that A and B are 
correlated. If match=1, we have ( ) ( ) ( )P AB P A P B= = , 
which indicates the case that A and B appear simultaneously. 
Furthermore, we analyze the match theoretically. We 
define the concept of correlation. 
P(AB)cor=
P(A) P(B)×
                                (6) 
1 P( AB)cor
P( A ) P(B)
=
×
                               (7) 
Hence, we have ( 1) ( )match cor cor P B= ? × . We will get 
1 1cor cor= = when cor  equals to cor1 for the reason that 
1 P(A)1
1 P(A)
corcor ? ×=
?
. That is to say, A is unrelated to B 
when A is unrelated to B. Moreover, 1cor  will be smaller 
than 1 while cor  is bigger than 1. In other words, A is 
negatively correlated to B if A is positively correlated to B. 
We can also find from the equation that the definition of 
match not only includes some correlation factors but also 
some ( )P B  factors. Therefore, it can reveal the validity of 
rule A=>B with the definition of match. 
V. EXPERIMENTAL RESULTS AND ANALYSIS 
The paper uses the adult database to verify the 
effectiveness of the proposed algorithm. Experiments are 
carried out on an IBMR52 notebook computer with 512M 
memory and 1.86GHz main frequency. The numerical 
attributes need to be discretized and we extract 24000 
records from the database. The objective of the experiments 
is to test whether the algorithm can dig more effective long 
patterns and improve the correlation between the antecedent 
and consequent of the rules under long patterns. 
Experimental settings are as follows: 
The Formula of Length-Decreasing Support 
adopts -2 2f(k)=c 1-d k× , where (1) 0.3f = , 
f(max_length) =0.5, max_length =5, and the minimum 
match=0.3. The experimental result is shown in Fig.2.  
When the number of records is 24,000, we extract two 
rules to do analysis: frequent itemset 14,11,12,19,23, rule 
14=>11,12,19,23, support=0.39, match=0.34; frequent 
itemset 13,14,11,19,23, rule 13,14=>11,19,23, support=0.45, 
match=0.31. If we use a constant minimum support, the 
above itemsets whose length is 5 can’t be frequent, not to 
mention generating rules. But if we use a length-decreasing 
support constraint, they will meet the requirement and 
generate association rules. Therefore, the method proposed 
in this paper can not only mine the long patterns with 
potential value, but also can obtain efficacious association 
rules.  
VI. CONCLUSIONS 
In order to discover the long patterns with potential value 
and remove the invalid short patterns in intensive database, 
this paper proposes a new length-Decreasing Support 
Constraint and combines the framework of support-match to 
generate association rules. Theory and experimental results 
have proved that the proposed method can not only discover 
the long patterns with potential significance but also can 
generate efficacious association rules. We can believe that 
the proposed method has high theoretical and practical value 
in the study of intensive data or decision support fields. 
REFERENCES 
[1] R. Agrawal, T Imielinski, A Swami. “Mining association rules 
between sets of items in large databases [A],” Proc 1993 ACM 
SIGMOD Conference on Management of data[C]. Washington, 
DC.207-216, 1993.  
[2] Agarwal R, Aggarwal CC, Prasad VVV. ”A tree projection algorithm 
for generation of frequent itemsets[J],” Parallel Distribute Compute, 
61:350-371, 2001.  
[3] Pasquier N, Bastide Y, Taouil R, Lakhal L. “Discovering frequent 
closed itemsets for association rules [C],” In: Proceeding of the 7th 
international conference on database theory (ICDT’99), Jerusalem, 
Israel, pp: 398–416, 1999.  
[4] Pei J, Han J, Mao R. “CLOSET: an efficient algorithm for mining 
frequent closed itemsets [C],” In: Proceeding of the 2000 ACM-
SIGMOD international workshop data mining and knowledge 
discovery (DMKD’00), Dallas, TX, pp: 11-20, 2000.  
[5] Zaki MJ, Hsiao CJ. “CHARM: an efficient algorithm for closed 
itemset mining [C],” In: Proceeding of the 2002 SIAM international 
conference on data mining (SDM’02), Arlington, VA, pp: 457-473, 
2002.  
[6] Wang J, Han J, Pei J. “CLOSET+: searching for the best strategies for 
mining frequent closed itemsets [C],” In: Proceeding of the 2003 
ACM SIGKDD international conference on knowledge discovery and 
data mining (KDD’03), Washington, DC, pp: 236–245, 2003. 
[7] Grahne G, Zhu J. “Efficiently using prefix-trees in mining frequent 
itemsets [C],” In: Proceeding of the ICDM’03 international workshop 
on frequent itemset mining implementations (FIMI’03), Melbourne, 
FL, pp: 123–132, 2003. 
[8] Omiecinski E. R.. “Alternative interest measures for mining 
associations in databases,” IEEE Transactions on Knowledge and 
Data Engineering, 15(1): 57-69, 2003. 
0
10
20
30
40
50
60
70
80
90
8 12 16 20 24
number of records(1000)
tim
e(
s)
Figure 2.  Efficiency of rule generating with 
length-decreasing support using match 
146
[9] Srikant R. , Agrawal R. . “Mining generalized association rules,” In: 
Proceedings of the 21th International Conference on Very Large Data 
Bases, Tokyo, Japan, 409-419, 1995. 
[10] Srikant R., Agrawal R. . “Mining quantitative association rules in 
large relational tables,” In: proceedings of the 1996 ACM SIGMOD 
International Conference on Management of Data,Montreal, Quebec, 
Canada, 1-12, 1996. 
[11] Tan Pang-Ning, Kumar V. . “Interestingness measures for association 
patterns: A perspective,” Department of Computer Science and 
Engineering, University of Minnesota, Minneapolis, USA: Technical 
Report, 2000. 
[12] Brin S., Motwani R., Silverstein C. . “Beyond market baskets: 
Generalizing association rules to correlations,” In: Proceedings of the 
1997 ACM SIGMOD International Conference on Management of 
Data, Tucson, Arizone, USA, 265-276, 1997. 
[13] Ahmed K. M., El-Makky N. M., Taha Y.. “A note on beyond market 
baskets: Generalizing association rules to correlations,” ACM 
SIGKDD Explorations Newsletter, 1 (2): 46-48, 2000. 
[14] He Zhi, huang Hou Kuan, Tian Shengfeng; “An Approach to Finding 
Optimized Correlated Association Rules,” Chinese Journal of 
Computers, 29(6):906-913, 2006. 
[15] Ye Deqian, Zhao Shilei; “Correlation Technique Research of 
Association Rule Base on Linear Regression,” Journal of Computer 
Research and Development, 291-294, 2008. 
[16] Wei Jinmao, Yi Weiguo et al. “Novel measurement for mining 
effective association rules [J],” Knowledge Based Systems 19 739–
743, 2006. 
 
147
