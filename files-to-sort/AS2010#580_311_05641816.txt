Efficient Strategies for Many-task Frequent Pattern 
Mining in Cloud Computing Environments 
KawuuW.Lin 
Department of Computer Science and Information 
Engineering 
National Kaohsiung University of Applied Sciences 
Kaohsiung, Taiwan 
linwc@cc.kuas.edu.tw 
Abstract-The goal of data mining is to discover the hidden 
useful information from large databases. Mining frequent 
patterns from transaction databases is an important problem in 
data mining field. As the size of database increases, the 
computation time and the required memory increase severely. 
Parallel and distributed computing techniques have attracted 
extensive attentions on the ability to manage and compute the 
significant amount of data in the past decades. The difficulty of 
mining large database launched the research of designing parallel 
and distributed algorithms to solve the problem. However, most 
of the past studies did not focus on the many-task issue that is 
very important, especially in cloud computing environments. In 
cloud computing environments, application is provided as service 
like Google search engine, meaning that it will be used by many 
users at the same time. In this paper, we propose a set of 
strategies for many-task frequent pattern mining. Through 
empirical evaluations on various simulation conditions, the 
proposed strategies deliver excellent performance in terms of 
execution time. 
Keyword?Data mining, cloud computing, association rule 
mining, frequent pattern mining 
I. INTRODUCTION 
The basic conception of frequent pattern mining problem is 
to discover the pattern whose frequency of appearance in the 
database is greater than a specific threshold. An association 
rule is defmed as X=>Y, where X and Y are sets of items. The 
concept of association rule mining is to discover the sets of 
items tending to associate with the others in the database. The 
studies on association rule mining can be classified into two 
types, 1) the generate-and-test [w] (Apriori-like) approach and 
2) the frequent pattern growth approach [5] (FP-growth-like). 
The Apriori-like methods iteratively generate candidate 
itemset of size (k+ 1) from frequent itemset of size k and scan 
the database repetitively to test the frequency of each 
candidate itemset. Definitely, the Apriori-like methods suffer 
from the large number of candidate itemsets, especially when 
the support threshold is small. In view of this reason, Han et 
al. [5] proposed a novel data structure, named frequent pattern 
tree (FP-tree), in which the transactions are compressed and 
stored. A mining algorithm, namely FP-growth was also 
proposed for discovering the frequent patterns from the FP-
978-1-4244-6588-0/10/$25.00 ©201 0 IEEE 
620 
Yu-ChinLuo 
Department of Computer Science and Information 
Engineering 
National Kaohsiung University of Applied Sciences 
Kaohsiung, Taiwan 
kim-x@yahoo.com.tw 
tree. FP-growth needs only two scans on physical databases 
and therefore has a great improvement on the execution time. 
As the size of database increases, the computation time and 
the required memory increase severely. Many studies on 
association rules mining were proposed mainly to improve the 
efficiency in terms of execution time. In the past decades, 
parallel and distributed computing (PDC) techniques have 
attracted extensive attentions on the ability to manage and 
compute the significant amount of data. The difficulty of 
mining large database launched the research of designing 
parallel and distributed algorithms to solve the problem [3], 
[4], [6], [7], [8], [9], [10], [11], [12], [13]. The main approach 
of the existing studies is to divide the database and then to 
distribute each part of the database to nodes or processors for 
mining with the goal to distribute the computation loading. 
During the mining process, the nodes will exchange required 
transactions from each other. The workload of data 
exchanging among nodes becomes heavy when the average 
length of transaction is long or the size of database is large. 
Although many algorithms have been proposed, the execution 
efficiency of frequent pattern mining is still a challenge to the 
researchers due to the data explosion. 
In [9], the authors proposed a data mining method named 
CARM, which is able to efficiently utilize the cloud nodes to 
discover frequent patterns in cloud computing environments, 
but did not discuss the many-task issue that is very important 
in this kind of environments. The authors [9] focused on only 
the aspect of speeding up the mining process for a single task. 
In cloud computing environments, application is provided as 
service like Google search engine, meaning that it will be used 
by many users at the same time. In this paper, we propose a set 
of strategies for many-task frequent pattern mining. Through 
empirical evaluations on various simulation conditions, the 
proposed strategies deliver excellent performance in terms of 
execution time. 
In the following sections, we briefly review related work in 
Section 2. In Section 3, the strategies for many-task frequent 
pattern mining are presented. The empirical evaluation for 
performance study is made in Section 4. The conclusions are 
given in Section 5. 
II. RELATED WORK 
In this section, we review the past studies on the three 
subjects closely related to this research, namely A) FP-tree and 
FP-growth and B) CARM algorithm. 
A. FP-tree and FP-growth 
Han et al. [5] proposed a tree based data structure named FP­
tree and the corresponding mining algorithm named FP-growth 
for discovering frequent patterns. The algorithm requires two 
scans on database to complete the mining task. The first scan is 
to calculate the support of each item. In the meantime, it also 
creates a header table recording the item name, its 
corresponding support and the first node-link linking to the fIrst 
node in the FP-tree carrying the same item name. The items of 
the header table are sorted descendingly by the support. In the 
second scan, for each transaction, the items with support 
smaller than the threshold are filtered out and the remaining 
items are sorted in descending order by the support value. The 
sorted items of each transaction are inserted to the tree, namely 
FP-tree. The structure of an FP-tree consists of a root node 
labeled as null, a set of item-prefix subtrees as the children of 
root, and a header table. The structure of the nodes of FP-tree is 
as <item-name, count (support), node-link>, in which the item­
name is the item name used for identification, the count is the 
number of transactions reaching this node by the same path 
from root, and the node-link is a pointer linking to the next 
node in the FP-tree with the same item name. To insert a 
transaction, P, into the FP-tree, T, we check whether T has a 
child, n, such that n. item-name is identical to the item-name of 
the first element of P. If the node exists, the count of n is 
increased by 1. Otherwise, it creates a new node, m, with the 
same item name as n. Meanwhile, the count of m is set to 1, the 
parent link is set to T, and its node-link is set to the nodes with 
the same item-name via the node-link structure. We recursively 
perform the insertion in order for each item in P until each item 
is inserted into the FP-tree. After the FP-tree is constructed, FP­
growth is used for discovering the frequent patterns. An item of 
the header table is selected to construct the conditional FP-tree 
by inserting all of the prefix paths of the item, which can be 
retrieved by node-link structure in header table. The name of 
the item is called the conditional pattern base. Then the FP­
growth is executed recursively and the conditional pattern base 
is cascaded by new one in each recursion until the conditional 
FP-tree contains only a single path or is an empty tree. The 
frequent patterns can be easily generated by the cascaded 
conditional pattern base and the FP-tree. After processing each 
item in header table, all of the frequent patterns are obtained. 
B. CARM Algorithm 
The algorithm CARM consists of two algorithms, High­
workability Distributed FP-Mine, abbreviated as HD-Mining, 
and Fast Distributed FP-Mine, abbreviated as FD-Mining. The 
main functionality of HD-Mining is to utilize the cloud nodes 
to mine the dataset that is with huge amount of frequent 
patterns, brought by the small support threshold, the large 
number of items, or the large database. The limitation of the 
conventional algorithm for mining this kind of dataset is the 
available memory of a single node. HD-Mining can merge the 
memory of several nodes to discover the frequent patterns. 
Furthermore, cloud computing techniques are often expected 
621 
to have high computation ability. The proposed FD-Mining 
focuses on the fast discovery of frequent patterns by utilizing 
the cloud nodes, and is useful to the applications that 
emphasize real time mining. 
To process a mining task, CARM invokes FD-Mining fIrSt in 
order to fast discover the frequent patterns. Since FD-Mining 
occupies more memory than HD-Mining, HD-Mining will be 
invoked if FD-Mining cannot mine the database. Finally, the 
algorithm ends with returning the frequent patterns. In CARM, 
the execution efficiency is set as the highest priority. Therefore, 
CARM applies FD-Mining first. If FD-Mining fails, CARM 
will use HD-Mining to complete the mining task. 
III. PROPOSED STRATEGIES FOR MANY-TASK FREQUENT 
PATTERN MINING 
In distributed environments, workload balancing among 
computing nodes is a critical issue. A good strategy for 
distributing workload will have minimal idle time and minimal 
complete time. Our proposed strategies for many-task frequent 
pattern mining are designed for CARM algorithm. CARM is an 
FP-tree based algorithm, and therefore to distribute the 
workload by header items is an intuitive way. Before applying 
the idea for load balancing, two characteristics should be 
discussed. 
1) The required mining time of each conditional pattern 
base is different. 
In the mining process of FP-growth, each item of 
head table will be used as a conditional pattern base 
and the algorithm will then reconstruct a corresponding 
FP-tree. The process will be performed recursively 
until the FP-tree is empty. The possibility of having 
two same FP-trees with different conditional bases is 
very low and consequently the mining time of each 
conditional pattern base is different. 
2) The required mining time for each conditional pattern 
base cannot be known in advance. 
The FP-tree structure of each conditional pattern 
base is decided by the corresponding subset of data and 
FP-growth will reconstruct FP-trees in the mining 
process so the mining time cannot be known in 
advance. 
Because the required mining time for each conditional 
pattern base is different and cannot be known in advance, we 
propose a set of strategies with the goal to balance the 
workload under these two characteristics. 
1. Balancing Strategy by Equal Working Set (EWS) 
The strategy works as the follows:: 
A. Construct the initial FP-tree and the header table 
namedHT. 
B. Uniformly partition the HT into N disjoint subsets, 
named ht], ht], ... , and htN, where N is the number of 
available computing nodes. 
C. Distribute the FP-tree with ht; to i-th computing node 
for mining. 
In Step B, the header table is uniformly partitioned into 
N parts in which each part has the same number of header 
items. Suppose there are M items of the header table. The 
strategy will randomly select MIN items for each 
computing node. Because the required mining time for 
each conditional pattern base is different and cannot be 
known in advance, we use random selection in this step. 
2. Balancing Strategy by Request On Demand (ROD) 
The EWS strategy is expected to incur a lot of idle time 
because the two challenge characteristics make it difficult to 
distribute the workload equally. To reduce the idle time and the 
complete time, this strategy use the method named request on 
demand. The strategy works as the following steps: 
A. Construct the initial FP-tree and the header table 
namedHT. 
B. Wait for computing node's requesting. 
C. If the computing node does not have the FP-tree, 
distribute the FP-tree with an unprocessed header item 
to the computing node for mining. Otherwise, 
distribute only an unprocessed header item to the 
computing node. 
D. Repeat Step C until all header items in HT are 
processed. 
The advantage of this strategy is that the idle time will be the 
minimal and the workload can be balanced. Although ROD has 
the advantages, the complete time is expected to be extended 
for it requires large a lot of times of data transmission over 
network. 
3. Balancing Strategy by Small Size Working Set (SSWS) 
The advantages of EWS and ROD are the minimal times of 
data transmission and the most workload balanced respectively. 
The third strategy in designed to find the trade-off between 
EWS and ROD. To avoid large amount of data transmission 
times as ROD, the proposed SSWS strategy partitions the 
header items into several working set in which the size of each 
working set is equal. Unlike ROD distributes to computing 
node one header item per time, SSWS distributes a set of 
header items per time to reduce the cost of data transmission. 
The detailed steps are as described below. 
A. Construct the initial FP-tree and the header table 
namedHT. 
B. Partition the HT into disjoint subsets, where each 
subset is with the L header items. 
C. Wait for computing node's requesting. 
D. If the computing node does not have the FP-tree, 
distribute the FP-tree with a subset of header items to 
the computing node for mining. Otherwise, distribute 
only the subset of header items to the computing node. 
E. Repeat Step C until all header items in HT are 
processed. 
In Step B, if L is large the strategy will be identical to EWS. 
If L is set to one, the strategy will be identical to ROD. 
622 
Therefore, determining the value of L is critical to the mining 
process. 
4. Balancing Strategy by Progressive Size Working Set 
(PSWS) 
SSWS attempts to find the trade-off between EWS and ROD. 
Only through detailed experiments can determine a suitable 
value of L. In this paper, we propose a strategy that is able to 
balance the workload by adjusting the size of working set 
dynamically. Unlike SSWS using a fixed size of working set, 
this strategy decreases the size of working set progressively in 
the mining process. The strategy works as follows: 
A. Construct the initial FP-tree and the header table 
namedHT. 
B. Let N be the number of available computing nodes 
and HTR be the remaining header items not processed. 
Partition the HTR into N+ 1 disjoint subsets, named ht], 
ht2' ... , and htN+J. Copy htN+J to HTR 
C. Distribute the FP-tree with ht; to i-th computing node 
for mining. 
D. Repeat Step B until all header items in HT are 
processed. 
IV. EXPERIMENTAL RESULTS 
To evaluate the performance of the proposed algorithm, 
CARM, we use IBM's Quest Synthetic Data Generator [1] to 
generate the workload data for mining. The experiments were 
conducted on a cloud system with three clouds. The fIrst cloud 
contains four nodes, including the kernel node, in which each 
node is equipped with an E8400 2.4GHZ CPU, 1GB of 
available RAM and 320GB of disk storage. The second cloud 
and third cloud contain four and three nodes respectively, in 
which each node is equipped with a P8600 2.4GHZ CPU, 1GB 
of available RAM and 160GB of disk storage. The network 
bandwidth among these three clouds is 100 Mbitlsec. The 
network latency from cloud 1 to cloud 2 is 20 ms on average. 
The network latency from cloud 1 to cloud 3 is 18 ms on 
average. Note that the kernel node is responsible for receiving 
the requests and is not used for mining. Therefore totally ten 
nodes can be used for mining in the system. To verify the 
performance, since there are very few parallel and privacy­
preserved algorithms of frequent pattern mining, we select the 
BTP-tree for comparison, which is one of the most efficient 
algorithms that can parallelize the mining task on grid systems. 
Both of CARM and BTP-tree were implemented in Java, and 
the message passing among nodes and remote function call 
were implemented in Java RMI technology. Since the most of 
the existing parallel algorithms are database dividing approach, 
we select the most efficient one, BTP-tree, for performance 
comparison. 
Effects of varying the number of tasks 
In the experiment, we investigate the effects of varying the 
number of tasks for the proposed strategies and BTP-Tree in 
terms of execution time by varying the number of tasks from 
10 to 50. We generate 50 dataset for performance evaluation. 
The transaction length is modeled as uniform distribution 
bounded from 10 to 30 and the mean is set to 20. The number 
of transactions is modeled as normal distribution and the mean 
is set to 150K. The support threshold is modeled as uniform 
distribution bounded from 0.1 % to 1% and the mean is set to 
0.5%. 
Figure 1 shows the required execution time of our proposed 
strategies and BTP-tree increases with the increase in the 
number of tasks. It is observed that the required execution time 
of each of our strategies is less than that of BTP-Tree. The 
slope of BTP-Tree is about 14.4 and the slope of our proposed 
strategies is about 3.1. It means that our proposed strategies 
can utilize the computing nodes more efficiently. Another 
main reason BTP-Tree requires more time for mining is that 
BTP-Tree needs to distribute the pieces of dataset to 
computing nodes. The size of transmitted dataset is equal to 
the size of original dataset. It can be seen that the data 
transmission requires a lot of time for BTP-Tree. 
Figure 2 shows the execution time of the four strategies. It is 
observed that PSWS is the best one. We also found that ROD 
requires the most execution time because of the lots of times of 
data transmissions. The required execution time of EWS is 
166.3 second, which is 10% larger than that of PSWS, 151.6 
700 ---------- EWS 
· · · · · · · · 0 · · ·  ROD 
600 -- ? -- SSWS -.. ? .-.. psws 
U ---<>-- BTP-tree <ll 500 ? 
<ll 
E 
i= 400 
c 
0 
'"5 " 300 
<ll X 
w 200 
"..,.. 
100 
0 
10 15 20 25 30 35 40 45 50 
Number of Tasks 
Figure 1. The execution time for our proposed strategies 
and BTP-tree with number of tasks varied. 
180 
160 ---- EWS ····· .. ·0···· ROD 
;; 
---.--- SSWS 
140 _ .. --6._ .. PSWS /.. 
U // /.' <ll '// ? 120 y: '  <ll vI' 
E 
i= 100 c 
0 
:s 80 " <ll x 
w 
60 
40 
20 
10 20 30 40 50 
Number of Tasks 
Figure 2. The execution time for our proposed strategies 
with number of tasks varied. 
623 
second. 
V. CONCLUSIONS 
In this paper, we have presented a set of strategies for 
efficiently utilize the cloud nodes to discover frequent patterns 
in cloud computing environments based on CARM algorithm. 
The proposed strategies, including EWS, ROD, SWSS and 
PWSS, have good performance in many-task environments. 
Through empirical evaluations on various simulation 
conditions, the proposed strategies deliver excellent 
performance in terms of execution time. 
REFERENCES 
[I] R. Agrawal and R. Srikant. Quest Synthetic Data Generator. IBM 
Almaden Research Center, San Jose, California, 
http://www.almaden.ibm.comlcs/questlsyndatahtml. 
[2] R. Agrawal, Imielinski T, Swami A. Mining association rules between 
sets of items in large databases. In: Proc. ACM SIGMOD IntI. Conf 
Management Data, 1993, pp. 207-216. 
[3] R. Agrawal, John C. Shafer, "Parallel Mining of Association Rules", 
IEEE Transactions on knowledge and Data Engineering, December 
1996, pp. 962-969. 
[4] R. Agarwal, C. Aggarwal, and V. V. V. Prasad. A Tree Projection 
Algorithm for Generation of Frequent Itemsets, Journal of Parallel and 
Distributed Computing, Volume 61, No 3, 2001, pp. 350-371. 
[5] J. Han, J. Pei, and Y. Yin. Mining Frequent Patterns Without Candidate 
Generation. Proc. of ACM Int. Conf. on Management of Data 
(SIGMOD), 2000, pp. 1-12. 
[6] J.D. Holt, S.M. Chung, "Parallel mining of association rules from text 
databases on a cluster of workstations," Proceedings of 18th 
International Symposium on Parallel and Distributed Processing, 2004, 
pp. 86. 
[7] P. Iko and M. Kitsuregawa, "Shared Nothing Parallel Execution of 
FPgrowth." DBSJ Letters, Volume 2, No.1, 2003, pp. 43-46. 
[8] A. Javed, A. Khokhar, "Frequent Pattern Mining on Message Passing 
Multiprocessor Systems," Distributed and Parallel database, Volume 16, 
Issue 3, 2004, pp. 321-334. 
[9] K. W. Lin and Y. C. Luo, "A Fast Parallel Algorithm for Discovering 
Frequent Patterns," Proceedings of the 2009 IEEE International 
Conference on Granular Computing, 2009 
[10] Y. Qiu, Y. J. Lan and Q. S. Xie, "An improved algorithm of mining from 
FP- tree," Proceedings of the Third International Conference on Machine 
Learning and Cybernetics, 2004, pp. 26-29. 
[II] E.-H. S. Han, G. Karypis, and V. Kumar. Scalable parallel data mining 
for association rules. IEEE Transactions on Knowledge and Data 
Engineering, Volume 12, No 3, 2000, pp. 352 -377. 
[12] J. Zhou, K.-M. Yu, "Tidset-based Parallel FP-tree Algorithm for the 
Frequent Pattern Mining Problem on PC Clusters," Lecture Notes in 
Computer Science 5036, 2008, pp. 18-28. 
[13] J. Zhou, K.-M. Yu, Balanced Tidset-based Parallel FP-tree Algorithm 
for the Frequent Pattern Mining on Grid System, Fourth International 
Conference on Semantics, Knowledge and Grid, 2008, pp.I 03-1 08. 
