- 3457 -
Genetic Network Programming with Estimation of Distribution Algorithms
and its Application to Association Rule Mining for Traf?c Prediction
Xianneng Li, Shingo Mabu, Huiyu Zhou, Kaoru Shimada and Kotaro Hirasawa
Graduate School of Information, Production and Systems, Waseda University, Japan
(Tel : +81-93-692-5261; E-mail: sennou@asagi.waseda.jp, mabu@aoni.waseda.jp, zhy836@toki.waseda.jp,
k.shimada@aoni.waseda.jp, and hirasawa@waseda.jp )
Abstract: In this paper, a novel evolutionary paradigm combining Genetic Network Programming (GNP) and Estimation
of Distribution Algorithms (EDAs) is proposed and used to ?nd important association rules in time-related applications,
especially in traf?c prediction. GNP is one of the evolutionary optimization algorithms, which uses directed-graph struc-
tures. EDAs is a novel algorithm, where the new population of individuals is produced from a probabilistic distribution
estimated from the selected individuals from the previous generation. This model replaces random crossover and mutation
to generate offspring. Instead of generating the candidate association rules using conventional GNP, the proposed method
can obtain a large number of important association rules more effectively. The purpose of this paper is to compare the
proposed method with conventional GNP in traf?c prediction systems in terms of the number of rules obtained.
Keywords: Genetic Network Programming (GNP), Estimation of Distribution Algorithms (EDAs), time-related associ-
ation rule mining
1. INTRODUCTION
The aim of association rule mining is to discover as-
sociation relationships or correlations among a set of at-
tributes in a database [1]. The form of association rules
can be represented as ”X ? Y ”, which means X is
likely to satisfy Y . The most popular model for associa-
tion rule mining is Apriori algorithm [2]. This algorithm
uses the support-con?dence framework to measure the
uncertainty and importance of association rules. Besides,
a method of association rule mining using Genetic Net-
work Programming (GNP) has been proposed [3]. The
algorithm using GNP could extract association rules by
calculating not only support and con?dence, but also ?2
values. GNP is a kind of evolutionary computation algo-
rithm, which uses the directed-graph structures to repre-
sent the genes [4][5][6].
Recently, many data mining methods have been pro-
posed to deal with temporal databases in order to sat-
isfy the demand in time-related dynamic systems. One
of them is time-related association rule mining using Ge-
netic Network Programming (GNP) [7]. In this method,
the database is time-related considering the real-time fac-
tor and Attribute Accumulation Mechanism (AAM) was
proposed to deal with a large number of attributes. Al-
though this method can tell how frequently the events
happen together in time-related dynamic environments,
the process is inef?cient for ?nding the important inter-
actions among the attributes.
The traditional ”time-related association rule mining
using GNP” adopts conventional genetic operators such
as crossover and mutation to generate offspring, which
means that the association rules are generated randomly.
In this paper, a novel evolutionary algorithm combining
GNP and Estimation of Distribution Algorithms (EDAs)
is proposed.
GNP with EDAs imports a learning mechanism to
guide the generation of individuals more ef?ciently,
where a probabilistic model is constructed by selected
outstanding individuals from the previous generation.
The probabilistic model is used to replace the conven-
tional genetic operators, in particular, crossover and mu-
tation.
In this paper, GNP with EDAs has been proposed to
realize the traf?c prediction system. Although traditional
GNP can extract interesting rules for traf?c prediction,
the proposed method can make the rule extraction more
effectively. The major points of this paper are as follows:
• The proposed method selects the outstanding in-
dividuals to construct the probabilistic model to
replace conventional genetic operators, such as
crossover and mutation.
• The database is time-related, which means at dif-
ferent time, the same attribute can have different
meanings. Besides, the database has several cat-
egories, representing several traf?c volumes in the
traf?c ?ow.
• The ef?ciency of the proposed algorithm is proved in
the simulation of a traf?c prediction system, where
several correlation measures are compared in the
evaluation of importance of association rules, such
as Lift(X,Y ), ?2(X,Y ), all?confidence(X,Y )
and cosine(X,Y ), and X is the set of attributes of
the antecedent part of the rule, while Y is the conse-
quent attribute.
The paper is organized as follows. In the next section,
some background is introduced. The proposed GNP with
EDAs is described in section 3. Section 4 presents the
experimental environments, conditions and results using
GNP with EDAs. At last, the paper concludes in section
5.
ICROS-SICE International Joint Conference 2009
August 18-21, 2009, Fukuoka International Congress Center, Japan
PR0002/09/0000-3457 ¥400 © 2009 SICE
- 3458 -
2. BACKGROUND
2.1 Genetic Network Programming (GNP)
Genetic Network Programming is an extension of Ge-
netic Algorithm (GA) and Genetic Programming (GP)
[4]. Like the other evolutionary computation algorithms,
GNP is trained to evolve the population of candidate so-
lutions. As Fig. 1 shows, GNP is composed of three
kinds of nodes: one start node, several judgment nodes
and processing nodes. Typically, judgment nodes are de-
?ned as the set of J1, J2, ..., Jn, which works as if-then
type decision making functions, while processing nodes
are the set of P1, P2, ..., Pm, which works as some kind
of action functions. The directed-graph structure of GNP
can express the attributes as judgment nodes and the con-
nections of judgment nodes is regarded as an association
rule. The implementation of GNP is like this: once GNP
starts, the ?rst execution is the start node, and secondly
the judgments or actions are done in the judgment nodes
and processing nodes.
S
1J 1P
2J
3J 4J
2P
3P
Start Node
Processing Node
Judgment Node
Fig. 1 The structure of GNP.
2.2 Estimation of Distribution Algorithms (EDAs)
EDAs [8][9] are new kind of evolutionary algorithms
that work with a population set of candidate solutions.
This new class of algorithms generalizes conventional
evolutionary algorithms by replacing the genetic opera-
tors such as crossover and mutation with learning and
sampling from the probability distribution which is esti-
mated from a database containing selected best individu-
als from the previous generation. Working in such ways,
the relationships between the individuals can be explic-
itly and effectively captured and exploited. The funda-
mental advantages of EDAs over conventional evolution-
ary algorithms are the absence of multiple parameters to
be adjusted (For example, crossover and mutation proba-
bilities). In conventional evolutionary computation algo-
rithms, the interrelations between the different variables
expressing the individuals are kept implicitly. This phe-
nomenon is called building blocks [9][10][11]. In EDAs,
the interrelations are explicitly represented through the
joint probability distribution associated with the best se-
lected individuals. Based on these advantages, EDAs are
useful and effective tool for solving the real-world opti-
mization problems.
2.3 Attribute Accumulation Mechanism (AAM)
Attribute Accumulation Mechanism (AAM) has been
proposed to deal with a large number of attributes [7]. By
using AAM, the individuals accumulate better attributes
gradually generation by generation. The procedure of
AAM is as follows:
1. In the initial generation, a small attribute set is ran-
domly selected from the whole attribute set which
has a large number of attributes.
2. Then, association rules are extracted from the cho-
sen attribute set.
3. After the processing of step 2 called round, the
mechanism sums up the count of the occurrence of
the attributes in the chosen attribute set. The most
frequently used attributes will be remained in the
chosen set. And the other attributes will be replaced
by selecting from the whole attribute set.
4. Return to step 2.
A nested loop is used in AAM. The outer loop is used
to update the chosen attribute set, while the inner loop
extracts association rules by using GNP. By using this
method, the database with a large number of attributes
can be dealt with ef?ciently.
3. GNP WITH EDAS TO ASSOCIATION
RULE MINING
In this section, a novel algorithm GNP with Estima-
tion of Distribution Algorithms (GNP with EDAs) is pro-
posed. Conventional GNP based on general evolutionary
framework such as selection, crossover and mutation has
been described in the previous section. GNP with EDAs
is based on GNP, but the probabilistic model is built to
produce the next generation. The aim of building the
probabilistic model is to produce the population more ef-
?ciently by learning from the current good individuals,
while conventional GNP evolves the individuals based on
the crossover and mutation. The speed of GNP evolution
is mainly based on multiple parameters (For example,
crossover and mutation probabilities), as a result, its pro-
cess is slow. On the other hand, the proposed algorithm
selects outstanding individuals and extracts the informa-
tion on the connections between different judgment nodes
from them to construct the probabilistic model, then the
process of evolution becomes very clear and ef?cient.
3.1 Structure of GNP with EDAs
The basic structure of GNP with EDAs is the same
as conventional GNP shown in Fig. 1. Three kinds of
nodes are represented to construct the structure of GNP
with EDAs. They are one start node, several judgment
nodes and processing nodes. In association rule mining,
attributes correspond to the functions of judgment nodes,
and association rules are represented as the connections
of nodes.
The selection operator in GNP with EDAs is the same
as in conventional GNP, i.e., better individuals are se-
lected based on their ?tness values. However, GNP with
EDAs has a novel operator using the probabilistic model
[Fig. 2], where each connection of judgment nodes is
re-connected to another node by using the probabilistic
model.
- 3459 -
i
j
i
e
Next generation
Parent Offspring
Calculate the connection
probability from the      bra-
nch of node     to node    :
              .
thk
i j
),,( jkiP
thk thk
The       branch of node
connects to node    using:
              .
thk i
),,( ekiP
e
Node 1 ... Node j ... Node e ...
Branch (i, k) P(i, k, 1) ... P(i, k, j) ... P(i, k, e) ...
Connection probability table of the      branch of nodethk i
The sum of probabilities in the table is 1
Fig. 2 The evolution of GNP with EDAs
3.2 Probabilistic Model
The connection probability between judgment nodes
is considered to construct the probabilistic model.
P (i, k, j) represents the connection probability from the
kth branch of judgment node i to judgment node j. By
learning from all the connection information on judgment
nodes, the probabilities of judgment nodes can be ex-
tracted. The probabilistic model is used to guide the evo-
lution and can be updated every generation.
The construction of the probabilistic model is as fol-
lows.
1. The connection probability P (i, k, j) are initialized
to generate the initial population randomly.
2. After one generation, the connection probabilities
are updated by the selected top |N |% individuals
(0 ? |N | ? 100).
3. The next population is generated by sampling the
new connection probabilities.
4. If the connection probabilities converge to the op-
timal ones, the procedure ends, else return to step
2.
In themth generation, the connection probability from
the kth branch of judgment node i to judgment node j
Pm(i, k, j) is calculated by the following Eq. (1).
Pm(i, k, j) =
?
n?N ?mn (i, k, j)?
j?A(i, k)
?
n?N ?mn (i, k, j)
, (1)
where,
Pm(i, k, j): connection probability from the kth branch
of node i to node j in themth generation.
N : set of suf?xes of individuals having better ?tness val-
ues.
A(i, k): set of suf?xes of branches from the kth branch
of node i.
?mn (i, k, j): value de?ned by
?mn (i, k, j) =
????
???
1 (if the kth branch of node i in
individual n is connected to
node j in themth generation),
0 (otherwise).
We could also consider the following Exponential
Smoothing method to update the current connec-
tion probability considering the previous connection
probability.
P (i, j, k) = (1? ?)P (i, k, j) + ?Pm(i, k, j), (2)
where,
?: exponential coef?cient (0 ? ? ? 1).
P (i, j, k): connection probability from the kth branches
of node i to node j.
3.3 Extraction of Time-related Association Rules
Time-related association rules are used to predict the
events in time domain.
In time related association rules, Ai(?)(t = p) having
the value 0 or 1 is used to represent the attribute Ai(?)
at time p. Ai(?) represents Ai(Low), Ai(Middle) and
Ai(High). The proposed method extracts the associa-
tion rules like the following:
(Ai(?)(t = p) = 1) ? ... ? (Aj(?)(t = q) = 1)?
(Am(?)(t = r) = 1) ? ... ? (An(?)(t = s) = 1).
Here, p ? q ? r ? s. t represents time and p always
equals 0. The other times are the relative times shifted
from the ?rst attribute.
Fig. 3 shows the basic structure of GNP with EDAs
for time-related association rule mining. Each process-
ing node is a starting point of association rule mining.
In judgment node, Yes-branch is connected to another
judgment node, while No-branch is connected to the next
numbered processing node. The processing nodes are im-
plemented to calculate the criteria, i.e., support values,
con?dence values and Chi-squared values.
A1(Mid)
=1
A2(High)
=1
A3(High)
=1
A4(Low )
=1
P P
Jump
M
a b c d
: Judgment Node: Processing Node : Moved Position
: Yes-branch connection : Jump: other-branch connection
T=2 T=1 T=2 T=5
Fig. 3 Basic structure of GNP with EDAs for time-
related association rule mining
In Fig. 3,M represents the number of total tuples, and
a, b, c and d are the number of tuples moving to the Yes-
branch from each judgment node. For example, in Fig. 3,
the measures of association ruleA1(Mid)? A2(High)
can be calculated by:
support(A1(Mid)? A2(High)) = b/M ,
confidence(A1(Mid)? A2(High)) = b/a.
In addition, the measures of association rule A1(Mid)?
A2(High) ? A3(High) can be calculated by the same
way:
support(A1(Mid) ?A2(High)? A3(High))
= c/M ,
confidence(A1(Mid) ?A2(High)? A3(High))
= c/b.
- 3460 -
In order to measure the interesting association rules,
we apply 4 kinds of correlation measures like, Lift, ?2,
all ? confidence and cosine [12][13][14].
Lift is a simple correlation measure which is de?ned
by Eq. (3). The occurrence of itemset X is independent
of the occurrence of itemset Y if Lift(X,Y ) = 1.0,
otherwise, X and Y are dependent and correlated. If
Lift(X,Y ) > 1.0, X and Y have positive relationship,
while they have negative relation if Lift(X,Y ) < 1.0.
Lift(X,Y ) =
confidence(X ? Y )
support(Y )
. (3)
Table 1 shows the contingency table of itemset X and
Y . The upper parts are the expectation values under the
assumption of their independence, and the lower parts are
observational. Then the ?2 is de?ned by Eq. (4).
?2(X,Y ) =
?
AllCells
(O ? E)2
E
. (4)
The ?2 value can be calculated by Eq. (5) using x, y, z
andM of Table 1.
?2(X,Y ) =
M(z ? xy)2
xy(1? x)(1? y) . (5)
Table 1 The contingency ofX and Y .
Y ¬Y ?row
X Mxy M(x-xy) Mx
Mz M(x-z)
¬X M(y-xy) M(1-x-y+xy) M(1-x)
M(y-z) M(1-x-y+z)?
col My M(1-y) M
All ? confidence correlation measure is de?ned by
Eq. (6).
allconf(X,Y ) =
support(X ? Y )
max{support(X), support(Y )} , (6)
where,max{support(X), support(Y )} is the maximum
support of itemset X and itemset Y . If the all ?
confidence value approaches the value of 0.5, the rela-
tionship between X and Y is independent. If approaches
1.0 or 0.0, the two itemsets will be positively correlated
or negatively correlated, respectively.
The cosine measure is similar to Lift measure. The
difference is that the square root is taken in the denomina-
tor to measure the relationship of itemset X and itemset
Y in cosine measure. The calculation of cosine measure
is done by Eq. (7).
cosine(X,Y ) =
support(X ? Y )?
support(X)support(Y )
, (7)
For one association rule, such as X ? Y , X denotes the
antecedent part of the rule, and Y is de?ned as the con-
sequent part. In order to calculate 4 kinds of correlation
measures, we need the support value of Y . So we adopt a
jump method [Fig. 3], which makes the processing node
randomly jump to another judgment node belonging to
the same transition route. Then, we can calculate the
support of the consequent part Y by counting the total
number of tuples moving to Yes-branch at each judgment
node.
Depending on different correlation measures, the de?-
nition of important association rules is as follows:
support(X ? Y ) > supportmin(X ? Y ), (8)
Lift(X ? Y ) > Liftmin(X ? Y ), (9)
?2(X ? Y ) > ?2min(X ? Y ), (10)
all ? conf(X ? Y ) > all ? confmin(X ? Y ), (11)
cosine(X ? Y ) > cosinemin(X ? Y ), (12)
where, supportmin, Liftmin, ?2min, all ? confmin
and cosinemin are the thresholds for extracting impor-
tant rules. As we described previously, Lift, all ?
confidence and cosine measures can judge not only the
positive relationships of rules, but also the negative rela-
tionships. By using from Eq. (9) to Eq. (12) we can just
extract the rules which are positively related. If the rule
”X ? Y ” is judged important by the above de?nition for
the threshold, then, the rule ”X ? ¬Y ”, ”¬X ? Y ”,
”¬X ? ¬Y ”, ”Y ? X”, ”Y ? ¬X”, ”¬Y ? X” and
”¬X ? ¬X” are also extracted as important rules.
In the time-related association rule mining, the ?tness
function of GNP with EDAs is de?ned as:
F =
?
r?R
{C(r) + ?(na(r)? 1) + ?(nc(r)? 1)
+?new(r) + ?multi(r)}, (13)
where,
F : ?tness value.
R: set of suf?xes of extracted important association rules
in GNP individuals.
C(r): Correlation measure of rule r. We consider four k-
inds of correlation measures: Lift(r), ?2(r), all?
confidence(r) and cosine(r).
?: coef?cient de?ning the in?uence of the number of an-
tecedent and consequent attributes of rule r. ? is diffe-
rent correlation measure by correlation measure.
na(r): the number of attributes in the antecedent of rule
r.
nc(r): the number of attributes in the consequent of rule
r.
?new(r): additional constant de?ned by
?new(r) =
?
?new (if r is a new rule),
0 (otherwise).
?multi(r): additional constant de?ned by
?multi(r) =
??
?
?multi (rule r has many
different attributes),
0 (otherwise).
C(r), na(r), nc(r), ?multi(r) and ?multi(r) are con-
cerned with the importance, complexity, novelty and
diversity of rule r. The ?tness represents the potential to
extract new rules.
- 3461 -
4. SIMULATION
In this section, the proposed method is simulated in
a simple traf?c prediction model, where the number of
rules extracted by the proposed method is compared with
that of the conventional method.
4.1 Simulation Environments
A traf?c simulator consisted of a 7*7 road map model
is used in the simulation to generate traf?c data [Fig.
4]. In the model, each section has the same length, and
different cars have different speeds depending on traf?c
lights in intersections, and so on. The cars are generated
based on the O/D (Original/Destination) which de?nes
the number of cars moving from each starting place to
ending place.
#W1
#W2
#W3
#W4
#W5
#W6
#W7
#E1
#E2
#E3
#E4
#E5
#E6
#E7
#N1 #N2 #N3 #N4 #N5 #N6 #N7
#S1 #S2 #S3 #S4 #S5 #S6 #S7
This model is 7*7 grid network;
: Intersection : Section
Fig. 4 Simple road map model
Table 2 An example of database of a traf?c system.
Time W1N1,W2N1 W1N1,W2N1 W1N1,W2N1
Low Mid High
0001 0 1 0
0002 0 1 0
0003 0 0 1
0004 1 0 0
0005 0 1 0
An example of the database is shown in Table 2,
where ”W1N1,W2N1” represents a section from the in-
tersection W1N1 to intersection W2N1 of the traf?c
model. The traf?c volume of the section is discretized
to Low/Middle/High.
The parameter setting for evolution is shown in Ta-
ble 3. Here, the attributes correspond to the sections in
the road map model, and each judgment node represents
one attribute. There are 7*8*2=112 sections exist in the
road map as shown in Fig. 4. Besides, each section has
2 directions and three categories representing the traf-
?c volume (Low/Middle/High). So, ?nally we have
112*2*3=672 attributes corresponding to the traf?c sec-
tions.
Table 3 Parameter setting for evolution.
Parameters Values
Processing nodes size 10
Judgment nodes size 100
Population size 100
Attribute size 672
4.2 Simulation Results
In this subsection, the simulation results are shown and
analyzed.
In the ?rst simulation, the proposed method is com-
pared with the conventional GNP method. The proposed
association rule mining using GNP with EDAs and con-
ventional association rule mining based on GNP method
were studied using the sub attribute set size of 50 and ?2
correlation measure to de?ne the importance of associ-
ation rules. Table 4 shows the other parameters of ?rst
simulation.
Table 4 Parameters for the comparison of the proposed
and conventional methods.
Parameters Values
Sub attribution size 50
Total generations size 1000
Generation size/Round 150
Fig. 5 shows the total number of extracted rules by
using the proposed method and conventional method. It
is shown from simulation 1 that the proposed method can
extract association rules more ef?ciently.
0
50000
100000
150000
200000
250000
300000
350000
400000
0 200 400 600 800 1000
Generation
N
um
be
r o
f A
ss
oc
ia
tio
n 
R
ul
es
Conventional GNP GNP with EDAs
Fig. 5 Comparison of the total number of extracted
rules between the proposed method and conventional
method
In the second simulation, 4 kinds of correlation mea-
sures are studied to analyze their difference by using the
proposed method. Fig. 6 shows the performances of rule
extraction using Lift, ?2, all ? confidence and cosine
correlations under the conditions of Table 3.
We can see from Fig. 6 that the proposed method can
obtain almost the same number of rules even if different
kinds of correlation measures are used. It seems from
simulation 2 that just using only one correlation measure
is not a good method in the case, which should be studied
more in the future.
- 3462 -
0
50000
100000
150000
200000
250000
300000
350000
400000
0 200 400 600 800 1000
Generation
N
um
be
r o
f A
ss
oc
ia
tio
n 
R
ul
es
Lift Chi-Square All-Confidence Cosine
Fig. 6 Comparison of the total number of extracted rules
among 4 kinds of correlation measures
The extracted rule is like the following:
?W1,W1N1(Mid)(t = 0001) ?W1N1,W2N1
(Low)(t = 0003)?W2N1,W2N2(High)(t = 0007)
This rule implies that if section ”#W1,W1N1” has
middle traf?c volume at time 0001, and section
”W1N1,W2N1” has low traf?c volume at time 0003,
then the section ”W2N1,W2N2” will probably have
high traf?c volume at time 0007.
According to these extracted rules, we can predict the
future traf?c volumes in sections.
5. CONCLUSION
A novel method using Genetic Network Programming
with Estimation of Distribution Algorithms has been pro-
posed for association rule mining in this paper. The pro-
posed method can extract important time related associ-
ation rules more ef?ciently than the conventional GNP
method. We have built a simple traf?c simulator and sim-
ulations were done to study the effectiveness of the pro-
posed method. Now, we are studying further improve-
ments of the probabilistic model to make the population
generation more accurate and ef?cient.
REFERENCES
[1] C. Zhang and S. Zhang, “Association Rule Mining:
models and algorithms”, Springer, 2002.
[2] R. Agrawal and R. Srikant, “Fast Algorithms for
Mining Association Rules”, In proc. of the 20th
VLDB Conference, pp. 487-499, 1994.
[3] K. Shimada, K. Hirasawa and J. Hu, “Genetic Net-
work Programming with Acquisition Mechanisms
of Association Rules”, Journal of Advanced Com-
putational Intelligence and Intelligent Informatics,
Vol.10, No.1 pp. 102-111, 2006.
[4] S. Mabu, K. Hirasawa and J. Hu, “A Graph-Based
Evolutionary Algorithm: Genetic Network Pro-
gramming (GNP) and Its Extension Using Rein-
forcement Learning”, Evolutionary Computation,
MIT Press, Vol.15, No.3, pp. 369-398, 2007.
[5] K. Hirasawa, T. Eguchi, J. Zhou, L. Yu and S.
Markon, “A Double-Deck Elevator Group Supervi-
sory Control System Using Genetic Network Pro-
gramming”, IEEE Trans. on Systems, Man and Cy-
bernetics, Part C, Vol.38, No.4, pp. 535-550, 2008.
[6] T. Eguchi, K. Hirasawa, J. Hu and N. Ota, “A Study
of Evolutionary Multiagent Models Based on Sym-
biosis”, IEEE Trans. on Systems, Man and Cyber-
netics, Part B, Vol.36, No.1, pp. 179-193, 2006.
[7] H. Zhou, W. Wei, K. Shimada, S. Mabu and K.
Hirasawa, “Time Related Association Rules Min-
ing with Attribute Accumulation Mechanism and its
Application to Traf?c Prediction”, Journal of Ad-
vanced Computational Intelligence and Intelligent
Informatics, Vol.12, No.5, pp. 467-478, 2008.
[8] S. Baluja, “Population-based Incremental Learning:
A Method for Integrating Genetic Search Based
Function Optimization and Competitive Leaning”,
Tech. Report. No. CMU-CS-94-163, Carnegie Mel-
lon University, 1994.
[9] P. Larranaga and J.A. Lozano, “Estimation of Dis-
tribution Algorithms. A New Tool for Evolutionary
Computation”, Kluwer Academic Publishers, 2002.
[10] M. Pelikan, D. E. Goldberg and F. G. Lobo, “A Sur-
vey of Optimization by Building and Using Proba-
bilistic Models”, Computational Optimization and
Applications, Kluwer Academic Publishers, Vol.21,
pp. 5-20, 2002.
[11] M. Toussaint, “The Structure of Evolutionary Ex-
ploration: On Crossover, Buildings Blocks, and
Estimation-Of-Distribution Algorithms”, In proc. of
the Genetic and Evolutionary Computation Confer-
ence (GECCO2003), 2003.
[12] S. Brin, R. Motwani and C. Silverstein, “Beyond
Market Baskets: Generalizing Association Rules to
Correlations”, In proc. of the ACM SIGMOD, pp.
487-499 1997.
[13] J. W. Han and M. Kamber, “Data Mining: Concepts
and Techniques”,Morgan Kaufmann, 2000.
[14] P. N. Tan, V. Kumar and J. Srivastava, “Selecting
the Right Interestingness Measure for Association
Patterns”, In proc. of the ACM International Con-
ference on Knowledge Discovery and Data Mining
(SIGKDD2002), 2002.
