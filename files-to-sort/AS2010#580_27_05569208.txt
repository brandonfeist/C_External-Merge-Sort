                                 978-1-4244-5934-6/10/$26.00 ©2010 IEEE                                 1465
2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010)                       
Research on Improved Strategy of FDM Algorithm 
Huang Darong 
Institute of Information Science and Engineering 
Chongqing JiaoTong University 
ChongQing, China 
Huang Huimin and Wang Peng 
Institute of Information Science and Engineering 
Chongqing JiaoTong University 
ChongQing, China
Abstract—This FDM algorithm is a fast algorithm of distributed 
mining of association rules. However, the algorithm is designed 
under the condition of non shared resource; therefore the cost of 
the algorithm is great. Moreover, the important information at 
every site is exposed to other sites that is opposite to the 
nowadays trend of attaching importance to privacy preserving 
increasingly. In order to improve FDM algorithm, a novel 
strategy is proposed: to compute the total support count with the 
method of privacy preserving, meanwhile to ensure the source of 
every local large item-set and local support count is covered, thus 
to preserve the privacy of the data distributed at sites. The 
efficiency and effectiveness of the proposed method have been 
validated by the experiments based upon some public data sets. 
Keywords-distributed data mining; FDM; privacy preserving  
I. INTRODUCTION 
Count Distribution (CD) and Data Distribution (DD) 
algorithms have been developed by Agrawal [1] in 80’s of last 
century for effectively distributed mining of association rules 
and the communication complexity to compute global support 
count of a large item-set by means of these two algorithms is 
which is relatively great. In 90’ of last century, Fast Data 
Mining (FDM) algorithm has been developed by D.W.Cheung 
which is much improved comparing with CD algorithm. In 
FDM algorithm, local pruning is performed for every locally 
large item-set before locally large item-sets broadcasted to all 
sites, which makes unuseful locally large item-sets greatly 
decreased, spending of memory reduced and efficiency of 
algorithm increased accordingly. Moreover, communication 
complexity to compute global support count of a large item-set 
is cut down to ) through introducing into Hash function in [2].  
)( 2nO
(nO
However, FDM algorithm was designed under the 
condition of non shared resource, namely the network 
framework of topology is formed between all sites in [3] and 
local large candidate item sets are broadcasted to all sites that 
results into the exposure of important information of every site 
in the distributed system and disbennifit to privacy preserving.  
Therefore, it is indispensable to discuss how to make up 
this defect of FDM algorithm. An improved strategy is 
proposed here which computes global support count with the 
method of privacy preserving, and ensures the source of every 
locally large item-set and local support count is covered, thus 
preserves the privacy of the data distributed in all sites. 
II. DESCRIPTION OF THE IMPROVED STRATEGY
Nowadays with the increasing access to information in 
electronic format or from web, as well as more and more tools 
for data mining coming into being, people appeal to privacy 
preserving urgently in [4]. Singularly high privacy preserving 
is required in some fields of data mining, especially in the field 
of finance, medical treatment etc. For instance, to analyze the 
incidence of a disease, it needs for several hospitals to integrate 
and analyze the information held by their own, but in practice, 
the hospitals are unwilling to share the information for the 
reason of protecting privacy of patients or for other reasons. 
Thus, in some fields, privacy preserving becomes the important 
index to evaluate the system of distributed data mining. in [5] 
As far as the defect of FDM algorithm concerned, since it was 
designed under the condition of non shared resource, the 
topology of network causes one site to expose its own 
information to other sites. Accordingly, the stress of this paper 
would be put to adding the function of privacy preserving to 
classical FDM algorithm that may help prevent revealing 
important data and improve the performance of the algorithm. 
Depending on partition of data, distributed mining of 
association rules can be classified into two types: horizontally 
partitioned and vertically partitioned. in [6-11] FDM algorithm 
is on the base of horizontally partitioned data and 
correspondingly the theory of privacy preserving in 
horizontally partitioned data mining is that ensure locally large 
item-sets are accessible to local sites but inaccessible to other 
sites. Hereby the motive of introducing privacy preserving in 
this paper, namely the problems needed to be solved is as 
follows. 
1) Ensure the locally large item-set and local support count 
is covered to other sites. 
2) Compute the global support count. 
In the first place, secure set union is proposed to adopt. By 
means of encrypting, re-encrypting and permuting encrypted 
items at every site, the local large item-set and local support 
count could be transferred between sites and the tracing of 
source of original data could be prevented well. 
Secondly, secure sum could be adopted to solve the second 
problem. In detail, a home site is proposed to set up, then it is 
proposed to compute a certain function from the home site to 
other sites with the privacy input into this function, return the 
ultimate function value to the home site, decrypt the returned 
This work was sponsored by the Graduate Innovation Fund of Chongqing 
Jiaotong University, Chongqing, China. 
                                                                                                                                          1466
function value at the home site according to the original 
privacy input, and obtain the secure sum finally, i.e. global 
support count. 
III. TECHNIQUE OF PRIVACY PRESERVING FOR FDM
ALGORITHM
On the one hand, in classical FDM algorithm, the locally 
large item-sets need to be broadcasted to other sites after the 
local pruning so that the global support count of these locally 
large item-sets could be computed. In order to ensure the 
information of local site such as locally large item-sets and 
local support count could not be aware to other sites, secure set 
union is suggested to introduce into the algorithm.  
Secure set union is a method of privacy preserving in data 
mining, through which the information of local site such as 
rules, locally large item-sets etc. can be broadcasted in 
distribution system, but owners of broadcasted information 
can’t be exposed. Theoretically, secure set union executes its 
function basing on the thought of permuting encrypt item. 
Figure 1 shows the principle to set up secure set union. 
))(( 32 CEE
))(( 32 DEE                             )(1 CE
                                                C
                                     D)(3 CE
)(3 DE
)))((( 132 CEEE                                                                   ))(( 13 CEE
Figure 1. Determining the union of the set of items 
If given key 1,... nK K K? , for any permutation , the 
following two equations hold:  
,i j
                                           (1) 
1 1
(... ( )...) (... ( )...)
i in j jnK K K K
E E M E E M 
2121 ,, MMMMM z? , given arbitrary kk 2
1, H , s.t 
                
1 11
( (... ( )...) (... ( )...))
i in j jnr K K K K
P E E M E E M 2 H            (2)  
By introducing the secure set union, each site encrypts the 
local data and transfers it to other sites, then each site re-
encrypt data received from other sites. Accordingly to equation 
1 and equation 2, duplicates in the original items will be 
duplicated in the encrypted items, and can be deleted. In 
addition, the decryption can occur in any order. Consequently, 
by permuting the encrypted items, it is prevented that each site 
tracks the source item-sets. 
Through this method of secure set union, each site could 
transfer the information of locally large item-sets and local 
support count etc., without revealing which information from 
which site. However during the course of data transfer, the 
number of locally large item-sets is revealed which exists in 
two sites. For example, if K site have a locally large item-set, 
it will be duplicated k times. Although the item-set itself is not 
revealed, the true secure computation could not reveal this 
information. In practice, allowing innocuous information 
leakage in an algorithm means lower cost than the algorithm 
with fully secure computation.
On the other hand, we would like to compute the global 
support counts and ensure the local supports of each site could 
not revealed to other sites as well. This can be easily fulfilled 
by the method of secure sum.   
If given sites1, 2,...s , first a home site(site No.1) must to be 
determined; and site No.1 randomly produces a 
random R which ranges in [1  and will be added the local 
support count of site No.1, then transfers
, ]n
1 modR v n  to site 
No.2; as R is a random ranging in , site No.2 could not 
obtain the real value of  after receiving the information of 
[1, ]n
1v
1 modR v n ; similar mode to compute the function will be set 
up in remainder sites No. l  ( ) and now the 
received function value in site No. l  is  , 
which will be added  (that is )
and transferred to site No. l ; …; similarly the last site (site 
No. ) computes the function and returns the function value to 
site No.1 where decryption will be implemented according to 
the value of cryptically , global support count will be 
acquired and local support counts of other sites can’t be 
revealed. Figure 2 shows the principle to compute secure sum. 
2... 1l s 
1
1
mod
l
j
j
V R v n

 
  ¦
R
1
mod ( ) mod
l
j j
j
R v n v V
 
  ¦ n
1
s
R
                               712 
                                              
                               19                                                   
                                                                    
                                                                    19 !2  R
17 R
                                                   
517                                                            0R
Figure 2. The principle to compute secure sum 
Theoretically, the method of secure sum will be confronted 
with problem if sites collude. For instance, site No. l 1  and 
2
D
3
C
1
C
Site No.3 
7
Site No.2 
-5
Site No.1 
0
                                                                                                                                          1467
site No.  could collude, then could confirm the real value 
of  by comparing the function values that they sent out and 
received. However one site could be threatened on privacy 
secure, unless all the other sites colluded. This makes it 
possible for secure sum to be used in our proposed strategy. 
1l 
lv
IV. EXPERIMENT AND ANALYSIS
Our proposed improved algorithm is test on some UCI 
datasets. And the distributed system in the experiment is made 
of four personal computers which are deployed with the 
following hardware and software: CPU: Pentium(R) D CPU 
2.80GHZ; Memory: 504MB; Operation System: Windows XP. 
And Java was adopted as the programming language in the 
experiment.  
The front 1400 records of dataset named Contraceptive 
Method Choice in UCI datasets are used in the experiment. We 
firs discretize an attribute named Wife's age, the original values 
of which are integers and range in [20, 50] (the values of other 
attributes are discretized originally and need not be discretized). 
We suppose the data distributes symmetrically in each 
computer, namely the numbers of the data distributed in each 
site are approximately equal. Our scheme is described as: 
symmetrically distributing 1400 discretized records to each site, 
just 350 records per site. Table I describes some samples within 
records. 
TABLE I. SOME SAMPLES0 WITHIN RECORDS
Code
of 
Attribute 
          No. of 
            record 
Name                
of  attribute 
1 2 3 4 5
A Wife’s age 2 4 4 4 3
B Wife’s education 2 1 2 3 3
C Husband’s education 3 3 3 2 3
D
Number of 
children ever 
born
3 10 7 9 8
E Wife’s religion 1 1 1 1 1
F Wife’s now working? 1 1 1 1 1
G Husband’s occupation 2 3 3 3 3
H Standard of living index 3 4 4 3 2
I Mediaexposure 0 0 0 0 0
J Contraceptivemethod used 1 1 1 1 1
Among the above attributes, firstly, attribute A denotes 
wife’s age: 2 for 20~29 years old, 3 for 30~39 years old, 4 for 
40~49 years old; secondly, attribute B denotes wife’s education 
level which ranges from low to high as: 1, 2, 3, 4; thirdly, 
attribute C denotes husband’s education level which ranges 
from low to high as: 1, 2, 3, 4; and attribute D is the statistic of 
number of children ever born; attribute E shows wife’s religion: 
0 for non-Islam and 1 for Islam; attribute F figures whether 
wife is now working: 0 for working and 1 for not working; 
attribute G denotes husband’s occupation level which ranges 
from low to high as: 1, 2, 3, 4; in addition, attribute H depict 
standard of living index which ranges from low to high as: 1, 2, 
3, 4; and attribute I shows media exposure: 0 for good and 1 for 
not good; last, attribute J shows way to contracept: 1 for never 
use, 2 for long-time use and 3 for short-time use. 
Considering mobile agent is of self-determination, mobility 
and resource-saving, it well adapts to be introduced into 
distributed data mining. Accordingly, in our experiment, Aglets 
of IBM, an open source programming platform developed in 
Java language was used to create and dispatch mobile agents 
which can migrate from a start host to a destination host and 
execute tasks of data mining. We designed two kinds of agents 
in our experiment, AgentA and AgentB. AgentB is used to 
compute the global support counts and this kind of agent 
extends from Aglets class, takes its own algorithm of both 
privacy preserving and data mining. AgentA is used to 
compute the locally large item-set and similar with AgentA in 
framework except absence of algorithm of privacy preserving. 
The framework of the AgentB class is as follows.  
public class AgentB extends Aglet { 
 AgletID AgentBID; 
 URL currentHost;  
// information of  datasource 
 String datasource; 
 //create a listener. MyListener is our original class 
which extends from MobilityListener class. 
 MyListener myListener=new MyListener(); 
 public void onCreation() { 
 // initiate AgentB  
 } 
public void AlgorithmB (){ 
 // the algorithm of privacy preserving and data mining  
 } 
public void run() { 
 // AgentB starts running from this  entry when 
migrating to destination host 
 } 
public void handleMerssage(Message msg) { 
 // to handle message transfer  
                                                                                                                                          1468
 } 
 this.addMobilityListener(myListener); 
public void onDisposing() { 
 // action when a AgentB is disposed  
 } 
 } 
During the whole course of mining, the home site is in 
charge of creating, dispatching and retracting AgentA or 
AgentB to destination host. When task of the agent done, 
relevant agent will be disposed by home site.  
 A testing on effectiveness and efficiency of the proposed 
strategy was hold. Given min_sup=20%, min_conf=70%. We 
got average time of 10 times tested on experimented dataset 
respectively by classic algorithm and improved algorithm. And 
the experimental results are showed in Table II. 
TABLE II. EXPERIMENTAL RESULTS ON EFFECTIVENESS TESTING
Table II shows a summary of computation results which 
verifies the effectiveness of the proposed strategy to improve 
FDM algorithm. For one thing, we have got the same large 
association rules by the improved algorithm as classical FDM 
algorithm. Furthermore, we have compared the efficiency of 
the improved algorithm to the classical one. Although the 
proposed strategy added algorithm of privacy preserving, the 
proposed strategy does cut short the computation time with 
home-site communication method replacing broadcast method. 
Thirdly, through analysis, the communication complexity to 
compute global support count of a large item-set in proposed 
strategy is same as classical FDM algorithm, namely . Last 
but not least, the space efficiency of our proposed strategy is 
lower than classical FMD algorithm because of additional 
space cost for algorithm of privacy preserving.
)(nO
V. CONCLUSION
In this paper, we have discussed a strategy of privacy 
preserving to improve FDM algorithm. To reduce time spent 
on communication and preserve privacy distributed in each site, 
computation method of privacy preserving has been adopted 
including secure set union and secure sun. Our test on UCI 
datasets proves that this method is rather suitable for practical 
fields particularly the field which needs severe privacy 
preserving in data mining.    
ACKNOWLEDGMENT
The authors acknowledge the research grants provided by 
the Graduate Innovation Fund of Chongqing Jiaotong 
University (No.0904). 
REFERENCES
[1] Wang Peng, Lv Shuang, Nie Zhi, Xie Qianhe etc., “Application and 
Practice of Paralleled Computation,” Beijing, Machine Industry 
Publishing House, 2008.  
[2] Liu Qun, Yin Yulan, “Research on Distributed Mining of Association 
Rules Based on FDM Algorithm,” Computer and information 
technology, 2005(04).
[3]  Huang Xianying, Wang Keke, Fan Wei, “Distributed Mining of 
Association Rules Based on Network of Start Model,” Science of 
Computer, 2004(12), pp.180-188.  
[4] Huang Yiqun, Lu Zhengding, Hu heping, Li Ruixuan, “Algorithm of 
Privacy-preserved Association Rules Mining in Distributed System,” 
Computer Engineering, 2006(13), pp.12-14. 
[5] R.Agrawal and R.Srikant, “Privacy-preserving Data Mining,” In 
Proceedings of 2000 ACM SIGMOD Conference on Management of 
Data, Dallas, TX, 2000,  pp.439-450. 
[6] Zhang Guorong, “Problem of privacy preserving in Distributed Data 
Mining,” Knowledge and Technology of Computer, 2006(08), pp.30-212.   
[7] S.C.Pohlig and M.E.Hellman, “An improved algorithm for computing 
logarithms over GF(p) and its cryptographic significance,” IT-24, 1978, 
pp.106-110.  
[8] B.Schneier, “Applied Cryptography,” John Wiley & Sons, 1995. 
[9] UCI Repository of Machine Learning Databases. Available at: 
http://archive.ics.uci.edu/ml/. 
[10]  The Aglets2.0.2 Manual. Available at: http://download.csdn.net/source 
/183757 
FDM Algorithm Improved FDM Algorithm 
Large
Association
Rules 301
,111
JIE
JFE
??
??
301
,111
JIE
JFE
??
??
Time Spent 2350ms 2050ms 
Communication 
Complexity )(nO )(nO
[11]  Aglets 2.0.2 API Documentation: Available at: http://aglets.sourceforge .
net
