Incrementally Mining High Utility Itemsets in Dynamic Databases 
 
 
Chun-Wei Lin 
Department of Computer 
Science and Information 
Engineering 
National Cheng Kung 
University 
Taiwan, R.O.C. 
jerry@jerry.idv.tw 
Tzung-Pei Hong 
Department of Computer Science 
and Information Engineering 
National University of Kaohsiung 
Taiwan, R.O.C. 
Department of Computer Science 
and Engineering 
National Sun Yat-sen University 
Taiwan, R.O.C. 
tphong@nuk.edu.tw 
Guo-Cheng Lan, Hsin-Yi Chen, 
Hung-Yu Kao 
Department of Computer Science 
and Information Engineering 
National Cheng Kung University 
Taiwan, R.O.C. 
rrfoheiay@gmail.com 
p78981215@mail.ncku.edu.tw 
hykao@mail.ncku.edu.tw 
 
 
Abstract 
 
Utility mining is proposed to consider additional 
measures, such as profits or costs according to user 
preference. In the past, a two-phase mining algorithm 
was proposed for fast discovering high utility itemsets 
from databases. In this paper, an incremental mining 
algorithm to efficiently update high utility itemsets is 
proposed for record insertion. Experimental results 
also show that the proposed algorithm executes faster 
than the two-phase batch mining algorithm.  
 
1. Introduction 
 
Utility mining [3, 10] may be thought of as an 
expansion of frequent-itemset mining [1-2, 5] with sold 
quantities and item profits considered. Liu et al. 
designed the two-phase algorithm [7] for efficiently 
extracting all high utility itemsets based on the 
downward-closure property. In the above approaches, 
the database was assumed static and the mining 
processes were performed in a batch way.  
In real-world applications, transactions in a 
database do not usually remain a stable condition. 
Some transactions may be inserted into an original 
database due to new purchases from customers [6, 9]. 
Cheung et al. then proposed the Fast-UPdate (FUP) 
algorithm [4] to solve the limitations of association-
rule mining in an incremental approach.  
In this paper, an incremental mining algorithm to 
update the discovered high utility itemsets is thus 
proposed. It is based on Liu et al.‘s two-phase mining 
approach [7] and the FUP concept [4] to partition 
itemsets into four parts according to whether they are 
high transaction-weighted utilization itemsets in the 
original database and in the new transactions. Each part 
is then executed by its own procedure. Experimental 
results show that the proposed algorithm has a better 
performance than the two-phase batch mining 
algorithm. 
 
2. Review of related works 
 
In this section, the FUP algorithm and the concept 
of mining high utility itemsets are briefly reviewed. 
 
2.1. The FUP algorithm 
 
In real-world applications, transactions in a 
database do not usually remain a stable condition. 
Considering an original database and some new 
transactions, the following four cases (illustrated in 
Figure 1) may occur. 
 
Original database
New transactions
Large 
Itemsets
Small 
Itemsets
Large 
Itemsets
Small 
Itemsets
Case 1 Case 2
Case 3 Case 4
 
Figure 1. Four cases when new transactions are 
inserted into existing database 
2010 IEEE International Conference on Granular Computing
978-0-7695-4161-7/10 $26.00 © 2010 IEEE
DOI 10.1109/GrC.2010.151
303
Since itemsets in Case 1 are frequent (large) in both 
the original database and the new transactions, they 
will still be frequent (large) after the weighted average 
of the counts. Similarly, itemsets in Case 4 will still be 
non-frequent (small) after the new transactions are 
inserted. Thus Cases 1 and 4 will not affect the final 
frequent (large) itemsets. Case 2 may remove existing 
frequent (large) itemsets, and Case 3 may add new 
frequent (large) itemsets.  
 
2.2. Mining high utility itemsets 
 
In the past, several mining algorithms were 
proposed for efficiently discovering high utility 
itemsets [3, 10]. Liu et al. then designed a two-phase 
algorithm for efficiently discovering all high utility 
itemsets [7]. It consists of two phases to generate-and-
test high utility itemsets in a level-wise way. The 
transaction utility was first used as the effective upper 
bound of each candidate itemset in the transaction such 
that the “transaction-weighted downward closure 
property” could be kept in the search space to decrease 
the number of candidate itemsets. An additional 
database scan was then performed to find out the real 
utility values of the remaining candidates and identifies 
the high utility itemsets. 
 
3. The proposed incremental algorithm for 
record insertion 
 
Considering there is an example to show the 
original database in Table 1. It consists of 10 
transactions and 6 items, denoted {A} to {F}. 
 
Table 1. An original database in the example 
TID A B C D E F 
1 3 2 0 3 0 0 
2 2 0 0 4 2 0 
3 3 0 5 0 0 3 
4 1 0 3 0 1 2 
5 1 0 0 3 2 0 
6 1 2 0 4 0 0 
7 2 3 2 0 1 1 
8 0 0 0 0 0 2 
9 0 0 3 3 0 0 
10 3 0 0 4 0 0 
 
Assume the minimum high utility threshold is set at 
35%, and also assume the user-defined profit values for 
the items are given in a utility table shown in Table 2. 
The two-phase algorithm is first performed to find high 
transaction-weighted utilization itemsets and their 
actual utility values before new transactions come. The 
results are then shown in Table 3. 
 
Table 2. The utility table 
Item Profit ($) 
A 3 
B 150 
C 1 
D 50 
E 100 
F 20 
 
Table 3. The high transaction-weighted utilization 
itemsets and their actual utility values 
Itemset High transaction-weighted utility 
Actual utility 
value 
A 2728 48 
B 1540 1050 
D 2083 1050 
E 1483 600 
AB 1540 1068 
AD 1930 930 
AE 1483 618 
 
The details of the proposed incremental mining 
algorithm are described below. 
 
The proposed incremental algorithm: 
INPUT: An original database D, the discovered high 
transaction-weighted utilization itemsets 
with their actual utility values from the 
original database, a minimum high utility 
count mucD (= total transaction utility 
?
?DT
k
k
tu * minimum high utility threshold ? ) 
in the original database, and a set of d new 
transactions. 
OUTPUT: A set of high utility itemsets (HUU) for the 
updated database U (= D d? ). 
STEP 1: Calculate the utility value ujk of each item ij 
in each new transaction tk as ujk = qjk*pj, 
where qjk is the quantity of ij in tk and pj is 
the profit of pj. Accumulate the utility values 
all items in each transaction tk as the 
transaction utility tuk. That is: 
1
.
m
k jk
j
tu u
=
=?  
STEP 2: Calculate the minimum high utility count 
mucd (= ?
=
n
k
ktu
1
* minimum high utility 
threshold ? ) in the new transactions.  
STEP 3: Set k = 1, where k records the number of 
items in the itemsets s currently being 
processed.  
304
STEP 4: Generate the candidate k-itemsets and 
calculate their transaction-weighted utilities 
twud(s) from the new transactions as the 
summation of the utilities of the new 
transactions which include ij. That is: 
.)( ?
?
=
kj ti
k
d tustwu  
STEP 5: Check whether the twud(s) of each k-itemset 
from the new transactions is larger than or 
equal to the minimum high utility count 
mucd in the new transactions. If s satisfied 
the condition, put it in the set of high 
transaction-weighted utilization k-itemsets 
for the new transactions, dkHTWU . 
STEP 6: For each k-itemset s in the set of high 
transaction-weighted utilization k-itemsets 
( DkHTWU ) from the original database, if it 
also appears in the set of high transaction-
weighted utilization k-itemsets ( dkHTWU ) 
in the new transactions, do the following 
substeps (Case 1): 
Substep 6-1: Set the updated transaction-
weighted utility of itemset s as: 
twuU(s) = twuD(s) + twud(s), 
where twuD(s) is the high transaction-
weighted utility of itemset s in the original 
database ( DkHTWU ) and twu
d(s) is the high 
transaction-weighted utility of itemset s in 
the new transactions )( dkHTWU , 
respectively. 
Substep 6-2: Put s in the set of updated high 
transaction-weighted utilization k-itemsets, 
U
kHTWU . 
STEP 7: For each k-itemset s in the set of high 
transaction-weighted utilization k-itemsets 
( DkHTWU ) from the original database, if it 
does not appear in the set of high 
transaction-weighted utilization k-itemsets 
( dkHTWU ) in the new transactions, do the 
following substeps (Case 2): 
Substep 7-1: Set the updated transaction-
weighted utility of itemset s as: 
twuU(s) = twuD(s) + twud(s). 
Substep 7-2: Check whether the updated 
twuU(s) is larger than or equal to the updated 
minimum high utility count (mucD + mucd). 
If s satisfied the above condition, put it in 
the set of updated high transaction-weighted 
utilization k-itemsets, UkHTWU ; 
Otherwise, remove s from the set of high 
transaction-weighted utilization k-itemsets 
( DkHTWU ) in the original database.  
STEP 8: For each k-itemset s, if it does not appear in 
the set of high transaction-weighted 
utilization k-itemsets ( DkHTWU ) from the 
original database, but appears in the set of 
high transaction-weighted utilization k-
itemsets )( dkHTWU  in the new 
transactions, do the following substeps 
(Case 3): 
Substep 8-1: Rescan the original database 
to determine the transaction-weighted utility 
twuD(s) of itemset s. 
Substep 8-2: Set the updated transaction-
weighted utility of itemset s as: 
twuU(s) = twuD(s) + twud(s). 
Substep 8-3: Check whether the updated 
transaction-weighted utility twuU(s) is larger 
than or equal to the updated minimum high 
utility count (mucD + mucd). If s satisfied the 
above condition, put it in the set of updated 
high transaction-weighted utilization k-
itemsets, UkHTWU .   
STEP 9: Generate the candidate (k+1)-itemsets from 
the set of high transaction-weighted 
utilization k-itemsets ( UkHTWU ) in the 
updated database. 
STEP 10: Set k = k + 1; 
STEP 11: Repeat STEPs 4 to 10 until no new 
candidate itemsets are generated. 
STEP 12: For each high transaction-weighted 
utilization itemset s in UHTWU  of the 
updated database, if it appears in the set of 
high transaction-weighted utilization 
itemsets in DHU of the original database, 
do the following substeps. 
Substep 12-1: Calculate the actual utility 
value of each itemset s for the new 
transactions as: 
??
? ?
=
k jts si
jk
d usau )( , 
where ujk is the utility value of each item ij 
in each new transaction tk. 
Substep 12-2: Set the updated actual utility 
value of itemset s in the updated database 
as: 
)()()( sausausau dDU += . 
Substep 12-3: Check whether the actual 
utility value of itemset s is larger than or 
305
equal to the updated minimum high utility 
count (mucD + mucd). If it satisfies the 
above condition, put it in the set of updated 
high utility itemsets, HUU. 
STEP 13: For each high transaction-weighted 
utilization itemset s in UHTWU  of the   
updated database, if it does not appear in the 
set of high transaction-weighted utilization 
itemsets in DHU of the original database, 
do the following substeps. 
Substep 13-1: Calculate the actual utility 
value of each itemset s for the new 
transactions as: 
??
? ?
=
k jts si
jk
d usau )( . 
Substep 13-2: Rescan the original database 
to determine the actual utility value auD(s). 
Substep 13-3: Set the updated actual utility 
value of itemset s in the updated database 
as: 
)()()( sausausau dDU += . 
Substep 13-4: Check whether the actual 
utility value of itemset s is larger than or 
equal to the updated minimum high utility 
count (mucD + mucd). If it satisfies the 
above condition, put it in the set of updated 
high utility itemsets, HUU. 
 
After STEP 13, the high utility itemsets for the 
updated database can then be updated. 
 
4. An example 
 
In this section, the new transactions to be inserted 
are shown in Table 4. 
 
Table 4. Five new transactions in the example 
TID A B C D E F 
11 3 0 4 8 0 0 
12 3 0 3 7 0 0 
13 3 0 2 6 0 0 
14 1 0 0 0 1 1 
15 4 3 0 0 0 0 
 
The original database and already discovered high 
transaction-weighted utilization itemsets with their 
actual utility values were shown in Table 3. Assume 
the minimum high utility threshold is also set at 35%. 
The proposed incremental algorithm for record 
insertion proceeds as follows.  
STEP 1 & 2 & 3: The utility value of each item 
occurring in each new transaction in Table 4 is 
calculated. The minimum high utility count in the new 
transactions is then calculated as (1671*0.35), which is 
584.85. The variable k is first set to 1.  
STEP 4 & 5: In this example, {A:1671}, {C:1086}, 
and {D:1086} are then put in the set of high 
transaction-weighted utilization 1-itemsets in the new 
transactions. 
STEP 6: In this example, {A:4399} and {D:3169} 
are then put in the set of high transaction-weighted 
utilization 1-itemsets for the updated database. 
STEP 7: In this example, only {B:2002} is put in 
the set of high transaction-weighted utilization 1-
itemsets for the updated database. 
STEP 8 & 9 & 10: In this example, only {C:2037} 
is then put in the set of high transaction-weighted 
utilization 1-itemsets for the updated database. After 
STEP 8, the high transaction-weighted utilization 1-
itemsets for the updated database are {A:4399}, 
{B:2002}, {C:2037} and {D:3169}. The candidate 2-
itemsets are then generated from the above results. 
STEP 11: The STEPs 4 to 10 are then repeated 
until no candidate itemsets are generated. In this 
example, the results are {A:4399}, {B:2002}, 
{C:2037}, {D:3169}, {AB:2002}, {AC:1884}, and 
{AD:3016}. 
STEP 12: In this example, two itemsets {D:2100} 
and {AD:2007} are considered as the high utility 
itemsets for the updated database.  
STEP 13: In this example, no high utility itemsets 
are generated in this STEP.  
 
After STEP 13, the high utility itemsets for the 
updated database are {D:2100} and {AD:2007}. 
 
5. Experimental results 
 
A series of experiments was conducted to evaluate 
the performance of the two-phase algorithm (TP-HUI) 
in a batch way and our proposed incremental algorithm 
for record insertion (FUP-HUI). The public IBM data 
generator was used in our experiments [8] to evaluate 
the performance. The first 200,000 transactions were 
then extracted [8] to initially mine the high transaction-
weighted utilization itemsets with their actual utility 
values. The next 2,000 transactions were then 
generated sequentially used each time as new inserted 
transactions. Figure 2 then showed the execution time 
required by the two-phase algorithm (TP-HUI) and the 
proposed incremental algorithm (FUP-HUI) for 
processing each 2,000 new transactions on the 
T10I4N4KD200K dataset at 0.2% minimum high 
utility threshold. 
 
306
 
Figure 2. The comparison of the execution time for 
different numbers of inserted transactions 
 
It can be observed from Figure 2 that the proposed 
FUP-HUI ran faster than the TP-HUI in a batch way.  
Experiments were then also made to evaluate the 
efficiency of the proposed FUP-HUI in different 
minimum high utility threshold values and shown in 
Figure 3 for the execution time. The minimum high 
utility thresholds were then set from 1.0% to 0.2% 
(decrease 0.2% each time). 
 
 
Figure 3. The comparison of the execution time at 
different minimum utility thresholds 
 
It can easily be observed from Figure 3 that the 
execution time by the proposed FUP-HUI was much 
less than that by the TP-HUI in a batch way for 
handling record insertion at different minimum high 
utility thresholds.  
 
6. Conclusion 
 
In this paper, an efficient incremental algorithm to 
update the discovered high utility itemsets for record 
insertion is proposed. When new transactions are 
inserted into the original database, the proposed 
maintenance incremental algorithm then partitions 
itemsets into four parts according to they are high 
transaction-weighted utilization itemsets in the original 
database or not and in the new transactions. Each part 
is then processed to update the discovered high utility 
itemsets in its own way. Experimental results show 
that the performance of the proposed algorithm 
executes faster than the two-phase algorithm in a batch 
way.  
 
7. References 
 
[1] R. Agrawal and R. Srikant, “Fast algorithms for mining 
association rules in large databases”, The 20th International 
Conference on Very Large Data Bases, pp. 487-499, 1994. 
 
[2] R. Agrawal, T. Imielinski, and A. Swami, “Mining 
association rules between sets of items in large databases”, 
International Conference on Management of Data, pp. 207-
216, 1993. 
 
[3] R. Chan, Q. Yang, and Y. D. Shen, “Mining high utility 
itemsets”, The 3rd IEEE International Conference on Data 
Mining, pp. 19-26, 2003. 
 
[4] D. W. Cheung, H. Jiawei, V. T. Ng, and C. Y. Wong, 
“Maintenance of discovered association rules in large 
databases: An incremental updating technique”, The 12th 
International Conference on Data Engineering, pp. 106-114, 
1996. 
 
[5] J. Han, J. Pei, Y. Yin, and R. Mao, “Mining frequent 
patterns without candidate generation: A frequent-pattern tree 
approach”, Data Mining and Knowledge Discovery, vol. 8, 
pp. 53-87, 2004. 
 
[6] T. P. Hong, C. W. Lin, and Y. L. Wu, “Incrementally fast 
updated frequent pattern trees”, Expert Systems with 
Applications, vol. 34, pp. 2424-2435, 2008. 
 
[7] Y. Liu, W. k. Liao, and A. Choudhary, “A two-phase 
algorithm for fast discovery of high utility itemsets”, Lecture 
Notes in Computer Science, vol. 3518, pp. 689-695, 2005. 
 
[8] IBM Quest Data Mining Project, (1996, Quest synthetic 
data generation code. Available: 
http://www.almaden.ibm.com/cs/quest/syndata.html. 
 
[9] N. L. Sarda and N. V. Srinivas, “An adaptive algorithm 
for incremental mining of association rules”, The 9th 
International Workshop on Database and Expert Systems 
Applications, p. 240, 1998. 
 
[10] H. Yao, H. J. Hamilton, and C. J. Butz, “A foundational 
approach to mining itemset utilities from databases”, The 4th 
SIAM International Conference on Data Mining, pp. 211-
225, 2004. 
307
