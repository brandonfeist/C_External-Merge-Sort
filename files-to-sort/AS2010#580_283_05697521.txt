ANALYSIS AND IMPLEMENTATION OF  
ASSOCIATION RULE MINING  
KARTHIYA BANU.R 
Master of Computer 
Applications 
Loyola Institute of Technology 
Palanchur, Chennai, Tamil 
Nadu, India 
karthiyabanu@gmail.com
Dr. RAVANAN. R 
Department of Statistics 
Presidency College 
Chennai, Tamil Nadu, India. 
ravananstat@gmail.com
GOPAL.J 
Master of Computer 
Applications 
Loyola Institute of Technology 
Palanchur, Chennai, Tamil 
Nadu, India 
jgopalmca@in.com 
. 
Abstract 
Data mining Build models of the world 
(regression, decision trees, neural networks, 
association rules, fuzzy systems,..  ) from data 
that represent snippets of information about the 
world. Use these models to understand and 
discover patterns of interest that may provide 
knowledge deployable in improvingbusiness 
processes. The non-trivial extraction of novel, 
implicit, and actionable knowledge from large 
databases and in a timely manner. The APriori 
Data Mining Algorithm is used to create 
association rules from sets of items.   
The algorithm finds patterns of items Algortihm 
uses knowledge from previous iteration phase to 
produce frequent itemsets that are frequently 
associated together. A confidence measure is 
created for each rule generated from the 
frequent itemsets.  
Keywords: Data mining, Apriori Algorithm, 
Assocaition rules  
1. Introduction 
A set of items is defined as an itemset and 
represents items found in a dataset 
The datasets can be obtained from real world 
databases representing shopping carts, retail 
transactions, data warehouses, sales, orders and 
purchases database tables or created artificially. 
The APriori algorithm is used to analyze a list of 
transactions for items that are frequently purchased 
together. Considering a transaction where the sale 
of software is increased by the sale of e-books, 
Support and Confidence are two measures used to 
describe market based analysis association rules 
created with an APriori algorithm.  
2. Association rule mining
Association rule mining finds interesting 
associations and/or correlation relationships among
large set of data items. Association rules show 
attribute value conditions that occur frequently 
together in a given dataset. A typical and widely-
used example of association rule mining is 
Market Basket Analysis.  
The associations that Apriori finds are 
called Association rules. An association rule has 
two parts. The Antecedent is a subset of items 
found in sets of data. The Consequent is an item 
that is found in combination with the antecedent. 
Two terms describe the significance of the 
association rule. The Confidence is a percentage of 
data sets that contain the antecedent. The Support
is a percentage of the data sets with the antecedent 
that also contain the consequent 
The input to association rule mining consists of a 
database T of N transactions, T = t1; t2; : : : tN 
over a set of m items 
I= fI1; I2; : : : Img. Each transaction is a subset of 
I. Let ¢ denote the size of the largest transaction2. 
A subset X ? I is called an itemset. The frequency 
of an itemset is the ratio of the number of  
transactions that contain the itemset to the total 
number of transactions in the database. We say that
an itemset X is p-frequent if its frequency is at least 
p. The goal of association rule mining is to 
discover association rules of the type W ) I where 
W ? I and I 2 I nW. The support of a rule W ) I is 
equal to the frequency of the itemset W [I. The of a 
rule W ) I is equal to the ratio of the frequency of W 
[I to the frequency of W. Given two parameters, ? · 
1 (called as support threshold) and ° · 1 (called as 
confidence threshold), the goal of association rule 
mining is to discover association rules that have a
475978-1-4244-8594-9/10/$26.00 c©2010 IEEE
support of at least ? and a confidence of at least °. 
The intuitive meaning of such a rule is that 
transactions that contain W[I occurs frequently and 
a large fraction of the transactions that contain W 
also contain I. 
3. Problem Formulation 
Typically, the task of association rule mining is 
carried out in two steps. The  fiirst step consists of 
finding all ?-frequent “ itemsets in the database. 
The second step consists of forming the association
rules among the frequent itemsets [2]. It has been 
observed that the ¯ rst step of identifying the 
frequent itemsets is the most computation and I/O 
intensive. 
Therefore, we first  consider the problem of 
frequent itemset mining where the goal is to mine 
all ?-frequent itemsets. 
4. APriori Data Mining Algorithm 
Its Developed by Agrawal and Srikant 1994. It 
gives an Innovative way to find association rules 
on large scale, allowing implication outcomes that 
consist of more than one item 
Apriori algorithm in pseudocode 
L1= {frequent items}; 
for (k= 2; Lk-1 != ; k++) do begin
Ck= candidates generated from Lk-1 (that is: 
cartesian product Lk-1 x Lk-1 and eliminating any  
k-1 size itemset that is not frequent); 
for each transaction t in database do
increment the count of all candidates in  
 Ck that are contained in t 
Lk = candidates in Ck with min_sup 
end
return ?k Lk; 
5. Sets of database 
Transactional database D 
All products an itemset I = {i1, i2,…, im} 
Unique shopping event T ? I 
T contains itemset X iff X ? T 
Based on itemsets X and Y an association rule can 
be X  Y
It is required that X ? I, Y ? I and 
X ? Y = ?  
up(1 ? 2)     3/5 
conf((1,2)) = ---------------- = ------ = 3/4 
    sup(1)          4/5 
relation of number of events containing both 
itemsets Xa and Xb to number of events containing 
an itemset Xa  
Each set of data has a number of items and is called 
a transaction. The output of Apriori is sets of rules 
that tell us how often items are contained in sets of 
data 
There are thousands (or more) total items to search
and possibly a much larger number of 
combinations of those items that make up all the 
data sets. Apriori is a fairly efficient way to iterate 
through the sets of data and finds association rules 
depending on a particular confidence and support 
provided as input. 
5.1 Large Item Set  
A set of items that is contained in enough 
transactions such that the percentage of 
transactions that contain this item set is greater 
than or equal to the minimum support.  
476 2010 International Conference on Signal and Image Processing
5.2 Candidate Set 
 A set of items that is currently being tested to see 
if it is a large item set or not. Candidate sets have a 
reference count and a current count. The reference 
count is the number of transactions (or sets of 
items) in the entire data set that contain this 
candidate set. The current count is used for 
calculating a probability of this set being a large
item set as the algorithm iterates and adds 
candidate sets to the frontier set. 
5.3 Frontier Set  
The set of all Candidate Sets. This is reset at the
end of each iteration of the algorithm to be the set 
of candidate sets that are expected to be large but
are not yet known if they are really a large item set 
or not.  
6. Limitations of Apriori algorithm 
1) Needs several iterations of the data 
2) Uses a uniform minimum support 
threshold 
3) Difficulties to find rarely occuring events 
4) Alternative methods (other than appriori) 
can address this by using a non-uniform
minimum support thresold 
5) Some competing alternative approaches 
focus on partition and sampling
Results 
Table-1 
Total No.of  Items =5 
               
Table-2 
 
 

 
 

    







     	 






  Graphical Representation 
5. Conclusions  
The association rules are simply taken from subsets
of the large item sets. First of all, if there is a Large 
Item Set that has 4 items, then all the subsets of 
items of length ( 3, 2, and 1) are also large item 
sets. The association rule is found by taking the 
reference count of those item sets of length n-1, 
where n is the length of the item set, that are 
contained in the item set, and dividing by the 
reference count of the item set. The result is the 
confidence of the association rule. If the 
confidence meets your minimum confidence 
requirement, then the rule is output.  
The APriori Algorithm basically finds the support 
count and confidence of itemsets eliminating those 
itemsets that do not meet a minimum support count 
and confidence measure from a final list of rules 
created.  




  


  ! "
  
 "
  ! "	
  
 "
  # "
.	
 



$% &''''	(
)
&'''	''
'	''	'	(
*
&''	''
	'	''	'
	'	(
+)
&'	'	'
	'	(
$ &	(
2010 International Conference on Signal and Image Processing 477
6. References 
[1] R. Agrawal, T. Imielinski, and A. Swami. 
Mining      associcion rules between sets of items 
in large databases. In SIGMOD Conference, 
pages 207{216, 1993. 
[2] R. Agrawal and R. Srikant. Fast algorithms 
for miningassociation rules in large databases. In 
VLDB, pages 487{499, 1994. 
[3] N. Alon and J. Spencer. The Probabilistic 
Method. JohnWiley, 1992. 
[4] A. Ceglar and J. Roddick. Association 
mining. ACM Computing Surveys, 38(2), 2006. 
[5] B. Chen, P. Haas, and P. Scheuermann. A 
new two-phase sampling based algorithm for 
discovering association rules. In Proceedings of 
ACM-SIGKDD Conference on Knowledge 
Discovery and Data mining 
(KDD), pages 462{468, 2002. 
[6] H. Mannila, H. Toivonen, and A. Verkamo. 
Efficient  algorithms for discovering association 
rules. In Proceedings of the AAAI workshop on 
Knowledge Discovery in Databases, pages 
181{192, 1994. 
[7] H. Toivonen. Sampling large databases for 
association rules. In VLDB, pages 134{145, 
1996. 
[8] M. Zaki, S. Parthasarathy, W. Li, and M. 
Ogihara. Evaluation of sampling for data mining 
of association rules. In RIDE, 1997. 
[9]M. Ester, H.P. Kriegel, J. Sander, X. Xu, A 
density-based algorithm for discovering clusters 
in large spatial databases with noise, in:Proc. of 
the 2nd International Conference on Knowledge 
Discovery and Data Mining, Portland, Oregon, 
1996, pp. 226– 231.  
[10] Fayyad U , Piatetsky-Shapiro G, Smyth P, 
The KDD process for extracting useful 
knowledge from volumes of data. Communi-
cations of the ACM, 1996 , 39(11):27 35  
[11] E. Knorr, R. Ng, Finding aggregate 
proximity relationships and commonalities in 
spatial data mining, IEEE Transactions on 
Knowledge and Data Engineering 8 (6) (1996) 
884–897.  
[12Jiangping Chen, An algorithm about spatial 
association rule mining based on cell pattern, 
Geoinformatics2006,wuhan. 
478 2010 International Conference on Signal and Image Processing
