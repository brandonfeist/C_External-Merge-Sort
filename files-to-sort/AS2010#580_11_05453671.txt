Associating IDS Alerts by an Improved Apriori Algorithm 
 
Wang Taihua 
School of Computer and Information Engineering 
 Jiangxi Normal University 
Nanchang Jiangxi 330022, China 
E-mail: nuciewth@Yahoo.cn 
Guo Fan 
School of Computer and Information Engineering 
 Jiangxi Normal University 
Nanchang Jiangxi 330022, China 
 
 
Abstract—Among a large number of association rule mining 
algorithms, Apriori algorithm is the most classic one, but the 
Apriori algorithm has three deficiencies, namely: the need for 
scanning databases many times, generating a large number of 
Candidate Anthology, as well as frequent itemsets iteratively. 
The paper presents a method that solves the maximal frequent 
itemsets through one intersection operation. The degree of 
support is obtained through the times of intersection without 
having to scan the transaction database, by numbering some of 
the properties to reduce memory space and search the 
candidate set list easily, thereby enhancing the efficiency of the 
algorithm. Finally, it can generate association rules for 
Intrusion Detection System. Experimental results show that 
the optimized algorithm can effectively improve the efficiency 
of mining association rules. 
Keywords-data mining ? association rules ? Apriori 
algorithm?itemsets 
I. INTRODUCTION 
Data mining [1] is the most dynamic emerging research 
in today's database technology and artificial intelligence 
research; the main goal is to dig out valuable models from a 
large database for users. In the transaction database, mining 
association rule is a very important research topic in data 
mining field. Intrusion Detection System (IDS) is the core of 
security technology. It can effectively cooperate with the 
other network security products and provide proactive and 
real-time protection for the network. Data mining 
technology may be used to discover the knowledge and 
establish attack behavior model from original IDS alerts. 
Firstly, some basic concepts and issues of association 
rules are presented in the following.  
Association rules discovery is an aspect of data mining. 
An association rule is a rule that describes relationship 
between the data items in the database. Mining objects are 
generally transactional database.  
The following is the formal description of association 
rule mining problems: Set I = (i1, i2… im) ij is an item. Set D 
as a transaction database, T ? I, T has an identity TID. 
Association rule is the form like "X Æ Y", if X ? I, Y ? 
I, X ? Y = ?. Conditions that association rule X ÆY is set 
up: ?  with support for S. Namely, in the transaction 
database D, there are at least S% of the transaction that 
contains X ? Y, itemset (X ? Y) is called the support 
rate for the support rate of association rules. Denoted by: S 
(X Æ Y) = S (X ? Y). ? with a confidence level C. 
Namely, in the transaction database D contains X's affairs at 
least C% of the transaction and contains Y. Association rule 
X Æ Y level of confidence recorded as: C (X Æ Y) = s (x 
? y) / s (x) * 100%; if S (X Æ Y) ? min_sup (minimal 
support) and C ( X Æ Y) ? min_conf (minimal confidence 
level), claimed that stronger rules of association rules, 
otherwise known as the weak rule. 
Maximal frequent itemsets [2]: all of its direct supersets 
are not frequent itemsets. 
Closed itemsets [3]: If all the direct supersets of an 
itemset do not have the same degree of support with it. 
Frequent closed itemsets [3]: a closed itemset is frequent. 
Third International Symposium on Intelligent Information Technology and Security Informatics
978-0-7695-4020-7/10 $26.00 © 2010 IEEE
DOI 10.1109/IITSI.2010.47
478
Association rule mining problem is to find out all the 
strong association rules with a given degree of support and 
confidence in the D. Therefore, the mining association rules 
can be divided into two sub-issues: 
According to the minimum support rate to find out all the 
frequent itemsets in the database D, if S (X) ? min_sup, 
claims X as a frequent itemset. 
Generate association rules. For each frequent itemset X, 
Y, if X ? Y, X ? ?, S (X) / S (Y) ? min_conf, the 
association rule is Y Æ (Y-X). 
As the second step is relatively easy, the current research 
focuses on the first step, that is, to find frequent itemsets. As 
the number of different itemsets can be up to 2m and the 
scale of database is large, it is almost impossible calculating 
the support of all items. 
II. RELATED WORK 
A. Apriori Algorithm 
Apriori algorithm is proposed by R. Agrawal and R. 
Srikant in 1994. To be used in IDS, the algorithm may be 
improved from the following aspects: 
If some candidate itemsets are considered as 
non-frequent ones, they should not be generated. 
There are many duplicated comparing operations on the 
same items in the connection operation. 
Each time after the candidate itemsets are generated, it 
scans the database again to determine whether these 
candidates are frequent ones. The procedure includes many 
duplicated and unnecessary scanning operation. 
To be used in IDS process, it only considers the 
association rules between the maximal frequent itemsets and 
all the other ones can be ignored. 
B. Improved Apriori algorithm  
Many researchers have focused on improving the Apriori 
algorithm, and they have put forward a number of ideas. All 
the previous research may fall in the following categories: 
partition-based technology, matrix compression, the 
weighted attributes [4] etc. Valdes [5] improved the 
algorithm by cutting the candidates of non-frequent 
sequences in the L1 sequence, and identifying sequential 
models from the remaining candidates. In order to reduce the 
number of scanning and quickly discover user behavior 
models, Yan [6] used the ratio of support to expected 
support to denote the conditional probability from item X to 
item Y. Treinen [7] proposed an improved one by applying 
priority attributes to items with length l (l ?k) to determine 
the candidate k-th itemsets so that the scanning times is 
reduced. 
III. IMPROVEMENT ON NON-ITERATIVE APRIORI 
ALGORITHM 
Traditional Apriori algorithms solve candidate itemsets 
by iteration. They are improved by decreasing candidate 
itemsets and reducing scanning times. But in essential, the 
bad performance of the algorithm mainly results from the 
iteration of self-join operations. The paper proposes a 
non-iterative improved Apriori algorithm which is mainly 
used in IDS. 
A.  The algorithm basis  
The characters and lemma of association rules include: 
1) Subsets of any frequent itemset are also frequent 
itemsets. 2) The super sets of any non-frequent itemset are 
non-frequent.  3) The subsets of any maximum frequent 
itemset must be frequent, and super sets of it are 
non-frequent.4) The super sets of any closed itemsets are 
non-frequent.Lemma 1: Any maximum frequent itemset can 
be obtained by the intersection operation. Lemma 2: 
Intersection operation can get all the frequent itemsets. 
Lemma 3: The value of support degree relates to the number 
of intersection operations. 
The following is the demonstration procedures of the 
lemmas (min_sup value with 1 is not considered). 
  1) ???? supmin_)(,( XsIXX   
     sup))min_)(,,( <??? YsIYYXY  
      =>s(X)?min_sup?2 
      =>
),(ji Xji TT ji =??? ?  
  Conclusion: Any maximum frequent itemset must be 
supported by at least two items. 
  2) sup)min_)(,( ??? XsIXX  
     => ?<???¬ sup)min_)(,,( YsIYYXY  
       sup)min_)(,,( <??? YsIYYXY  
479
     =>
),(ji TT jiXji ?????  
  Conclusion: Any frequent itemset is a maximal 
frequent itemset, or a subset of a maximum frequent itemset. 
  3) Define a function count(x) which denotes the times 
of the intersection to get itemset x. Let x is supported by n 
items, if there is an intersection between any two items, the 
total number of intersections is count(x).The relationship 
between s(x) and count(x) is that count(x) = CS(X)2 
  Conclusion: the support degree of an itemset is 
determined by count(x) without scanning the transaction 
database D. 
During IDS alert mining procedure, only the maximum 
frequent itemsets are considered, since association rules with 
low-dimension have no practical effects. Since most 
candidate itemsets with high degree of support are obtained 
by intersection operation, and they are probably the maximal 
frequent ones, the paper proposes a method that replaces 
iteration with intersection operation, discarding useless 
sub-frequent itemsets. Intersection operations can select the 
candidate itemsets whose support degree are not less than 
two and be sure to get all the maximum frequent itemsets. 
The support degree of the candidate itemsets is obtained by 
counting the number of intersection operations, not by 
re-scanning transaction database. In order to simplify the 
intersection operations, in the pre-processing stage, some of 
the attributes are indexed separately. 
B.  The algorithm procedure 
The algorithm procedure is depicted in the following: 
Step 1: The conversion phase makes indexes for alert 
attributes such as protocol type, alert type, and attack 
category so as to simplify intersection operation. 
Step 2: Doing intersection between transactions to get 
the maximal itemsets. If the results are found in the list of 
the candidate itemsets, the counter is added by 2, otherwise, 
the result is inserted into the list and the counter is reset as 2. 
The counter denotes the support degree for the transaction. 
Step 3: Obtaining all frequent itemsets. The counters in 
the list are converted into the value of the support degree. A 
candidate itemset is a frequent one if its support degree is 
not less than predefined min_sup. 
Step 4: Generating Association rules. In our experiments, 
an association rule only involves attack type, and the 
algorithm only generates the association rule like XÆY, 
where Y is the attack behavior. If the confidence of an 
association rule is greater than or equal to min_conf, it is a 
strong one. 
The formal description of Algorithm is described as 
below: 
Input: transaction database D = (TID1, TID2 ... TIDn), 
the minimal transaction support threshold min_sup.  
Output: maximal frequent itemsets L 
/ / Pre-processing  
for (each i,j i<n&&j<m){ 
        if (itemj? TIDi) 
convert(itemj); // the last three properties  will be encoded 
} 
// Core Algorithm 
count= 0;   //the number of itemsets elements 
for each TIDi? D?TIDj? D?i? j?{ 
temp = TIDi ? TIDj;   // Seek common ground 
if(temp!=? ){      
// Search for candidate itemset list 
Index = Serchitem(temp);    
// If it already exists, then the automatic counting, otherwise, this 
//candidate set to join the candidate list. 
if(index== -1)  hash[index]++; 
else{ 
         itemsets.add(temp); 
hash[Count++]=1; 
}}} 
For each itemsets.get(k) (k?Count){ 
    if(hash[k]? min_sup-1){ 
       Add itemsets.get(k) to L 
 // the candidate set K is a frequent candidate set 
    }} 
// generating association rules 
For each Li?L { 
 Y = Attacks?         X = Li –Y; 
 If(conf(XÆY)?min_conf)  // it is a strong //association rules? 
480
   Associate(XÆY)     // Generating a new rule 
} 
C.  An example 
Table I shows the original database D from 
AllElectronics [8], which includes nine items and five 
attributes. The minimum support degree is 2. 
TABLE I. THE TRANSACTIONAL DATABASE OF A BRANCH OF   
ALLELECTRONICS. 
id items 
T1 I1,I2,I5 
T2 I2,I4 
T3 I2,I3 
T4 I1,I2,I4 
T5 I1,I3 
T6 I2,I3 
T7 I1,I3 
T8 I1,I2,I3,I5 
T9 I1,I2,I3 
The Apriori algorithm works in the following procedure: 
Error! Reference source not found.Scanning database 5 
times to get five 1-frequent itemsets {I16, I27, I36, I42, 
I52}.Error! Reference source not found.10 times 
intersection operation for the candidate itemsets, and 10 
times scanning operation to get six 2-frequent itemsets 
{I1I24, I1I34, I1I52, I2I34, I2I42, I2I52}.Error! Reference 
source not found.30 times intersection operation and 6 
times scanning operation to get two 3-frequent itemsets 
{I1I2I32, I1I2I52}.Error! Reference source not found.One 
intersection operation and one scanning operation to get 
nothing.  
Apriori needs 41 times intersection operation and 
scanning database 22 times to get frequent itemsets {{I1, I2, 
I3, I4, I5}, {I1I2, I1I3, I1I5, I2I3, I2I4, I2I5}, {I1I2I3, I1I2I5}}.  
The improved works like the following. 
Since the transaction database has only one attribute, the 
pre-processing stage is unnecessary. In this case, after the 
intersection operation repeats C92 times and scanning 
candidate itemset list 9 times to count the values of support 
degree, the result list of the frequent itemsets is like {{I1,I2,I3 
},{ I1I2, I1I3, I2I3, I2I4}, {I1I2I3, I1I2I5}}. It is obvious that 
itemsets I2I4?I1I2I3?I1I2I5 are maximum frequent itemsets 
and others are their subsets.  
If either intersection operation or the comparison 
operation is a basic unit operation, Apriori algorithm needs 
41+22×9=239 units, but the improved algorithm needs only 
C92+9=81 units. The non-iterative algorithm is obviously 
more efficient than Apriori. 
D.  Experimental Analysis 
MIT Lincoln Laboratory DARPA99 and DARPA2000 
[9] data sets are chosen to evaluate the effect of the 
algorithm. Inside-network alerts of the third week are used 
off-line with Snort 2.4.2 running as NIDS mode under Red 
hat Linux 9.1, opening all the detection capabilities, using 
the default full alert mode.  
Table II shows the original DARPA99 and DARPA2000 
data. The first and second column denotes the week day on 
which the alerts were generated. The third column means the 
total number of the captured packets and the forth column 
points out the number of the types of the alerts. For example, 
on Wednesday, there are 39 kinds of alerts and the total 
number of alert is 3465.  
TABLE II. DARPA ORIGINAL DATA SHEET 
data source alert number alert type 
2000year inside 1883 21 
DMZ 486 19 
99Mon inside 3407 40 
99Tue inside 3887 43 
99Wen inside 3465 39 
99Thu inside 3840 36 
99Fri inside 4151 44 
TABLE III. ALERT CORRELATION RESULTS  
data source association 
number 
attack 
type 
2000 inside 18 4 
DMZ 46 4 
99Mon inside 9 3 
99Tue inside 10 3 
481
99Wen inside 11 3 
99Thu inside 10 4 
99Fri inside 6 3 
Firstly a format conversion module converts the original 
alerts to the normalized ones, which take source IP, source 
port, destination IP, destination port, protocol type, alert 
classification, and attack type as mining attributes. We use 
the normalized alerts as the input. The implementation is 
based on the java platform. Threshold values are configured 
as min_sup = 0.01 and min_conf =0.1. 
Table III shows the mining association results. The 
algorithm generates some useful association rules. The first 
two column are as same as table 1.The third column points 
out the number of the strong association rules of the alerts 
and the forth column denotes the number of the attack type 
of the alerts. For example, on Wednesday, there are 3 kinds 
of attack types and the total number of strong association 
rules is 11.  
Experimental results denote the analysis of data sets in 
the third week. Only 0.4% alerts are mined as strong 
association rules, which include "CHAT IRC message",    
"Potential Corporate Privacy Violation" originated by 
attacking the port 6667 of address 192.168.1.20 frequently. 
The rule "INFO TELNET access” also shows that telnet 
service on IP address 172.16.112.50 is frequently accessed.  
There is an important rule named "SNMP public access 
udp" which denotes 635 duplicated alerts on Thursday, since 
IP 192.168.1.30 sends data packets to port 161 on IP 
172.16.112.100 through port 32775 every 1 ~ 2 minutes. 
Obviously, the algorithm is useful to reduce the duplicated 
alerts and help the administrator improving the efficiency. 
The inside network dataset of Darpa2000 is also used. In 
the dataset, there is an attack chain composed of five stages. 
Four of the five stages are denoted correspondingly by the 
alerts "RPC portmap sadmind request UDP", "Decode of an 
RPC Query", "RPC sadmind query with root credentials 
attempt UDP", "RPC port map Solaris sadmin port query 
udp portmapper sadmin port query attempt". The algorithm 
successfully mined all the four rules, which show the full 
intension of the attacker. The attacker starts from 
202.77.162.213 attempting to find the host with "RPC 
sadmind" vulnerability. Then, he sends a decoding of RPC 
requests. After that, he launches an exploit to obtain 
administrator privileges. Finally, he calls rsh to get a remote 
Shell. This result demonstrates that the algorithm may help 
the administrator finding out the intension of the attacker. 
IV.  CONCLUSION  
The iterative self-join operations used in traditional 
algorithms include many duplicated and unnecessary scans 
which result in the low performance. The paper proposes an 
improved way which removes the iteration procedure and 
uses one intersection operation to generate maximal frequent 
itemsets. Experiments demonstrate that the improved one 
can quickly generate some strong association rules. These 
rules may denote the targets of the attacks and the intention 
of the attackers so that they may help the administrator to 
find out valuable information. 
By now, the improved algorithm mines association rules 
with IDS alerts not with alert attributes, so it may not be 
extended to broad excavation. The time attribute of the alerts 
are not considered yet. In future work, alert attributes are to 
be involved in the association rules which help constructing 
the attack scenarios in the form of IDMEF [10]. 
REFERENCE 
[1] Hu Kan, Xia Shao2wei. Data mining based on large data ware2house: 
survey [J]. Journal of Software, 1998, 9 (1): 53262. 
[2] R.Bayardo. Efficiently Mining Long Patterns from Databases. In Proc. 
Of 1998 ACM-SIGMOD Intl.conf.on Management of Data, pages 
85-93,Seattle,WA,June 1998 
[3] M.J.Zaki and M,Orihara.Theoretical foundations of association rules. 
In Proc. Of the 1998 ACM SIGMOD Workshop on Research Issues in 
Data Mining and Knowledge Discovery, seattle, WA , June1998. 
[4] G.D.Rankumar, S.Ranka, and S.Tsur.Weighted Association Rules: 
Model and Algorithm. http://www.cs.ucla.edu/~czdemo/tsur/,1997 
[5] A Valdes, K Skinner. Probabilistic Alert Correlation [C] . 4th 
International Workshop on the Recent Advances in Intrusion Detection 
(RAID’2001), Davis , USA ,2001. 
[6] X.Yan, J.W.Han, R.Afshar. CloSpan: Mining Closed Sequential 
Patterns in Large Databases. In SDM'03, San Francisco, CA, May 2003. 
[7] J.J.Treinen, R.Thurimella. A Framework For The Application Of 
Association Rule Mining In Large Intrusion Detection Infrastructures. 
Recent Advance In Intrusion Detection 2006, LNCS 4219, Berlin: Springer 
Verlag 2006:1-18. 
[8] Jiawei Han and Micheline Kamber, Data Mining: Concepts and 
Techniques [M], 2nd edition, Morgan Kaufmann, 2006, Page 151.  
[9] MIT Lincoln Labs. 1999 DARPA intrusion detection evaluation [EB 
/OL ]. [ 2007 - 03 - 15 ]. http: //www. ll.mit.edu /IST/ideval/ in2dex. html.  
[10] POPPI S. Snort IDMEF plugin [EB /OL ]. [2005 - 11 - 15 ].http:// 
sourceforge.net/projects/ snort2idmef. 
482
