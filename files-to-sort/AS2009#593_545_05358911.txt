Foundation item:  Supported by the National Natural Science Foundation of China (NO.70861001) and Natural Science 
Foundation of Guangxi (Guangxi Science 0991027).  
Biography: Lv Yue-jin was born in 1958. He is a professor. His main research interests include Rough Sets and Data 
Mining. Tao Duo-xiu was born in 1985. Her research interests include Data mining, Rough Sets. 
A Method Based on Rough Set for Mining Multi-dimensional Association Rules  
Tao Duo-xiu1  
College of Electrical Engineering  
Guangxi University 
Nanning, China 
e-mail: tdx220@163.com 
LV Yue-jin2 
College of Mathematics and Information Sciences 
Guangxi University 
Nanning, China 
e-mail: lvyjin@126.com
  
Abstract—It is very time-consuming to discover association 
rules from the mass of data, but not all the rules are interesting 
to the user, a lot of irrelevant information to the user’s 
requirements may be generated when traditional mining 
methods are applied. In addition, most of the existing 
algorithms are for discovering one-dimensional association 
rules. Therefore, this paper defines a mining language which 
allows users to specify items of interest to the association rules, 
as well as the criteria (for example, support, confidence, etc.), 
and proposes a method based on rough set theory for multi-
dimensional association rule mining methods, dynamically 
generate frequent item sets and multi-dimensional association 
rules, which can reduce the search space to generate frequent 
itemsets. Finally, an example is used to illustrate the algorithm 
and verify its feasibility and effectiveness.  
Keywords: association rule; multi-dimensional association 
rule; frequent itemsets; rough set 
I.  INTRODUCTION 
An association rule describes the interesting association 
or relevant connection among items in the large amount of 
data [1]. Association rules have been widely applied in many 
areas, such as e-commerce, association analysis of the link 
between the web documents and so on. With the 
accumulation of data, many industry and researchers are 
increasingly interested in mining association rules, which 
makes the research and application of association rule 
mining is still constantly developing. 
However, the size of the transaction database can be very 
large. It is very time consuming to find all the association 
rules from a large database and users may be only interested 
in some information. Moreover, the criteria of the discovered 
association rules may not be the same. Many uninteresting 
information for the user requirements can be generated when 
traditional mining methods are applied. Hence, a data mining 
language needs to be provided such that users can query only 
interesting knowledge to them from a large database of 
customer transactions. In this paper, a data mining language 
is presented in which users can specify the interested items 
and the criteria of the association rules or sequential patterns 
to be discovered. 
Literature discussion: Association rule mining problem 
and Apriori algorithm were proposed firstly by Agrawal etc.  
[2]. Initial research was largely motivated by the analysis of 
market basket data, the results of which allowed companies 
to more fully understand purchasing behavior and, as a 
result, better target market audiences. Some have also made 
optimization of Apriori algorithm, see as reference [3,4]. 
However, Apriori-like methods may produce a large number 
of frequent item sets. It is time-consuming and costly to 
compute frequent itemsets. In response to this inherent 
defect, J. Han etc. [5] introduced a FP-growth, which doesn't 
produce frequent itemsets. After the first scanning, put the 
frequent itemsets in the database into a compressed Frequent 
Pattern Tree (FP-tree), meanwhile, keep the key information, 
and then, divide the FP-tree into certain condition bases, 
each is relevant to 1-lenth frequent itemsets, thus mining 
association rules on these condition base can be performed 
respectively. So it can reduce the search costs and improve 
efficiency. However, it is unrealistic to build FP-tree based 
on memory when the database is large. Besides, many 
constraint-based mining methods have been proposed. Pei 
and Han [5] developed pattern-growth methods for 
constrained frequent pattern mining and sequential pattern 
mining. An item constraint specifies what is the particular 
individual or group of items that should or should not be 
presented in the pattern. In paper[6],the author categorized 
all the constraints into five classes, proposed and studied one 
class of constraints called convertible constraints, which can 
be nicely integrated into the existing framework of frequent 
pattern mining, moreover, developed a new constrained 
frequent pattern mining method, called constrained frequent 
pattern mining CFG. But all the above approaches cannot 
discover the associations among certain items and all the 
other items.  
Meo R etc. proposed a SQL-like operator for extracting 
association rules [7]. However, SQL-like operator cannot 
completely express the associations among certain items and 
all the other items. Furthermore, the SQL-like operator 
performs have little efficiency. Yen, S.J [8] proposed a data 
mining language for mining interesting association rules. 
The approach constructs an association graph and generates 
all the frequent itemsets by traveling the association graph. 
However, it needs to take a lot of memory space to record 
the related information. 
To date, most of algorithms aim at mining 2-value 
attributes database or one-dimensional association rules 
mining, but multi-value attributes and multi-dimensional 
rules are more general. Although a number of one-
dimensional association rules can be extended to multi-
dimensional association rule mining, but there are lots of 
problem such as low efficiency when they are applied to 
large database [9]. 
2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery
978-0-7695-3735-1/09 $25.00 © 2009 IEEE
DOI 10.1109/FSKD.2009.163
34
In response to these issues above: Constraint-based 
approach to improve efficiency; allows users personalized 
requirements to mining process, obtain association rules in 
multi-dimensional case. This paper defines a mining 
language allows users to specify interesting items and 
criteria(such as support, confidence, etc. moreover, propose a 
novel multi-dimensional association rules mining technology 
based on rough set, which can reduce the generation of 
frequent itemsets search space and improve the efficiency. 
II. BASIC CONCEPTS AND PROBLEM IN MULTI-
DIMENSIONAL ASSOCIATION RULE MINING 
2.1 The basic concepts [1,10]  
Definition 1 Let 
1 2{ , , , }mAI I I I= " be the set of all of 
items, in which ( 1, 2, , )kI k m= "  is called item. An 
itemset of length k  is called an k ? itemset. 
Definition 2 A transaction ,T TID I=< > is a tuple, 
whereTID is the identifier of transaction, and I AI? . 
A transaction database TDB is the set of 
transactions, { 1, 2, }TDB T T Tn= " . Let X be an itemset, i.e. 
,T TID I=< > support (also can be said as contain) X  if and 
if X T? . The support number of X  is the number of 
transactions which contain itemset X , then the support of X  
is the support number divided by the total number of 
transactions inTDB . 
Definition 3 If the support for an itemset X satisfies the 
user-specified minimum support threshold 
minsup ( 1 minsup TDB? ? ), then X  is called a frequent 
itemset, simply as a large itemset. 
Definition 4 A rule has the form ,X Y?  in which X and 
Y  are two sets of items. , ,X T Y T X Y? ? = ?? and .  
The support of a rule X Y?  is defined as the support 
for the itemsets X Y? . That is, 
{ ( ) }
( ) ( )
T T TDB X Y T
TDB
support X Y P X Y
? ? ? ?
=? = ?  
The confidence of a rule X Y? is defined as the ratio of 
the support for the itemsets X Y? to the support for the 
itemset X . That is, 
{ ( ) }
{ }
( ) / ( ) .
( ) T T TDB X Y T
T T TDB X T
support X Y support X
confidence X Y ? ? ? ?
? ? ?
=
? =
?
 
If itemset X Y?  is a frequent itemset and the confidence 
of X Y?  is no less than the user-specified minimum 
confidence, then the rule X Y?  is an association rule. 
An multidimensional association rule has the form 
,X Y? in which ,X Y are called the antecedent and 
consequent of the rule respectively, refer to logic formula 
composed by conjunctive normal form, X Y = ?? . 
If a rule only described the items appears in certain case 
or not, then it is a single-dimensional boolean association 
rule, for example, buy milk? buy bread [support = 2%, 
confidence= 60%]. If a rule concern two or more 
dimensional, such as age, income, occupation, buy computer 
or not and so on, then it is a multidimensional association 
rule. For example, age( x ,”30?34” )?income( x ,”42K?
48K”) ? buy ( x ,”computer”), in which x refer to 
customer. 
2.2 Multi-dimensional association mining 
Given a transaction database TDB (see as table 1), 
support threshold is minsup , confidence threshold is 
minconf .Mining multidimensional association rules is a 
task to find those rules whose support is no less than 
minsup and confidence is no less than minconf .Usually, the 
task can be divided to two part processes: (1) the 
identification of sets of items or itemsets within the 
dataset;(2) the subsequent derivation of inferences from 
these itemsets.  
TABLE I.  A TRANSACTION DATABASE OF BASKET DATA FROM A 
SUPERMARKET [11] 
TID ME G income age beer fish 
"
 
39808 CH M 27000 46 F F 
"
 
63762 CA F 30000 28 F T 
"
 
10872 CA M 13200 36 T F 
"
 
26748 CA F 12200 26 T T "  
91609 CH M 11000 24 F F "  
"  "  
"
 "  "  "  "  
"
 
III. ROUGH SET THEORY 
Rough Set theory, initially proposed by the Polish 
mathematician Z. Pawlak in 1982 [12], is a powerful tool to 
deal with uncertainty and ambiguity of the data. To date, the 
theory has received an increasing attention from number of 
scholars all over the world [13-16], and it has been widely 
used in many fields, such as decision-making analysis, 
artificial intelligence, expert systems, pattern recognition, 
machine learning, knowledge discovery and so on.  
Definition 5  Information system , , ,S U A V f=< > , where 
U is a non-empty finite set of n objects, 
1 2{ , , , }nu u u" ,called the universe of discourse, and 
1 2{ , , , }mA a a a= " is a non-empty finite set of m attributes, 
f is an information function, such that ( , ) : af u a U A V× ? , 
for any ,a A?  i.e., ( ) ,aa x V x U? ? ? . aV  is called the 
domain of attribute a .Especially, if ,A C D C D= = ?? ? , 
then , , ,S U A V f=< > is named a decision system (or decision 
table), where D  is a decision attribute set, and C is termed 
the conditional attribute set. We can treat the decision 
attribute as a kind of classifier on the universe of objects 
given by an expert or a decision-maker. 
35
Definition 6 For an information system , , ,S U A V f=< > , 
one can describe relationships between objects through their 
attribute values. With respect to an attribute subset B A? , a 
binary equivalence relation BR  may be defined as 
, , ( , ) ( ) ( )Bx y U x y R a x a y a B? ? ? = ? ?  
BR  is referred to the relation with respect to B derived 
from information system S .With relation B , two objects 
are considered to be indiscernible if and only if they have the 
same value on each a B? , in other words, the 
indiscernibility relation of B  is defined by: 
( ) {( , ) , ( , ) ( , )}ind B x y U U a B f x a f y a= ? × ? ? =  
Obviously, ( )ind B  is also a equivalence relation, 
inducing a partition onU , denoted as / ( )U ind B , or simply 
as /U B . Each element in /U B  is equivalence class 
of ( )ind B , called as elementary set or elementary concept. 
Definition 7 Let B A? , call B is a reduction of A , if: (1) 
( ) ( );ind B ind A=  (2) there exist no 'B B? such 
that '( ) ( )ind B ind A= . 
IV. APPROACH BASED ON ROUGH SET FOR 
MULTIDIMENSIONAL ASSOCIATION RULE MINING 
4.1 Analysis of rough set for multidimensional association 
rule mining 
Based on rough set, we can have that , , ,TDB T I V f=< >  
Definition 8 Indiscernibility relation *( )ind I induces a 
partition on T : /U I ? , I I? ? . Let [ ]X  be a equivalence 
class in it, if I k? = , I k? = ? 1 1{ , , , },kI I I I? = " then 
[ ]X  is called as k ? elementary set, denoted as [ ]kX , 
' '1 1
[ ] { ( , ) ( , ) }k i i i k kX T f T I i f T I i= = ? ? =" , Here, kX  
referred to k ? description ' '1 1( ) ( )
k
k k
X I a I a= = ? ? =" , 
where each normal form 't tI i=  is termed as description 
clause, ' ( )tti V I? . For distinguish, we call the elementary 
set appear in the antecedent of the rule as feature class, and 
those elementary sets appear in the consequent of the rule as 
concepts. 
Definition 9 The support of k ? elementary set is 
([ ]) ([ ]) / ( ).k ksup_count X card X card T= , where ( )card X  
means the cardinal of set X ,i.e., X . Let minsup be support 
threshold, then [ ]kX  is called k ? frequent elementary set, if 
([ ])ksup_count X minsup? . Denote kC  as the family of all 
k ? elementary sets, kL as the family of all k ? frequent 
elementary sets. 
Formally, use ,i jX Y  to represent the item in the 
antecedent and consequent of the rule, respectively. 
According to ' '1 1( ) ( )k kX x X x= ? ? ="  and 
' '1 1
( ) ( )k kY y Y y= ? ? ="  one can derive an association rule 
X Y? between itemset X Yand , whose support and 
confidence as below, respectively, 
' ' ' '1 11 1
([( ) ( )] [( ) ( )])
% 100%
( )
k kk k
card X x X x Y x Y x
s
cardU
= ? = = ? =
= ×
" ? "
, 
' ' ' '1 11 1
([( ) ( )] [( ) ( )])
% 100%
([ ])
k kk k
card X x X x Y x Y x
c
card X
= ? = = ? =
= ×
" ? "
 
Based on the attribute reduction in RS, redundant rule 
can be defined as below. 
Definition 10 If 1 2,X Y X Y? ?  are two rules 
inducing the same concept description, where 
'
1 1 2 2( ) ( ) ( ),k kX X x X x X x= = ? = ? ? =" ,
''
1 1 2 2 1 1( ) ( ) ( ) ( ) ( )k k k k k m k mX X x X x X x X x X x+ + + += = ? = ? ? = ? = ? =" "
i.e. 2 1 1 1( ) ( )k k k m k mX X X x X x+ + + += ? = ? =" , then 
''X Y?  is a redundant rule. 
According to Apriori, a subset of any frequent itemset is 
still a frequent itemset, any superset of a non-frequent 
itemset is still a non-frequent itemset, then we can have that: 
Theorem 1 The necessary condition of a k ? elementary 
set to be k ? frequent elementary set is that all of the 
j ? elementary set including in the k ? elementary set is a 
frequent elementary set. 1 1j k? ? ? . 
To conclude, the rough set approach for 
multidimensional association rule mining is composed of 
two major operations: 
(1) According to Theorem 1, generate 1kC +  from kL  via 
the conjunction operator of elementary sets as follows: 
obtain kC , then choose those feature classes whose support is 
no less than support threshold to form kL . And then make 
conjunction by the feature classes of kL  and 1L , to 
produce 1kC + . 
(2) Delete: According to the principle of Theorem 1, 
check all k ? description of 1[ ]kX +  in 1kC + , if there exist 
[ ]kX  doesn’t appear in kL , then delete [ ]kX  from kC . 
Extract rules whose support is no less than support 
threshold via computing 
' ' ' '1 11 1
([( ) ( )] [( ) ( )])
% 100%
([ ])
k kk k
card X x X x Y x Y x
c
card X
= ? = = ? =
= ×
" ? "
 
in kL , and delete the elementary sets corresponding to the 
rules, in order to avoid redundant rules. 
4.2 Data mining language expressing the users' 
personalization needs (Personalized Data Mining Language, 
PDML) 
The data mining language for interesting multidimensio-
nal association rules is defined as follows. Users can query 
association rules by specifying the related parameters in the 
data mining language. 
Ming<interesting items> From<Transaction DB> with 
minsup s% and minconf c% 
Where <interesting items>specify the items of interest, 
<Transaction DB> is used to specify the database to which 
users query the association rules, and minsup followed by 
36
the user-specified minimum support s%, minconf followed 
by the user-specified minimum confidence c%. 
4.3 An algorithm for mining interesting multidimensional 
association rules based on RS and PDML 
In this section, we focus on mining interesting 
association rules according to proposed data mining 
language. We divide the query into two cases. Case 1: there 
are items in the antecedent and consequent of the discovered 
rules specified. Case 2: there are items in the consequent of 
the discovered rules specified, but the item in the antecedent 
is not specified, which can be any items. Suppose that the 
itemset specified in the antecedent of the discovered rules in 
Case 1 is 1{ , , }tX X X= " , and the itemset specified in the 
consequent of the discovered rules is 1{ , , }Y Y Ys= " . We 
propose an efficient algorithm named MIMAR-RS (Mining 
Interesting Multi-dimensional Association Rules based on 
Rough Set) to find all the interesting association rules 
according to the user requirements, which is described as 
follows: 
Input: transaction data base TDB  , minimum support 
minsup , minimum confidence minconf  
Output: multidimensional association rules sets that 
satisfy the user requirements RL 
Process: 
 Step1: Initialization RL=? ; 
Step 2:Scan TDB ,find all 1-item feature classes, to form 
the set 1C of 1-elementary sets, and compare these 
elementary sets’ support to minsup TDB× , then find all the 
frequent 1-itemsets, generating 1L ;. 
Step3: Obtain elementary sets containing the itemset 
specified and their support 
( ' ' ' '1 11 1[( ) ( ) ( ) ( )]t st sX x X x Y y Y y= ? = ? = ? =" " for case 
1; ' '1 1( ) ( )]s sY y Y y= ? ="  for case 2), If there is no 
elementary set satisfy support threshold, then the algorithm 
end; else all elementary sets no less than minsup  compose 
kL , where k is referred to the length of itemset that user 
specified ( k s t= +  for case 1; k s= for case 2). Then, for 
case 2, go to step 5; 
' ' ' '1 11 1
[( ) ( ) ( ) ( )]t st sX x X x Y y Y y= ? = ? = ? =" "  Or 
' '1 1
( ) ( )]s sY y Y y= ? ="  can be obtained by intersecting 
'[ ]iX x=  and '[ ]jY y=  with elementary sets in 
1L . 
Step 4: For case 1, try to derive association rules that 
satisfy user-specified requirements. If there 
exists ' ' ' '1 11 1[( ) ( ) ( ) ( )]t st sX x X x Y y Y y= ? = ? = ? =" " , such 
that its confidence no less than minconf , then add it into RL, 
and delete ' ' '1 11 1[( ) ( ) ( )t tX x X x Y y= ? = ? = ?"  
'( )]s sY y=" ,which is corresponding with the rule; else go 
to step 5; 
Step 5: Generate candidate ( 1)k + -itemset 1kC +  as 
follows: join kL  and 1L  by intersecting their elementary sets. 
And then 1kL +  can be obtained from 1kC + ; 
Step 6: Similar to step 4, try to extract association rules 
that satisfy user-specified requirements in 1kL + , If there 
exists, then put it into RL and delete the normal form 
corresponding to it; else repeat these steps until the 
n iteration such that k nL + = ? , then stop the calculation, 
output RL. 
Time complexity analysis of the algorithm: Suppose that 
there are n  records in transaction data base, m 1-item, and 
each 1-item can has t  discrete value. The time complexity of 
computing support of one elementary set is O(n) .If the 
length of itemset Y  that user-specified in consequent is L , 
i.e. Y L= , corresponding to h  concepts, then there are 
1 2 2 2 m L
m L m L m LK C t C t C t
?
? ? ?
= × + × + + ×"  feature classes. In 
the worst case, it needs computing K  support to performing 
the rules for one concept, and discreting the values for 1-item 
needs logn n ,so the time for the algorithm is 
( log )h Kn n n× + , since , ,m t h n , hence, the time 
complexity of the algorithm is ( log )O n n . Besides, in this 
algorithm, after obtaining frequent k -itemsets, if some rules 
can be derived, then the elementary sets corresponding to the 
rule will be deleted, thus avoid redundant rules, at the same 
time, reduce performing intersection for frequent ( 1)k + -
itemsets, thus the efficiency of the algorithm can be 
improved. 
V. AN EXAMPLE 
Suppose there is a transaction database TDB  (see as 
table 2), there are 10 transactions in which, i.e. TDB =10. 
If a user want to correlation between B  and E : 
consider E as consequent itemset, discover the effect of B  to 
E , besides, minimum support is 30%minsup = , and 
minimum confidence 70%minconf = . 
Firstly, we turn this requirement to PDML, that is: 
Mining ( B ), ( E ) From TDB  with 30%minsup =  and 
70%minconf = . 
According to the algorithm developed, the performing 
process as follow: 
Scan TDB , obtain 1-elementary sets. 
1 {[ 0],[ 1],[ 2],[ 1],[ 2],[ 0],
[ 1],[ 3],[ 0],[ 1],[ 2],[ 0],[ 1]}.
C A A A B B C
C C D D D E E
= = = = = = =
= = = = = = =
 
Obtain frequent 1-elementary sets. For example, 
([ 0]) { 1, 2, 3, 8} 4 minsupSup_count A T T T T TDB= = = > ×  
Analogously, the support of other 1-elementary sets can 
be computed. Then, 
1 {[ 0] ,[ 1],[ 1] ,[ 2],
[ 3],[ 1],[ 0],[ 1]}
L A A B B
C D E E
= = = = =
= = = =
 
Find 2L  that contains B  and E , that is 
2 {[ 1 1],[ 2 1]}L B E B E= = ? = = ? =  
37
Try to derive association rules containing the itemsets 
that use-specified in 1L  as follow: 
The confidence of 1 1B E= ? =  is : 
([ 1] [ 1])( 1 1)
([ 1])
{ 1, 3, 5}
60% .
{ 1, 3, 5, 9, 10}
card B Econf B E
card B
T T T
minconf
T T T T T
= =
= ? = =
=
= = <
?
 
Analogously, the confidence of 2 1B E= ? =  is also 
60% minconf< , So, both of the rules can’t be add into rule 
sets RL. 
Generate frequent 3- elementary sets contain B and E  to 
form 3L  by performing intersection operation between 
elementary sets in 2L  and 1L . 
For example, [ 1 1] [ 3] [ 1 3B E C B C= ? = = = = ? = ??  
1]E = can be put into 3C , as the support of which is 
{ 1, 3, 5} 3T T T minsup TDB= = = × . 
The result is 3 {[ 1 3 1],[ 2 1L B C E B D E= = ? = ? = = ? = ?  
1]}=  
Try to derive association rules containing the itemsets 
that use-specified in 3L as follow: 
1 3 1B C E= ? = ? = , the confidence is 75%> minconf ; 
2 1 1B D E= ? = ? = , the confidence is75%> minconf  
Then, add these two rules into RL , and delete 
[ 1 3 1],B C E= ? = ? = [ 2 1 1]B D E= ? = ? =  from 3L . 
 Now, 3L become empty, so output the rules in RL , end. 
TABLE II.  AN  EXAMPLE 
TID A  B  C  D  E  
T1 0 1 3 1 1 
T2 0 2 0 1 1 
T3 0 1 3 0 1 
T4 1 2 3 1 1 
T5 2 1 3 2 1 
T6 1 2 1 1 1 
T7 1 2 3 2 0 
T8 0 2 0 1 0 
T9 1 1 1 1 0 
T10 2 1 3 1 0 
VI. CONCLUSIONS 
In this paper, on the basis of the literature research, we 
introduce a data mining language. From the data mining 
language, users can specify the interested items or the 
sequences, and the minimum support and the minimum 
confidence threshold to discover interesting multi-
dimensional association rules. And then according to Rough 
set theory, we transform multi-dimensional association rules 
to elementary sets description, antecedents corresponding 
with feature classes, consequent corresponding with concept 
in RS, and then propose the efficient data mining algorithm 
MIMAR-RS to process the user requirements, combined 
with the idea of generating frequent itemsets dynamically, 
thus reducing the search space to produce frequent itemsets, 
reducing the time complexity. Furthermore, it can avoid 
redundant rules. 
REFERENCES 
[1] Wu shen, Gao xue-dong, M.Bastien. Data warehouse and data 
mining. Metallurgical Industry Press, Beijing, 2003 
[2] Agrawal R, Imielinski T, and Swami A. Mining Associations Between 
Sets of Items in Massive Databases.  In: Proc. of the 1993. 
[3] Agrawal R,Srikant R. Fast Algorithms for Mining Association rules. 
In: Proc. VLDB’94, Santiago, Chile, 1994, pp. 487~499 
[4] Savasere A., Omieciniski., Navathe S. An efficient algorithm for 
mining association rules in large database. In: Proc. VLDB’95, 
Zurich,1995, pp.432~443. 
[5] Han, J, Pei, J. Mining frequent patterns by pattern-growth: 
Methodology and implications. In Proceedings of ACM SIGKDD 
international conference on knowledge discovery and data mining. 
2000, pp.30–36. 
[6] Pei, J, Han, J. Can we push more constraints into frequent pattern 
mining? In Proceedings of ACM SIGKDD international conference 
on knowledge discovery and data mining. 2000, pp.350–354. 
[7] Meo, R., Psaila, G., & Ceri, S. A new SQL-like operator for mining 
association rules. In Proceedings of international conference on very 
large data base. 1996, pp.122–133. 
[8] Yen, S.J.Chen, A.L.P. An efficient data mining technique for 
discovering interesting association rules. In Proceedings of 
international conference on database and expert systems applications 
(DEXA). 1997, pp. 664–669. 
[9] Huang Yong, Liu Feng. A New Algorithm for Data mining of 
Multidimensinal Association Rules in Relational Database. Computer 
Applications and Software, 2008,24(10) , pp.60-61,83. 
[10] Zhu Ming. Data Mining.Hefei:University of science and technology 
of China Press. 2002. 
[11] Hettich, S. and Bay, S. D. (1999). The UCI KDD Archive 
[http://kdd.ics.uci.edu]. Irvine, CA: University of California, 
Department of Information and Computer Science,1999. 
[12] Zhang Wenxiu etc.Rough Set Theory and Method.Beijing:science 
press.2001. 
[13] Lv Yue-Jin, LiuNan-Xing, Chen Lei. Rough Set Attribute Reduction 
Algorithm Based on PGA. Computer Science, 2008,35(03)., pp.219-
221 
[14] Li Jin-hai, Lv Yue-jin. Relation matrix-based algorithm for reduction 
of attribute in information systems. Computer Engineering and 
Applications, 44(09) , pp.147-149,189 
[15] Chen Xin-ying, Li Xiong-fei. Parallel algorithm of attribute reduction 
in rough set. Journal of Computer Applications, 2007,27(08), 
pp.1964-1966. 
[16] Wang Jia-wei, Huang Da-rong2, Lei Ming. Optimal control of traffic 
flow based on rough theory and fractal theory. 2008,28(05), pp.1200-
1203.
 
38
