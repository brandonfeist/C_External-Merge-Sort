The Application of a Top-Down Algorithm in 
Neighboring Class Set Mining 
 
Gang FANG, Cheng-Sheng TU, Jiang XIONG, Zi-Quan WANG 
College of Math and Computer Science 
Chongqing Three Gorges University 
Chongqing 404000, P.R. China 
cqwzjsjfg@163.com, tucscqedu@163.com, xjcq123@sohu.com, wzq123@163.com 
 
Abstract—This paper focuses on character of present frequent 
neighboring class set mining algorithms which is suitable for 
mining short frequent neighboring class set, and introduces a 
top-down algorithm in frequent neighboring class set mining. 
This algorithm is suitable for mining long frequent neighboring 
class set in large spatial data according to top-down strategy, and 
it creates digital database of neighboring class set via neighboring 
class bit sequence. The algorithm generates candidate frequent 
neighboring class set via top-down search strategy, namely, it 
gains k-neighboring class set as candidate frequent items by 
computing k-subset of (k+1)-non frequent neighboring class set. 
The mining algorithm computes support of candidate frequent 
neighboring class set by digit logical operation. The algorithm 
improves mining efficiency through these two methods. The 
result of experiment indicates that the algorithm is faster and 
more efficient than present algorithms when mining long 
frequent neighboring class set in large spatial data. 
Keywords- spatial data mining; neighboring class set; top-down 
strategy; bit sequence; long frquent itemsets 
I.  INTRODUCTION 
As we all know, geographic Information Databases is an 
important form of spatial database in spatial data mining, 
mining spatial association rules from Geographic Information 
Databases is one important part of spatial data mining and 
knowledge discovery (SDMKD), which is also known as 
spatial co-location pattern as in [1]. Spatial co-location pattern 
are some implicit rules expressing construct and association of 
spatial objects in Geographic Information Databases, and also 
expressing hierarchy and correlation of different subsets of 
spatial association or spatial data in Geographic Information 
Databases as in [2]. Nowadays, in research of spatial data 
mining, there are mainly three kinds approaches of mining 
spatial association rules as in [3], such as, layer covered based 
on clustering as in [3], mining approach based on spatial 
transaction as in [2, 4, 5, and 6] and mining approach based on 
non-spatial transaction as in [3]. The first two methods may be 
also used to mining frequent neighboring class set, The spatial 
association as in [4, 5, and 6] is quite single, because they only 
express spatial association among these objects which are all 
close to objective. However, neighboring class set expresses 
another spatial association among these objects which are close 
to each other. MFNCS as in [2] uses the similar method of 
Apriori to search frequent neighboring class set, which gains 
some right instance of (k+1)-neighboring class set only through 
connecting right instance of k-neighboring class set according 
to down-top strategy, and so this algorithm is only suitable for 
mining short frequent neighboring class set according to 
character of Apriori. Hence, this paper introduces a top-down 
algorithm in frequent neighboring class sets mining, denoted 
by TDA, which is suitable for long frequent neighboring class 
set according to top-down strategy. 
II. PRELIMINARY KNOWLEDGE 
According to these representations as in [2], every object in 
spatial domain forms a spatial data set, which is expressed as 
this data structure, denoted by <Object Identify, Class Identify 
and Spatial Location>. Here, identify of different class in 
spatial data set is denoted by Class Identify, identify of 
different object instance in the same class is denoted by Object 
Identify, location coordinate of object is denoted by Spatial 
Location. We regard an object as an instance of corresponding 
class, and so spatial data set is made up of these instances of 
spatial Class Identify. Sets of Class Identify are thought as a 
class set, denoted by C = {C1?C2?…, Cm}, means there are 
m different classes. 
A. Definition and Property 
Definition 1 Neighboring Class Set, it is a subset of spatial 
class set in spatial data set, which is expressed as {Ct1?
Ct2?…?Ctk} (tk  m), denoted by NCS.  
Let I = {it1?it2?…?itk} be an instance of neighboring 
class set denoted by NCS={Ct1?Ct2?…?Ctk}, here, itj is an 
instance of Ctj (j?1, 2, …, k). 
Example, let {V, X, Y, Z} be a NCS, and I = {V4, X7, Y6, 
Z3} is an instance of NCS. 
Definition 2 Neighboring Class Set Length, its value is 
equal to the sum of class set contained in neighboring class set. 
If the length of NCS is equal to k, it is denoted by k-NCS. 
Example, let {V, W, Y} be a NCS, and its length is 3. 
Definition 3 Right Instance of Neighboring Class Set, let 
I={it1?it2?…?itk} be an instance of NCS, if ?  ip and iq (ip ,iq 
? I), and distance (ip?iq)  d, and then we think I be an right 
instance of NCS. Here, d is the minimal distance used by 
deciding two spatial objects are close to each other, Euclidean 
distance is expressed as distance (ip?iq). 
This work was fully supported by science and technology research 
projects of Chongqing Education Commission (Project No. KJ091108), and it 
was also fully supported by science and technology research projects of 
Chongqing Three Gorges University (Project No. 10QN-22, 24 and 30). 

___________________________________ 
978-1-4244-6793-8/10/$26.00 ©2010 IEEE  
  
Definition 4 Neighboring Class Set Support, it is equal to 
the sum of right instance of neighboring class set, which is 
denoted by support (NCS). 
Definition 5 Frequent Neighboring Class Set, its support is 
not less than the minimal support given by user. 
Property Let (k+1)-NCS is frequent neighboring class set, 
and k-NCS is also frequent neighboring class set. Here, k-NCS 
? (k+1)-NCS. 
B. Problem Description 
According to above definition, property and these 
representations as in [2], we describe frequent neighboring 
class set mining as follows: 
Input:  
(1) Class set is denoted by C = {C1?C2?…, Cm}, instance 
set is denoted by I = {i1? i2?…, in}, each ik (ik ? I) is 
expressed as above defined data structure.  
(2) Minimal distance is denoted by d. 
(3) Minimal support is denoted by s. 
Output:  
Frequent neighboring class set. 
III. THE TOP-DOWN ALGORITHM  IN FREQUENT 
NEIGHBORING CLASS SET MINING 
A. Forming Digital NCS Database 
In order to form digital database of neighboring class set, 
we need find corresponding NCS of every right instance, and 
turn NCS into a digit. The course of turning used by the 
algorithm is expressed as follows: 
Step1, Firstly, we define the order of class as C = {C1, C2… 
Cj…Cm}, Here j is defined as bit sequence, and so each class 
existing in right instance has bit sequence denoted by BSj. 
Step2, and then, we use an exponent to denote every class, 
if bit sequence of this class is denoted by BSj, and then this 
exponent is equal to 12 ?jBS . 
Step3, we will gain a digit by computing this value, denoted 
by

=
?
L
j
BS j
1
12 , here L is equal to Neighboring Class Set Length, 
and namely, it is the sum of class existing in this neighboring 
class set.  
According to this method, the algorithm will gain a digit by 
scanning every right instance and this digit also denote this 
corresponding NCS of right instance. 
Now we save these digits by this data structure expressed as 
follows: 
Structure neighboring class set { 
Int Digit; // saving digit expressed as NCS of right instance 
Int Count; // saving the sum of same digit expressed as 
NCS} NCS 
Example, here class set is expressed as C = {V, W, X, Y, 
Z}, the first three right instances are express as I1 = {W2, X4, 
Y3, Z1}, I2 = {V1, W5, Y2}, I3 = {W3, X5, Y4, Z2}. 
Now we use the previous introductive method to create 
digital NCS database, this course is expressed as follows: 
NCS of I1 is expressed as {W, X, Y, Z}, and the bit 
sequence is expressed as {2, 3, 4, 5}, and then digit = 2(2-1) + 
2(3-1) + 2(4-1) + 2(5-1) =30, NCS [0]. Digit =30, NCS [0].Count=1. 
NCS of I2 is expressed as {V, W, Y}, and the bit sequence 
is expressed as {1, 2, 4}, and then digit = 2(1-1) + 2(2-1) + 2(4-1) 
=11, NCS [1]. Digit =11, NCS [1].Count=1. 
NCS of I3 is expressed as {W, X, Y, Z}, and the bit 
sequence is expressed as {2, 3, 4, 5}, and then digit = 2(2-1) + 
2(3-1) + 2(4-1) + 2(5-1) = 30, because NCS [0] has already saved 
this information, and only NCS[0].Count=NCS[0].Count 
+1=2, ....... 
B. The method of generating candidate frequent NCS 
The algorithm generates candidate frequent neighboring 
class set according to top-down strategy. Namely, it uses digit 
logical operation to generate k-candidate frequent itemsets of 
digit form by (k+1)-digit non-frequent itemsets. The algorithm 
adopts search strategy which is similar to B_UDMA as in [7] 
and ITDASN as in [8]. The course of generating is expressed 
as follows: 
Suppose here are three non-frequent neighboring class sets 
and two frequent neighboring class sets, their length are all 
equal to 4, and they may generate some candidate frequent 
neighboring class set, their length ought to be 3. 
Non-frequent neighboring class set: 
(1)NFNCS1=21-1+22-1+23-1+25-1=23; 
(2)NFNCS2=21-1+22-1+23-1+24-1=15; 
(3)NFNCS3=21-1+23-1+24-1+25-1=29; 
Frequent neighboring class set: 
(1)FNCS1=22-1+23-1+24-1+25-1=30; 
(2)FNCS2=21-1+22-1+24-1+25-1=27; 
Generating candidate frequent neighboring class set: 
No. 1 NFNCS1=21-1+22-1+23-1+25-1=23, these subsets of 
non-frequent itemsets are expressed as follows: 
C1 = 21-1+22-1+23-1=7. 
C* = 21-1+22-1+25-1=19, which is deleted by FNCS2. 
C2 = 21-1+23-1+25-1=21. 
C* = 22-1+23-1+25-1=22, which is deleted by FNCS1. 
No. 2 NFNCS2=21-1+22-1+23-1+24-1=15, these subsets of 
non-frequent itemsets are expressed as follows: 
C* = 21-1+22-1+23-1=7. (Duplication) 
C* = 21-1+22-1+24-1=11, which is deleted by FNCS2. 
C3 = 21-1+23-1+24-1=13. 

C* = 22-1+23-1+24-1=14, which is deleted by FNCS1. 
No. 3 NFNCS3=21-1+23-1+24-1+25-1=29, these subsets of 
non-frequent itemsets are expressed as follows: 
C* = 21-1+23-1+24-1=13. (Duplication) 
C* = 21-1+23-1+25-1=21. (Duplication) 
C* = 21-1+24-1+25-1=25, which is deleted by FNCS2. 
C* = 23-1+24-1+25-1=28, which is deleted by FNCS1. 
C. The method of computing support 
Accordingly to chapter A and digit logical operation, we 
may gain this property as follows: 
Property Let p and q express two right instances, let Cp be 
a NCS denoted by p, let Cq be a NCS denoted by q, then 
Cp ? Cq ? p & q=p. 
This algorithm uses logical operation to compute support 
according to this property. The process is expressed as follows: 
Suppose class set is expressed as C = {U, V, X, Y, Z}, 
there are 5 neighboring class sets as follows:  
NCS1 = {U, X, Y, Z}; 
NCS2 = {V, X, Z}; 
NCS3= {U, V, X, Y, Z}; 
NCS4 = {V, X, Y, Z}; 
NCS5 = {X, Y, Z}; 
Their digits denoting neighboring class set of right instance 
are expressed as {29, 22, 31, 30 and 28}. Suppose a candidate 
is 20 which is denoted by C-NCS = {X, Z}, and then 29&20 
=20, 22&20=20, 31&20=20, 30&20=20, 28&20=20. Because 
of this, we write 5 to support (C-NCS). 
D. The process of mining frequent neighboring class set 
Input:  
(1) Spatial class set is denoted by C = {C1?C2?…?Cm}.  
(2) Instance set is denoted by I = {i1?i2?…?in}.  
(3) The minimal distance is denoted by d.   
(4) The minimal support is denoted by s. 
Output: Frequent neighboring class set. 
Step1: Firstly, the algorithm computes the entire right 
instances denoted by I’ from instance set in spatial database as 
I by the minimal distance as d. 
Step2: And then, forming neighboring class set database as 
NCS after scanning once right instance set as I’ via the 
introductory method in chapter A of III. 
Step3: Using top-down strategy to generate candidate 
frequent NCS according to this chapter B of III. Namely, if a k-
candidate is frequent neighboring class set, and it is written to 
FNCS which saves frequent neighboring class set, otherwise, 
the algorithm will compute (k-1)-subset of k-candidate, and 
then continue to search frequent neighboring class set. 
Step4: Output FNCS according to chapter A of III. 
IV. THE ANALYSIS AND COMPARING OF CAPABILITY 
At present, there are very little documents of research 
frequent neighboring class set. Here we compare MFNCS as [2] 
with TDA which is introduced by this paper as follows: 
A. The Analysis of Capability 
MFNCS: this algorithm uses idea of Apriori to find 
frequent neighboring class set, which is made of three stages, 
firstly, computing all the frequent 1-NCS, secondly, generating 
all the 2-NCS by range query, and generating all the k-NCS 
(k>2) by iteration. The algorithm has some repeated computing 
and superfluous candidate frequent neighboring class set, 
which gains some right instance of (k+1)-neighboring class set 
only through connecting right instance of k-neighboring class 
set. As this algorithm adopts down-top strategy to generate 
candidate frequent neighboring class set, it is only suitable for 
mining short frequent neighboring class set. 
TDA: this algorithm adopts top-down strategy to generate 
candidate frequent neighboring class set, which is made of 
three stages, firstly, computing the 1st m-candidate frequent 
neighboring class set which contains all classes, and then 
generating (m-1)-candidate frequent neighboring class set, let 
(m-1) be k, and generating all (k-1)-frequent neighboring class 
set (k>3) by iteration. But the algorithm is only suitable for 
mining long frequent neighboring class set for top-down 
strategy. 
B. The comparing of experimental result 
Now we use experiment to testify above analyses and 
comparison. Two mining algorithms are used to generate 
frequent neighboring class set from 12267 right instances, 
whose class sets are expressed as digit from 3 to 8191, 
neighboring class set does not include any simple class, namely, 
it has two classes at least, the number of spatial class set is 
denoted by m=13, the number of right instance included by 
these neighboring class set observe the discipline which is 
expressed as follows: 
NCS of digit denoted by 8191 has one right instance. 
NCS of digit denoted by 8190 has two right instances. 
NCS of digit denoted by 8189 has one right instance. 
NCS of digit denoted by 8188 has two right instances. 
… 
Our experimental circumstances are expressed as follow: 
Intel(R) Celeron(R) M CPU 420 ? 1.60 GHz, 1.24G, language 
of the procedure is Visual C# 2005.NET, OS is Windows XP 
Professional. 
The experimental result of two algorithms is expressed as 
Fig.1, where support is absolute. The runtime of two 
algorithms is expressed as Fig.2 as support and length of 
neighboring class set change. 

 Figure 1.  The experimental result 
0
5000
10000
15000
20000
25000
1000(3) 500(4) 200(5) 100(6) 50(7) 20(8) 10(9) 5(10)
Support(Length)
R
un
tim
e(
M
ill
is
ec
on
d
MFNCS
TDA
 
Figure 2.  The comparing of runtime 
V. CONCLUSION 
This paper introduces a top-down algorithm in neighboring 
class sets mining, which is suitable for long frequent 
neighboring class set. The result of experiment indicates that 
the algorithm is faster and more efficient than present 
algorithms when mining long frequent neighboring class set in 
large spatial data. 
ACKNOWLEDGMENT 
This work was fully supported by science and technology 
research projects of Chongqing Education Commission 
(Project No. KJ091108), and it was also fully supported by 
science and technology research projects of Chongqing Three 
Gorges University (Project No. 10QN-22, 24 and 30). 
REFERENCES 
[1] MA, R.H., PU, Y.X., Ma, X.D.: GIS Spatial Association Pattern Ming. 
Science Press, 2007 Beijing.  
[2] MA, R.H., HE, Z.Y.: Mining Complete and Correct Frequent 
Neighboring Class Sets from Spatial Databases. Journal of Geomatics 
and Information Science of Wuhan University, vol.32(2), pp.112-114, 
2007. 
[3] ZHANG X.W., SU, F.Z., SHI, Y.S., ZHANG, D.D.: Research on 
Progress of Spatial Association Rule Mining. Journal of Progress in 
Geography, vol.26(6), pp.119-128, 2007. 
[4] LIU, Y.L., FANG, G.: The research and application of a transaction 
complement mining algorithm. Journal of Computer Engineering and 
Applications, vol. 44(35), pp.168-170, 2008. 
[5] FANG, G., WEI, Z.K., YIN, Q.: Extraction of Spatial Association Rules 
Based on Binary Mining Algorithm in Mobile Computing. In: IEEE 
Information Conference on Information and Automation, pp. 1571-1575. 
IEEE press, 2008, China, Zhangjiajie. 
[6] FANG, G., LIU, Y.L.: Application of Binary System Based Spatial 
Mining Algorithm in Mobile Intelligent Systems. Journal of Southwest 
University (Natural Science Edition), vol.31(1), pp. 95 - 99, 2009. 
[7] FANG, G., WEI, Z.K., YIN, Q.: The Research of Association Rules 
Mining Algorithm Based on Binary. In Proc. of International Conference 
on Cybernetics and Intelligent Systems and International Conference on 
Robotics, Automation and Mechatronics. IEEE press, vol 1. pp. 406-410, 
2009. 
[8] FANG, G., LIU, Y.L. XIONG, J., YING, H.: An Improved Top-Down 
Data Mining Algorithm for Long Frequents. Lisa O’Conner ed. 
International Conference on Artificial Intelligence and Computational 
Intelligence, IEEE press, vol. 4, pp.312-316, 2009. 
 

