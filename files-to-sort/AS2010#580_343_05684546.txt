978-1-4244-585 8- 5/10/$26.00 ©2010 IEEE                                                          ICALIP2010 414
Mining Association Rules Based on an Improved Apriori Algorithm 
Yanfei Zhou, Wanggen Wan*, Junwei Liu, Long Cai 
*School of Communication and Information Engineering, Shanghai University 
Shanghai 200072, China 
Email Address: wanwg@staff.shu.edu.cn
Abstract 
In this paper, we first describe the classical Apriori 
Algorithm. And then, we present the defects exist in this 
algorithm. Such as spending a lot of time to produce 
the candidate item-sets , scanning the database in a 
simple method, and so on. At last we promote our 
improved Apriori Algorithm which consists of three 
parts. The first part is reducing the number of 
judgments, and the second part is reducing the number 
of candidate frequent item-sets. The last part is 
optimizing the database. And the experimental results 
proved our improvement 
1. Introduction 
With the popularization of computer and 
development of Database Technology, more and more 
data are stored in the large databases. Obviously 
speaking, it is impossible to find useful information 
without using efficient methods. And then, Data mining 
(DM) techniques have emerged as a reflection of this 
request. Association rules mining, an important 
research direction, is aim to find out the dependence of 
among multiple domains basing on a given degree of 
support and credibility.  
Association rules mining process is divided into two 
steps. The first step is to find the frequent item-sets 
which support degree is large than the initial support 
degree from the transaction database; the second step to 
generate the rules of value from the frequent item-sets, 
and the acquisition of frequent item-sets is the key step 
during mining association rules procedure. In 1993, R. 
Agrawal first promoted an association rule mining 
algorithm named apriori algorithm (AA). And in the 
following year, Agrawal proposed two kinds of 
improved AA named AprioriTid algorithm and 
AprioriHybrid algorithm. What’s more, subsequent 
researchers have also given a lot of improvement for 
the AA. However, all of these improved algorithms 
have the following problems in varying degrees. The 
first problem is these algorithms need a lot of time to 
produce the candidate frequent item-sets. And the 
second one is these algorithms have to scan the 
transaction database many times to do the 
pattern-matching for candidate frequent item-sets. 
These two issues are both the hotspots and difficulties 
during current research on mining association rules. In 
our paper, we promote a faster and more efficient 
algorithm based on the classical AA  
2.Basic conception 
The concept of the association rules was first 
proposed by R. Agrawal. It is used to describe the 
patterns of customers' purchase in the supermarket. The 
association rules can be formally defined as: 
Definition 1: Let { , , , , }1 2 3 nI i i i i  be a set of items. 
D is a transactional database. Where 
( , , , )ki k 1 2 3 n   is an item. Tid is the exclusive 
identifier of transaction T in transactional database. 
Definition 2: The implication of the form X Y
is called an association rules. Where X I ,Y I , and 
X Y   .
Definition 3: Let D be a transactional database. If the 
percentage of transactions in D that contains X Y is
s%, the rule X Y holds in D with Support s . If the 
percentage of transactions in D  containing X that 
also contain Y is c %, the rule X Y has 
Confidence c .The definitions of probability are: 
( ) ( )Support X Y P X Y   ,
( ) ( | )Confidence X Y P Y X  .
Rules that satisfy both minimum support threshold 
(min-sup) and minimum confidence threshold 
(min-conf) are called strong rules. 
Definition 4: If the support of item-sets X is greater 
than or equal to minimum support threshold, X is 
called frequent item-sets. If the support of 
item-sets X is smaller than the minimum support 
threshold, then X is called infrequent item-sets. 
 415
3. The basic idea of Apriori Algorithm 
Generally speaking, AA uses an iterative method to 
search the rules Layer by layer. We should find out the 
1-item-set named 1L at first, and then we use 1L  to 
identify the set of 2-item-set named 2L .Go on this 
operation until we can’t seek out the item-set. Here 
there are two parts during the AA: 
a.Connection Step 
Generate a new set of candidate item-set named kC , 
here k is the length of candidate item-set. kC is the 
produced through the connection operation of 1kL 	 .
Here 1kL 	 is a frequent item-set and 1k 	 is the length of 
this frequent item-set. The connection rules reads as 
follows. Let 1L and 2L belong to the 1kL 	 . If all the items 
of these two frequent item-set are same except their last 
items, then they can be connected 
b.Pruning Step 
Actually speaking, it is scanty that all the subset of 
kC fill the min-sup. As a result, we must determine 
how many subset of kC are belongs to kL by scanning 
the transaction database D . That is to say, we should 
determine the support of every item-set in kC in order to 
delete the candidate item-set which can’t match the 
min-sup. 
4. Apriori Algorithm Performance 
Analysis
From the Implementation of AA, we can find there 
are three fatal defects exist in this algorithm 
a) First, we need to scan the database repeatedly. 
That is, we need to scan the whole database every time 
when we calculate an item-set. 
b) The time complexity and space complexity are 
too high due to its large candidate item-sets. 
c) There exist many rules, discovered by the method 
which is based on the theory of credibility, which have 
no practical significance. 
5. Improvement of Apriori Algorithm 
In this paper, we decide to improve the performance 
of AA in the following three aspects: 
a) Reduce the number of judgments. 
b) Reduce the number of candidate frequent 
item-sets. 
c) Optimize the database. 
5.1 Reduce the number of judgments 
During the process of AA, all these transactions have 
already been sorted. Therefore, we can affirm that the 
candidate frequent item-set is ordered. And any 
comparison between the two candidate item-set  is 
ordered on the bit comparison .That is to say, we can 
reduce the number of judgments during the process of 
producing candidate frequent item-set  through the 
use of this property. The details are as follows.  
Definition 1: Let us compare two frequent item-set 
named lx and ly . If  
[ ] [ ] [ ] [ ] [ ] [ ],lx 1 ly 1 lx i 1 ly i 1 lx i ly i 1 i k 
 	  	 
   ?
Then we can say that lx is smaller than ly : lx ly . If 
there exists m frequent item-sets and 1 2 ml l l   ,
we can allege that these item-sets are ordered. There 
are many properties for this definition. 
Property 1: For any item of k-item-set, there 
exists [ ] [ ]l 1 l 2 ?M<L> .
Proof: Because l is an ordered item-set, so the 
property is proved. 
Property 2: For any item of k-item-set: 
,lx ly .let 1 x y z m    .
If [ ] [ ] [ ] [ ] [ ] [ ],lx 1 ly 1 lx i 1 ly i 1 lx i ly i 1 i k 
 	  	 
   ? , than 
we can get that [ ] [ ]lx j lz i  while counter j is smaller 
than z and larger than 1. 
Proof: Because y z , so we can affirm ly lz .
Therefore, if [ ] [ ]ly i lz i , [ ] [ ]lx i lz i  is true when j 
equals to i which is a specific number. By the same 
token, if [ ] [ ]ly i lz i , [ ] [ ]ly p lz p  is true when j equals 
to p which is a specific number. 
We can optimize the link step by using the properties 
mentioned above.  
With regards to these two k-1 frequent item-set  
named lx and ly , if these two item-set can’t be 
connected, then we can affirm that all the item-sets  
after lx  and ly can’t satisfy the connection 
condition .As a result, there is no need to determine 
whether the item-sets  which are behind the item-set  
lx  and ly  satisfy the connection conditions or not. 
What’s more, both item-set lx and item-set ly  get 
from k-item-set. So, repeated connection operations are 
existed during the Traversal process. That is, the result 
of connecting x  and y is same to the result of 
connecting y to x. So, it is necessary to execute further 
optimization. 
,1 2declare TL TL
, ;1 K 1 2 K 1Set  TL L TL L	 	 
1foreach lx TL
 416
{ 2foreach ly TL
{ [ ] [ ] [ ] [ ]if  lx 1 ly 1 lx i 2 ly i 2 
 	  	?
[ ] [ ]lx k 1 ly k 1
 	  	 )
{ ;c lx ly 
{ }k kC C c 
;2 2TL TL x 	 }
//Item-set lay behind ly can't connect to lx }
}
5.2 Pruning the frequent item-sets  
Frequent item-sets have the following properties: 
Property 1: The necessary condition for a 
k-dimensional becomes a frequent item-set is that all 
the (k-1)-dimensional subsets are also frequent 
item-set. 
Property 2: Let k-dimensional item-set 
{ , , , }1 2 kx i i i  , ( )K 1L j k 1	  	  is true when j 
belongs to X, then we can say that X is not a frequent 
item-set. Here ( )K 1L j	  means the number of j  in 
( )K 1L j	 .
Proof: Let X be a k-dimension item-set. Now we 
take any k 1	 elements from X . Obviously, there are 
k  possibilities. So, there are k 1	  project j  in all 
the (k-1)-dimension item-set which are produced by X .
As far as the above properties are considered, we can 
get a conclusion. The details are as follow. 
Let ci , 1	 kLc , here i is an project, c is an element 
and 1	KL  is a k-dimension frequent item-set . If the 
inequality ( )K 1L j k 1	  	  is established, then the 
candidate k-dimension 1	KC  item-set produced by 
1	KL  can’t be a frequent item-set. As a result, there is 
no need to let 1	KC  participate in join operations. 
Here is the new strategy for pruning the frequent 
item-set. 
Calculate ( )K 1L j	 . Here ( )K 1L j	  is the frequency 
of ( )K 1L j	 , and 
' { ( ) |, }k 1j L U A A L 	  
Find the projects which frequency are smaller than 
k 1	  and then put them into a Set name 'I .
Get rid of the frequent item-set of K 1L 	  which 
contains the subset of 'I , than we can get a new K 1L 	
named 'K 1L 	 .
5.3 Database optimization 
Mark a delete tag on all the transactions of item-set 
which not contains the kC during the calculation of kC .
Therefore, there is no need to take these item-set into 
consideration in the following calculation. The 
efficiency can be more and more obvious with the 
growth of value k. 
6 Improved algorithm description 
Input: Transaction D , Minimum support threshold: 
min-sup; 
Output: Li , Frequent item-set in D ;
Here is the flow chart: 
(1) );(_1__1 DitemsetfrequentfindL 
/ / find  the 1-itemset
(2) 1( 2; ; )kfor k L k	    
(3) { sup);min_,(_ 1	 Kk LgenaprioriC
/ / KCreate the candidate itemset C   
(5) .k kL C itemset
(6) }   
(7) kreturn L=UL
Procedure apriori_gen( 1kL 	 ,min_sup); 
(1) ,1 2declare TL TL
(2) ' { / ( ) }k 1Get  I i L i k 1	  
(3) 'k 1 k 1Set  L L I	 	 	
(4) ,1 k 1 2 k 1Set  TL =L TL L	 	
(5) 1foreach lx TL
(6){ 2foreach ly TL
(7)  { ( [ ] [ ] [ ] [ ]if lx 1 ly 1 lx 2 ly 2 
  ??
(8) [ ] [ ] [ ] [ ])lxk 2 lyk 2 lxk 1 lyk 1	  	 
 	  	
(10)   { c lx ly 
(12)    ( _ )k 1if has infrequent_itemset(c,L )	
(13)  { delete c }
(16)  { }k kC C c 
(17)  2 2TL TL lx 	
(18)   } 
(19)   else break; }
(21) } 
Has_infrequent_item-set ( c , K 1L 	 )
(1) for  each (k-1) subset s of c .
(2) k 1if  s L  return true; else return false	 .
7 Experimental Result 
 We compared the performance of our improved 
 417
algorithm with the classical AA. The experimental 
platform is Intel Core(TM) 2 CPU 6600 2.4GHz. 
2.00G RAM Windows XP Operating System. It is 
based on Microsoft Sql database. The algorithm adopts 
C# program and compiles in Visual Studio 2005 
experiment environment. 
Our experiment uses a fictional supermarket 
transaction database which consists of 10000 TDs and 
120 items. 
Experiment 1: Number of items: 120; 
    Number of TD: 10000; 
0 0.005 0.01 0.015
0
5000
10000
15000
Support Degree
E
la
ps
ed
 T
im
e
Constrast1(with different Support Degree)
AA
IAA
Fig 1. Experiment Contrast with different 
Support degree 
From Fig 1, we can see that the execution time of 
IAA is shorter than AA while under different support 
degree. 
Experiment 2: Support Degree:0.005 
    Number of items:120 
0 2000 4000 6000 8000 10000 12000
0
1
2
3
4
5
6
7
x 104
Number of TD
E
la
ps
ed
 T
im
e
Constrast2(with different Number of TD)
AA
IAA
Fig 2. Contrast with different Number of TD 
From Fig 2, we can see that the execution time of 
IAA is shorter than AA while under different number of 
trading services. 
Experiment 3: Support Degree: 0.005 
    Number of TD: 10000 
0 20 40 60 80 100 120
0
1
2
3
4
5
6
7
8
9
10
x 104
Number of Items
E
la
ps
ed
 T
im
e
Constrast3(with different Number of Items)
AA
IAA
Fig 3. Contrast with different number of items 
From Fig 3, we can see that the execution time of 
IAA is shorter than AA while under different number of 
items. 
The above three experiment results demonstrate that 
while comparing the classical AA, the IAA improves 
the overall performance by reducing the number of 
scanning the database, using the new data 
representation and adopting a new Connection method 
between items. 
8 Conclusions 
In this paper, an improved Apriori-based algorithm 
IAA is proposed. Our improvement consists of three 
parts which are reducing the number of judgments, 
adopting new pruning strategy and optimize the 
transaction database. These improvements can greatly 
reduce the redundant operation while generating 
frequent item-sets and association rules in the database. 
Validated by the experiments, the improvement is 
notable. 
Acknowledgements 
The paper is supported by National Natural Science 
Foundation of China (60872115), Shanghai’s Key 
Discipline Development Program (J50104). 
References 
[1] Kun-Ming Yu, Jia-Ling Zhou, “A Weighted 
Load-Balancing Parallel Apriori Algorithm for Association 
Rule Mining”, Granular Computing, 2008. GrC 2008. IEEE 
International Conference on 26-28 Aug. 2008, pp.756-761 
[2] Colin Cooper, and Michele Zito, “Realistic Synthetic Data 
for Testing Association Rule Mining Algorithms for Market 
 418
Basket Databases”, Knowledge Discovery in Databases: 
PKDD 2007, Volume 4702/2007, pp.398-405 
[3] Chao-Tung Yang, Wen-Chung Shih, and Shian-Shyong 
Tseng, “A Heuristic Data Distribution Scheme for Data 
Mining Applications on Grid Environments”, Fuzzy Systems, 
2008. FUZZ-IEEE 2008. (IEEE World Congress on 
Computational Intelligence). IEEE International Conference 
on 1-6 June 2008, pp.2398-2404 
[4] A Savasere, E Omiecinski, S Navathe. Mining for strong 
negative association in a large database of customer 
transactions [J]. Data Engineering (ICDE’98), 1998, pp. 
494-502. 
[5] Taorong Qiu, Xiaoming Bai, Liping Zhang, “An Apriori 
algorithm based on granular computing and its application in 
Library management system”, Control & Automation, 2006, 
pp.218-221 
[6] Ya-Han Hu, Yen-Liang Chen .Mining association rules 
with multiple minimum supports: a new mining algorithm 
and a support tuning mechanism Decision Support Systems, 
2006, pp.1 -24 
