Using Association Rules for Discovering Tag Bundles in Social Tagging Data
Walter Christian Kammergruber
Institut für Informatik
Technische Universität München
Boltzmannstr. 3, 85748 Garching, Germany
walter.kammergruber@gmail.com
Maximilian Viermetz
Siemens AG, Corporate Technology
Otto-Hahn-Ring 6
81739 München, Germany
maximilian.viermetz@acm.org
Karsten Ehms
Siemens AG, Corporate Technology
Otto-Hahn-Ring 6
81739 München, Germany
karsten.ehms@siemens.com
Manfred Langen
Siemens AG, Corporate Technology
Otto-Hahn-Ring 6
81739 München, Germany
manfred.langen@siemens.com
Abstract—Social tagging has become very popular with the
rise of Web 2.0, making it an important piece of the puzzle
that makes up the web phenomenon. In contrast to more
elaborate ways of organizing resources, such as taxonomies
or ontologies, tagging is very easy to use and understand.
Because of its simplicity tagging does not create explicit,
formalized, structures. By applying a well-established data
mining algorithm we show how common structures in form
of tag bundles (a set of related tags) can automatically be
derived from a bag of tags. Based on these computed tag
bundles tagging applications can assist users with improved
user interfaces by introducing user based semantic labelling.
For navigating and searching his or her tagged information
space there are certainly better user interface elements possible
than a tag cloud or a plain list of tags ordered by frequency.
We propose that combining frequently associated tags into a
tag bundle is such a way. We have tested our approach on a
data set gained from Delicious and evaluated it by utilizing the
Normalized Google Distance.
Keywords-social tagging; data mining; association rule min-
ing; folksonomy; tag bundle; personal information manage-
ment
I. INTRODUCTION
Fueled by the wild growth of social media, an increasing
amount of information can be found online. This results in
an increasingly fragmented and inhomogeneous body of data
being offered by social media sites.
In this context social tagging has become a very popular
tool for categorizing knowledge items over the last few years
[1], [2]. By allowing individuals to categorize and mark
their own data as well as data of others, an overview of
content with some personal relevance can be won. One of
the ?rst social tagging applications was Delicious1, a social
bookmarking platform. Many other Internet services such
as Flickr, Last.fm, 43things, Citeulike or Bibsonomy2, make
1http://www.delicious.com/
2http://www.?ickr.com/, http://www.last.fm/,
http://www.43things.com/, http://www.bibsonomy.org/
use of tagging for structuring their content.
But since the information is being categorized by many
individuals who do not necessarily share a common under-
standing of all or even a part of the subject matter, the
challenge of interpreting tags in large group or corporate
contexts has been of developing interest. First of all social
tagging follows very heterogeneous and individual usage
patterns. Each user and each application has different char-
acteristics. In general one can observe a long tail distribution
of tag frequencies [3]. This means that users tend to employ
some tags very frequently and a huge number of tags very
infrequently. Having many different tags leads to informa-
tion scattering and therefore navigational interfaces based on
un?ltered tags quickly become very inef?cient. This applies
both to simple lists of tags that are either in an alphabetical
order or sorted based on the frequency of a tag. Tag clouds,
as alternative representation, display only an excerpt of the
more commonly used tags.
A related challenge is presented by the variety of reasons
motivating tagging in an information system. Golder and Hu-
berman [4] identify seven possible functions: (i) Identifying
what (or who) a document is about, (ii) Identifying what
the document itself is, (iii) Identifying who owns the docu-
ment, (iv) Re?ning documents or other tags, (v) Identifying
qualities or characteristics, (vi) Self reference and (vii) Task
organising.
Similar, Marlow et al. [1] describe incentives and moti-
vations for users to annotate resources with tags: (i) Future
retrieval, (ii) Contribution and sharing, (iii) Attract Atten-
tion, (iv) Play and Competition, (v) Self Presentation and
(vi) Opinion Expression. From these enumerations one can
see that the usage of tagging is manifold. The personal
information aspects are easily recognized by taking the
individual nature of social tagging into account, especially
the motivation “Future retrieval”. For a lot of cases a user
wants to organize his or her personal information items
414978-1-4244-7818-7/10/$26.00 c©2010 IEEE
(bookmarks, pictures, books, bibliography, notes, etc.).
Additionally with the advent of social software as knowl-
edge management tools in companies – sometimes referred
to as enterprise 2.0 [5] – organizing tagged information on a
larger scale and also in a professional working environment
has become an important issue. Organizing in this context
means creating some structures which provide a certain
degree of stability to tagging activities. Technically this
translates into the need to derive structures from tag sets.
We believe that it is nearly impossible to automatically
generate complex formalizations such as ontologies or even
elaborated taxonomies from social tagging data. Therefore
we direct our efforts towards simpler structures and use tag
bundles as a starting point. In Delicious tag bundles are a
way to group tags. This helps to aggregate resources tagged
with the individual tags contained in the corresponding tag
bundle. But since a user has to de?ne these bundles manually
the average user typically does not make use of this feature.
The approach presented in this paper is focused on the
extraction of semantic commonalities in tagging behavior,
and draws on parallels used to discover item sets of interest
in a “grab bag environment” —precisely the mentioned tag
bundles.
II. RELATED WORK
Finding structures in social tagging data has received
quite some attention in recent work. Begelman et al. [6]
describe a method for clustering social tagging data based on
the co-occurrence values of tags. The co-occurrence values,
meaning that two tags have been used together in a tag
assignment, is used as a similarity measure in the applied
clustering algorithm. Brooks et al. [7] follow an analo-
gous approach. Additionally they apply an agglomerative
clustering for computing a hierarchy of tag clusters. Other
examples for clustering tag sets can be found in [3], [8],
[9], [10]. Xu et al. [11] describe a goodness measure for tag
suggestions.
Heymann et al. [12] use association rule mining based
in combinations with other measures for link prediction
on social tags. In contrast to our approach they perform
association rule mining based on tag assignments for a
certain URL without distinguishing between different users.
We consider tag assignments on a individual basis targeting
the organization of personal tag spaces.
Schmitz et al. [13] describe the idea of using associa-
tion rules to determine hypernymy and hyponymy relations
between tags in social tagging data. They have a strong
emphasis on formal concept analysis and its usage in context
of social tagging data.
Although we are following a similar initial thought of
utilizing classical data mining techniques for discovering
structures in folksonomies our focus is on structuring tags in
a less formal and sharp-edged manner. Our aim is to suggest
to the user tag bundles for organizing tagged information
objects. The idea is that tag assignments assigned by any
given user are a re?ection of his understanding and “taxon-
omy” of the subject at hand. By using the tags occurring in
common sets an accurate picture of relationships between
tags and their user perceived “taxonomy” can be gained. By
constructing tag bundles with a common root tag a subject
grouping can be seen.
III. DISCOVERING TAG BUNDLES
Tagging behavior, as opposed to keyword extraction from
text, is geared towards the complete and succinct description
of content and the organization of documents for a keyword
based search. A user will distribute tags on several granular-
ities, for instance “java” to describe more general concepts
and “bean” for speci?c uses.
By discovering the usage of such broadly descriptive
terms in combination with other more speci?c terms a tag
bundle can be created which gathers all speci?cs to a general
term into a set. This set re?ects the conceptual taxonomy and
associated documents from a user perspective.
Tag bundles stem from personal information
management[14], e.g. used when organizing a blog
(can consist of many posts when used as a notepad) or
bookmarks. This creates an individual tag space associated
with every user which is dependant on his or her own
viewpoint. While general concepts are easy to reconcile
across worldviews, speci?cs tend to be perceived in a
slightly different light. Tag bundles can help to reconcile
concepts with each other by offering the general terms as a
bridge between user perceptions.
Conversely the same tag can appear in different tag
bundles of a single user, re?ecting the different meanings
of a term. Such overlapping bundles shows tags used in
different contexts, e.g. java can be placed in a bundle books
together with other book related tags such as “tutorial” or
“toread” as well as in a bundle programming together with
tags such as “tools” or “tips”. Additionally the problem of
ambiguous meanings of tags, such as challenge presented by
acronyms and homonyms3, must be considered. Depending
on the context, a tag with several meanings can occur
in several tag bundles, each representing different topical
collections of resources.
A. Social Tagging
In most current work social tagging data is also referred
to as a folksonomy [15]. A folksonomy is a portmanteau
consisting of the words taxonomy and the word folk. The
term refers to the implicit structures (therefore taxonomy4)
between entities emerging from the individual tagging be-
haviour (therefore folk).
3Acronyms: “GIS” can stand e.g. for “Geographic information system”,
“Greenland ice sheet” or “Gruppo di Intervento Speciale”; homonyms:
“java” can e.g. stand for the programming language or the island
4Taxonomy actually can be considered as the wrong expression since
there are no real hierarchical structures present.
2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM) 415
We de?ne a folksonomy similar to the de?nition given by
Hotho et al. [16]:
De?nition 1: A folksonomy is a tuple F := (U, T,R, Y )
where
• U , T and R are ?nite sets, whose elements are called
users, tags and resources, resp.
• Y is a ternary relation between them, i. e. Y ? U ×
T ×R, called tag assignments.
In general a folksonomy contains n-ary relations between
user, tags and resources. Additionally sometimes the system,
meaning the tagging application in which the individual
tag assignment occurred, is also considered [17]. For the
sake of simplicity we intentionally exclude the system as a
participant in this paper.
B. Tag Bundles
The goal of this paper is to distill tag bundles B consisting
of tags for a user. A tag bundle consists of a head with
the most important tag being the common denominator
for the linked resources. Additionally there is a set with
sub-tags which are more speci?c and can re?ect different
aspects of the resources in question. An example can be
seen in ?gure 2. By using the relationship between tags
associated with a resource we seek to discover tag bundles
in user tagging. Not only do tags elucidate the content
of a document, but the same tags are also in a semantic
relationship with each other simply by being used to describe
the same source of information.
C. Association Rule Mining for Bundle Discovery
Association Rule Mining (ARM) is a popular data mining
method. Association rules have been extensively studied
in the literature. However most widely used algorithms
are based on the original a-priori algorithm proposed by
Agrawal et al [18].
A typical application of ARM is the analysis of trans-
action data recorded by point-of-sale (POS) systems in
supermarkets. The results are, e.g. integrated in the decision
process of how to arrange items in a supermarket. This
sometimes leads to surprising results. Observations in a
grocery store show that people who buy diapers also buy
beer [19]. Based on that insight diapers can then be placed
together with beer. In analogy to grouping items that are
bought together frequently we are trying to group frequently
used tags together so that the represented resources (book-
marks, documents, etc.) can be more easily accessed.
Association rules are in general of the form:
X ?? Y [Support,Con?dence]
Support is the number of transactions containing both X
and Y. A transaction for the super market example consists
of the items a customer has bought together at exactly one
visit. Con?dence stands for P (Y|X), meaning how likely Y
is given X. Given a minimum support association rules can
be computed with the algorithm described by Agrawal.
A tagging, meaning a user has tagged an entity with
several tags, is our special type of transaction.
Based on these tagging transaction rules of the form
{xi1, . . . , xik} ?? yi [Support,Con?dence] where xij ?
T and yi ? T are computed.
By restricting the set of generated association rules with
thresholds for support (minSup) and minimum con?dence
(minCon?dence) only a selection of rules is considered as
input for the target bundles. In a ?nal step the rules are
joined into bundles if they share the same head yi.
Computed association rules have the following form, for
example:
{management, crisis, failure} ?? ?nance [ 0.5, 60 ]
or
{history, trust} ?? ?nance [ 0.7, 20 ]
In this example both rules have the same head and are
therefore merged into a bundle:
{management, crisis, failure, history, trust} ?? ?nance
Depending on the individual tagging behaviour and the
parameter thresholds there are a number of tag bundles
discovered. The resulting tag bundles can function as a
suggestion for a user on how to organize his or her personal
tags.
IV. EVALUATION
We have applied our approach on social tagging data
extracted from internal knowledge management tools at
Siemens (a blogging platform [20] and a wiki [21]). These
applications are widely used within Siemens. The results
are very promising, but since the amount of available data
does not nearly reach the numbers obtained in Internet usage
we decided to evaluate our approach on data collected from
Delicious.
A. Dataset
During a period of about eight weeks (end January -
March 2009) we periodically fetched the RSS feeds for the
bookmarks of 2300 randomly chosen users of the popular
bookmarking service Delicious. During this time period
three accounts where removed and 27 users did not assign
any tags, which leads to a total number of 2270 investigated
users. The total number of resources for all users aggregate
to 462,415 (with duplicates), of which 345,674 unique
resources form R.
The number of resources tagged by a user range from a
single resource (three users) to over 1,000 different resources
(eight users). Surprisingly these eight users were not spam
and we could also not detect any spam resources in our
sample set. In average there were 201 resources per user.
For some more details about the data set see [22].
416 2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM)




      	  
       








Figure 1: Histogram: Number of distinct tags vs number of
user.
There where 2,942,633 tags in total and 97,522 uniquely
different tags forming our tag set T . While 27 users did not
display any tagging activity, the average number of different
tags per user was 201. The median of different tags per user
was 165. One hyperactive user registered 3328 distinct tags.
For a graphical representation of the number of distinct tags
against the number of users having used the corresponding
number of distinct tags see ?gure 1. We observed a typical
long tail distribution of tags [3].
B. Preprocessing
For cleaning the social tagging data we applied only a
conversion to lower case. We did not apply stemming since
it depends on the language used, and ?rst tests have shown
that language detection on tags remains inconclusive. This
may be because tags are typically very speci?c and often just
a simple phrase. We did not utilize a thesaurus because the
overlap of tags and a thesaurus such as WordNet is expected
to be low. When it comes to mapping tags to concepts in
WordNet, Laniado et al. state that only 8% of the different
tags in their data sample (480,000 different tags collected
from 30,000 Delicious users) ?nd a corresponding concept
in WordNet [23].
C. Association Rule mining
We have used three different parameter threshold: (0.5,
8), (0.7, 4) and (0.9, 3) (con?dence and minimum support).
We selected these parameter thresholds based on preliminary
experiments where we tried to get a feeling for which
thresholds are practical.
D. Bundles
Depending on the characteristics of the individual tagging
data we compute users with bundles: For (0.5, 8): 825, (0.7,
4): 1207 and (0.9, 3): 1330. It was not possible to derive tag
bundles for users if they did not repeatedly use more than
one or two tags per resource or if they used many different
tags. Association rule mining can not be utilized to derive
tag bundles in these cases.
Table I shows the statistics for the generated tag bundles.
For (0.5, 8) there tend to be less tags per bundle, since the
threshold for the minimum support is rather high. There are
less rules created, but rules are more easily accepted as a
finance
systems
uk
belief
trust
confidence
learning
business
risk
history
politics
cognitive
failure
psychology
money
wealth
economics
crisis
management
growth
Figure 2: Example Tag Bundle for ?nance (From the test
run with Con?dence > 0.7 and MinSupport > 4)
base for a bundle. Also there are less users whose bundles
could be computed. (0.7, 4) and (0.9, 3) have more tags per
bundle and the number of users with derived tag bundles is
higher.
In Figure 2 an example of a tag bundle is shown. In
this bundle all computed rules with the head “?nance” are
merged together. Contained in the tag bundle are tags such
as “failure”, “risk”, ”economics” or “crisis” indicating that
the user for whom this bundle was created, seemed to be
interested in resources related to the current ?nancial crisis
(the data was collected in early 2009).
E. Normalized Google Distance
In order to determine if the derived tag bundles provide
useful grouping of tags, we use the Normalized Google
Distance (NGD) [24] as measurement for the semantic
relatedness of two terms. NGD takes advantage of the
number of hits returned by Google to compute the semantic
2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM) 417
Table I: Statistics for generated Bundles.
Min Max ? Median Variance ?
0.5, 8 tags per bundle 1 127 4,09 13 37,24 6,1
bundles per user 1 91 5,88 1 70,32 8,39
0.7, 4 tags per bundle 1 246 5,48 4 73,06 8,55
bundles per user 1 225 9,67 6 263,39 16,23
0.9, 3 tags per bundle 1 303 6,24 5 92,37 9,61
bundles per user 1 307 12,74 2,5 479 21,89
Table II: NGD for Bundles and Random Tags
Parameter ? Median Variance ?
0.5, 8 0,390 0,528 0,050 0,230
0.7, 4 0,390 0,453 0,050 0,220
0.9, 3 0,380 0,242 0,050 0,220
random tags 1 0,640 0,636 0,040 0,210
random tags 2 0,660 0,588 0,040 0,200
distance between concepts. The basic idea behind NGD is
that if you have two terms, you ?rst query Google for each
term separately and set the number of returned results in
relation to the number of results returned by a query using
both terms together.
Given two search terms x and y, the normalised Google
distance between x and y, NGD(x, y), can be obtained as
follows
NGD(x, y) =
max{log f(x), log f(y)} ? log f(x, y)
logM ?min{log f(x), log f(y)}
where f(x) is the number of Google hits for the search term
x, f(y) is the number of Google hits for the search term y,
f(x, y) is the number of Google hits for the tuple of search
terms x y and M is the number of web pages indexed by
Google5.
Table II shows the statistical characteristics of the NGD
values between the tag bundle head and the bundled tags.
The ?rst three rows show the results for ARM with different
parameter combinations. For each bundle head the normal-
ized google distance to each tag contained in the tag bundle
is computed. The arithmetic average over each tag bundle for
each user is for each parameter threshold setting about 0.4.
For putting the determined NGDs into context we computed
the pairwise NGD for two samples of ?ve hundred randomly
selected tags. The last two rows contain the pairwise NGD
of these two runs. The expected value (?) of the random
tags is noticeable bigger than the expected values of the
experiments. Although this is no proof —with an excessive
empirical bases— it still gives a strong indication that the
(semantic) similarity between the head of the tag bundles is
higher than the (semantic) similarity between random tags.
It was not possible in a reasonable time or with a reasonable
5The Google search engine indexes contains currently approximately ten
billion pages (M ? 1010). Google does not publish the exact number and
they are subject to change anyway. We use 8, 058, 044, 651 as the one
given in the original paper.
number of request per second to perform a test with a larger
set of random tags.
V. CONCLUSION AND FUTURE WORK
We have shown that it is possible to compute tag bundles
out of social tagging data by applying a popular association
rule mining algorithm. One problem with the described
approach is that association rule mining does not scale very
well for big data sources. For very large data sets it might
be promising to use map reduce [25] methods in order to
increase scalability. For some users with a certain tagging
gusto it was also not possible to determine tag bundles. Other
association rule mining algorithms [26] might deliver better
results or results with other characteristics. We are planning
to incorporate bundles into user interface design. Bundles
can also be a starting point for piled user interfaces [27].
Our next step is to incorporate our approach for organizing
tagged information in the existing social software landscape
at Siemens. This helps us to gain an insight into the
usefulness of generated bundles for the average user in an
enterprise environment.
ACKNOWLEDGMENT
Parts of this paper are based on results of research within
the framework of the Theseus project6, more precisely the
Use Case Alexandria. The project was funded by means of
the German Federal Ministry of Economy and Technology
under the promotional reference “01MQ07012”.
REFERENCES
[1] C. Marlow, M. Naaman, D. Boyd, and M. Davis, “Ht06,
tagging paper, taxonomy, ?ickr, academic article, to read,”
in HYPERTEXT ’06: Proceedings of the seventeenth
conference on Hypertext and hypermedia. New York, NY,
USA: ACM Press, 2006, pp. 31–40. [Online]. Available:
http://portal.acm.org/citation.cfm?id=1149949
[2] A. Mathes, “Folksonomies - cooperative classi?cation
and communication through shared metadata,” Computer
Mediated Communication - LIS590CMC, December 2004.
[Online]. Available: http://www.adammathes.com/academic/
computer-mediated-communication/folksonomies.html
[3] E. Tonkin, “Searching the long tail: Hidden structure in social
tagging,” Proceedings of the 17th SIG Classi?cation Research
Workshop, 2006.
6http://www.theseus-programm.de/home/default.aspx
418 2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM)
[4] S. A. Golder and B. A. Huberman, “Usage patterns of
collaborative tagging systems,” J. Inf. Sci., vol. 32, no. 2,
pp. 198–208, 2006.
[5] A. P. McAfee, “"Enterprise 2.0: The Dawn of Emergent
Collaboration" . reprint 47306,” MIT Sloan Management
Review, vol. 47, no. 3, pp. 21–28, 2006. [Online]. Available:
http://sloanreview.mit.edu/smr/issue/2006/spring/06/
[6] G. Begelman, P. Keller, and F. Smadja, “Automated
tag clustering: Improving search and exploration in the
tag space,” in Collaborative Web Tagging Workshop at
WWW2006, Edinburgh, Scotland, 2006. [Online]. Available:
http://www.pui.ch/phred/automated_tag_clustering/
[7] C. Brooks and N. Montanez, “Improved Annotation of the
Blogosphere via Autotagging and Hierarchical Clustering,”
in Proceedings of the 15th international conference on World
Wide Web. ACM New York, NY, USA, 2006, pp. 625–632.
[8] J. T. Tennis, “Social tagging and the next steps for indexing,”
in Proceedings 17th SIG/CR Classi?cation Research Work-
shop, J. Furner and J. T. Tennis, Eds., 2006.
[9] A. Hotho, R. Jäschke, C. Schmitz, and G. Stumme,
“Emergent semantics in bibsonomy.” in GI Jahrestagung
(2), ser. LNI, C. Hochberger and R. Liskowsky, Eds.,
vol. 94. GI, 2006, pp. 305–312. [Online]. Available:
http://dblp.uni-trier.de/db/conf/gi/gi2006-2.html#HothoJSS06
[10] M. Grahl, A. Hotho, and G. Stumme, “Conceptual clustering
of social bookmarking sites,” in 7th International Conference
on Knowledge Management (I-KNOW ’07). Graz, Austria:
Know-Center, SEP 2007, pp. 356–364.
[11] Z. Xu, Y. Fu, J. Mao, and D. Su, “Towards the semantic
web: Collaborative tag suggestions,” in Proceedings of
the Collaborative Web Tagging Workshop at the WWW
2006, Edinburgh, Scotland, May 2006. [Online]. Available:
http://www.ibiblio.org/www_tagging/2006/13.pdf
[12] P. Heymann, D. Ramage, and H. Garcia-Molina, “Social tag
prediction,” in SIGIR ’08: Proceedings of the 31st annual
international ACM SIGIR conference on Research and de-
velopment in information retrieval. New York, NY, USA:
ACM, 2008, pp. 531–538.
[13] C. Schmitz, A. Hotho, R. Jäschke, and G. S. and,
“Mining association rules in folksonomies,” in Data
Science and Classi?cation, ser. Studies in Classi?cation,
Data Analysis, and Knowledge Organization. Springer
Berlin Heidelberg, 2006, pp. 261–270. [Online]. Available:
http://www.springerlink.com/content/gmv832553g0x3673/
[14] K. Ehms, “Persönliche Weblogs in Organisationen –
Spielzeug oder Werkzeug für ein zeitgemäßes Wissensman-
agement?” Ph.D. dissertation, Universität Augsburg, 2010.
[15] T. V. Wal, “Folksonomy. Folksonomy Coinage and
De?nition,” 2007, http://vanderwal.net/folksonomy.html.
[Online]. Available: http://vanderwal.net/folksonomy.html
[16] A. Hotho, R. Jäschke, C. Schmitz, and G. Stumme,
“Information Retrieval in Folksonomies: Search and
Ranking,” in The Semantic Web: Research and Applications,
3rd European Semantic Web Conference, ESWC 2006, Budva,
Montenegro, ser. Lecture Notes in Computer Science, vol.
4011. Berlin/ Heidelberg: Springer, June 2006, pp. 411–426.
[Online]. Available: http://dx.doi.org/10.1007/11762256_31
[17] T. Gruber, “Ontology of folksonomy: A mash-up of
apples and oranges,” November 2005, http://tomgruber.
org/writing/ontology-of-folksonomy.htm. [Online]. Available:
http://tomgruber.org/writing/ontology-of-folksonomy.htm
[18] R. Agrawal, T. Imielinski, and A. Swami, “Mining association
rules between sets of items in large databases,” in SIGMOD
’93: Proceedings of the 1993 ACM SIGMOD international
conference on Management of data. New York, NY,
USA: ACM Press, 1993, pp. 207–216. [Online]. Available:
http://doi.acm.org/10.1145/170035.170072
[19] X. Fu, J. Budzik, and K. J. Hammond, “Mining navigation
history for recommendation,” in IUI ’00: Proceedings of the
5th international conference on Intelligent user interfaces.
New York, NY, USA: ACM, 2000, pp. 106–112.
[20] K. Ehms, Globale Mitarbeiter-Weblogs bei der Siemens AG.
München: Oldenbourg, 2008, pp. 199–209. [Online]. Avail-
able: http://www.oldenbourg-wissenschaftsverlag.de/olb/de/1.
c.1330715.de
[21] B. Lindner, “Der Einsatz von Wikis in der Siemens AG,” I-
KNOW, 2008.
[22] W. C. Kammergruber, M. Viermetz, and C.-N. Ziegler, “Dis-
covering communities of interest in a tagged on-line environ-
ment,” in CASoN2009: Proceedings of the 1st International
Conference on Computational Aspects of Social Networks,
2009.
[23] D. Laniado, D. Eynard, and M. Colombetti, “Using WordNet
to turn a folksonomy into a hierarchy of concepts,” Proceed-
ings of SWAP 2007, the 4th Italian Semantic Web Workshop,
p. 192, 2007.
[24] R. Cilibrasi and P. M. B. Vitanyi. (2005, March) Automatic
meaning discovery using google. [Online]. Available:
http://arxiv.org/abs/cs/0412098
[25] J. Dean and S. Ghemawat, “Mapreduce: simpli?ed data pro-
cessing on large clusters,” in OSDI’04: Proceedings of the 6th
conference on Symposium on Opearting Systems Design &
Implementation. Berkeley, CA, USA: USENIX Association,
2004, pp. 10–10.
[26] J. Hipp, U. Güntzer, and G. Nakhaeizadeh, “Algorithms for
association rule mining - a general survey and comparison,”
SIGKDD Explor. Newsl., vol. 2, no. 1, pp. 58–64, 2000.
[27] R. Mander, G. Salomon, and Y. Y. Wong, “A “pile” metaphor
for supporting casual organization of information,” in CHI
’92: Proceedings of the SIGCHI conference on Human factors
in computing systems. New York, NY, USA: ACM, 1992,
pp. 627–634.
2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM) 419
