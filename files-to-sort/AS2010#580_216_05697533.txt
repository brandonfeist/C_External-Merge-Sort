An efficient for discovery of Frequent Itemsets 
Venkateswari S#, Suresh R.M*
#Department of Software Engineering, *Department of Computer Science -  
#Noorul Islam University, Kumaracoil, Thuckalay, K.K.Dist, India 
*RMD Engineering College, Kavaraipettai, Chennai, India 
1
venki.vasan@gmail.com 
Abstract— Association rule mining is a well researched method 
for discovering interesting relations between variables in large 
databases. The first phase of association rule mining is the 
discovery of frequent itemsets which is a critical step and plays 
important role in many data mining tasks. The existing 
algorithms for finding frequent itemsets suffer from many 
problems related to memory and computational cost. In this 
paper, we propose a new algorithm ILLT (Indexed Limited Level 
Tree) which gets frequent itemsets efficiently in the given 
database without doing multiple scans and extensive 
computation. ILLT algorithm works in two phases. First, the 
transactional data is converted into three level compact tree 
structures. Then, these trees are scanned to discover the frequent 
itemsets. Experimental status shows the effectiveness of the 
algorithm in mining frequent itemsets.
Keywords— Data Mining, e-commerce, frequent itemsets, 
ILLTree
I. INTRODUCTION
Large amount of data have been collected routinely in the 
course of day-to-day management, in business, administration, 
banking, e-commerce, the delivery of social and health 
services, environmental protection, security and in politics. 
With the tremendous growth of data, users are expecting more 
relevant and sophisticated information which may be lying 
hidden in the data. Existing analysis and evaluating techniques 
do not match with this tremendous growth. Data mining is 
often described as a discipline to find hidden information in 
databases.   It involves different techniques and algorithms to 
discover useful knowledge lying hidden in the data [1]. 
Association rule mining has been one of the most popular data 
mining subjects which can be simply defined as finding 
interesting rules from collection of data [2]. The first step in 
association rule mining is finding frequent itemsets. It is a 
very resource consuming task and for that reason it has been 
one of the most popular research fields in data mining 
II. PROBLEM STATMENT 
Following is the formal statement of association rule mining 
for transactional databases [2,3]: 
Let I = {i1, i2,…im} be a set of literals, called items.  Let D 
be a set of transactions, where each transaction T is a set of 
items such that T ? I. A unique identifier TID is given to each 
transaction. A transaction T is said to contain X, set of items 
in I, if X ? T. An association rule is an implication of the 
form “X?Y", where X ? I, Y ? I, and X?Y = ø. An item set 
X is said to be large or frequent if its support s is greater or 
equal than a given minimum support threshold?. The rule 
X?Y has a support s in the transaction set D if s% of the 
transactions in D contain X ? Y. In other words, the support 
of the rule is the probability that X and Y hold together among 
all the possible presented cases. It is said that the rule X ? Y 
holds in the transaction set D with confidence c if c% of 
transactions in D that contain X also contain Y . In other 
words, the confidence of the rule is the conditional probability 
that the consequent Y is true under the condition of the 
antecedent X. 
Association mining task can be broken into two steps:  The 
first step is to find each set of items, called itemsets, such that 
the co-occurrence rate of these items is above the minimum 
support ?, and this itemsets are called frequent itemsets. The 
size of an itemset represents the number of items in that set. 
Second step of generation of association rules is straight 
forward. 
III. RELATED WORK
Several algorithms are devised for finding frequent itemsets. 
Apriori is the foremost and popular algorithm for finding 
frequent itemsets [3]. The Apriori is a level wise search 
algorithm for mining frequent itemsets for Boolean 
association rules. Apriori uses the property stating that for a k 
itemset to be frequent , all its k-1 itemsets have to be frequent. 
The drawback of  Apriori is that of repeated database scanning 
and high computational cost.  
Another approach of discovering frequent itemsets is the FP-
growth (Frequent Pattern growth) algorithm [4]. This 
algorithm uses compact data structure called FP-Tree. FP-
growth algorithm requires only two scans of database. First 
scan get all frequent 1-itemset and the next scan of database 
constructs the tree structure. Mining takes place directly in the 
tree structure. The shortcoming of the algorithm is the 
generation of thousands of FP tree. This memory based data 
structure consumes lot of space and time and this becomes a 
serious bottleneck for cases with large databases. Several 
methods do single scan of databases for finding the itemsets 
[7]. The TIMV algorithm [8] uses three dimensional itemset 
matrix vectors. Unlike Apriori, this algorithm needs one pass 
to scan the database and gains all frequent itemsets without 
generating candidate itemsets. The Diffset algorithm [9]  uses 
tree data structure and mines the frequent itemset by 
traversing the search tree thus saving a lot of I/O. 
 In this paper, we propose  a new algorithm named ILLT – 
Limited Level Tree algorithm  that uses candidates but it has 
an advantage of  single database scan and finding the frequent 
itemsets  quickly for any given support threshold. 
The remainder of the paper is organized as follows:  The 
proposed algorithm ILLT is described in section 2. 
Experimental results are discussed in section 3.  Conclusion is 
presented in section 4. 
IV.  THE  ILLT ALGORITHM
The main objective of developing this Indexed Limited Level 
Tree algorithm is to reduce the repeated database scans and to 
reduce the cost of computation required for generating 
531978-1-4244-8594-9/10/$26.00 c©2010 IEEE
frequent itemsets. Proposed ILLT algorithm is a three level 
tree structure algorithm composed of two steps. First step is 
construction of ILLTree structures. Second step is mining the 
tree structures for finding frequent itemsets. Frequent itemsets 
for any given support levels can be discovered quickly from 
the ILLTree structures. The mining process might take in 
some cases less than one full scan of the data structure for 
discovering frequent itemsets. 
V. CONSTRUCTING ILLTREE STRUCTURES
First step of ILLT algorithm is construction of tree data 
structures. The levels of the tree are limited to three with an 
index node so it is named as Index Limited Level Tree (ILLT). 
The compact trees constructed in the first step is done  by 
doing only one scan of given transactional database. From the 
resultant ILLTree it is easy to find frequent itemsets for 
different support levels. Scanning the database again is not 
needed at any stage. The tree structures store the contents of 
the transactions in their nodes. 
ILLT algorithm scans the database first and generates 
candidate itemsets for every transaction in the database. These 
generated candidate itemsets are of different lengths. An 
unique tree is constructed for each k-length itemsets. Level 1 
of the trees is the header node. This header node with the label 
H indicates which k- itemset that tree stores. If the label of the 
header node is 3, then this tree stores all 3-itemsets. The 
header node has n children at level two. n is the total number 
of items that occur in the transactions. Each node in the level 
two indicates an individual item. Third level of the tree stores 
the candidate itemsets as its nodes. An index is associated 
with each tree. The Indexed Limited Level Tree structure with 
three levels is shown in the figure 1. 
Fig. 1: ILLTree structure 
When candidate itemsets are generated, an unique 
identification number is assigned to each of them. This 
candidate itemset with its identification number is stored in 
the index first. Then this itemset is stored in the third level of 
the tree in the following syntax. 
<Node Id number><Number of occurrence> 
Then a new candidate itemsets has to be inserted in the tree, it 
is first checked with the index. If it already exists in the index, 
only the occurrence number is incremented in the respective 
nodes. If it does not exist, then a new identification number is 
assigned and the itemset is stored in the tree. Depending on 
the length of the candidate itemset the appropriate tree is 
chosen for insertion.  For illustration we use the example in 
table 1. 
TID Items 
T1 ABC 
T2 AB 
Table 1 
T1 and T2 are Transaction Ids. Transaction T1contains 3 
items and T2 contains 2 items.  
The candidate itemsets generated for the transactions in the 
table are: 
T1: {a}{b}{c}{ab}{ac}{bc}{abc} 
T2: {a} {b} {ab} 
Candidate itemsets of transaction T1 are 
1-Itemsets : {a}, {b}, {c} 
2-Itemsets : {ab}, {ac}, {bc} 
3-Itemsets : {abc} 
Fig 2:  Tree structures for T1 
The respective tree structures after the insertion of candidate 
itemsets of transaction T1 is shown in figure 2. 
Candidate itemsets for transaction T2 is as follows: 
1-Itemsets : {a}, {b} 
2-Itemsets : {AB} 
The resultant 1-item and 2-item tree structures after inserting 
the candidate itemsets of given two transactions is in figure 3. 
Fig 3:   Tree structures after T1 and T2 
In the figure 3, trees show the difference in the occurrence 
value for the nodes of repeated candidate itemsets. The second 
part of the node value shows the number of occurrences. Since 
532 2010 International Conference on Signal and Image Processing
2010 International Conference on Signal and Image Processing 533
