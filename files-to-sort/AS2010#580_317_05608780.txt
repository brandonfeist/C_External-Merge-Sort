  
Study of Data Ming based on Apriori Algorithm 
 
Xiaojun Wang 
Zhejiang Sci-Tech University 
HangZhou, China 
wxj678@126.com 
 
 
Abstract—According to the current characteristics of Internet 
users to search information, this article provides preprocessing 
steps and algorithms of log mining for non-registered and 
registered users. Focus on the study of the user's access pattern 
generated after preprocessing logs, and generated frequent 
access sets. It mainly studies the algorithm of web site users' 
personalized information recommendation and compares 
current various algorithms about the personalized 
recommendation. As the amount of Internet users log is very 
large, and contains a lot of useless information, this article 
improves the existing Apriori algorithm, by using the division 
and governance strategy to introduce the method of the Hash 
technology to complete the compressed candidate sets, 
reducing the times of frequently scanning the database, 
overcoming problems of the data mining algorithm of original 
association rules generating relatively large frequent sets, and 
needing repeatedly scanning the database .  
Keyword-Web Data Mining, Web Personalized Information 
Recommendation, association rules 
With the rapid development of the network information 
technology, the amount of information in the network is 
increasing, thereby the Internet emerges the phenomenon of 
"Information Explosion". In this background, users may not 
get the information resources they need after spending a lot 
of time that is the phenomenon of "Information Trek"[1-4] is 
produced. Therefore, by identifying the characteristics of 
different users' needs, for this reason the use of personalized 
service strategies and methods will solve this problem very 
well. The most important service in the intelligent 
personalized initiative information service is the 
personalized information recommendation. Resnick [5] first 
proposed the definition of recommendation systems, 
pointing out that recommendation systems is to recommend 
for users to realize personalized items". Schafer [6] had a 
deeper understanding of recommendation systems that 
recommending systems is a system that any providing a 
single recommendation result as the output or in a 
personalized way to guide users in the large capacity of 
optional items to find their own interested or useful items for 
themselves. Currently the combination of the Web log 
mining with the personalized information recommendation 
services has become an important research topic. While with 
the development of the network technology, the existing 
massive Internet users are available, and their browsing 
amount of information is also very large; the existing 
recommendation system is obviously not enough to process 
data in the speed aspect, so how to find an appropriate way 
to enable to more quickly recommend the information to 
Internet users seems to be specially important. 
I. APRIORI ALGORITHM 
Apriori and others in 1993 designed a basic algorithm of 
Apriori[7,8], and proposed an important method of mining 
association rules based on two-stage frequency sets ideas, 
which is the most typical level algorithm and the most 
successful type of algorithm among Boolean association 
rules mining algorithms. Its core technology has been widely 
used in other types of Boolean association rules mining 
algorithms. The idea of the algorithm is [9, 10]: If S is a 
frequent item set, as for any non-empty subset L of S, 
through calculating the confidence degree, that is: 
conf=support(S)/support (L), and by conf ?miniconf (the 
minimum confidence) we can determine whether the rule of 
L?(S-L) is established (The rule certainly has the minimum 
support for S is the frequent item set). 
For example: ABCD is a frequent item set, and AB is its 
subset. 
If conf=support (ABCD)/support (AB) ?miniconf (the 
minimum confidence) 
Then the rule of AB?CD is established, otherwise not. 
For example: ABCD is a frequent item set, AB is a 
subset of it 
If confsupport (ABCD) / support (AB) miniconf 
(minimum confidence) 
Then the ABCD rule is established, otherwise not valid. 
Specific in the page dialogue, S is the frequent item set 
that is the page in S is the page often visited at the same 
time in a visit, while the last page in the visit sequence is 
always the purpose of users’ visiting. Therefore, when using 
frequent item sets to generate the demanded rules, it is to 
mainly export rules of the pre-n-1 page of S to the last page; 
if this rule meets the minimum confidence, store this rule 
into the model library. The basic idea of the Apriori 
algorithm of frequent sets is found that, each scan of the 
transaction database needs constructing a frequent set; 
calculate the support of each candidate set, and then 
determine the frequent item set according to the pre-given 
minimum support. For example, the first scan obtains the 
candidate one item set, and then according to the minimum 
support determines the frequent one item set L1. To find the 
frequent 2 item set, taking the fact into account that any 
subset of frequent item sets has the minimum support, the 
Apriori algorithm uses L1?L1 to generate candidate sets, 
2010 2nd International Conference on Software Technology and Engineering(ICSTE)
V2-400C978-1-4244-8666-3/10/$26.00      2010 IEEE
  
here ? representing the join operation. C2 consists of C2|L1| 
two item sets. However, when |L1| is large, then C2 L1 
becomes very large. Next, scan the transactions in the 
database, and calculate the support of each candidate set in 
C2 to find their support not less than the minimum support 
of the frequent set L2. And so on, before the k (k?1) time of 
scanning, first it is to use the (k-1) time of scanning result 
(i.e. frequent (k-1) item set Lk-1,) and the candidate k item 
set Ck generated by the Apriori-gen function, then in the 
process of the k time of scanning determine the support of 
each element, find the frequent k item set Lk. The algorithm 
ends when the candidate k item set Ck is empty. It can be 
found that in the process of calculating candidate item sets, 
generating candidate sets as small as possible is very 
important to the implementation efficiency, because at the 
time of scanning the whole database it needs calculating the 
support of each item set in Ck. The larger candidate sets are, 
the greater the cost of generating frequent sets is. Some 
experiments indicated that the initial scanning process has 
determined the cost of the entire implementation process; 
candidate sets generated from scanning are larger than those 
item sets which are real frequent item sets. Therefore, the 
generation of the initial candidate sets, especially of the 
frequent two item set, is the key to improve the association 
rules mining efficiency. Another factor associated with the 
implementation performance is the number of data which 
need scanning in the process of finding frequent item sets. 
General algorithm is that during each iteration it needs 
scanning once the database of all transactions. To note that, 
with the increase of k value, not only the element of the 
frequent k item set reduces, also transactions including any 
frequent k item set becomes less and less. At this time, still 
scanning the entire database to calculate the support will be 
a great waste of time and space. Therefore, reducing the 
number of transactions needed scanning and the number of 
items in each transaction is an effective way to improve the 
mining efficiency. 
II. THE IMPROVEMENT OF THE APRIORI ALGORITHM 
It can be seen from the idea of the Apriori algorithm that, 
when there is a considerable number of frequent item sets, 
Apriori will generate a large number of candidate sets, and 
may have to repeatedly scan the database, which certainly 
reduces the efficiency of the algorithm; the algorithm 
proposed in this article is through the division and 
governance strategy to introduce the hash technology to 
improve the generation of frequent item sets, and uses the 
data to search the language to realize the association rule 
mining algorithm. To obtain users’ frequent access path, if 
the maximum forward reference of users’ each visit is very 
long, then it needs generating a number of k item sets; 
generating a large number of candidate item sets, each time it 
needs several repeated scanning of the same transaction 
database; we have proposed a strategy for improvement. For 
the sake of convenient discussion, here each item in I uses its 
item number to replace. Same as the previous, name the set 
of all frequent k item sets as Lk, such as L1 for the set of all 
frequent one item sets. Here we assume that transactions in 
the transaction database and items of any item sets appearing 
in the algorithm are all arranged in accordance with the item 
number sequence. In the later algorithm, we easily see that, 
as long as making sure at the beginning that is items in the 
two item set are in order, and then the implementation of the 
algorithm will automatically make ensure that any item set is 
also in order. 
Through the use of the hash technology it constructs a 
very small C2 to generate smaller L2 to export C3. If C2 is 
very large, the database can not effectively prune. After this 
step, the size of Li decreases rapidly as the value of i 
increases, thus it results in really small Li+1; then the 
corresponding cost is much less, greatly improving the 
proceeding efficiency of the entire process. 
The advantage of the Hash table is to avoid the process 
of repeated searching, by the method of addressing to 
directly find the data which is needed; usually through the 
design of a hash function, which is a mapping, as long as it 
makes the hash function value obtained from any keyword 
be within the allowable scope of the table length.  Basic 
idea is as follows: 
Same as the Apriori idea, first of all generate candidate 
one ?  item set Cl. The algorithm simply scans the 
transactions database, and count for each item. 
Set the minimum transaction support number (i.e. 
min_support), which can be calculated by the storage 
procedure, and can also be specified by the user himself. 
Determine the L1 set of frequent one ? item sets, as the 
following table. Any transaction in the frequent item set L1 
is larger than or equal to the minimum support degree. 
Generate candidate 2 ? item sets. The algorithm uses 
L1? L1 to generate the candidate item set C2. Each item set 
in C2 is to make a connection with two frequent item sets 
belonging to L1 to generate  
Scan the transactions database, calculate the support 
number of each candidate item set in C2, and store C2 with a 
temporary table. 
Select transactions of which each transaction is not less 
than the minimum support degree, thus to determine the 
frequent two item set L2, and calculate the corresponding 
hash function of its transaction and the combination of item 
number 2. 
Generate three item candidate set C3, use the 
characteristics of the Apriori algorithm, adopt the pruning 
technique, and remove all candidate item sets whose subsets 
are not frequent item sets, thus greatly reduce the size of 
3-item candidate sets, to improve the efficiency for 
generating frequent item sets L3. 
Generate frequent three ? item set L3, and calculate the 
support number of each transaction. 
The circulation continues like this, continues to generate 
candidate sets, and from this generates frequent item sets, 
until the candidate item is empty. 
The main purpose of using the Hash Algorithm is to 
generate the next candidate set by filtering out the item sets 
which are not needed. When scanning the database to 
calculate the support degree of the candidate k item set, it is 
to use the hash technology to pre-store the candidate (k +1) 
2010 2nd International Conference on Software Technology and Engineering(ICSTE)
V2-401
  
item set, that is, after through certain cutting, hash all 
possible (k +1) item set in a hash table. Each hash unit in 
the Hash table consists of one number, which represents so 
far the number of item sets hashed to this unit. The bit 
vector is constructed based on the Hash table; if the number 
of the corresponding number in the Hash table is larger than 
or equal to s, then the corresponding bit value is set to be 1, 
otherwise 0. 
III. EXPERIMENTAL ANALYSIS 
Figure 1 uses the example to analyze the Apriori 
algorithm. In the first iteration, the Apriori algorithm simply 
scans all the transactions, calculate the times appearing of 
each item, and obtain the candidate one item set of Cl; it 
assumes that the minimum support degree of transactions is 
2, then the frequent one item set L1, is constituted by the 
candidate one item set which meets the minimum support 
degree. The Apriori algorithm uses L1 ?L1 to generate the 
candidate set C2. Next, scan 10 transactions in the database, 
and calculate the support degree of each candidate set in C2. 
Then, based on the support degree of each candidate two 
item set in C2 can determine the frequent 2 item set L2. The 
candidate set C3 is produced by L2, the process as follows: 
first identify two frequent 2 item sets of {AB} and {AC} in 
L2 which are the same with the first project. Then, Apriori 
check the two item set {BC} composed by the previous two 
projects of {AB} and {AC} whether constitutes a frequent 
two item set. As {BC} itself is a frequent two item set, 
hence all subsets that can get {ABC} are frequent, then 
{ABC} becomes a candidate three item set. Similarly {ABE} 
is also a candidate three item set. This is using the above 
mentioned nature of Apriori to precede the connecting and 
pruning process. The candidate four item set cannot be 
constructed from L3, at this time the algorithm to be 
terminated.  
Seen from the process of this algorithm, it is very 
important to produce candidate set Ci as small as possible, 
because in the process of scanning the entire database it 
needs to calculate the support degree of each project in Ci. 
  
C 2  
U se r  ID          Ite m s 
2 0 2 .1 9 9 .1 3 7 .6     A B E  
2 0 2 .1 9 9 .1 3 7 .6     A B D  
2 0 2 .1 9 9 .1 3 7 .6     B D  
2 0 2 .1 9 9 .1 3 7 .6     B C  
2 0 2 .1 9 9 .1 3 7 .6     A B C  
2 0 2 .1 9 9 .1 3 7 .6     A B C E  
2 0 2 .1 9 9 .1 3 7 .6     A C  
2 0 2 .1 9 9 .1 3 7 .6     B C  
2 0 2 .1 9 9 .1 3 7 .6     A B F  
2 0 2 .1 9 9 .1 3 7 .6     A C  
Ite m s    S u p  
A        7  
B        8  
C        6  
D        2  
E        2  
F        1  
S c a n  D  
C 1  
Ite m s    S u p  
A        7  
B        8  
C        6  
D        2  
E        2
L 1  
Ite m s 
A B  
A C  
A D  
A E  
B C  
B D  
B E  
C D  
C E  
D E  
Ite m s    S u p  
A B       5  
B C       4  
A D       1  
A E       2  
B C       4  
B D       2  
B E       2  
C D       0  
C E       1  
D E       0  
S c a n  D  
C 2  
Ite m s    S u p  
A B       5  
A C       4  
A E       2  
B C       4  
B D       2  
B E       2  
L 2  
C 3  
Ite m s 
A B C  
A B E  
S c a n  D  
Ite m s    S u p  
A B C      2  
A B E      2  
C 3  
Ite m s   S u p  
A B C      2  
A B E      2  
L 3  
 
Figure 1.  The analysis of the Apriori algorithm 
Figure 2 shows an example of the specific application of 
the hash thinking. The purpose of constructing the hash 
table is to compress candidate sets by the hashing technique, 
and then the construction method of the hash table to some 
extent determines the hashing results. In this paper, it adopts 
the method of MVR to construct hash functions: (x * factor 
?  y) mod hashtblsize. Obviously, the two uncertain 
parameters: the table length of the hash table and the factor 
coefficient are important elements to determine the hashing 
effects. For, if the table length of the hash table is smaller, 
then the hash result is that each bucket in the hash table has 
a number of candidate sets; if the count of each bucket is 
larger than the minimum support degree, then the hash table 
can not filter out any item; then it does not have any 
compression and filter effect, also the process of the 
construction consumes time. While the factor coefficient is 
an uncertain element, for example, we take x = 3, y = 2, 
when hashtblsize = 10, no matter which of 10,20,30 the 
factor takes, the results are the same; however, when 
hashtblsize = 20?the results will be different. Through 
experiments on the same test sets, under the condition of the 
same minimum support degree and different lengths of 
tables, using relevant results produced by the algorithm to 
analyze, comparing results, we can get, when the hash table 
length is longer, the effect of hashing is better. And we have 
verified this conclusion: the generation of initial candidate 
set, especially the frequent two item set, is the key to 
improve the mining efficiency of association rules. By use 
of the Hash table to effectively form frequent two item set 
and increase the efficiency of the algorithm. 
 
Figure 2.  the hash technology causes frequent sets 
IV. CONCLUSION 
In view of the status that the present classic algorithm of 
association rules generating larger amount of candidate sets 
and more data amounts needed to be scanned, using the 
hash technology and the method of combining division with 
conquest, improving the existing Apriori algorithm, to 
achieve the purpose of increasing mining efficiency and 
raising the speed of appearing the recommended page. 
2010 2nd International Conference on Software Technology and Engineering(ICSTE)
V2-402
  
REFERENCE  
[1] Hai-Tao Xiao, etc. Research on Web-based Data Mining Apriori 
Algorithm and Optimization Algorithms"[J], "Education," 2006 (1). 
[2] J Han.M Kamber Data Mining Concepts and Techniques 2001. 
[3] Ouyang River. Based on Association Rule Algorithm Improvement 
Research " 2006 (21). 
[4] Yao-chang proposed. Research of the Application on Customer 
Analysis of an Association Rules Mining Method 2008 (4).   
[5] Zhang Ling, An Improved Algorithm Based on Apriori and IUA ," 
2009 (1). 
[6] Ma yu nv. An improved Apriori Algorithm based on mining 
association rule," 2004 (4). 
[7] Chen Yao. An Improved Apriori Algorithm Based on Graph 2008 
(7). 
[8] UNESCO. Medical Data Mining Based on Association Rules, 1996. 
[9] SHENG Qinghong, ZHANG Jianqing, XIAO Hui. A New Approach 
for Segmentation of Forest Image Based on the Color and Texture [J]. 
GEOMATICS AND INFORMATION SCIENCE OF WUHAN 
UNIVERSITY. 2008.33(3):306-309  
[10] Rechard Davide, Optimization of Apriori Algorithm in Mining 
Association Rules " 2009 (6) 
 
2010 2nd International Conference on Software Technology and Engineering(ICSTE)
V2-403
