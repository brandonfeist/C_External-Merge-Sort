An Associative Watermarking based Image Authentication Scheme
Lamiaa M. El Bakrawy1, Neveen I. Ghali1, Aboul Ella Hassanien2 and Ajith Abraham3,
1Faculty of Science, Al-Azhar University, Cairo, Egypt
Email: lamiaabak, nevghali@yahoo.com
2Faculty of Computers and Info., Cairo University,Cairo, Egypt
Email: aboitcairo@gmail.com
3Machine Intelligence Research Labs, MIR Labs, USA
Email: abraham.ajith@gmail.com
Abstract—In this paper, we propose an associative wa-
termarking scheme which is conducted by the concept of
Association Mining Rules (AMRs) and the ideas of Vector
Quantization (VQ) and Soble operator. Performing associative
watermarking rules to the images will reduct the amount
of the embedded data, and using VQ indexing scheme can
easily recall the embedded watermark for the purpose of
image authentication, and establishing the relation between the
association rules on both the original image and the watermark
image. The Vector Quantization decoding technique is applied
to reconstruct the watermarked image from the watermarked
index table. The experimental result shows that the proposed
scheme is robust. When the watermarked images suffered from
various kinds of image-processing procedures, such as Gaussian
noise, brightness, blurring, sharpening, cropping, and JPEG
lossy compression can be detected without the original images
assistance.
I. INTRODUCTION
In the modern world of information, any kind of data
is available to anyone over the Internet. Of all the data
transmitted over the Internet, images are the most common
means of message conveyance. However, the convenient
access to the images on the Internet makes it easy for
anyone to download, copy, edit, or distribute images with
ease, which of course has a direct and severe impact
on the copyright owners (many times the image creators
themselves). Therefore, copyright protection for intellectual
property on the Internet is an important issue [1], [2],
[12]. Digital watermarking techniques have been proposed
for the copyright protection of digital images [10]. In
digital watermarking techniques, some types of watermarks
such as logos, labels, trademark, or random sequence,
representing the author’s ownership, are embedded into
the desired digital image. Generally, a registration to
the authentication center is necessary, which helps to
solve ownership disputes by identifying the owner of the
disputed media. If necessary, the embedded watermark in
the digital image can be used to verify ownership [11], [16].
Watermarking techniques have been studied extensively
in the past. By taking account of the domain in which the
watermark is embedded. Watermarking techniques can be
classi?ed into two broad categories: spatial domain and
frequency domain techniques [3], [4]. In spatial domain
schemes, the watermark is embedded by directly modifying
the pixel values of the host image. On the other hand,
watermarking techniques used in the spatial domain directly
modify coef?cients of images to achieve the purpose
for watermarking [5], [16]. The watermarking technique
proposed in this paper is based on vector quantization (VQ)
[11], [12]. Strictly speaking, VQ cannot be categorized
into either of the above types; rather, it is a kind of image
compression technique that uses indices of codewords in
the codebook to represent the input image and ?nally refers
the index table as the original image.
The remainder of this paper is organized as follows. Brief
introduction of vector quantization (VQ), association rule,
and edge block detection are respectively introduced in Sec-
tion (II). The detailed of the proposed scheme is presented
in Section (III). Section (IV) shows the experimental results.
Conclusions are discussed in Section (V).
II. AN OVERVIEW
A. Vector quantization (VQ)
VQ is a simple data compression technique which was
?rst proposed by Gray [2]. In the beginning, an image is
segmented into several blocks with the same size, such
as 4 × 4. Each block consists of 16 pixels. These pixels,
from left to right and top to bottom, can form a vector
v = {v1, v2, ..., vk}, where k represents number of dimen-
sions. The pixel value of each block is different, so before
encoding, representative vectors, called codeword c, should
be collected to form a codebook CB = {ci : i = 1, ..., L?1}
, where L denotes the codebook size and i denotes the
index value. The well-known LBG algorithm [11] can be
employed to form the codebook. By clustering code words,
it ?nds a representative codeword from each cluster and uses
the representative code words to form a codebook. Through
823978-1-4244-8136-1/10/$26.00 c©2010 IEEE
Euclidean distance d(v, ci) shown in Eq. (1), where vj and
cij are respectively the jth elements of the vector v and ci,
we can ?nd code words nearest to the input vector and record
the index value of each code word.
d(v, ci) =
????
k?1?
j=0
(vj ? cij) (1)
Once the closest codeword for v is found, the index i
of the best matching codeword is assigned to the input
vector v for the basis of future VQ decoding. VQ facilitates
compression by means of transmitting or storing the index
of the codeword instead of the codeword itself. In the
decoding phase, the decoder also utilizes the same codebook
to perform a simple table look-up operation for each index
i, so as to obtain the corresponding codeword ci. Finally, ci
is applied to reconstruct the input vector v [2].
B. Association rules
Association rule mining, which was ?rst proposed by
Agrawal et al. [8], is one of the most important topics in the
area of data mining, and has many successful applications,
especially in the analysis of consumer market-basket data
[6], [17]. An association rule is a probabilistic relationship,
with the form X ? Y between sets of database attributes,
where X and Y are sets and termed as itemsets, and
x
?
y = ?. It is inferred empirically from examination of
records in the database. Such a rule reveals that transactions
in the database containing items in X tend to contain items
in Y , and the probability, measured as the fraction of the
transactions containing X also containing Y , is called the
con?dence of the rule. The support of the rule is the fraction
of the transactions that contain all items in both X and Y
[9].
C. Edge block detection method - the Sobel operator
Edge detection is the task of ?nding the boundaries
between the objects that appear in a digital image [13]. Sobel
operator is used to detect image edges by calculating partial
derivatives in 3×3 neighborhoods. The reason of using Sobel
operator is that it is insensitive to noise and it has relatively
small masks than other operator such as Robert operator,
two-order Laplacian operator and so on [14]. The detection
Equations (2) and (3).
Gx = (Z7 + 2Z8 + Z9) + (Z1 + 2Z2 + Z3) (2)
Gy = (Z3 + 2Z6 + Z9) + (Z1 + 2Z4 + Z7) (3)
where Z’s are the gray levels of the pixels inside the mask.
The masks are moved pixel by pixel and the procedure is
repeated until all possible locations have been computed.
Finally, the result generated in the gradient image whose
size is the same as the original image. The block under
Figure 1 The overview of the proposed algorithm
consideration will be regarded as an edge block if any value
of those two computed values is larger than the reselected
threshold value [15].
III. THE PROPOSED IMAGE AUTHENTICATION SCHEME
In the proposed method both the original image X with
size AX ×BX and the watermark W with size AW ×BW
are divided into non-overlapping blocks with size k×k, and
for each block, the codebook C (including Lk2-dimensional
codewords) is utilized to ?nd the closest codeword so as to
obtain the index tables of the original image and watermark,
XT and WT , respectively. The size of XT and WT are
(AX
k
×BX
k
) and (AW
k
×BW
k
). Subsequently, association rules
de?ned upon 4-itemset are exploited to mine association
rules from XT and WT , respectively. Then we embed
the association rules generated from the watermark into
the original image, the overall description of the proposed
system are given in Figure (1).
A. Mining Association rules of the original image and
watermark
For each index in the index tables of original and wa-
termark images the 4-itemset association rules can be illus-
824 2010 10th International Conference on Intelligent Systems Design and Applications
trated as (item1, item2, item3) ? (item4). The ?rst three
items are utilized to ?nd the nearest original image rules for
the watermark rules, and by changing the fourth item’s value
of the rule, which is derived from some selected original
image blocks, such that the watermark can be embedded.
The four items for each block’s rule are de?ned in Algorithm
1.
Algorithm 1 The four items for each block’s rule
Input Parameters: T, S, Imagearray, ImageCells,
Normalizedfactor
Phase-I Embedding :
1: Calculate the mean of its index and the indices of its
neighboring eight blocks
2: if the mean value >= T1 then
3: Item1 =1
4: else
5: Item1 = 0
6: end if
7: Calculate the variance of its index and the indices of its
neighboring eight blocks
8: if the variance value >= T2 then
9: Item2 =1
10: else
11: Item2 = 0
12: end if
13: Sobel is applied to do convolution on this block to
determine whether its corresponding codeword is an
edge block or not
14: if any value of those two computed values >= T3 then
15: this block is an edge block, and Item3 = 1
16: else
17: it is = 0
18: end if
19: The item4 value is the corresponding index value in-
dicated in the index table, Where T1,T2,T3 are given
threshold.
B. Embedding Process
The detailed procedure of hiding association rules WR in
XR being derived from XT and WT is described as follows:
1) The ?rst three items play a role as the matching pattern
in XR and WR. ( i.e. if a rule wr = {(1, 0, 1) =?
5}in WR, then the matched rule from XR will be
{(1, 0, 1) =? ?} where ? ? [0, L? 1]). This matching
process is repeated until each rule in WR has found
at least one matched rule in XR, if there is any rule
in WR unable to ?nd a matched rule in XR, go to 2;
otherwise, go to 3.
2) If any rule in WR has no matched rule in XR, any of
the ?rst three item values of this rule must be changed,
and go to 1. This process is repeated until each non-
matched rule in WR ?nd at least one matched rule in
XR.
3) If any rule wr in WR has more than one matched rules,
say s rules xr1, xr2, ..., xrs, the selected rule xr is so-
called the most similar rule to wr. The similarity is
de?ned as follows:
Similarity =
1
MSE ? TM (4)
MSE =
1
k × k
k?1?
i=0
k?1?
j=0
((cwr (i, j)? cxrt))2 (5)
Where 1 ? t ? s, TM is a given threshold, cwr is the
codeword denoted by the index taken from the item4
value of wr, and cxrt is the codeword denoted by the
index taken from the item-4 value of rule xrt which
represents each rule of xr1, xr2, ..., xrs.
4) For any rule xr in {xr1, xr2, ..., xrs}. If there are more
than one XT ’s block which derived the same rule xr
then one of these xr’s relevant blocks is randomly
selected for the watermark information. Subsequently,
by replacing the index of this block with the item4 value
of wr, the purpose for watermarking is successfully
achieved.
5) VQ decoding is performed on the watermarked index
table, which has been embedded with all the rules in
WR, to reconstruct the watermarked image.
C. Extracting Process
For extracting the watermark from the watermarked image
Y . Four keys should be recorded.
1) key1: the set of all selected XT ’s block’s locations.
2) key2: the set of original indices of these blocks.
3) key3: the MSE values between the codewords of orig-
inal indices of these blocks, and the codewords of
indices of these blocks after embedding.
4) key4: for each element of key2, record all of its
corresponding blocks in WT
Then the detailed process is described as follows:
1) Perform VQ encoding on the test image Y to obtain
the index table YT .
2) Use key1 to pick out the watermarked blocks YTW
from YT .
3) Calculate the MSE values between the code words
indexed by all the elements in YTW and key2.
mse(1) = MSE(cYTW (1)? CKey1(1)) (6)
Let Q be the set comprised of all the {mse(l)}, l is
the lth element in YTW and key2, cY TW (l) and ckey2
(l) stand for the codewords with indices YTW (l) and
2010 10th International Conference on Intelligent Systems Design and Applications 825
key2(l), respectively; and MSE(cY TW (l), ckey2(l)) is
the MSE value calculated from these two codewords.
4) Given a threshold TR and key3, Set
R = {mse(l)|mse(l) ? key3(l)× TR} (7)
and calculate
P =
|R|
|Q| (8)
Where |R| and |Q| denote the total quantities of ele-
ments in R and Q
5) Given a threshold TS If P ? TS . Y is treated as a
watermarked image and goes to 6, Otherwise, Y is not
watermarked, and the extraction is terminated.
6) According to key4, restore each element in key into its
corresponding locations on the watermark index table.
7) Do VQ decoding with the above results to reconstruct
the extracted watermark
IV. EXPERIMENTAL RESULTS
In this paper we compare our experimental results with
the method proposed by Shen and Ren [11]. This is because
that the authors utilized the concepts of vector quantization
(VQ) and association rules in data mining to propose a robust
watermarking technique.The 4× 4 masks are used to detect
edge block and each mask stands for different direction
occurring in the edge block. Afterwards, those masks are
applied to do convolution on the 4× 4 image block.
In this research , PSNR (Peak Signal-to-Noise Ratio) is
used to evaluate the difference between the watermarked
image and the original image; NC (Normalized Correlation)
is applied to determine the degree of similarity between
the original watermark and the extracted watermark. Here,
AX and BX represent the height and width of the original
image X , respectively. AW and BW are the height and
width of watermark W. XW and XW separately denotes
the watermarked image and the extracted watermark.
The original image and the watermark are divided into
non-overlapping blocks with size 3 × 3. The codebook
used in this study adopts the traditional LBG method [18]
to train a grayscale Lena image with size 512 × 512, and
the threshold for the termination of training is set as 0.05.
There are 256 codewords in this codebook, and the size
of each codeword is 3 × 3 pixels. Sobel operator is used
to detect edge block since Sobel operator is insensitive to
noise and it has relatively small masks than other operators
such as Robert’s operator, two-order Laplacian operator
and so on. The original image used in the experiments is a
grayscale Lena image with size 512× 512.
Since in [11], the watermark is binary, in order to
make the comparison of different methods objectively,
binary watermark is applied. Here, watermarks with
different sizes are considered in the experiments. Also
the parameters in this paper are the same in [11]. First,
for convenience, the thresholds T1 and T2 are set as the
half of the codebook size which is 128. The threshold
T3 applied to determine whether an image block is an
”edge block” is set to 70, and TM = 80 is selected
since it ensures the better PSNR value, threshold TR and
TS for the judgment of whether an image is embedded
with a watermark or not are set as 0.1 and 0.35, respectively.
(a) Watermarked with (b) Extracted watermark
PSNR = 31.9998(dB) (64× 64)with NC = 0.9928
(c) Watermarked with (d) Extracted watermark
PSNR = 31.8379(dB) (128× 128) with NC = 0.9871
(e) Watermarked with (f) Extracted watermark
PSNR = 31.8379 (dB) (256× 128)with NC = 0.9875
Figure 2 Watermarking image and its watermark extraction
The image pixel of the binary watermark in our method
is either 0 or 255. In order to minimize the distortion of
the extracted watermark in this approach, the codeword
with all values only 0 (c0) and the codeword with all
values only 255 (c255) will be produced, and then replace
these two codewords nearest to c0 and c255, respectively.
MSE (Mean-Square Error) as mentioned above is utilized
826 2010 10th International Conference on Intelligent Systems Design and Applications
to decide two codewords will be modi?ed to c0 or c255.
Thus, the codeword with the minimum MSE value between
c0 and the codeword itself will be changed to c0. Similarly,
the codeword with the minimum MSE value between c255
and the codeword itself will be changed to c255. Besides,
since the codebook applied in our method is grayscale, the
extracted watermark will be in grayscale form. However,
in order to make objective comparisons between our
approach and [11], the extracted grayscale watermark will
be polarized. That is, the pixels with values larger than or
equivalent to 128 will be reset to 255, and the pixels with
values smaller than 128 will be reset to 0, respectively.
Fig. 2 shows watermarked images and the corresponding
extracted watermarks of the proposed method.
Table (I) shows that the value of PSNR of watermarked
images with different sizes of watermarks in the proposed
method is greater than the value of PSNR of watermarked
images in Shen and Ren method. It means that the
watermarked image of our proposed method have better
image quality. Since NC value can be anywhere between
0 and 1. The closer the NC value is to 1, the higher
the accuracy is for the extracted watermark [14]. So the
extracted watermark of our proposed method is more
accuracy than the extracted watermark of Shen and Ren’s
method.
Also the well-known image processing software, Pho-
toshop, is applied to perform 32 image attacks (including
JPEG lossy compression (quality level 0, 1, 2,..., 12), sharp-
ening (1-3 times), adding in Gaussian noise (?= 2, 4, 6, 8,
10, 15 and 20), blurring (1-3 times) and 6 kinds of cropping
methods) on the watermark images. Then NC is used to
compare the difference between the original watermark
and the extracted watermark. After applying 6 kinds of
cropping attacks, JPEG lossy compression (quality level =
0), sharpening three times, adding in Gaussian noise (? =
20) and blurring three times to watermarked images of the
proposed method and Shen and Ren’s method, we can obtain
the corresponding extracted watermarks. Table II shows that
no matter which kinds of attacks the watermarked images
suffer from, extracted watermarks are still similar with the
watermark extracted from non-attacked watermarked image.
Moreover, NC values calculated from extracted watermarks
using the proposed method outperform Shen and Ren’s
method especially in case of Gaussian noise and blurring.
Table I
PSNR OF WATERMARKING IMAGE AND NC OF ITS WATERMARK
EXTRACTION
watermark PSNR NC PSNR NC
Size proposed proposed Shen & Ren Shen & Ren
method method method method
64× 64 31.9998 0.9928 30.8683 0.9872
128× 128 31.8379 0.9871 30.7539 0.9772
256× 128 31.8379 0.9875 30.7493 0.9843
(a) 512× 512 original image (b) 128× 128 watermark
(c) Watermarked image (d) Extracted watermark
with PSNR = 30.8466(dB) with NC = 0.9948
Figure 3 Watermarking image and its watermark extraction
Finally, we use another 512 × 512 image, Mandril and
another watermark to emphasis that the proposed method
can be easily applied in different kinds of protected images.
Figs. 3(a) and 3(b) are the original images, 128 × 128
watermark. Figs. 3(c) is the corresponding watermarked
image. It is noticed that PSNR values of the watermarked
image is smaller than watermarked image, Lena, since the
codebook was trained using Lena only. Figs. 3(d) shows the
extracted watermark. Then, we also apply the same image
processings, JPEG lossy compression (quality level = 0),
sharpening three times, adding in Gaussian noise (? = 20)
and blurring three times, to the watermarked image, we
obtain the corresponding extracted watermarks and there NC
values are shown in table (III).
V. CONCLUSIONS
In this paper, a robust watermarking technique is pro-
posed using vector quantization (VQ) and association rules
2010 10th International Conference on Intelligent Systems Design and Applications 827
Table II
COMPARISON BETWEEN THE NC VALUES OF WATERMARKS EXTRACTED
FROM ATTACKED WATERMARKED IMAGES OF PROPOSED METHOD AND
SHEN AND REN’S METHOD
Experiments The proposed Shen & Ren
method method
Quarter-cropped 0.9584 0.9509
Quarter-cropped and ?lled 0.9629 0.9618
with pixels valued
Quarter-cropped 0.9600 0.9566
and replaced with
the original image
Half-cropped 0.9593 0.9566
Half-cropped and 0.9415 0.9344
?lled with pixels valued
Half-cropped and 0.9516 0.9433
and replaced with
the original image
JPEG lossy compression 0.9578 0.9452
(quality level = 0)
sharpening three times 0.9608 0.9519
adding in Gaussian noise 0.9734 0.9314
(? = 20)
blurring three times 0.9707 0.9457
Table III
NC VALUES OF WATERMARKS EXTRACTED FROM ATTACKED
WATERMARKED IMAGES OF PROPOSED METHOD
Experiments NC
JPEG lossy compression (quality level = 0) 0.9918
sharpening three times 0.9908
adding in Gaussian noise ( ? = 20) 0.9943
blurring three times 0.9933
depending on Sobel operator to detect edge of image. The
reason of using Sobel operator was insensitive to noise and
it has relatively small masks than other operator such as
Robert’s operator and two-order Laplacian operator. The
experimental result shows that the proposed scheme achieves
more effective resistance against several images processing
such as blurring, sharpening, adding in Gaussian noise,
cropping, and JPEG lossy compression especially in case
of Gaussian noise and blurring.
REFERENCES
[1] Shen, J., Hsu, P., A robust associative watermarking tech-
nique based on similarity diagrams, Pattern Recognition
Society, vol.40, pp.1355 - 1367, 2007.
[2] Yang, C., Shen, J., Recover the tampered image based on
VQ indexing, Signal Processing, Vol.90, pp.331-343, 2010.
[3] Yen, E., Lin, L., Rubik’s cube watermark technology for
grayscale images, Expert Systems with Applications, Vol.37,
pp.4033-4039, 2010.
[4] Shen, R., Fu, Y., Lu, H., A novel image watermarking scheme
based on support vector regression, The Journal of Systems
and Software, Vol.78, pp.1-8, 2005.
[5] Aslantas, V., An optimal robust digital image watermarking
based on SVD using differential evolution algorithm, Optics
Communications, Vol.282, pp.769-777, 2009.
[6] Shen, B., Yao, M., Wu, Z., Gao, Y., Mining dynamic associ-
ation rules with comments, Knowl Inf Syst, Vol.23,pp.73-98,
2010.
[7] Ma, W., Wang, K., Liu, Z., Mining potentially more inter-
esting association rules with fuzzy interest measure, Soft
Computing,Vol.10, pp. 1-10, 2010.
[8] Agrawal, R., Imielinski, T., Swami, A., Mining association
rules between sets of items in large Databases, Proceedings
of the ACM SIGMOD conference on management of data,
pp.207-216, 1993.
[9] Linde, Y., Buzo, A., Gray, RM., An algorithm for vector
quantization design, IEEE Transactions on Communications,
Vol.28, pp.84-95,1980.
[10] Wang, Y., Doherty, J., Dyck, R., A wavelet-based watermark-
ing algorithm for ownership veri?cation of digital images,
IEEE Transactions on Image Processing, Vol.11, pp.1-11,
2002.
[11] Shen, J., Ren, J., A robust associative watermarking tech-
nique based on vector Quantization, Digital Signal Process-
ing,Vol.1o, pp.1- 16, 2009.
[12] Wu, H., and Chang, C., A novel digital image watermarking
scheme based on the vector quantization technique, Comput-
ers & Security , Vol.24, pp.460 - 471, 2005.
[13] Meinhardt, E., Zacur, E, Frangi, A., Caselles, V., 3D Edge
Detection by Selection of Level Surface Patches, Journal of
Mathematical Imaging and Vision, Vol.34, pp.1-16, 2009.
[14] Dong, Q., Song, C., Ben, C., Quan, L., A fast subpixel edge
detection method using Sobel-Zernike moments operator,
Image and Vision Computing, Vol.23, pp.11-17, 2005.
[15] Fan, K., Kan, K., Chang, J., Edge preservance and block
effect reduction by block coef?cient diffusion method, Signal
Processing, Vol.61, pp.171-180, 1997.
[16] Tsai, P., Hu, Y., Chang, C., A color image watermark-
ing scheme based on color quantization, Signal Processing,
Vol.84, pp.95 - 106,2004.
[17] Weng, C., Chen, Y., Mining fuzzy association rules from
uncertain data, Knowledge and Information Systems,Vol.9,
pp.24, 2009.
[18] Chang, C., Tsou, C., Chou, Y., A remediable image authenti-
cation scheme based on feature extraction and clustered VQ,
Lecture Notes in Computer Science, Vol.4810, pp.446-449,
2007.
828 2010 10th International Conference on Intelligent Systems Design and Applications
