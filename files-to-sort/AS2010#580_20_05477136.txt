Towards a Discovering Knowledge  
Comprehensible and Exploitable by the End-user  
Amel Grissa Touzi 
Department of Technologies of Information and Communications in 
 Ecole Nationale d’Ingénieurs de Tunis, Tunisia  
amel.touzi@enit.rnu.tn 
 
 
Abstract—The main goal to extract knowledge in database is to 
help the user to give semantics of data and to optimize the 
information research. Unfortunately, this fundamental 
constraint is not taken into account by almost all the 
approaches for knowledge discovery. Indeed, these approaches 
generate a big number of rules that are not easily assimilated 
by the human brain. In this paper, we propose a new approach 
for Knowledge Discovery in Databases through the fusion of 
conceptual clustering, fuzzy logic, and formal concept analysis. 
While basing on the hierarchical structure offered by the 
lattices, we proceed to discover the Knowledge in a 
hierarchical way. Thus, according to the degree of detail 
required by the user, this approach proposes a level of 
knowledge and different views of this knowledge, so the user 
can easily exploit all knowledge generated. Moreover, this 
solution is extensible; the user is able to choose the fuzzy 
method of classification according to the domain of his data 
and his needs.  
Keywords;  Clustering, formal concept analysis, Fuzzy Logic, 
knowledge discovery in databases, association rules.  
I. INTRODUCTION  
Nowadays, we notice a growing interest for the 
Knowledge Discovery in Databases (KDD) methods. Thus, 
several algorithms for mining association rules were 
proposed in the literature, they are based on neural networks, 
trees, concept lattices, association rules, etc. [1]. However, 
generated rules by these algorithms, exceeding some times of 
thousand rules, are not easily assimilated by the human 
brain. In this case, the user must choose among these rules 
those which are intimately bound to the operation that he 
wants to carry out [2, 3]. Several approaches of reduction of 
this big number of rules have been proposed like the use of 
quality measurements, syntactic filtering by constraints, and 
compression by the representative or generic bases [4]. 
Authors of [4] show that with this method the number of 
generated rules has been reduced but remains always 
thousands of rules. 
To our opinion, the big number of the generated rules is 
due because these approaches try to determine rules starting 
from the enormous data set.  To cure this problem, we 
propose a new KDD approach having the principal following 
characteristics:  
x Extract knowledge taking in consideration another 
degree of granularity into the process of knowledge 
extraction. Indeed, we propose to define rules (Meta-
Rules) between classes resulting from a preliminary 
classification on the data. Then, we automatically 
deduce knowledge about the initial data set. 
x Discover knowledge, which covers parts of the primary 
database at different levels of abstraction. Thus, we 
define the level i of knowledge as the set of knowledge 
on all objects verifying i properties. Therefore, 
according to the degree of detail required by the user, 
this approach proposes a level of knowledge, so the 
user can easily exploit all knowledge generated.  
x Propose different views of knowledge discovered 
according to the user's needs. 
x The knowledge discovered contains no redundant rule. 
 
Also, we prove that this solution reduced considerably 
the number of generated rules, offered a better interpretation 
of the data and optimized both the space memory and the 
execution time. This approach is extensible; the user is able 
to choose the fuzzy method of classification according to the 
domain of his data and his needs.  
The rest of the paper is organized as follows: Section 2 
presents the basic concepts of discovering association rules, 
Fuzzy conceptual scaling and Formal Concept Analysis 
(FCA). Section 3 presents problems and limits of the existing 
knowledge discovery approaches. Section 4 gives notations 
related to our new approach that we proposed. Section 5 
describes our KDD model. Section 6 presents how the user 
can easily exploit knowledge generated by our approach. 
Section 7 enumerates the advantages of the proposed 
approach. Section 8 validates the proposed approach. We 
finish this paper with a conclusion and a presentation of 
some future works.  
II. BASIC CONCEPTS 
In this section, we present the basic concepts of 
discovering association rules, Fuzzy conceptual scaling and 
FCA. 
A.  Discovering Association Rules  
Association rules mining have been developed in order to 
analyze basket data in a marketing environment. Input data 
are composed of transactions: each transaction consists of 
items purchased by a consumer during a single visit. Output 
data is composed of rules [5]. Even if this method was 
introduced in the context of Market Business Analysis, it has 
many applications in other fields, like webmining or 
textmining. It can also be used to search for frequent co-
occurrences in every large data set.  
2010 Second International Conference on Advances in Databases, Knowledge, and Data Applications
978-0-7695-3981-2/10 $26.00 © 2010 IEEE
DOI 10.1109/DBKDA.2010.36
126
The first efficient algorithm to mine association rules is 
APriori [6]. The first step of this algorithm is the research of 
frequent itemsets. The user gives a minimum threshold for 
the support and the algorithm searches all itemsets that 
appear with a support greater than this threshold. The second 
step is to build rules from the itemsets found in the first step. 
The algorithm computes confidence of each rule and keeps 
only those where confidence is greater than a threshold 
defined by the user. One of the main problems is to define 
support and confidence thresholds. Other algorithms were 
proposed to improve computational efficiency. Among them, 
we mention CLOSED [7], CHARM [8], TITANIC [9, 10], 
GENALL [11] and PRINCE [12].  
Several varieties of lattice have been introduced with 
these algorithms,  like  Iceberg Concept lattices  [10],  where 
the nodes are frequent closed itemsets  ordered by the 
inclusion relation, Minimal Generators Lattice [12], where 
the nodes are the minimal Generators (called  key itemsets) 
are ordered by the inclusion relation. In these cases, we don't 
construct the FCA on the data but on the found itemsets. For 
more detail the reader can see [12].  
B. Fuzzy conceptual scaling and FCA 
Conceptual scaling theory is the central part in Formal 
Concept Analysis (FCA). It allows introduce for the 
embedding of the given data much more general scales than 
the usual chains and direct products of chains. In the direct 
products of the concept lattices of these scales the given data 
can be embedded [13]. 
FCA starts with the notion of a formal context specifying 
which objects have what attributes and thus a formal context 
may be viewed as a binary relation between the object set 
and the attribute set with the values 0 and 1. Wille’s 
definition of a concept is a pair consisting of a set of objects 
(the extension) and a set of attributes (the intension) such 
that the intension consists of exactly those attributes that the 
objects in the extension have in common, and the extension 
contains exactly those objects that share all attributes in the 
intension [13]. In [14], an ordered lattice extension theory 
has been proposed: Fuzzy Formal Concept Analysis (FFCA), 
in which uncertainty information is directly represented by a 
real number of membership value in the range of [0,1]. In 
this case, the similarity of a fuzzy formal concept is defined 
as follow: 
Definition. The similarity of a fuzzy formal concept   111 ,BAC M  and its subconcept   222 , BAC M  is defined 
as: 
        21
21
21 , AA
AA
CCS MM
MM
?
? 
 
where ? and ? refer intersection and union operators on 
fuzzy sets [15], respectively. 
In [16, 17, 18, 19], we showed as these FFCA are very 
powerful as well in the interpretation of the results of the 
Fuzzy Clustering, in Optimization of the flexible query that 
in the definition of a summary of a Database.  
Example: Let a relational database table presented by 
Table1 containing the list of AGE and SALARY of 
Employee. 
TABLE I.  A RELATIONAL DATABASE TABLE. 
 SALARY AGE 
t1 800 30 
t2 600 35 
t3 400 26 
t4 900 40 
t5 1000 27 
t6 500 30 
 
Table 2 presents the results of fuzzy clustering (using 
Fuzzy C-Means [20]) applied to Age and Salary attributes. 
For Salary attribute, fuzzy clustering generates three clusters 
(C1,C2 and C3). For AGE attribute, two clusters have been 
generated (C4 and C5).   In our example, CutD (Salary) = 
0.3 and CutD (Age) = 0.5,  so, the Table 2 can be 
rewriting as show in Table 3.  
TABLE II.  FUZZY CONCEPTUAL SCALES FOR AGE AND SALARY 
ATTRIBUTES  
 SALARY AGE 
 C1 C2 C3 C4 C5 
t1 0.1 0.5 0.4 0.5 0.5 
t2 0.3 0.6 0.1 0.4 0.6 
t3 0.7 0.2 0.1 0.7 0.3 
t4 0.1 0.4 0.5 0.2 0.8 
t5 - 0.5 0.5 0.6 0.4 
t6 0.5 0.5 - 0.5 0.5 
TABLE III.  FUZZY CONCEPTUAL SCALES FOR AGE AND SALARY 
ATTRIBUTES WITH CutD .  
 SALARY AGE 
 C1  C2 C3   C4 C5 
t1 - 0.5 0.4 0.5 0.5 
t2 0.3 0.6 - - 0.6 
t3 0.7 - - 0.7 - 
t4 - 0.4 0.5 - 0.8 
t5 - 0.5 0.5 0.6 - 
t6 0.5 0.5 - 0.5 0.5 
 
The corresponding fuzzy concept lattices of fuzzy 
context presented in Table 3, noted as TAH’s are given by 
the linediagrams presented in the Figure 1 and 2. 
 
 
 
 
 
 
 
 
Figure 1.  Salary TAH 
127
 
Figure 2.  Age TAH 
III. PROBLEMS AND MOTIVATION 
The traditional algorithms try to trace the decision tree or 
the FCA or one of these extensions to extract the association 
rules.  In this case, researchers always focus on giving an 
optimum set of rules modeling in a faithful way the starting 
data unit, after having done a data cleansing step and an 
elimination of invalid-value elements. To our point of view, 
limits of these approaches consist in extracting the set of 
rules departing from the data or a data variety like the 
frequent itemsets or the frequent closed itemsets, which may 
be huge. Thus we note the following limits:  
x These approaches require a big space memory for data 
modeling and an important execution time for the 
management of their data structures;  
x The rules generated from these data are generally 
redundant rules;  
x These algorithms generated a very big number of rules, 
almost thousands, that the human brain cannot even 
assimilate;  
x Some previous works demonstrated that the behavior of 
these algorithms of association rules extraction varies 
strongly according to the features of the used data set 
[21]. The number of the generated association rules in 
general varies from several ten of thousands to several 
millions [3, 22].  The Execution times obtained strongly 
vary according to the used algorithm [23];  
x Generated rules by these algorithms don't take into 
account the data semantics nor the importance of an 
attribute in relation to another in the data description, 
according to the specific domain of this data set; and  
x Generally the goal to extract a set of rules is to help the 
user to give semantics of data and to optimize the 
information research. This fundamental constraint is not 
taken into account by these approaches.    
 
To cure all these problems, we propose a new approach 
for knowledge extraction using conceptual clustering, fuzzy 
logic, and FCA. 
IV. NOTATIONS RELATED TO OUR KDD MODEL 
In this section, we present some news concepts for our new 
approach. 
Definition. A fuzzy Clusters Lattice (FCL) of a Fuzzy 
Concept Lattice, is consist on a Fuzzy Concept Lattice such 
as each equivalence class (i.e. a node of the lattice) contains 
only the intentional description (intent) of the associated 
fuzzy formal concept. We make in this case a certain 
abstraction on the list of the objects with their degrees of 
membership in the clusters. The nodes of FCL are clusters 
ordered by the inclusion relation. 
Definition A level i of a FCL is the set of nodes of FCL 
having cardinality equal to i.  
 
Definition A Knowledge level is an abstraction level is 
regarded as a level in the FCL generated. 
 
Definition. Let I= {C1, C2, …, Cp, Cq , …, Cn} n Clusters 
generated by a classification algorithm. 
A fuzzy association meta-rule (called meta-rule) is an 
implication of the form      
R: I1  => I2 (CF)   
where  I1 = { C1, C2, …, Cp } and 
 I2={ Cq , …, Cn }. I1 and I2 are called, respectively, the 
premise part and conclusion part of the meta-rule R. The 
value CF is in ]0..1] and called Confidence Factor of this 
meta-rule. This value indicates the relative degree of 
importance of this meta-rule.  
 
R is interpreted as follows:  if an object belongs to a 
cluster C1? C2?…? Cp then this object can also belongs to 
the cluster Cq?…? Cn with a probability equal to CF.   
 
Note that classical (or crisp) association meta-rules can 
be defined as a special case of fuzzy association meta-rules. 
Indeed, when CF=1, then a fuzzy association meta-rule is 
equivalent to a classical one. 
 
Example. Let R: C1 => C2  (60%). This means that any 
object belongs to a cluster C1 can also belongs to the cluster 
C2 with a probability equal to 60%. 
 
Definition. Let A1,A2...,Ap,Aq,…An; n attributes having 
respectively {l11,l12...,l1m },{l21,l22... ,l2m}..., 
{lp1 ,lp2..., lpm },{lq1,lq2...,lqm}…., ,{ln1,ln2...,lnm} as 
linguistic labels.  
A fuzzy association rule (or rule) is an implication of the 
form               r: I1  => I2,   (CF);  
where I1 = { A1(l1), A2(l2), …, Ap(lp) } and   
I2= { Aq(lq), …, An(ln) }.  
Ai(li) models the attribute Ai having a linguistic label li. I1 
and I2 are called, respectively, the premise part and 
conclusion part of the fuzzy rule r. The value CF is in ]0..1] 
and called Confidence Factor of this rule.  
 
Definition. We define Meta Knowledge (respectively. 
Knowledge), as a set of fuzzy association meta-rule 
(respectively. rule).  
We define the level i of Meta Knowledge (respectively.. 
knowledge) as the set of fuzzy association meta-rule 
(respectively. rule) on all objects verifying i properties. 
 
Proposition 1: Rewriting meta- rule  
Let C1= {A1, A2, …, An} and C2={B1 , …, Bm} two set 
of Clusters. The fuzzy association meta-rule   
128
R : A1,..,An => B1,..,Bm    (CF)  is equivalent to  
R1 defined as follow:  
R1: A1,..,An => C1,..,Cq    (CF)    such that   
{C1,…,Cq} = C2\C1   ( Ci, Ci ? {A1,…An}) 
 
Proposition 2: Rule Generation  
Given C1={A1.., An},  C2={B1.., Bn} and 
 C3={D1.., Dn} three set of Clusters and R1,R2 two meta 
rule defined as follows:    R 1: A1,..,An => B1,..,Bn   (d1);  
 and   R 2: B1,..,Bn => D1,..,Dn    (d2) 
Then, we deduce the meta rule defined as follows:   
R 3: A1,..,An => D1,..,Dn      (d3);  such that d3= d2(d1) = d2*d1 
 
Example.  From the two meta-rule R1 and R2 defined as  
R1 : C2 => C2,C4    60% and  R2 : C2,C4 =>C2, C3, C4  53% . 
We can deduce  
R3: C2 =>C2, C3,C4   31%. R3 can rewriting as:  
      R3:         C2 => C3,C4                  31%.  
This rule is interpreted as follows: 53% of 60% of the 
objects which belong to C2 obtained by the rule R1, can also 
belongs to the cluster C3 and C4 with a probability equal to 
31%. 
V. KDD MODEL DESCRIPTION  
In this section, we present the architecture of the KDD 
model and the process for discovering knowledge.  
A. System Architecture 
Our KDD model takes the database records and provides 
the set of knowledge correspondent. Figure 3 shows the 
proposed approach. It consists of two steps: the first step 
consists in data organization and the second aims at 
Extraction of Knowledge.  
 
 
Figure 3.  KDD Model 
B. Theoretical Foundation of the KDD model  
In this part, we present the theoretical foundations of the 
proposed approach, based on the following properties:  
Properties 1 
x The number of clusters generated by a classification 
algorithm  is always  lower  than the number of starting 
objects to which one applies the classification algorithm   
x All objects belonging to one same cluster have the same 
proprieties. These characteristics can be deduced easily 
knowing the center and the distance from the cluster.  
x The size of the lattice modeling the properties of the 
clusters is lower than the size of the lattice modeling the 
properties of the objects.   
x The management of the lattice modeling the properties 
of the clusters is optimum than the management of the 
lattice modeling the properties of the objects.   
 
Properties 2 
Let C1, C2 be two clusters, generated by a classification 
algorithm and verifying the properties p1 and p2 
respectively. Then the following properties are equivalent:  
         C1 ? C2  (CR)   ? 
x    object O1 ? C1 =>  O1 ?C2 (CR) 
x   object O1 ? C1,  O1 checks the property p1 of  
    C1 and the property p2 of C2.  (CR) 
 
Properties 3 
Let C1, C2 and C3 be three clusters generated by a 
classification algorithm and verifying the properties p1, p2 
and p3 respectively. Then the following properties are 
equivalent:       C1, C2 = > C3  (CR) 
                                 ? 
x  object O1 ? C1 ?  C2 = > O1 object ?C3 (CR) 
x  object O1? C1 ?  C2 then O1 checks the properties 
p1, p2 and p3 with (CR) 
 
The proof of the two properties rises owing to the fact 
that all objects which belong to a same cluster check 
necessarily the same property as their cluster.   
C. Data Organization Step 
This step gives a certain number of clusters for each 
attribute. Each tuple has values in the interval [0,1] 
representing these membership degrees according the formed 
clusters. Linguistic labels, which are fuzzy partitions, will be 
attributed on attribute’s domain. This step consists of TAH’s 
and MTAH generation of relieving attributes. This phase is 
very important in KDD Process because it allows to define 
and interpreter the distribution of objects in the various 
clusters. We already used this step in [16, 17, 18, 19].  
Example: Let a relational database table presented by 
Table 1 containing the list of AGE and SALARY of 
Employee. Table 2 presents the results of fuzzy clustering 
applied to Age and Salary attributes.   
The minimal value (respectively. maximal) of each 
cluster corresponds on the lower (respectively. higher) 
interval terminal of the values of this last. Each cluster of a 
129
partition is labeled with a linguistic labels provided by the 
user or a domain expert. For example, the fuzzy labels young 
and adult could belong to a partition built over the domain of 
the attribute AGE. Also, the fuzzy labels low, Medium and 
High, could belong to a partition built over the domain of the 
attribute Salary. The Table 4 presents the correspondence of 
the linguistic labels and their designations for the attributes 
Salary and Age. The corresponding fuzzy concept lattices of 
fuzzy context presented in Table 5, noted as TAH’s are given 
by the line diagrams presented in Figure 1 and 2. 
TABLE IV.  CORRESPONDENCE OF THE LINGUISTIC LABELS AND THEIR 
DESIGNATIONS  
Attribute Linguistic labels Designation 
Salary Low C1 
Salary Medium C2 
Salary High C3 
Age Young C4 
Age Adult C5 
TABLE V.  FUZZY CONCEPTUAL SCALES FOR AGE AND SALARY 
ATTRIBUTES WITH CutD .  
 SALARY AGE 
 Low  C1 
Medium 
     C2 
High 
C3 
Young 
   C4 
Adult 
 C5 
t1 - 0.5 0.4 0.5 0.5 
t2 0.3 0.6 - - 0.6 
t3 0.7 - - 0.7 - 
t4 - 0.4 0.5 - 0.8 
t5 - 0.5 0.5 0.6 - 
t6 0.5 0.5 - 0.5 0.5 
 
This very simple sorting procedure gives us for each 
many-valued attribute the distribution of the objects in the 
line diagram of the chosen fuzzy scale.  Usually, we are 
interested in the interaction between two or more fuzzy 
many-valued attributes. This interaction can be visualized 
using the so-called fuzzy nested line diagrams.  It is used for 
visualizing larger fuzzy concept lattices, and combining 
fuzzy conceptual scales on-line. Figure 4 shows the fuzzy 
nested lattice constructed from Figure 1 and 2. 
 
 
Figure 4.  Fuzzy Lattice:  MTAH  
D. Phase of Discovering Knowledge 
This step consists on three phases: FCL Generation,   
Discovering Meta knowledge and Deduction Knowledge. In 
the following, we detail these different steps.  
1)  FCL Generation  
The goal of this phase is make a certain abstraction on 
the list of the objects with their degrees of membership in the 
clusters. Indeed, to determine the set of fuzzy meta-rule we 
don't need more to safeguard the data since we already 
safeguarded the distance between these nodes.  Thus, from 
the fuzzy lattice, obtained in the first step, we can draw the 
correspondent FCL. The nodes of FCL are clusters ordered 
by the inclusion relation. As shown from the Figure 5, we 
obtain a lattice more reduced, simpler to traverse and stored.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5.  Fuzzy Clusters Lattice  FCL 
Considering the FCL in Figure 5, we can generate the 
following levels with the corresponding FCL. The Level 0 
and Level 6 are both the root and leaves of FCL. The Level 1 
corresponds to the nodes {C1}, {C5},{C2}, {C4}. It allows 
the identification of the clusters which permits to deduce 
knowledge. The Level 2 corresponds to nodes {C2, 
C5},{C2, C4},{C2, C3},{C1, C4}. This level permits to 
identify all the existing overlapping between two clusters. 
Thus, it allows the knowledge discovery of all objects 
belonging to the intersection of the two clusters. Generally 
Level i corresponds to the nodes having i clusters. This 
permits to identify all the existing of overlapping between i 
clusters. It allows the knowledge discovery on all objects 
belonging to the intersection of these i clusters. Note that the 
nodes of Level 4 has all the departing arcs with weight d=0; 
i.e. since there is no object belonging to the intersection of 
this clusters. Consequently, there is no knowledge to 
discover. Also, note that the Level 5 corresponds to the 
leaves of FCL, therefore, there is no knowledge to discover.   
  
2) Discovering Meta knowledge 
In this subsection, we present our algorithm for 
discovering Meta Knowledge from a FCL.  
Given an FCL, the derivation of fuzzy association meta-
rules can be performed straightforwardly. Indeed, the meta-
rule represent “inter-node” implications, assorted with the 
FC, between two adjacent comparable equivalence classes, 
130
i.e., from a set of clusters to another set of clusters 
immediately covering it. The confidence Factor will be equal 
to the weight of the arc binding the two nodes.  Such an 
implication brings into participate two comparable 
equivalence classes, i.e. of a set of clusters towards another 
set of cluster including it in the partial order structure.  
a) Principle for discovering knowledge from FCL  
Rule1: Discovering meta rule  
Let C1={A1.., An} and C2={B1.., Bm} two nodes of 
FCL such as C2 is successors of C1 in the lattice and having 
as distance d>0 (weight of the arc) the generated meta-rule 
will be defined as follows: R : A1,..,An => B1,..,Bm      (d) 
 
Note that, If d=0 this implies that there is no object in 
common to the two concepts C1, C2. There is no knowledge 
to discover. This implies that it doesn't exist no knowledge 
to generated. 
 
Example The meta-rule C5 ? C2,C5 (0,83), is generated 
starting from the two equivalence classes, whose their 
respective nodes are Clusters {C5}, {C2,C5} having as 
distance d=0.83. 
 
Rule2: Discovering meta rule 
Let C1={A1.., An} and C2={B1.., Bm} two nodes of 
FCL such as C2 is successors of C1 in the lattice and having 
as distance d>0 (weight of the arc). The generated meta-rule 
will be defined by  
R : A1,..,An => C1,..,Cq      (d) such that  {C1,…,Cq} = 
{B1.., Bm}\{A1.., An}    ( Ci, Ci ? {A1,…An}) 
Example The meta-rule C5 ? C2 (0,83), is generated 
starting from the two equivalence classes, whose their 
respective nodes are Clusters {C5}, {C2,C5} having as 
distance d=0.83.  
 
Rule3: Generated meta-rule 
Let C1={A1.., An} C2={B1.., Bn} and C3={D1.., Dn} 
three concepts such as C2 successors of C1 and C2 successor 
of C3 having as respectively distance d1 and d2.  
The generated meta-rule will be defined by: 
R 3: A1,..,An => D1,..,Dn      (d2*d1) 
 
Example 
The meta-rule C2 =>C2, C3,C4       31% is generated starting 
from the three equivalence classes, whose their respective 
nodes are Clusters {C2} {C2,C4}and {C2, C3, C4 } having 
as distance 0.60 and =0.53. 
This rule can be simplified as follows C2 = > C3, C4 31% . 
This is interpreted as follows:  31% of the objects which 
belong to C2 check the properties modeled by the clusters 
C3 and C4  
b) Algorithm for Discovering Fuzzy Association Meta-
rules 
This algorithm traverses the search space (FCL) by level 
to determine the Fuzzy Meta Rules Set (FMRS). As input it 
takes the lattice of Clusters FCL and  returns, as output, the 
list of all Fuzzy Meta Rules Set (FMRS) generated. It works 
as follows: For each non empty node ? ?FCL in descending, 
we generate all meta-rules with one cluster conclusion (level 
0). Then, generate the set of all meta-rules with two Clusters 
conclusions. The same process is applied to generate 
conclusions with four clusters, and so on until conclusions 
with n clusters have been generated. The pseudo-code for 
this algorithm is given in the Figure 6.  
Note that Niveau_max (FCL) is a function return the 
number of clusters modeled in the FCL.  
Figure 6.  The pseudo-code for Diskovering FMRS algorithm 
Find_Cluster (FCL, i, S) is a procedure allow to  
compute the set S containing all set of clusters modelled in 
the nodes to level i. 
Generate_Rule(FMRS,FMRS1) is a  procedure permits to 
determine the set of all rules which one can deduce with part 
of the FMRS set  by applying the Rule3. 
Let's note that the FMRS set doesn't contain any 
redundant rule. Indeed one has the following proposition:   
 
Proposition 3 
If the system of extraction rules traverses the search 
space  by level of the lattice of clusters then no rule 
generated by this system is redundant (all the generated rules 
are obligatorily distinct).   
Proof. This is due that of a level to another of the lattice the 
nodes are obligatorily distinct (by definition even of a level 
of lattice).   
3) Deduction Knowledge 
In this part, we present, in the first, the rule of 
Transformation of a fuzzy association meta-rule into fuzzy 
association rule  
Generating Meta-knowledge 
Input: Fuzzy Cluster Lattice FCL 
Output : FMRS: Fuzzy Meta Rules Set 
Begin 
FMRS :=? 
Find_Cluster(FCL, 0, S) ;  
 For  each  subconcept Cj ={y1,…ym}of Ci in S  
     r.premise=  ? 
     r.conclusion={y1,y2,…ym}  
      r.CF=1 
      FMRS=FMRS ? {r}  
 End For 
Nmax :=Niveau_max(FCL) ;  
For Niv  :=1  to Nmax-1 do 
   Find_Cluster(FCL, i, S) ;  
For  Ci={x1,…xm}  in  S   do 
For each  subconcept Cj ={y1,…ym}of Ci 
                  and having (d>0)  
          r.premise=  {x1,x2,…xn} 
                r.conclusion={y1,y2,…ym} \ {x1,x2,…xn} 
                r.CF=d 
                FMRS=FMRS ? {r}  
             End For 
    End For 
End For 
Generate_Rule(FMRS,FMRS1); 
FMRS:= FMRS ? FMRS1 
End. 
131
Rule: Transformation of a fuzzy association meta-rule 
into fuzzy association rule  
Let A1,A2...,Ap,Aq,…An be n attributes having 
respectively {l11,l12...,l1m} {l21,l22...,l2m} ... ,  
{lp1   ,lp2... ,lpm},{lq1,lq2...,lqm}…., ,{ln1,ln2...,lnm} as 
linguistic labels.  
Let I= {C1, C2, …, Cp, Cq , …, Cn} be a n Clusters 
generated by a classification algorithm. Each Ci designates 
linguistic labels for a given attribute.  
The fuzzy association meta-rule R: C1,..,Cp => Cq , …, Cn  
(CF)  is transformed in   R1 defined as follow:  
 R1: A1(l1), A2(l2), …, Ap(lp) =>  Aq(lq), …, An(ln) (CF) 
such that  Ai(i) is the linguistic label for attribute Ai  design 
the cluster Ci.  
Example. Let us consider Table 4 presents the 
correspondence of the linguistic labels and their designations 
for the attributes Salary and Age. 
The meta-rule C5 => C2  83% is transformed in          
Age(Adult) => Salary(Medium)    83% 
VI. HOW THE USER CAN EXPLOIT KNOWLEDGE 
GENERATED BY THIS APPROACH ? 
As we mentioned at the beginning,  the essential goal of 
the extraction of knowledge is to help the user to seek 
information in this data set and to satisfy his needs. In this 
section we propose different views of knowledge generated. 
According to the user's needs the generated rules can be 
ordered in several ways.  
Indeed,  while changing our point of entrance view, it is 
possible to have a different view point on data. So we can 
model our knowledge with three different views.   
x To order the list of rules by level of Knowledge 
(every level i of knowledge fact to intervene i 
properties).  
x To order the list of the rules by the characteristics 
which an object must check so that it can verified a 
certain properties.  
x To order the list of rules by properties that can have 
an object knowing that it verifies a p property.  
 
Moreover, this approach makes it possible to the user to 
define Da cut on the rules generated by the system to specify 
until which coefficient CF, it gives confidence to a rule. 
Beyond this value Dthe rule can be considered as weak 
and will not be taken into account.  
Examples 
1) The user wants to know all the objects checking 
two properties.  For this, we seek the rules describe in 
level2; so we find, as example, the following rules:    
Salary(Low) => Age(Young)     80%   
      2) The user wants to know, what are properties that 
must have an employee, so that he will have a medium 
salary? For this, we seeks the rules having like conclusion 
Salary(medium); so we find the two following rules:    
Age(young)  =>  Salary(Medium)    65% 
Age(Adult)  =>  Salary(Medium)              83% 
This we can interpret it as follows: to have a medium salary 
the person must be young (65%) or adult (83%) 
3) The user wants to know that are properties which 
an employee can check, if he has a low salary.    For this, 
we seeks the rules having like premise Salary(low); so we 
find the two following rules:    
     Salary(Low) => Age(Young) 80%   
     Salary(Low) => Salary(Medium), Age(Adult) 53%   
This we can interpret it as follows:  having the low salary 
two cases is possible: 
- Either this person is young   80% , or 
- Either this person is adult and has medium salary 53%: 
this means that his salary in the superior part of the interval 
modelled low Salary.  
Remark. The fact of having in the same rule Salary(Low) 
and Salary(Medium), is not contradictory but this means that 
the person has low Salary which are in the overlapping in the 
part medium Salary. This implies that his Salary is 
necessarily in the highest zone of the low Salary and in the 
lowest zone of medium Salary.  
VII. ADVANTAGES OF THE NEW APPROACH  
Different advantages are granted by the proposed 
approach: 
1)  The definition of the Meta knowledge concept: 
This definition is very important, since the number of rules 
generated is smaller: we define the set of meta-rules between 
the clusters and we can generate automatically the 
association rules between the data, if we want more details. 
Also, this concept permits to have a global view on the data 
set which is very voluminous. Thus, it models a certain 
abstraction of the data that is fundamental in the case of an 
enormous number of data.  
2) The definition of the level of knowledge concept: 
This approach enables us to hide and to exhibit the details 
encapsulated while moving between the different levels of 
the hierarchy during the discovery of knowledge. Thus, 
according to the degree of detail required by the user, we can 
propose a level of knowledge (more general level 1 towards 
most specific level N).  
3) Extensibility of the proposed approach: 1) Our 
approach can be applied with any fuzzy classification 
algorithm to classify the initial data. 2) We can generate the 
maximum of knowledge on our initial data set; it’s enough to 
modify the choice of the classification criteria. These criteria 
can be chosen by the user like parameters of entry according 
to the importance of the attribute in its applicability. 3) We 
can classify our data according to different criteria and 
obtain different clusters which generate a different set of 
Meta knowledge 
VIII. VALIDATION OF THE PROPOSED APPROACH  
To validate the approach proposed, we chose:  1) The 
FCM (Fuzzy C-Means) algorithm for a fuzzy classification 
of the data set, and 2) The Ganter algorithm [24] for the 
construction of the lattice. We currently develop this 
approach with JAVA language.  
About complexity: 1) The space complexity, whatever the 
number of database records, is thus reduced to a constant 
value, i.e., about  1O . This characteristic is fundamental in 
132
the treatment of the large database in knowledge discovery. 
2) The temporal complexity includes the following costs:  
- Construction of the attribute’s clusters. 
- Building the fuzzy lattice. 
For cluster’s construction, the complexity of fuzzy 
clustering algorithms is about  2NCO , where N  corresponds 
to database table records number and C  is the maximum 
number of clusters. For fuzzy lattice construction, temporal 
complexity of lattice construction algorithm is about  2NO  . 
IX. COMPARISON WITH OTHER APPROACHES. 
The approach that we propose in this paper offers a set of 
knowledge. The number of rules is really defined by the end-
user. Indeed, in the first step of our approach, the user must 
specify the number of clusters to generate by FCM algorithm 
to classify his data.  
Example  
In our case, the user specified a number = 3 for the 
attribute Salary and a number = 2 for the attribute Age. 
Consequently we obtain 5 clusters.  
 
In our approach, each cluster corresponds to a predicate. 
The lattice constructs, will be a lattice with N levels, N is 
equal to the number of clusters. By definition of the lattice, 
level 0 and level N contain 1 only node. The Level i contains 
a number of node equal to the number of overlapping 
between i clusters. This number will be equal to the 
maximum to  C
i
N  
The rules are generated by level: of the level i at the level 
i+1. A rule is defined of a node of level i towards a node of 
level i+1. The maximum number of rules which can be 
generated is, in consequence, equal to C
i
N   * C
i
N
1
 
 
We have N levels in the lattice = >    
The maximum Number of rules = 
¦ 
 
1
0
Ni
i (C
i
N  * C
i
N
1
) 
 
Example  
In our case N=5   
Let us calculate the maximum number of nodes for each 
level:  
The level 0 contains 1 node. The level N contains 1 node.  
C05  =  1 (level 0) 
C15  =  5  (level 1) 
C25  = 10 (level 2) 
C35  = 10 (level  3) 
C45 =    5 (level 4) 
C55  =   1 (level 5) 
 
 
 
Let us calculate the maximum number of rules which can be 
generated:  
level 0 -> level 1 :   1*5 =    5 rules   (maximum) 
level 1 -> level 2 :   5*10 = 50 rules  (maximum) 
level 2 -> level 3 : 10*10 =100 rules  (maximum) 
level 3 -> level 4 : 10* 5 =    50 rules (maximum) 
In conclusion, we will have to the maximum 205 rules.  
 
As we show, what is important is that in our approach, 
this number of generated rules, is independent of the size of 
the data. It rather depends on the number of generated 
clusters by the phase of classification. This number of 
clusters is given in entry by the user and it is the user who 
defines the linguistic labels for his clusters.  
Let's note that another solution can be possible, is to use an 
algorithm of classification that didn't have like entry the 
number of clusters generated: in this case, the algorithm 
proposes the best classification for the set of data and the 
user specifies the linguistic labels for every class.    
  The comparison with the existing approaches can be 
made another level, indeed the algorithms proposed don’t 
take into account any semantics of the data, and to our 
knowledge these approaches don't treat the problem of 
knowledge utilization. All the researchers focused 
themselves on the reduction of the set of rules of a variety of 
hundreds of rules, by proposing the concept of metadata, or 
on the method of visualization of this great number of rules.  
Our principle in this approach is to propose an extraction 
of knowledge based on the ties semantics of the data which 
is in our opinion more interesting, that the one existing 
which bases on the form (syntax) objects.   
To our opinion, it is not a question to compare the results, 
according to the number of generated rules which is 
distinctly lower in our case, obtained in the other 
approaches and those obtained in our approach. Rather it is 
necessary to see the degree of utilisability of generated 
knowledge. Indeed what it is the interest to propose several 
approaches of knowledge extractions, whereas the user 
cannot benefit to better exploit these gigantic data?    
In this approach we proposed different views according 
to which the user can exploit his data. In addition the fact to 
allow the user to choose attributes to classify and the 
numbers of generated clusters allows the user according to 
his needs to fix these choices. Indeed, the user can (1) apply 
any classification algorithm, and (2) generate the maximum 
of knowledge on its initial data set:  it’s enough to modify 
the choice of the classification criteria. These criteria can be 
chosen by the user like parameters of entry according to the 
importance of the attribute in its applicability.  
X. CONCLUSION 
In this paper, we presented a new approach that permits 
to extract knowledge combining classification and FCA 
methods. Generally, the researchers in this field use FCA 
based on Lattice theory or classification. All these methods 
generate a big number of association rules that are not easily 
assimilated by the human brain.  
133
To resolve this problem, we proposed a new KDD 
model. It consists of two steps: the first organizes the 
database records in homogeneous clusters having common 
properties which permit to deduce the data’s semantic. This 
step consists of TAH’s and MTAH generation of relieving 
attributes. The second permits to Discovering Knowledge. It 
consists to deduce the Fuzzy  Cluster Lattice corresponding 
to MTAH lattice generated in the first step, then traverse this 
lattice to extract the Meta Knowledge ( Set of fuzzy 
associations meta-rules on the clusters ), and in end deduce 
the rules modeling the Knowledge (Set of fuzzy associations 
rules on the attributes). While basing on the hierarchical 
structure offered by the lattices, we proceed to discover the 
Knowledge in a hierarchical way. Thus, according to the 
degree of detail required by the user, this approach proposes 
a level of knowledge and different views of this knowledge.  
Moreover, this solution is extensible; the user is able to 
choose the fuzzy method of classification according to the 
domain of his data and his needs.  
This solution reduced considerably the number of 
generated rules, offered a better interpretation of the data and 
optimized both the space memory and the execution time.  
As futures perspectives of this work, we mention 1) to 
test our approach on several the large data set, and 2) to 
define a new intelligent method of evaluation of requests 
which takes into account the Meta knowledge and/or the 
knowledge base generated by our KDD model. 
XI. REFERENCES 
[1] P. Berkhin, “Survey of clustering data mining techniques“, Technical 
report, Accrue Software, 2002. 
[2] M. Zaki, “Mining Non-Redundant Association Rules”, Data Mining 
and Knowledge Discovery, No 9, 2004, p. 223–248. 
[3] G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal, 
“Intelligent structuring and reducing of association rules with formal 
concept analysis”, Proceedings of KI’2001 Conference, Vienna, 
Austria, Lecture Notes in Artificial Intelligence 2174, Springer-
Verlag, September 2001, p. 335–350. 
[4] N. Pasquier “Data Mining : Algorithmes d'Extraction et de Réduction 
des Règles d'Association dans les Bases de Données”, Thèse, 
Département d’Informatique et Statistique, Faculté des Sciences 
Economiques et de Gestion, Lyon, 2000.  
[5] R. Agrawal, T. Imielinski, and Swami A., “Mining Association Rules 
between sets of items in large Databases”, Proceedings of the ACM 
SIGMOD Intl. Conference on Management of Data, Washington, 
USA, June 1993, p. 207-216. 
[6] R. Agrawal, and R. Skirant. “Fast algoritms for mining association 
rules”. In Proceedings of the 20th Int'l Conference on Very Large 
Databases, pages 478-499, June 1994. 
[7] N. Pasquier, Y. Bastide, R.Taouil, and L. Lakhal,          “ Efficient 
Mining of Association Rules Using Closed Itemset Lattices”, 
Information Systems Journal, vol. 24, no 1, 1999, p. 25-46. 
[8] M. J. Zaki, and C. J. Hsiao, “ CHARM : An Efficient Algorithm for 
Closed Itemset Mining ”, Proceedings of the 2nd SIAM International 
Conference on Data Mining, Arlington, April 2002, p. 34-43. 
[9] G. Stumme, R. Taouil, Bastide Y., Pasquier N., and L. Lakhal, “Fast 
Computation of Concept Lattices Using Data Mining Techniques”, 
BOUZEGHOUB M., KLUSCH M., NUTT W., SATTLER U., Eds., 
Proceedings of 7th Intl. Workshop on Knowledge Representation 
Meets Databases (KRDB’00), Berlin, Germany, 2000, p. 129-139. 
[10] G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal, “ 
Computing Iceberg Concept Lattices with TITANIC”, J. on 
Knowledge and Data Engineering (KDE), vol. 2, no 42, 2002, p. 189-
222. 
[11] S. Ben Tekaya, S. Ben Yahia, and Y. Slimani. “Algorithme de 
construction d`un treillis des concepts formels et de détermination des 
générateurs minimaux”, ARIMA journal, Novembre 2005, Numéro 
spécial CARI'04, pages: 171-193, 2005. 
[12] T. Hamrouni, S. Ben Yahia, and Y. Slimani. “Prince : Extraction 
optimisée des bases génériques  de règles sans calcul de fermetures”. 
In Proceedings of the Intl. INFORSID Conference, Editions Inforsid, 
Grenoble, France, pages : 353--368, 24-27 May 2005  
[13] B. Ganter, and R. Wille, Formal Concept Analysis: mathematical 
foundations. (translated from the German by Cornelia Franzke) 
Springer-Verlag, Berlin-Hei delberg 1999. 
[14]  T.Thanh, H.Siu Cheung, and C. Tru Hoang, “A Fuzzy FCA-based 
Approach to Conceptual Clustering for Automatic Generation of 
Concept Hierarchy on Uncertainty Data.” ,CLA 2004, pp. 1–12, 
ISBN 80-248-0597-9. 
[15]  L. Zadeh. Fuzzy sets. Information and Control, (69):338-353, June 
1965 
[16]  M. Sassi, M., A. Grissa Touzi, and H. Ounelli, “ “Interpretting Fuzzy 
Clustering Results based on Fuzzy Formal Concept Analyis”, IEEE 
International Conference on Fuzzy Systems. Imperial College, 
London, UK, 2007. 
[17]  A. Grissa Touzi, M. Sassi, and H. Ounelli,  “Using Formal Concept 
Analysis for Flexible Querying Optimization”, 23nd International 
Conference on Computers and Their  Applications, (CATA’08), 
Mexico, Avril 2008 
[18]  A. Grissa Touzi, M. Sassi, and H. Ounelli, “An innovative 
contribution to flexible query through the fusion of conceptual 
clustering, fuzzy logic, and formal concept analysis”, International 
Journal of Computers and Their Applications. Volume. 16, N°. 4, pp 
220-233, December, 2009.    
[19] M. Sassi, A. Grissa Touzi, and H. Ounelli, “A Fuzzy Linguistic 
Database Summarization Approach”, Fuzzy Systems Conference, 
IEEE International Conference on Fuzzy Systems.   Hong Kong, Juin 
2008. 
[20] J.C,  Bezdeck,  R.Ehrlich,  and  W.Full,  "FCM: The Fuzzy  C-Means 
Clustering Algorithm", Computers and Geoscience, vol. 10, no. 2-3, 
pp. 191–203, 1984 
[21]  N. Pasquier, Y. Bastide, R.Touil, and L.Lakhal, “Pruning closed 
itemset lattices for association rules”, Proceedings of 14th 
International Conference Bases de Données Avancées, Hammamet, 
Tunisia, 26–30 October 1998, p. 177–196. 
[22] M. J. Zaki, “Generating Non-Redundant Association Rules”, 
Proceedings of the 6th ACM SIGKDD International Conference on 
Knowledge Discovery and Data Mining,Boston, MA, August 2000, p. 
34-43. 
[23]  Y. Bastide, R.Taouil, N. Pasquier, G. Stumme, and L.Lakhal, 
“Mining frequent patterns with counting inference”, SIGKDD 
Explorations, vol. 2, no 2, 2000, p. 66-75. 
[24]  B. Ganter, “Two basics algorithms in concept analysis”, Technical 
report, Darmstadt, 1984. 
134
