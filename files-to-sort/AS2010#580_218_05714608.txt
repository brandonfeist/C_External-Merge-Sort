 978-1-4244-9008-0/10/$26.00 ©2010 IEEE   54 
 
Extracting Spatial Semantics in Association Rules for 
Weather Forecasting Image  
 
Senduru Srinivasulu  
Research Scholar 
Department of Information Technology 
Sathyabama University 
Chennai-600 119, India. 
sendurusrinivas@gmail.com 
 
P.Sakthivel 
Department of Electronics and Communication Engg. 
Anna University 
Chennai-600 025, India. 
psv@annauniv.edu 
 
Abstract— Association rule mining is one of the most important 
problems in image mining. We propose a new approach to apply 
association rule on weather forecasting image. We build an image 
system to store weather forecasting images and retrieve them 
later for further research, for example, to predict future 
temperature, relative humidity, rainfall, wind speed and 
atmospheric pressure. Image retrieval technology is therefore 
important. We describe weather forecasting image retrieval 
system based on content-based image retrieval. Currently, 
content based image retrieval technology does not exploit high-
level semantics, and it is hard to obtain predictive information 
from retrieved images. Association rules mining is applied in the 
search for these weather forecasting images. Most traditional 
data mining models focus on mining association rules among 
attributes within one transaction. Our improvement involves a 
spatial reference method that is used to get the spatial 
relationships between objects for a certain image. Spatial 
association rules are also mined and are subsequently used as a 
basis for retrieving additional images. As the spatial semantics in 
both the query image and spatial association rules retrieved 
images are more accurate. The proposed intelligent image 
retrieval system can get more images to help user predict future 
on weather forecasting. 
I. INTRODUCTION  
Atmospheric conditions change rapidly, weather 
forecasting is a very important activity, weather forecasting is a 
process of  collecting data on atmospheric conditions, 
including temperature, humidity, pressure, wind speed, and its 
direction etc , high-speed computers, meteorological satellites, 
and weather radars are tools used to collect the weather data , 
Such data are fed into the sophisticated computers to interpret 
the weather conditions it provides very comprehensive 
forecasting services for different users [1],[2]. Many countries 
are now concerning more about global climate change and its 
regional impacts and are investigating more research in to 
environmental changes in weather. Unisys is a global research 
organization that provides weather satellite images. This 
facilitates continuous monitoring of atmospheric conditions. 
The data collected, including weather satellite images, are 
made available to the public. 
We can build data base system to sore weather satellite 
images and retrieve them later for research purposes [12]. In 
order to get effective retrieval results, the image retrieval 
technology is critical to image data base systems. Currently, 
content based image retrieval technology is not so effective, 
especially when the image volume is large. Several content 
based image retrieval strategies have been proposed already. 
These strategies usually se low level features such as texture, 
color and shape to calculate the similarity between images. 
Here, the spatial relationship between the objects within the 
images are ignored since these low level features are not reveal 
spatial information such as the location  of an object.  It is hard 
to get predictive information from the retrieved images in 
content based image retrieval system [7], [11]. User never want 
to retrieve with similar low level features, rather prefers to have 
spatial relationships between the image objects that match 
those of the query image.  
This paper describes weather forecasting images and 
retrieves them later for further research, for example, to predict 
future temperature, relative humidity, rainfall, win speed an 
atmospheric pressure. Where content based image retrieval and 
inter transaction association rule mining methods are used to 
achieve the above goal. 
II. CONTENT-BASED IMAGE RETRIEVAL 
Content-based image retrieval (CBIR), also known as query 
by image content (QBIC) and content-based visual information 
retrieval (CBVIR) is the application of computer vision 
techniques to the image retrieval problem, that is, the problem 
of searching for digital images in large databases. Content-
based means that the search will analyze the actual contents of 
the image rather than the metadata such as keywords, tags, 
and/or descriptions associated with the image. The term 
'content' in this context might refer to colors, shapes, textures, 
or any other information that can be derived from the image 
itself. CBIR is desirable because most web based image search 
engines rely purely on metadata and this produces a lot of 
garbage in the results. Also humans manually enter keywords 
for images in a large database can be inefficient, expensive and 
may not capture every keyword that describes the image. Thus 
a system that can filter images based on their content would 
provide better indexing and return more accurate results. 
Modern multimedia technologies have led to huge and 
growing archives of images in diverse applications such as 
medicine, remote-sensing, entertainment, education and online 
 55 
 
information services. Traditional DBMS does not work well 
for image data due to the lack of semantic information in the 
data. To exploit the full benefit of the explosive growth of 
image data, there is an urgent demand to develop efficient 
techniques for storage, browsing, indexing and retrieval. In 
recent years, automatic indexing and retrieval based on image 
content has become more desirable for developing large 
volume image retrieval applications [9]. Color, shape and 
texture are the main features both humans and computers used 
to recognize images. Several systems have been proposed in 
the research community for content-based information retrieval 
such as QBIC (Query by Image Content) by IBM, and Visual 
SEEK by Columbia University. Most content-based image 
retrieval techniques employ the following two steps to retrieve 
the images. First, each image’s feature vector is computed and 
then stored in the image database. Secondly, given a query 
image, the feature vector of the query image is computed and 
then is taken to be compared with the feature vector of each 
image stored in the image database. A certain image’s feature 
vector that is close to the feature vector of query image is 
returned to the user. Weighting Euclidean distance is used to 
measure the distance between images which is described by 
equation (1). 
=TQ, ii
i
i tq ???                                   (1) 
Where Q is query image and qi is low level feature of Q. T 
is a certain image in database and ti is low level feature of T. ?i 
is the weight factor. 
III. ASSOCIATION RULE ALGORITHM 
 Association rule mining is one of the important advances 
in the area of data mining. The initial application of association 
rule mining was on market basket data. Recently study on 
association rule mining has been extended to more areas, such 
as multimedia data. An association rule is a relationship of the 
form X?Y, where X and Y are sets of items. X is called the 
antecedent and Y the consequence. An example of the rule can 
be, “customers who purchase an item X are very likely to 
purchase another item Y at the same time”. There are two 
primary quality measures for each rule, support and 
confidence. The rule X?Y has support s% in the transaction 
set D if s% of transactions in D contain X?Y. The rule has 
confidence c% if c% of transactions in D that contain X also 
contain Y. The goal of association rule mining is to find all the 
rules with support and confidence exceeding user specified 
thresholds. 
Conceptually, Apriori-based association rule algorithm is 
designed to deal with the boolean type data set. In detail each 
item can be regarded as a boolean type attribute, each 
transaction can be viewed as a row record, and the entire data 
set can be organized as a table with the boolean type attributes 
as the fields and the transactions as row records. The value of 
an attribute for a given record is “1” if the item corresponding 
to the attribute is present in the transaction corresponding to the 
record, and is “0” if the item is not in the transaction. Our data 
have richer attribute types, more specifically, they are all 
quantitative. Therefore how to convert these numeric attributes 
to boolean-type has become an important issue in our study. 
Fortunately there is a straightforward solution. We can 
break down the attributes into several disjoint ranges. Thus 
instead of having just one field in the table for each attribute, 
we can have as many boolean fields as the number of attribute 
ranges for each attribute. The value of a boolean field will be 
“1” if the attribute has a value falling in the corresponding 
range, and “0” otherwise. 
A. Spatial Transactions and Spatial Semantics 
“Fig. 1” shows a visible satellite image and “Fig. 2” shows 
a monthly temperature image downloaded from Unisys [2]. In 
order to simplify our research, only the environmental changes 
in weather Inter-transaction association rules mining are 
employed for discovering Weather forecasting or temperature 
variation patterns. However, association rule mining algorithms 
assume that a finite set of disjoint transactions are given as 
input to the algorithms [3], [8], and there is no explicit finite set 
of transactions in a Weather forecasting image. This study 
adopts the strategy proposed in [8], where the spatial 
transaction is defined around the instances of a special 
reference feature. An image is chosen as the reference site and 
concentric circles are used to define neighboring regions to the 
reference site. Fig. 3 shows this enhanced infrared satellite 
image. The weather forecasting or temperature variations are 
extracted first from each image. The variations within the 
concentric circles are treated as a single transaction. The 
concentric circles are also used to annotate the location of the 
salinity or temperature variations. The sub-zones defined by the 
concentric circles represent different distances and directions to 
the reference image. 
B. Inter-transaction Association Rules Mining 
This section introduces fundamental concepts defined in 
[12] related to inter-transaction itemset and intertransaction. 
Let I = {i1,i2 ,...,iu} be a set of items. Let D be a dimensional 
attribute and Dom (D) be the domain of D. A transaction 
database is a database containing records in the form (d,Ij) , 
where d  Dom(D) and Ij I. We call this type of database a 
one-dimensional database. The dimensional attribute usually 
describes the occurring time or location of an item.  
An inter-transaction association rule that spans p intervals 
is found if an association exists between items that are p 
intervals apart. Since an inter-transaction association rule may 
encompass many intervals, finding all such rules is time 
consuming. In order to minimize the effort involved in mining 
uninteresting rules, a sliding window denoted by w is 
introduced. When mining inter-transaction association rules, 
only the rules spanning shorter than or equal to w intervals are 
considered. The sliding window is thus used to avoid mining 
rules that span many consecutive intervals [4].Each sliding 
window forms an inter-transaction. An inter-transaction M that 
is contained within W can be described as follows: 
M = {ik ( j) | ik W[ j];1  k  u,0  j  w-1}          (2) 
 Where W is a sliding window with w intervals and u is the 
number of items in I = {i1,i2 ,...,iu}. 
 56 
 
To distinguish the items in an inter-transaction from the 
items in a traditional transaction, the items in an 
intertransaction are called inter-transaction items. The set of all 
possible inter-transaction items are denoted I’. Given I’ and w, 
then: I’= {i1(0),...,i1(w-1),i2(0),...,i2(w-1),...,iu (0),...,iu (w-1)}.An 
inter-transaction itemset is a set of inter-transaction items B  I 
’such that ik B,1 k u .An inter-transaction association 
rule has the form X Y, 
Where 
1. X  I’, Y  I’ . 
2. ik (0) X,1  k u. 
3. ik ( j) Y,1  k  u, j  0. 
4. X Y = {}. 
The support and confidence of an inter-transaction association 
rule X Y can be defined by equation (3). 
xT
xyT
confidence
S
xyT
port == ,sup                    (3)            
Where Txy is the set of inter-transactions that contains a 
set of extended items X Y and Tx be the set of inter-
transactions that contains X. S is the number of transactions in 
the transaction database. 
IV. DISCUSSION 
“Fig. 1” is the equivalent of taking a black and white photo 
of the earth. The bright areas show where the sun is being 
reflected back into space as a result of clouds or snow cover. 
Clouds and snow show up white. The thicker cloud is 
represented as brighter the color. Land surfaces show up as 
gray and ocean surfaces nearly black. The major limitation to 
visible imagery is that it is only valid during daylight.  
 
 
 
 
 
 
 
 
 
 
 
A. Selecting a Template (Heading 2) 
 
“Fig. 2” shows heat based radiation from the infrared 
spectrum. In other words, the warmer the surface, the more 
infrared radiation it emits. For a satellite image, cooler surfaces 
are bright and warmer surfaces are dark. Since the atmosphere 
cools as increase in altitude, clouds would show up as bright 
areas and land surfaces as dark areas. In addition, low clouds 
will be grayer and higher clouds will show up more white. Tall 
thunderstorm clouds will show up as bright white and fog will 
be hard to discern from land areas. A large advantage of IR is 
that we can view it 24 hours a day. 
“Fig. 3” is an infrared image enhanced to highlight the 
cloud areas and the coldest cloud tops. Since, IR images could 
be used to determine cloud height these images are enhanced to 
highlight the highest, coldest cloud tops. Areas of strong 
precipitation will show up as shades of cyan. Thunderstorms 
will show up in blue and green. In addition, the contrast of 
warmer clouds is increased so that low clouds will show up.     
A color bar at the top of the Table I will describe the 
enhancement scheme. The tick marks at the top of the bar 
represent 10 degree Celsius increments starting at 50C on the 
left and going to -110C on the right. In table 1 the attributes 
used in our study is given. First, confirm that you have the 
correct template for your paper size. This template has been 
tailored for output on the A4 paper size. If you are using US 
letter-sized paper, please close this file and download the file 
for “MSW_USltr_format”. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Visible Satellite Image 
 
Figure 2. Infrared Satellite Image 
 
Figure 3. Enhanced Infrared Satellite Image 
 57 
 
“Fig. 4” shows an infrared band which is affected strongly 
by the presence of water vapor and also it shows the altitude of 
the highest moist layer in the atmosphere. Bright areas reflect 
the location of high clouds either due to jet stream cloudiness 
or due to thunderstorm activity. The dark areas reflect the 
location of dry area at high altitudes. This is associated with 
dry air intrusion and sinking motion associated with high 
pressure systems. This image is a decent tracer of jet stream 
winds which will show up as bright streaks. 
 
 
 
 
 
 
 
 
 
 
“Fig. 5” is the infrared image overlaid with the radar 
summary. The infrared image will highlight the deeper/higher 
clouds as bright white and the radar summary allows 
correlating the high clouds with precipitation. The radar 
summary is stippled so that the image will partially show 
through the radar summary. 
 
 
 
 
 
 
 
 
 
 
 
 
TABLE I.  THE ATTRIBUTES  USED IN OUR STUDY 
 
Colors Temps (C) Temps(F) Description 
Dark cyan -32 to -43 -25 to -45 Jet stream and anvil clouds 
Cyan -43 to -54 -45 to -65  
Light blue -54 to -60 -65 to -76 Thick jet stream clouds 
Dark blue -60 to -64 -76 to -83 Strong thunderstorm tops 
Dark green -64 to -70 -83 to -94  
Green -70 to -76 -94 to -105 Severe thunderstorm tops 
Brown -76 to -81 -105 to -114 Strong Hurricane tops 
Yellow -81 to -90 -114 to -130  
V. CONCLUSION 
This study proposes a strategy where segment of images are 
used as a reference model to annotate location information to 
the objects in image. This allows the spatial semantics to be 
maintained for either the images in database or the query 
image. In order to obtain additional information from images 
that are used to predict future variation trend, an improved 
inter-transaction association rules algorithm is employed to 
discover weather forecasting and temperature variation 
patterns. In query stage, images similar to the query image in 
both color and spatial semantics are retrieved. The retrieval 
results are more accurate. The proposed intelligent image 
retrieval system can get more images to help user predict future 
on weather forecasting. 
REFERENCES 
[1] Y. Huang, S. Shekhar, and H. Xiong, “Discovering co-location 
patternsfrom spatial datasets: a general approach,” IEEE Trans. on 
Knowledge and Data Engineering, vol. 16, no. 12, pp.1472-1485, Dec. 
2004. 
[2] Unisys weather satellite images are available at 
www.weather.unisys.com/satellite/index.html. 
[3] Y.P. Huang, L. J. Kao and F.E. Sandnes, “Using minimum bounding 
cube to discover valuable salinity/temperature patterns from ocean 
science data,” Proc. IEEE SMC, Taipei, Taiwan, pp.478-483, Oct. 2006. 
[4] Y.P. Huang, L. J. Kao and F.E. Sandnes, “Predicting ocean salinity and 
temperature variations using data mining and fuzzy inference,” 
Int.Journal of Fuzzy Systems, vol. 9, no. 3, pp.143-151, Sept. 2007. 
[5] J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal and 
M.C.Hsu, “PrefixSpan: Mining sequential patterns efficiently by 
prefixprojected pattern growth,” Proc. Int. Conf. Data 
Engineering,Heidelberg, Germany, pp.215-224, Apr. 2001. 
[6] R. Srikant and R. Agrawal, “Mining quantitative association rules in 
large relation tables,” Proc. of ACM SIGMOD Int. Conf. Management 
of Data, Montreal, Canada, pp.1-12, 1996. 
[7] S. Shekhar and Y. Huang, “Discovering spatial co-location patterns: a 
summary of results,” Proc. of 7th Int. Symp. on Spatial and Temporal 
Databases, L.A., CA, U.S.A., pp.236-256, Jul. 2001. 
[8] T.K. Shih, J-Y. Huang, C.-S. Wang, J.-C. Hung, and C.-H. Kao, “An 
intelligent content-based image retrieval system based on color, shape 
and spatial relations,” Proc. Natl. Sci. Counc., vol. 25, no. 4, pp.232-
243,Apr. 2001. 
[9] A.K.H. Tung, H. Lu, J. Han and L. Feng, “Efficient mining of 
intertransaction association rules,” IEEE Trans. on Knowledge and Data 
Engineering, vol. 15, no. 1, pp.43-56, Jan./Feb. 2003. 
[10]  Y. Zhang, M.A. Nascimento, and O.R. Zaiane, “Building image 
mosaics:an application of content-based image retrieval,” Proc. IEEE 
Int. Conf.on Multimedia and Exposition, Baltimore, MD, U.S.A., 
pp.317-320, Jul.2003. 
[11] Y.P. Huang, L.J. Kao and F.E. Sandnes, “Efficient mining of salinity 
and temperature association rules from ARGO data,” Expert Systems 
with Applications, vol. 35, no. 1-2, pp.59-68, Aug. 2008. 
[12] Y.P. Huang, L.J. Kao and F.E. Sandnes, “Extracting Spatial Semantics 
in Association Rules for Ocean Image Retrieval mining,” Proceedings of 
the 2009 IEEE International Conference on Systems, Man, and 
Cybernetics, pp.2924-2928, Oct. 2009. 
 
 
Figure 4. Water Vapor Satellite Image
 
Figure 5. Water Vapor Satellite Image 
 
