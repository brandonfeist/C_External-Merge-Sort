2009 IEEE International Advance Computing Conference (IACC 2009)
Patiala, India, 6-7 March 2009
Parallel Privacy Preserving Association rule mining on pc Clusters
B.Janaki Ramaiah Dr. A Rama Mohan Reddy M.Kamala Kumari
Associate.Profissor, Dept ofCSE, Professor, Dept ofCSE, Associate.Profissor, Dept ofCSE,
DVR & Dr HS MIC College of Tech, Sri Venkateswara University, Adikavi Nannaya University,
Vijayawada, A.P, India. Tirupati,A.P, India Rajahmundry, A.P, India
Abstract: - Association rules discovered by association includes a large number of transactions. Different from
rule mining may contain some sensitive rules, which data modification, data reconstruction [7] is a new
may cause potential threats towards privacy and promising method in dealing with the association rule
security. In this paper, we address the problem of hiding problem. This approach is based on knowledge
privacy preserving association rule mining by sanitization. Specifically, it hides the rules by sanitizing
proposing a Knowledge Sanitization to prevent the itemset lattice called a knowledge base rather than
disclosure of sensitive rules. We also present parallel sanitizing original dataset. Then a reconstruction
approach to generate a non-sensitive and sensitive rule procedure reconstructs a new released dataset from the
mining. Our proposed solution key issue is to provide a sanitized itemset lattice. In this way, data reconstruction
high degree of parallelism for privacy to the data gives user a knowledge level window to control the
owner. availability of rules handily and control the hiding
1. Introduction effects directly. Our approach is based on knowledge
sanitization.
Association rule mining extracts novel, hidden
and useful patterns from huge repositories of data. 2. Formulate the problem
These patterns are useful for an effective analysis and
decision making in corporation, marketing, business, Given a database D to be released with
medical analysis, website linkages, financial minimum support threshold and minimum confidence
transactions, health-care records and other applications. threshold, a set of rules R mined from D, and a set of
The sharing of association rules can bring a lot of sensitive rules Rh C R to be hided, we need to
advantages in industry, research and business construct a new data set D', such that the rules in Rh
collaboration. At the same time, a huge repository of cannot be mined from D', while the rules in R-Rh can
data contains private data and sensitive rules that must still be mined as many as possible.
be protected before sharing. On demand to various Two problems are addressed here: one is the
mismatched requirements of data sharing, privacy protection of private data; another is the protection of
preserving and knowledge discovery, privacy sensitive rules contained in the data. The former settles
preserving data mining has become a research hotspot how to get normal mining results when private data
in data mining. Simply, the association rule-hiding cannot be accessed accurately; the latter settles how to
problem is to hide secret, sensitive association rules protect sensitive rules contained in the data from being
contained in data from being discovered, while without discovered, while non-sensitive rules can still be mined
losing non-sensitive at the same time. This problem normally.
motivated different authors [5, 6, 7] who proposed a
number of algorithms to this problem. There have been 3. Proposed Framework
two broad approaches: Data modification approaches
and data reconstruction approaches. Data modification The framework is depicted in Figure 1. The
[4] methods hide sensitive association rules by directly whole approach is divided into three phases: The first
modifying original data. According to different phase is to use Fast Frequent Set Mining (FFSM)
modification means, it can be further classified into the algorithm, to generate all frequent itemsets with their
two subcategories: Data Distortion techniques and Data supports and support counts from original database D.
Blocking techniques. Data Distortion[3] is implemented This gives the set of association rules R. In the second
by deleting or adding items to reduce the support or phase, we perform sanitization algorithm over R and get
confidence of the sensitive rules, while data-blocking the sanitized frequent itemsets FFSM'. In the best case,
is implemented by replacing certain items with a from FFSM', ensured from sanitization algorithm we
question mark "?" to make the support and confidence get exactly the set of non-sensitive rules R-Rh, with no
of the sensitive rules uncertain. As a traditional method, normal rules lost and no ghost rules generated. The
data modification can operate simply. However, they third phase is to generate released database D' from
suffer from the weakness of providing a way of fine- FFSM' by using inverse frequent set mining algorithm.
tuning the generation of the released database, which The fast frequent itemset mining algorithm and inverse
makes that they cannot control the hiding effects frequent set mining algorithm are parallelized by using
directly and clearly. Data sanitization can produce a lot Linux cluster environment.
Of I/O operations, especially when the original database
978-1T-4244-1888-6/08/f$25.OO Q 2008 IEEE 1538
D:-Original Data Base. 5. Parallel data mining in Linux Clusters
FFSM: -Fast Frequent Set Mining algorithm.
R: -Set of Association rules (sensitive + Non sensitive). Challenging problems in engineering and
Rh: - Set of Sensitive Association rules. information sciences typically require a lot computing
FFSM':-Inverse Fast Frequent set Mining algorithm. power and Linux clusters are one of the solutions.
R-Rh:-only non sensitive rules. Linux clusters are less expensive and are scalable. Data
D': -Reconstructed Data Base. mining applications require processing huge collections
of data and are computationally intensive. Hence these
applications can be parallelized to reduce the time
r
T |. a required to complete the calculations. A cluster of
_FFSM _ machines was built to use as a parallel processing
D P_, R platform. Applications can be parallelized to reduce the
time required to complete the calculations. Parallelism
can affect the execution time of data mining
applications. Benefits of clusters are Lower cost,
Scalability, Vendor independence, Adaptability,
Reliability, Availability and Serviceability and Faster
Linux cluster nodes technology innovation.
Clusters are becoming increasingly popular as
computational resources both in research and
Knowledge Sanitization commercial organizations. These organizations are
favoring clusters over single large servers for a wide
variety of problems. Super computers being highly
expensive and being less scalable. The increasing
popularity of the Linux operating system is adding fuel
< FFSM ' 1 to this. Linux provides a very cost effective and open
D'v R-Rh environment to build a cluster. The main motivation
factor is usually faster computation very simple idea
that n computers operating simultaneously can achieve
the result n times faster. Other motivation factors are:
fault tolerance, larger amount ofmemory available, etc.
Linux cluster nodes U
__rAppiator'
PoullIle Prograrnmming Lib ra ry and Devekppreznt Tcls |
Fig. 1. Proposed Framework I_nernect NlsagIrg Protocol
lntrcoonneck Hardiare (N5Cs, Swlteha and Cble|s)
4. Procedure Cluster Nodes
Begin Fig. 2. Layers in a typical Cluster
Step 1: A cluster of n machines was built to use as a
parallel processing platform. 5.1 Fast Frequent set Mining algorithm
Step 2: Use Fast Frequent set Mining algorithm to We introduce a new parallel algorithm PFPT
generate itemset with supports over original (Parallel Frequent Pattern Tree) for parallel mining of
dataset D. (D 4 FFSM 4 R) frequent patterns, based on FP-growth mining[2], that
Step 3: Find all frequent itemsets from Database and uses only two full I/O scans of the database, eliminating
generate corresponding association rules R. the need for generating the candidate items, and
Step 4: Identify sensitive frequent itemsets and select distributing the work fairly among processors. We have
the hiding strategy. devised partitioning strategies at different stages of the
Step 5: Perform sanitization algorithm. mining process to achieve near optimal balancing
Step 6: Next generate exactly the set of non-sensitive between processors. The PFPT approach we proposed
rules R-Rh from sanitization algorithm. consists of two main stages. Stage one is the
(Sanitization i R-Rh) construction of the parallel frequent pattern trees (one
Step 7: Reconstructed database D' based on inverse for each processor) and stage two is the actual mining
frequent set mining algorithm, of these data structures, much like the FP-growth
(R-Rh -)Inverse FFSM o D') algorithm.
End
2009 IEEE Inxternational Advanxce Computing Conference (IACC 2009) 1539
5.2 Knowledge Sanitization algorithm Each processor finds the local counts of each
data item. Data item A, has 2 references, item 3 has
(1) Choosing hiding strategy: We would decrease three references say for example. The local counts of
support of sensitive rule from current support, so that it each processor on each data item are shown in Table 3.
will not be mined from dataset with a minimal support
threshold value. Counters
(2) Configuring support values: We will find all the Item P P1 P2
subsets of sensitive rule. Then subtract their support,
finding all supersets of sensitive rule, and then modify A 2
the support. After finding all subsets of superset B 3 3 2
excluding subsets of sensitive rule, their supports are C 1 0 0
modified accordingly. D 3
(3) After completion of Knowledge sanitization, use B 0
parallel frequent set mining algorithm to generate F 3
exactly the set of non-sensitive rules R-Rh.
G 2 3 1
5.2 Example H 0 1 1
K 0 0 1
Table 1 represents a transaction database D, having ()
nine transactions with 11 different items.
Tid Items Bought Table 3. Local Counts
1 A,B,C,D,E
2 F,B,D,E,G These local counts of each data item are
3 B,D,A,E,G summed which gives global count of each processor.
A,B,F,G,D Item A has a total of 7 references overall, which gives
A,B,F,D,G,H the global count of it. We find Global count of all data
6 A,B,F,G,D items similarly. This is shown in Table 4
8 A,F,,A,DJ Proc. # Item Global counter
9 A,B,F,I,J A 7
Table 1. Original transaction database (D)
D
In order to enumerate the frequent items E 3
efficiently, we divide the datasets among the available P1 F 6
processors. We consider three processor for example. G 6
Each processor is given an approximately equal number H 2
of transactions to read and analyze. In this original data K I
base is horizontally partitioned into three parts and each P2 2
part is assigned to corresponding processors shown in 2
Table 2. So each processor is having three itemsets, Table 4. Global count
which performs the given tasks similarly and parallely
on pc clusters. Let us assume the Minimum Support threshold
value is 6. Items which are below the threshold value
Tid Items Bought Processor are removed and which are equal to or above theNumber threshold value are retained. This levies A, B, D, F, and
tA.BC. E G to retain in the frequent items.
2 F,B,D,E,G PO
Item Global counter
4 A,B,F,G,D A 7
5 B,F,D,G,H P1 B 8
6 A,B,F,G,D D 7
7 AXBFJ GJQ,,,,Uf_'_1 A TN IDi F 6
Table 2. Divide the datasets
Table 5. Frequent Items Frequent Item sets: FS
11540 2009 IEEE Internactionalz Advance Computing Conference (IACC 2009)
From Table 5 to find all possible Frequent Now after the sanitization, we have the
Item sets (FS). frequent itemsets set FS' from which we get the set of
non sensitive association rules R-Rh shown in this
Items Support Count Table 9.
7_
B 8 Rules Confidence % Support %
D 7 B=> D 87 77
F 6 B=>F 75 66
G 6 B =>G 75 66
A,B 6 D=>G 75 66
B,D 7 Table 9. Association Rules: R-Rh
B,F 6
B,G 6 Applying Inverse frequent set mining
D,G 6 algorithm to find released database (D'), from this
database (D') we can not find sensitive rules shown in
Table 6. Frequent Item sets: FS this Table 10.
From the frequent itemsets FS, we get six TID Items
association rules shown in this table 7 1 B,D,F,G
2 G,F,D,B
Rules Confidence % Support 4 B,DG
A=>B 75 66 5 F,D,B,G
B=>D 87 77 6 F,D,B,G
B=> F 75 66 7 G,B,D,F
B =>G 75 66
Table 10. Released Database (D')
LD=>G 75 66
5.4 Inverse frequent set mining algorithm
Table 7. Association Rules: R
Use parallel Inverse frequent set mining algorithm
Now let us suppose the first rule A=>B is a to reconstruct new database (D') from the sanitized
sensitive rule that needs hiding. So Applying frequent itemsets. First, we try to "guess" a FP-tree that
Knowledge Sanitization algorithms to remove the satisfies the set of non-sensitive rules R-Rh. The whole
A=>B rule we find the Frequent Itemsets (FS') shown process of the proposed method is the reverse process
in this table 8. of the FP-tree-based frequent itemsets mining. If we
apply mining process on D', it generates the set of non-
Rules Support Count sensitive rules R-Rh.
B 7 Inverse frequent set
D 7 Mining algorithm FFSM
F 6
G 6
BID 7
B,F 6
6. Experimental Results
Experiments used 64 Linux cluster nodes of
Intel Pentium dual core with 2.80GHz and 2 GB of
RAM (my institution laboratory environment) to
conduct the experiments. The sizes of the input
databases vary from 1 GB transactions to 50 GB. Each
of these transactions has at least 2 items preceded by a
unique transactional ID. The largest dataset is in the
order of 512 bytes
Frequent Set Mining Result
3000
* 2500
z 2000
w
1500
z
0
D 1000U
w
x
w 500
2 4 g 16 32 64
NO OF PROCESSORS
Fig. 4. Execution time
7. Conclusion
In this paper a Framework has been
implemented for Fast and Scalable Privacy-Preserving
Association Rule Mining. We have introduced an
efficient parallel implementation of an FP-Tree-based
association nule mining Algorithm on Linux clusters to
achieve fast, scalability and preserve a high degree of
accuracy in the mining results. Sanitization algorithm
provides a high degree of privacy to the user. Our
further research will focus on the optimal Knowledge
Sanitization to improve degree of privacy.
8. References
[1] R. Agrawal, A. Evfimievski, and R. Srikant. Information sharing
across private databases. In SIGMOD, 2003.
[2] J. Han, J. Pei, Y. Yin, and R. Mao. Mining frequent patterns
without candidate generation: A frequent-pattern tree approach. Data
Mining and Knowledge Discovery, 2003.
[3] Kargupta, H. Datta, S. Wang, Q. and Sivakumar K.: On the
Privacy Preserving Properties of Random Data Perturbation
Techniques. In Proceedings of the 3rd IEEE International Conference
on Data Mining (ICDM'03), Melbourne, Florida, USA, November
2003, pp. 99-106.
[4] Oliveira, S.R.M. and Zaiane, O.R. Protecting sensitive knowledge
by data sanitization. In: Proc. of the 3rd IEEE Int'l Conf on Data
Mining (ICDM'03). IEEE Computer Society, USA, 2003. 613-616.
[5] J. Vaidya and C. Clifton. Privacy preserving association rule
mining in vertically partitioned data. In SIGKDD, 2002.
[6] Z.Wang, B. Liu,W.Wang, H. Zhou, and B. Shi. An effective
approach for hiding sensitive knowledge in data publishing.
In WAIM, pages 146-157, 2006.
[7] Yuhong Guo, Reconstruction-Based Association Rule Hiding,
Pzroceedings of SIGMOD2007 Ph.D. Workshop on Innovative
Database Research 2007(IDAR2007), June 10, 2007, Beijing,
China.
154 2009ICMEEE International Advalnce Computing Conference (IACC 2009)
