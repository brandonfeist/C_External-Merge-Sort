Effective Mining of Fuzzy Quantitative Weighted 
Association Rules 
LI Cheng-jun and YANG Tian-qi 
Department of Computer 
University of Jinan 
Guangzhou,Guangdong Province, China 
chjlee09@gmail.com 
Abstract-This paper presents a new method of mining weighted 
association rules ,which can hold the “weighted downward closed 
property” by using an improved model of weighted support 
measurements in the weighted setting.Compared to some 
generalized weighted association rules mining, it proves that the 
method can quickly and efficiently mine important association 
rules.  
Keyword-weighted association rules; weighted support; 
quantitative itemsets 
I.  INTRODUCTION 
Data mining and knowledge discovery in databases is an 
interesting research area only developed in the last sixteen 
years. Association rules mining(ARM) aims to explore large 
transaction databases for association rules(AR), which may 
reveal the implicit relationships among the data attributes. It 
can be divided into boolean AR and quantitative AR. Agrawal 
first proposed boolean AR in 1993, and then proposed the 
classic Apriori and Apriori TID algorithm[1].ARM[2] is a 
popular data mining technique because of its wide application 
in marketing and retail communities as well as other more 
diverse fields[3 11].  
The classical model of ARM employs the support measure, 
which treats every transaction equally. In contrast, different 
transactions have different weights in real-life data sets. For 
example, in the market basket data, each transaction is 
recorded with some profit. Much effort has been dedicated to 
ARM with preassigned weights. 
The paper is organized as follows.In section II we presents 
background and related work;Section III gives problem 
definition for improved weighted ARM with fuzzy data and 
details weighted downward closure property;and section 
IV ,the detail of the IFWARM algorithms;section V reviews 
experimental evaluation with a real customer data and section 
VI concludes the paper. 
?. BACKGROUND AND RELATED WORK 
In literature on ARM,weights of items are mostly treated 
as equally important.Recently some approaches give items 
weights to reflect their significance to the user, The weights 
may be attributed to occasional promotions of such items or 
their profitability.[4] proposes a weighted boolean attributes 
of the concept of AR, and gives two weighted ARM 
algorithms: MINWAL (O) and MINWAL (W) . 
Fuzzy ARM is especially useful to consider the quantities 
involved in the user’s request. Such merit presents more detail 
and a more reliable exploration of the association rules than a 
generic association rule. [6] introduces the problem of mining 
weighted quantitative AR based on fuzzy approach.[7] 
develops a systematic approach to the assessment of fuzzy 
AR.[8] proposes a novel algorithm to avoid the loss of 
semantic information due to the partition of quantitative 
values. [9] addresses the issue of invalidation of DCP in 
weighted ARM.[10] deals with the fuzziness based upon 
fuzzy taxonomies that reflect partial belongings among 
itemsets.[11] proposes and implements an intelligent 
information system using fuzzy ARM.  
These fuzzy algorithms are composed of three steps:In the 
first step,it converts a generic transaction into fuzzy 
transaction[5],we can use a membership function to finish this 
conversion.In the second step,it calculates support value using 
a formula with the fuzzy transaction to discover the frequently 
occurring item.it is much important to find a good method for 
calculating items’ support value.In the last step,it calculates a 
confidence value with the all subsets of discovered frequently 
itemset according to a formula. 
In this paper we present an approach to mine weighted 
quantitative data by fuzzy means to address the issue of 
invalidation of WDCP. We then show that rules can be 
generated efficiently by using the proposed technique.  
2010 International Conference on E-Business and E-Government
978-0-7695-3997-3/10 $26.00 © 2010 IEEE
DOI 10.1109/ICEE.2010.360
1418
?. PROBLEM DEFINITION 
In this section formal definitions are presented to define 
quantitative attributes and The IFWARM concept. 
A. Improved Fuzzy Weighted Association Rule Mining 
A fuzzy dataset D consists of fuzzy transactions 
T= },...,,{ 21 nttt  with fuzzy sets associated with each item in 
I= },...,,{ ||21 Iiii ,which is identified by a set of linguistic labels 
L= },...,,{ ||21 Llll ,for example L={Small,Medium,Large},We 
assign a weight w to each l in L. 
Associated with i.Each attribute ][ ji it  is associated with 
several fuzzy sets The degree of of association is given by a 
membership degree in the range[0,1],which indicates the 
correspondence between the value of a given ][ ji it  and the 
set of fuzzy linguistic labels. The “ thk ” weighted fuzzy set for 
the “ thj ” item in the “ thi ” fuzzy transaction is given by 
]]][[[ wlit kji .Thus each label kl  for item ji  would have 
associated with it a weight, i.e. a pair ( wli ]],[[ ) is called a 
weighted item where Lli ?]][[  is a label associated with i and 
Ww? is weight associated with label l. 
We illustrate the fuzzy weighted ARM concept and 
definitions using tables I and II, Table I contains transactions 
for 2 quanitiative items discretised into two overlapped 
intervals with fuzzy vales. Table II has corresponding weights 
associated to each fuzzy item ][li  in T. 
TABLE I. FUZZY TRANSACTIONAL DATABASE 
TID X Y 
Small Large Small Large 
T1 
T2 
T3 
T4 
0.9 
0.2 
1.0 
0.6 
0.1 
0.8 
0.0 
0.4 
0.4 
0.5 
0.3 
0.2 
0.6 
0.5 
0.7 
0.8 
TABLE II. FUZZY ITEMS WITH WEIGHTS 
Fuzzy Items i[l] (X,Small) (X,Large) (Y,Small) (Y,Large) 
Weights(IW) 0.8 0.5 0.6 0.3 
Fuzzy Item Weight (FIW)  is a value attached with each 
fuzzy set.It is a non-negative real number value range [0,1] to 
list some degree of importance.weight of a fuzzy set for an 
item ji  is denoted as ]][[ wli kj . 
Fuzzy Itemset Transaction Weight (FITW)  is the 
aggregated weights of all the fuzzy sets associated to items in 
the itemset present in a single transaction. Fuzzy Itemset 
transaction weight for an itemset(X,A) is calculated as:Vote 
for it  satisfying  X= ]]][[[)max(
)min( ||
1
)]]][[[( wlitX
X
kji
L
k
Xwli?
=
??     (1) 
Let’s take an example of itemset <(X, Large), (Y, Small)>  
denoted  by  (X, Large)  as A  and  (Y, Small)  as  B. 
FITW of itemset (A, B) in transaction 1 is calculated as: 
FITW(A,B)=
6.0
5.0  ×  (0.1 × 0.5)× (0.4 × 0.6)=0.01 
Fuzzy Weighted Support (FWS)  is the aggregated sum of 
FITW of all the transactions itemset is present,divided by the 
total number of transactions.It is denoted as : 
FWS(X)=
n
wlit
X
Xn
i
kji
L
k
Xwli? ?
= =
??
1
||
1
)]]][[[( ]]][[[)max(
)min(
           (2) 
For  itemset(A, B) ,FWS(A,B)= 
4
138.0 =0.034 
Fuzzy Weighted Confidence (FWC)  is the ratio of sum of 
votes satisfying both X ? Y to the sum of votes satisfying X 
with Z=X ? Y.It is formulated as: FWC(X ? Y)= 
)(
)(
XFWS
ZFWS =
? ?
? ?
= =
??
= =
??
n
i
kji
L
k
Xwli
n
i
kji
L
k
Zwli
wlit
X
X
wlit
Z
Z
1
||
1
)]]][[[(
1
||
1
)]]][[[(
]]][[[
)max(
)min(
]]][[[
)max(
)min(
          (3) 
For itemset(A,B), FWC(A,B)= 
65.0
138.0 =0.212 
B. Weighted Downward Closure Property(WDCP) 
In a classical Apriori algorithm , DCP helps algorithm to 
generate large itemsets of increasing size by adding items to 
itemsets that are already large.but in the weighted ARM 
case[4 6] where each item is assigned a weight,the WDCP 
does not hold. Now we argue that the WDCP with quantitative 
data can be validated using the proposed approach.  
We also brefly prove that the WDCP is always valid in the 
proposed method.The following lemma applies to both 
Boolean and quantative data and is stated as: 
Lemma If an itemset is not frequent then its superset can 
not be frequent and FS(subset) ? FS(superset) is true 
1419
Proof For any itemset Y,X ? Y i.e superset of  X, 
Lli ?]][[ ,vote for t i satisfying X= ]][[)]][[( litiXli? ??  ,Similarly , 
vote for t i satisfying  Y= ]][[)]][[( litiYli? ?? . 
Since X ? Y and ]][[ liti  is between 0 and 1.we have 
]][[]][[
)]][[()]][[(
litlit ii YliXli ?? ???? ? . Therefore 
FS(X) =
n
lit
n
i
iXli??
=
??
1
)]][[( ]][[
? FS(Y)=
n
lit
n
i
iYli??
=
??
1
)]][[( ]][[
. 
According to the definition of FWS, formula (2). 
Since min(Y)=min(min(X),min(Y-X)),max(Y)= 
max(max(X),max(Y-X)),We can get  min(X) ?  min(Y), 
max(X) ? max(Y),then
)max(
)min(
)max(
)min(
Y
Y
X
X ? ,and the 
denominator stays the same, then we have FWS(X) ? FWS(Y) 
If FWS(X)<minfws,we get FWS(Y)<minfws.This then 
proves that Y is not frequent if its subset is not frequent. 
?. THE IFWARM ALGORITHM 
The IFWARM algorithm is given in Table III.In the 
Table:C k  is the set of candidate itemsets of cardinality k,w is 
the set of weights associated to items I.and L is the set of 
frequent item sets.R is the final set of generated fuzzy 
weighted ARs. 
Transform(T):This step generates a new transformed fuzzy 
database D from the original database by user specified fuzzy 
sets and weights for each fuzzy set. 
Initialize(D):The subroutine initializes itemset weights, 
weighted support and confidence, encodes attributes values 
and generates 1-frequent itemsets from the database D. 
Join( 1?kL ):This Join step generates kC from 1?kC .before 
we can prune it using WDCP and check that whether two 
label are in the same composite items.if two items in a 
candidate itemsets have the same prefix,we should drop it . 
Getsupw(D,c):In this subroutine we calculate weighted 
support of each candidates items using the formula (2). 
Rules(L,wconf):The last step calculates weighted 
confidence of each frequent items using the formula (3). 
TABLE III. IFWARM ALGORITHM 
Input:  T=data set,  wsup=weighted support,  
w=itemset weights,wconf=weighted confidence    
Output: R=Set of weighted ARs 
Main Algorithm: 
D=Transform(T) 
1L =Initialize(D) 
For(k=2; ??
?1kL ;k++) 
{ kC  =Join( 1?kL ) 
For each candidates kCc?  
c.supw=Getsupw(D,c) 
kL = sup}sup.|{ wwcCc k ??  
L= kk L? } 
R=Rules(L, wconf); 
?. EXPERIMENTAL COMPARISON 
In this section,we give a experimental analysis between 
classical fuzzy ARM(FARM)[7], MINWAL(W)[4], 
normalized weighted ARM(NWARM)[6],fuzzy weighted 
ARM(FWARM) [9] and IFWARM algorithm. To demonstrate 
the effectiveness of the approach,we performed several 
experiments using a real customer data set[12],The data is a 
composite transaction database containing 5900 records and 
20 attributes.we select 6 main attributes from the data itemsets, 
country includes three values,and education includes five 
values.we distribute age to three fuzzy regions{Young, 
Middle,Old},and year_income to three fuzzy regions {Low, 
Middle,High}, marital_status and gender are boolean 
items.We conduct the experiment using Matlab on the 
computercomposed of  1GB memory and Intel PE CPU. 
In the weighted process,the weight to set the value is of 
flexibility,primarily on the basis of expert experience ,taking 
full account of the user’s point of view. Table IV shows the 
attribute value distribution of the weight,and figure 1 give 
membership fuction of  year-come. 
We performe two types of experiments based on quality 
and performance measures.For quality measures,we compared 
the number of the interesting rules generated using five 
algorithms described above.In the second experiment,we 
1420
showed the scalability of this algorithms by comparing the 
execution time with varying user specified support thresholds. 
TABLE IV. THE WEIGHT OF ATTRIBUTES 
country 0.4 education 0.7 
Marital_status 0.5 age 0.8 
gender 0.6 year_income 0.8 
0
0.2
0.4
0.6
0.8
1
1.2
10 40 60 120 140 180
year-income(thousand)
M
em
be
rs
hi
p 
Va
lu
e
Low Middle High
 
Figure 1. The membership function of year-income 
0
500
1000
1500
2000
2500
3000
2 3 4 5 6 7 8 9 10
weighted support(%)
Nu
m
be
r o
f R
ul
es
FARM MINVAL(W) NWARM FWARM IFWARM
 
Figure 2. No. of Interesting Rules using support(wconf=0.2) 
0
20
40
60
80
100
120
140
160
2 3 4 5 6 7 8 9 10
weighted support(%)
Ex
cu
tio
n 
Ti
m
e(
se
c)
FARM MINVAL(W) NWARM FWARM IFWARM
 
Figure 3. Comparation of execution time(wconf=0.2) 
In figure 2,the results show quite similar behavior of the 
weighted algorithms to classical FARM.As expected the 
number of rules increases as the minimum support decreases 
in all cases.Results of IFWARM and FWARM approach are 
better than MINWAL(W) and NWARM approach,because the 
formers hold the WDCP and all the protential itemsets are 
considered from the beginning for pruning using WDCP.the 
IFWARM is more stable and effective than FWARM,and the 
smaller the support value,the more obvious performance.  
In figure 3,we compares the execution time of this 
algorithms. due to the way it generates frequent sets i.e it 
considers items weights ,The weighted algorithms hava less 
excution time than classical FARM. 
The experiments show that the proposed algorithms 
produces better results and has less excution time as it uses all 
the possible itemsets and generates rules effectively using 
valid WDCP. 
?. CONCLUSION 
In this paper,We have presented a generalized approach 
for mining weighted association rules from databases with 
quantitative attributes. And we have demonstrated the valid 
WDCP with detailed proof.The IFWARM algorithm can 
extract efficient and valid ARs for holding WDCP. To 
demonstrate the effectiveness of the approach,we performed 
several experiments using a real customer data set.Compared 
to some generalized weighted association rules mining, It is 
notable that the proposed approach can quickly and efficiently 
mine important association rules.  
REFERENCES 
[1] R Agrawal, R Srikant. Fast Algorithms for MiningAssociation Rules in 
Large Datebases[C],In:Proc 20th Int Conf VLDB,1994:487-499. 
[2] Bodon, F.:A Fast Apriori implementation, In ICDM Workshop on 
Frequent Itemset Mining Implementations, vol. 90, Florida, USA (2003). 
[3] GuoqingChen, Qiang Wei. Fuzzy association rules and the extended 
mining algorithms.Information Sciences 147(2002): 201-228. 
[4] Cai, C.H., Fu, A.W-C., Cheng, C. H.,  Kwong,  W.W.:  Mining  
Association  Rules  with Weighted  Items.  In:  Proceedings  of  
1998  Intl.  Database  Engineering  and  Applications Symposium 
(IDEAS'98), pages 68--77, Cardiff, Wales, UK, July 1998 
[5] Delgado, M., et al.: Fuzzy Association Rules: General Model and 
Applications.IEEE Transactions on Fuzzy Systems 11(2), 214–225 (2003) 
[6] Attila Gyenesei.Minning Weighted Association Rules for Fuzzy 
Quantitative Items.PKDD 2000,LNAI 1910,pp.416-423 2000. 
[7] Didier Dubois.etc A Systematic Approach to the Assessment of Fuzzy 
Association Rules,The 10th International Fuzzy Systems Association World 
Congress,Istambul,2003,[25]. 
[8] Chunqiu Zeng etc MPSQAR:Minning Quantitative Association Rules 
Preserving Semantics, ADMA 2008,LNAI 5139,pp.572-570,2008. 
[9] M.Sulaiman Khan,Maybin Muyeba and Frans Coenen.Weighted 
Association Rule Mining from Binary and Fuzzy Data.ICDM 2008,LNAI 
5077,pp.200-212,2008. 
[10] Guoqing Chen,Qiang Wei.Fuzzy association rules and the extended 
mining algorithms.Information Sciences 147(2002) 201-228. 
[11] Hyeong-Joon Kwon and Kwon and Kwang-Seok Hong.Intelligent 
Information System Based on a Speech Web Using Fuzzy Association Rule 
Mining.APCHI 2008,LNCS 5068,pp,104-113,2008. 
[12]  Laurentiu Cristofor.http://www.cyut.edu.tw/~schsueh/mkis/dm.htm. 
1421
