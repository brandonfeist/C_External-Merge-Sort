Enhanced Semantic Automatic Ontology Enrichment
Ali Harb
LIST, ENS des Mines de Saint-E´tienne
158 cours Fauriel, 42023
Saint-Etienne, France
harb@emse.fr
Ka?l Hajlaoui
ERIC, University of Lyon 2
5 Av. Pierre Mends-France, 69676
Lyon, France
Ka?l.Hajlaoui@univ-lyon2.fr
Abstract—With the fast growing development of the Web,
the adoption of ontologies to improve the exploitation of infor-
mation resources, is already heralded as a promising model of
representation. However, the relevance of information that they
contain requires regular updating, and speci?cally, the addition
of new knowledge. Recently, new research approaches were
de?ned in order to automatically enrich ontology. Usually they
extensively use either statistical models or experts to provide
the relevance and placement of new concepts. Unfortunately
these approaches suffer the following drawback: The detection
of new elements and position in ontology are not automatically
established, and lack of use of semantic or syntactic information
to extract relations between concepts.
In this paper, we present an approach for ontology enrich-
ment based on two steps where a novel effective ?ltering step
is utilized. First we extract the correlation between terms of
a learning dataset using the generation of association rules.
Second we retain the relevant new concepts using an extracted
semantic information. The suggested approach was tested on
an ontology of mechanical industry competencies. Experiments
were performed on real data, which show the usefulness of our
approach.
Keywords-Text mining; Ontology; Association Rules; Mutual
information; Syntactic analysis.
I. INTRODUCTION
Ontologies are a knowledge and reasoning representation.
They are the result of an organization process for the whole
concepts in a speci?c ?eld as well as the relations between
these concepts. Ontology transmits an exhaustive and
rigorous conceptualization of domain or ?eld into a mode
able to be analyzed by various information technology
methods. To build an ontology for a speci?c ?eld, we need
an expert in order to transfer the domain knowledge into an
ontological form [1], [2], [3]. However, this manual process
based on an expert is a fastidious and time consuming.
Thus, the relevance of ontology information needs to be
up to date. In addition, concept enrichment by the addition
of new knowledge is essential. In order to accelerate this
endeavor and to remove any subjectivity, recent research
has been interested in semi-automatic and automatic
techniques for ontology enrichment. In literature, most
of work often used statistical or syntactical approaches
to enrich their ontology[4], [5], [6], [7], [8]. Moreover,
many approaches integrated data mining techniques. These
approaches use neither semantic nor syntactic information
to extract relations between concepts. Also the detection of
new elements and position in ontology are not automatically
established.
In this article, we suggest an automatic enrichment
methodology for ontology based on combining two types
of knowledge: present in the initial ontological structure
suitable for a ?eld and that extracted from a textual corpora.
The process of enrichment is based on the generation of
association rules between terms that represent correlation
which are validated by semantic information and statistical
measurements.
This article is organized as follows: in section 2, an outline
of the techniques of enrichment of ontology is presented.
Third section describes our approach ontology enrichment
by a generic base of associative rules. Lastly, this paper
culminates with a conclusion as well as a description of
our works in progress.
II. STATE OF THE ARTS
The ontology enrichment process is composed of two
steps: the search for both new concepts and their relevant
relations and secondly their placement in the ontology.
A. Discovering potential conceptual term
We distinguish two methods for the discovery candidates
concepts: the ?rst is based on statistical calculations using
several measurements to select potential terms according to
their distribution in corpora [9], [7], [10], such as complex
measurements such as mutual information, tf-idf, etc, or the
use of statistical laws of term distributions [5]. These various
proposals enable identifying new enrichment terms candi-
date, but do not allow placing them in ontology, without a
tiresome human intervention [6]. The second is a syntactic
method which determines at determining the grammatical
function of a word or a word group within a sentence. It is
based on the following assumption: the grammatic structure
re?ect semantic dependences [11]. It uses the grammatical
functions of a word or a word group to present new concepts.
They present the drawbacks of identifying only the relations
1113978-1-4244-8136-1/10/$26.00 c©2010 IEEE
labelized by verbs. Other approaches use also syntactic
patterns [12]. The extracted terms illustrate the new potential
enrichment concepts.
B. Concepts placement in ontology
To place the provisional terms, it is essential to detect
the relations between these new terms and initial concept
ontology. [7] propose a statistical approach based on the
frequent co-occurrence of candidates terms with the con-
cepts of initial ontology. A lack of precision is noticed
among the new concepts and the ontological structure.
Other approaches are based on data mining techniques [6],
[13]. Several approaches suggest using frequent correlations
which exist among the corpora terms while using an ex-
tracted association rules [14] among potential concepts [11],
[8]. Each rule expresses the relation between two or more
concepts of the ?eld. This enrichment process requires
?ltering considering the large number of rules generated.
Consequently human intervention is necessary to de?ne
the semantic relations discovered. Other work [15], [5]
is based on the classi?cation methods in order to bring
closer the candidates terms contained in the texts to the
concepts present in ontology. The principle is to gather by
a method of clustering terms according to their number of
occurrences within corpora [10]. The disadvantage of these
approaches is that they do not detect the relations among
the candidates terms, i.e., which unfortunately then requires
a human intervention for the addition of these new terms.
III. APPROACH
Figure 1. The general process of our approach
The purpose of this section is to present our approach.
The overall process is described in 1. It consists of three
phases. In the following sub-sections these three phases are
presented in detail.
A. Corpora preprocessing
To extract and to preserve the context of sentences con-
tained in the corpora [16] initially obtained from web sites,
we manually built a list of stop words to be ?ltered (e.g.
&nbsp, mailto, next, previous, GIF, jpg . . . ). These words
are always frequent in the corpus in spite of the extraction
text phase (passage of the format HTML with the textual
format. This list is used to ?lter and clean the corpora.
According to the expert analysis of the ?eld for the
initial ontology concepts and the texts of the companies
describing the ?eld of ontology, the choice of the words
to be kept is according to three grammatical categories
(Verb, Noun and Adjectif ). In order to do that, we treated
morpho-syntactically the corpora using TreeTagger [17].
This application enables us to obtain the category and lemma
of each word. A ?ltering step according to these three
categories was made to build a new corpora based on words
considered grammatically relevant.
B. Window size creation and concept extraction
The objective is to search within the corpora the words
which are correlated to the concepts of the ontology. Per-
haps, a brief explanation of our use of the term window
size is in order. A window size is a set of words that
surround concepts. For this, from the processed copora, we
seek correlations between concepts of ontology and words
of documents to enrich the ontology with more relevant and
useful words. The question that arises at this point is: How
to search for words correlated to the concepts of ontology?
The answer consists in two steps:
1) construction of Window size;
2) generation of association rules.
Nevertheless, in order to obtain more relevant concepts,
consider the following hypothesis: the more a word is
close to a initial concept, the more likely this word has
strong semantic correlation. Thus, sentences are de?ned
by considering window sizes (WS). A window size is a
set of words that include one or more initial concept of
ontology. In other words, as aforementioned a set of words
that surround concepts. Our goal is to identify in sentences
how to represent these WS. For instance, if WS is set to 1
that means that a sentence is composed by one word before
and one after the pivot concept.
Figure 2. Example of Window Size (WS)
In ?gure 2 the pivot is stampings. Using WS whose size
1, we get the following transaction ”stampings, cuttings
1114 2010 10th International Conference on Intelligent Systems Design and Applications
and industrial”, and by specifying a WS= 2 : ”stampings,
cuttings, expertise, industrial and process. These windows
are the transactions for the next step.
The second step is the generation of the association
rules. In order to detect the semantic correlation between
the terms in documents and the ontology’s concepts, an
association rule algorithm as adapted [18] to our concern.
More formally, let I = {i1, ....in} a set of terms, and D
a set of sentences, where each sentence corresponds to a
subset of elements of I . An association rule is thus de?ned
as X?Y, where X?I , Y?I , and X ? Y = . The support
of a rule corresponds to the percentage of sentences in D
containing X?Y. The rule X?Y has a con?dence ratio c, if
c% of sentences from D containing X also contain Y .
C. Filtering and Enrichment
In order to minimize the number of false concepts learned,
the words found in documents that are in correlation with
several different concepts are removed. Indeed, as a dictio-
nary is not used, by excluding words correlated to more than
one concept, only those words that are highly correlated with
unique concepts should be retained.
After this phase, we obtain a list of potential concepts
learned. However a problem persists: what is the quality of
words in this list? In other words, do the concepts learned
correspond to real features or just noise? The various
experiments conducted have demonstrate that effectively it
was necessary to follow the learning by a ?ltering step.
One of the most commonly measures used for ?nding
the correlation between two words is the Cubic Mutual
Information (MI)[19]. This measure depends on a context
c. Given this context, it is then based on three frequencies:
nb(x, c) the number of co-occurrences of x and c, nb(y, c)
co-occurrences of y and c, nb(x, y, c) co-occurrences of x,y
and c. The measure then is computed with AcroDefMI3
formula [20]:
AcroDefMI3(x, y, c) =
nb((x, y) ? c)3
nb(x ? c) · nb(y ? c)
(1)
In our work, we wish to compute the dependency between
two concepts x and y. In this case, nb (x, y) represents the
number of web pages where x and y are present together.
The problem that persists is: How to identify context? To
do this, we will study the different situations of concepts
and words learned. We found that the major situations
in which the concepts and words learned appear in are:
Subject, Object, Verb and adjectives. The normal parsing
of natural language does not detect these variants of
categories. For this, a was used parser1 that can generate
the grammatical dependencies from which context can be
1http://www.latl.unige.ch/
extracted.
Example Consider the concept stampings which is a
concept of the original ontology. After the generation of
the previous steps, the learned words which are correlated
according to the association rules are: cuttings, machining,
Development and Client.
Firstly, we verify that there is no learned word as a con-
cept of the original ontology. For this, the term machining
is eliminated in this ?rst step. By doing so, we need to
identify the context of each word so that we can generate
the AcroDefMI3 values. Concerning the concept learned
cuttings, its context in relation to the term stampings is
sought. When the collection of documents is mined where
both words appear, the following sentences are found:
• Our expertise is in : cuttings, stampings and industrial
plastic process.
• Transformation of metals by cutting, stamping and
welding.
• We make tools for cutting and stamping.
• Our competency is based on three areas of expertise:
cutting, stamping and welding.
Based on the logical chaining of the grammatical
dependencies rules, we get the following information:
Competency, expertise, Metal, tools, transformation. These
terms forms the context of stamping and the word learned
cuttings.
To implement the correlation formula AcroDefMI3 , and to
evaluate the three frequencies queries were posted to Google.
The formula is applied between the concept stampings and
all words learned where it is correlated. The values obtained
are shown below.
• AcroDefMI3 (stampings, cuttings, C1) = 0.13462
• AcroDefMI3 (stampings, Development, C2) = 0.03029
• AcroDefMI3 (stampings, client, C3) = 4.9693E-005
Because of the numbers of pages indexed by google that
changes from one word to another, that prevent us from ?nd-
ing a threshold from which we can ?lter candidates. Hence,
the ?rst potential concept listed by the ?lter AcroDefMI3
is just accepted. So the word cuttings is validated as a new
concept and the others are removed.
IV. EXPERIMENTATIONS
In this section, the results of the different experiments we
conducted to validate our methodology are presented.
A. Corpora
To test our approach we used a corpora constituted by the
texts of twenty companies in the mechanical industry (our
ontology describes competences of these companies). This
corpora was built by collecting documents from the web
2010 10th International Conference on Intelligent Systems Design and Applications 1115
sites. Concepts found on these pages were cross-references
with their corresponding codes according to NAF2. The
collection contains 11926 documents is our test corpora.
B. Building an ”Ontology for competence traces”
1) Normalisation: The ?rst normalisation step is to ren-
der explicit the concepts of the knowledge domain. These
concepts should be expressed in the form of ”cognitive
constructs”, which have a non-contextual meaning. This al-
lows the arrangement of various constructs into semantically
interpretable formulations. [21] Proposed to identify such
cognitive constructs by applying differentiation mechanisms
among concepts. These authors suggested applying four
semantic differentiation principles to clarify the difference
between each ”cognitive constructs” and its ”parent” con-
structs .
Our objective is to engineer an ontology that deals with
”competence traces”. The normalisation procedure has been
divided into three phases. The ?rst automatically identi?es
candidate terms for the ontology. A corpus was extracted
from mechanical industrial company web sites, with the
indexation tool SMART for this application. Using this ?rst
identi?cation of terms, the second uses informal domain
expertise, asking several experts to provide an initial version
of the potential organisation of the domain concepts (con-
ceptual classes and their relationships). Here the experts’
thoughts have ”converged” to two approaches. First, a top-
down method offers a generic conceptualisation of the notion
of ”competence traces”. We show in Figure 2 that the results
are a so called ”generic ontology”. Second, a bottom up
approach which entails a pragmatic notion of competence
traces, closely linked to the activity ?led analysed (mechan-
ical industry). This 2nd approach results in a enumerated part
of the ?nal ontology called the ”domain ontology”. Finally, a
normalisation phase reduces ambiguities among the concepts
identi?ed and improves the formalisation of relationships
among terms and their de?nitions. The differentiation prin-
ciples proposed by Bachimont [2] were applied.
2) Formalisation: The formalisation structures the var-
ious levels of the ontology, notably by de?ning additional
properties to the ”cognitive constructs” identi?ed previously.
The three main types are differentiated: metaphysic, struc-
ture, and parataxic concepts. These three types correspond
also to distinct generality levels, from the conceptual level
of the ontology, to the more pragmatic.
The ?rst level of the ”competence traces” ontology is
composed of very generic commonly called ”metaphysical
concepts”. For this level, the generic competence model
must be created. Two generic classes are de?ned which
correspond to the types of company capabilities of interest:
2It is one of the codes of INSEE, it allows the coding of the principal ac-
tivity carried on in the company or association. We have code APE of 1973
to 1992 and code NAF since January 1st, 1993. (http://www.insee.fr/fr/nom
def met/nomenclatures/naf/pages/naf.pdf)
the classes ”technological competence traces” and ”method-
ological competence traces”. The structuring level covers a
set of interrelated concepts which should make possible to
provide an enumerative and conceptual description of the
knowledge domain. These concepts have the advantage of
being independent of the speci?c activity ?eld addressed:
”Competence Traces Ontology” CTO can be re-used for
various company activity domains.
The third, parataxic level of the ontology is constituted
by what we called in 3.2.1 the ”domain ontology”. The
”competence trace” concepts at that level are directly linked
to the application ?eld (mechanical industry sector). When
applying our approach to another industrial sector, it is
interesting to underline that the structuring level of the on-
tology remains stable and only the parataxic level has to be
modi?ed. Furthermore, the concept classes of this ”domain
ontology” are characterised by sets of class instances. These
instances correspond to speci?c terms of the domains, used
as ”competence trace identi?ers”. They are directly used to
extract the pertinent information which is composed of the
company competence traces. Figure 3 partially illustrates
this domain’s ontology.
Figure 3. Parataxic level of the ontology (mechanical industry)
3) Operationalisation: This does implement a computer
version of the ontology for the application of inference
mechanisms. We have employed the competence trace on-
tology using OWL (Ontologie Web Language).
C. List of initial ontology concepts
The initial domain ontology contains a large number of
concepts, and the enrichment is a tedious task that requires
a lot of time. Consequently, in a ?rst time we chose to test
on a single conceptual domain of the initial ontology to
measure the performance of our approach. The initial list
of concepts described in Table IV-C.
In order to study what might be the best distance between
words and concepts to retain. Different experiments were
1116 2010 10th International Conference on Intelligent Systems Design and Applications
Table I
LIST OF INITIAL ONTOLOGY CONCEPT.
Initial Concepts
Assembly Production
Boiler Grinding
Turning Surface
Stamping Treatment
Manufacturing Thermal
Forging Process
Milling Usage
Laser Machining
Carry
conducted by varying the parameter of windows size from 1
to 5. Then, to extract the correlation relationships between
words, we use a version of the Apriori algorithm 3. In
experiments, the support was varied from 1 to 10%. After
analyzing the results, we have assumed a support of 1%,
and a window size of 4.
Table II describes the generated association rules. As
could be constated, the terms of the corpora correlated to
the concept of the ontology are discriminant for the domain
concerned. Thus, a provisional list of concept learned is
obtained.
Table II
EXEMPLE OF GENERATED ASSOCIATION RULES
Generated Association Rules
assembly ? injection (3.2, 100.0)
stampings ? cutting (4.0, 90)
forging ? Threading (1.7, 100.0)
forging ? simulation (1.9, 100.0)
area ? Metrology (2.1, 100.0)
area ? Welding (1.6, 100.0)
machining ? expertise (2.3, 100.0)
machining ? accuracy (1.8, 100.0)
machining ? installation (2.9, 100.0)
As we explained in the previous section, we eliminate
from this list the common terms (those correlated with
several initial concept for the same support value). Figure
IV-C shows a set of concepts learned. Due to the association
rules generated, we have not only identi?ed new candidate
terms as a concept of the ontology, but also have determined
the relations between the initial and the new concepts to be
automatically positioned in the ontology.
D. Discussion
As seen from, the fact of using windows where the
pivots words are the initial concepts of the ontology, and
the using nouns, verbs and adjectives enables to improve
considerably the detection of correlation in texts. In the
same way, the use of ?lters signi?cantly retained correlated
relevant concepts. It should be noted that our approach was
3http://?mi.cs.helsinki.?/?mi03/
Table III
EXEMPLE OF CONCEPTS LEARNED
Concepts Learned
Adjusting Cutting
Metal Injection
Metrology Assembly
Tools precision
expertise Welding
Molding Simulation
Turning Threading
suf?ciently automatic to be applied in various ?elds and thus
extract the signi?cant concepts elsewhere.
The ?rst results obtained are promising: we discovered
and placed suitably new concepts. The analysis of the
ontology obtained showed that the whole of the concepts
discovered is coherent since most of them could be attached
to ontology via the rules obtained. These results were also
validated by the expert of the ?eld.
V. PERSPECTIVES
Future work may entail in a broad series of projects and
initiatives. Firstly, our learning method depends on the qual-
ity of documents constituents the training corpora. Currently
it is created manually from a collection of sites. We would
like to extend our method of learning corpora creating by
generating a speci?c queries on the web according to a
speci?c criteria for the domain treated.
Secondly, our approach can naturally be extended by
enhancing learning. In this case, we have just to reconsider
the new concepts learned as initial concepts.
Thirdly, the work on this project will continue enrichment
on all the domain of the ontology and at the same time
validate obtained results either by a expert or by statistical
methods.
Finally, the extraction method is based on the generation
of association rules between concepts and words of texts.
We want to investigate whether the order between words can
affect the correlation. Traditionally, text mining approaches
normally rather uses the n-grams to consider the order
between words or characters. The advantage of n-grams is to
?nd words that are very close (i.e. based on the value of n).
The failure of these approaches in the context of data mining
is that the words most be consecutive to be validate. But this
does not always re?ect natural language structure. Our idea
is to extend the approach using the concept of sequential
patterns which extracts pertinent concepts that are close but
not consecutive.
VI. CONCLUSION
Many studies and applications have addressed the problem
of ontology enrichment, in developing approaches and tools
for building and updating of such resources. Often, the
operations of identi?cation and placement of new elements
2010 10th International Conference on Intelligent Systems Design and Applications 1117
in these semantic resources such as ontology, are made
manually.
In this paper, we present a new approach of ontology
enrichment based on data mining technics speci?cally
the association rules and the use of extracted semantic
information to retain relevant new concepts. Our approach
is based on three steps:
1) Preprocessing of a textual corpora (cleaning and lem-
matising: treetagger).
2) Creating window size to promote the correlation be-
tween corpora words and concepts of the ontology,
then the application of the APRIORI algorithm to
extract association rules according to validated param-
eters (support, con?dence).
3) Automatic analysing and semantic ?ltering of
generated rules to keep those that are relevant to the
initial domain ontology.
The obtained enrichment results seem auspicious for the
chosen domain ontology. This approach is sensitive to the
domain studied: it is important to have a corpora that
describes the subject domain accurately, so there is a very
rich language with nouns and adjectives available. Although
the company websites do not represent the ideal source for
building a such corpora for the domain studied (companies
competency in the mechanical industry), but we have had
promising results.
REFERENCES
[1] G. Berio and M. Harzallah, “Towards an integrating architec-
ture for competence management,,” in Special Issue: Compe-
tence Management in Industrial Processes, guest editors X.
Boucher, E. Bonjour, N. Matta, Computers in Industry, vol.
V58, issue 2, 2007.
[2] E. Ermilova and H. Afsarmanesh, “Modeling and manage-
ment of pro?les and competences in vbes,” Journal of Intel-
ligent Manufacturing, vol. V18, pp. 561–586, 2007.
[3] J. Hodik, J. Vokrinek, J. Biba, and P. Becvar, “Competences
and pro?les management for virtual organizations creation.”
CEEMAS, pp. 93–102, 2007.
[4] G. Pepiot, “Modlisation des entreprises sur la base des
comptences.” EPFL, PhD Thesis :, 2005.
[5] K. Neshatian and Hejazi, “Text categorization and classi?ca-
tion in terms of multi-attribute concepts for enriching existing
ontologies,” Proceedings of the 2nd Workshop on Information
Technology and its Disciplines, pp. 43–48, 2004.
[6] L. D. Jorio, L. Abrouk, C. Fiot, D. Hrin, and M. Teisseire,
“Enrichissement d’ontologie bas sur les motifs squentiels,”
Actes de la Plateforme AFIA 2007, Atelier Ontologies et
gestion de l’htrognit smantique, 2007.
[7] A. F. A and R. Steinmetz, “Ontology enrichment with texts
from the www,” Proceedings of the 2nd Semantic Web Mining
Workshop at ECMLI/PKDD, WS’02, 2006.
[8] G. Stumme and A. H. B. Berendt, “Semantic web mining
: State of the art and future directions,” Web Semantics :
Science, Services and Agents on the World Wide Web, vol.
4, n. 2, pp. 124–143, 2006.
[9] E. Agirre, O. Ansa, E. Hovy, and D. Martinez, “Enriching
very large ontologies using the www,” Proceedings of ECAI
2000 workshop on Ontology Learning, 2002.
[10] V. Parekh and J. G. T. Finin, “Mining domain speci?c texts
and glossaries to evaluate and enrich domain ontologies,”
Proceedings of the International Conference of Information
and Knowledge Engineering, 2004.
[11] R. Bendaoud, “Construction et enrichissement d’une ontolo-
gie partir d’un corpus de textes,” Actes des Rencontres des
Jeunes Chercheurs en Recherche d’Information (RJCRI’06),
Lyon, pp. 353–358, 2006.
[12] A. M. V. Pekar and S. Staab, “On discovering taxonomic
relations from the web,” Journal of Information Retrieval,
Contextual Information Retrieval Systems, vol. Springer Ver-
lag, pp. 301–322, 2002.
[13] N. Hernandez, J. Chrisment, and D. Egret, “Modeling context
through domain ontologies,” Journal of Information Retrieval,
Contextual Information Retrieval Systems, vol. 10, pp. 143–
172, 2007.
[14] R. Srikant and R. Agrawal, “Mining generalized association
rules,” Future Generation Computer Systems, vol. 13, n. 23,
pp. 161–180, 1997.
[15] E. Han and G. Karypis, “Centroid based document classi?ca-
tion : Analysis and experimental results,” Proceedings of The
4th European Conference of Principles of Data Mining and
Knowledge Discovery, pp. 424–431, 2000.
[16] K.Hajlaoui, X.Boucher, and J. J. Girardot, “Competency
ontology for network building,” 10th IFIP Working Confer-
ence on Virtual Entreprises (PRO-VE’09), vol. Thessaloniki,
GREECE, 2009.
[17] H. Schmid, “Probabilistic part-of-speech tagging using de-
cision trees,” Conference on New Methods in Language
Processing, Manchester, UK., 1994.
[18] R. Agrawal and R. Srikant, “Fast algorithms for mining
association rules in large databases,” VLDB’94, 1994.
[19] D. Downey, M. Broadhead, and O. Etzioni, “Locating com-
plex named entities in Web text,” In Proceedings of the
IJCAI07, pp. 2733–2739, 2007.
[20] M. Roche and V. Prince, “Acrodef : A quality measure for dis-
criminating expansions of ambiguous acronyms,” CONTEXT,
pp. 411–427, 2007.
[21] B. B. B, A. Isaac, and R. Troncy, “Semantic commitment
for designing ontologies,” In the proceedings of 13th EKAW
Conference LNAI of LN, vol. Arti?cial Intelligence Springer,
2473, pp. 114–121, 2002.
1118 2010 10th International Conference on Intelligent Systems Design and Applications
