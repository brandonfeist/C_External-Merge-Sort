Privacy Preservation in Transaction Databases based 
on Anatomy technique 
 
Yingjie Wu  
School of Computer Science and Engineering 
Southeast University 
Nanjing, China 
College of Mathematic and Computer Science  
Fuzhou University 
Fuzhou, China 
yjwu@fzu.edu.cn 
Shangbin Liao, Xiaowen Ruan, Xiaodong Wang 
College of Mathematics and Computer Science 
Fuzhou University 
Fuzhou, China 
N080320044@fzu.edu.cn 
 
 
 
 
 
Abstract—This paper considers the problem of privacy 
preserving transaction data publishing. Transaction data are 
usually useful for data mining. While it is high-dimensional data, 
traditional anonymization techniques such as generalization and 
suppression are not suitable. In this paper, we present a novel 
technique based on anatomy technique and propose a simple 
linear-time anonymous algorithm that meets the l-diversity 
requirement.  The simulation experiments on real datasets and 
the results of association rules mining on the anonymous 
transaction data showed that our algorithm can safely and 
efficiently preserve the privacy in transaction data publication, 
while ensuring high utility of the released data. 
Index Terms—l-diversity, anatomy technique, privacy 
preservation, association rules mining 
I.  INTRODUCTION  
Privacy preservation in transaction data publication is a 
hotspot issue in privacy-preserving data publishing. 
Transaction data consist of many aspects such as querying log, 
online shopping, supermarket transaction data and so on. 
Transaction data are usually used for data mining, including 
association rule mining [3], user behavior prediction and 
recommender systems. Therefore, when we publish data for 
scientific research, it must be anonymized so that malicious 
attacker cannot re-identify user’s privacy information. We first 
show two examples for re-identification on transaction data 
[10,11]. 
Example 1. Bob has bought some things in the supermarket, 
including bread, milk, biscuits, red wine, beef, ice-cream, light 
bulbs and home pregnancy test strips. Assume that some of the 
items purchased by Bob were on top of his shopping bag (e.g., 
bread, milk, light bulbs) and his neighborhood Alice was in the 
same bus. Bob would not want Alice to know what s/he has 
bought (i.e., home pregnancy test strips). But if the 
supermarket decides to release its transaction data and there is 
only one record containing bread, milk and light bulbs, then 
Alice can immediately refer that this record corresponds to Bob 
and s/he can find out the rest thing Bob purchased. 
 Example 2. AOL recently released a query log database [1, 
2], in analyzing these records, the No. 4417749 user was found 
as a 62-year-old widow Thelma Arnold who lives in Liburn. 
Although not a record that contains her address or name, but a 
malicious attacker can still re-identify the user’s personal 
information using items permutations and combinations. 
In these examples, the data holder publishes transaction 
data for research purposes. Each transaction record contains an 
arbitrary set of items. An item can be either public (i.e. bread, 
milk and light bulbs) or private (i.e. home pregnancy test strips). 
The attacker attempts to re-identify the subset of some 
transaction records. As background knowledge, the attacker 
knows that the target person (i.e., Bob) has a transaction record 
in the published data and certain public items (e.g., bread, milk, 
light bulbs). If there are very few transaction records containing 
these items, the re-identification will be successful. 
Many privacy models, such as k-anonymity [4,5,6], l-
diversity [7] and t-closeness [8], are used to prevent re-
identification attacks on low-dimensional relational data, but 
directly adopt these to high-dimensional unstructured data will 
not produce good results. These models anonymize the public 
attributes (i.e., quasi-identifiers) to prevent the attacker using 
link attack to infer the privacy of personal information. 
However, for transaction data, any attribute (i.e., item) 
permutations and combinations are considered as the attacker's 
background knowledge. Therefore, these models are not 
suitable to solve transaction data. Paper [9] pointed out that the 
high-dimensional data are more easily attacked by inference 
attack, and to achieve a degree of anonymity, a large number of 
data information will be lost. 
Traditionally there are two ways to achieve data anonymity: 
generalization and suppression. Generalization is to replace a 
value to a more general one, such as use drink to replace milk 
and beer. Suppression is to delete the existing record, so the 
user cannot see it in the publishing data. 
Currently there is only a few works to research privacy 
preservation in transaction data. [10] partitions high-
dimensional data set into private and public item set and 
proposed (h,k,p)-coherence model. Attacker's background 
knowledge can be viewed as a subset of public item set. 
(h,k,p)-coherence model requires that any item set whose 
978-1-4244-6005-2/10/$26.00 ©2010 IEEE 
The 5th International Conference on
Computer Science & Education
Hefei, China. August 24–27, 2010
 173 
WeP2.5
         
length is no more than p appear at least k times in the data and 
the probability that the attacker can get the personal 
information is not greater than h. The author uses suppression 
method to preserve privacy. [11] does not distinguish between 
public item set and private item set and all the item sets are 
viewed as potential public item set. Similarly, the attacker can 
get any subset of public item set as his background knowledge. 
The author proposed km-anonymity model, and use 
generalization method to solve the problem, but it costs too 
much to obtain the optimal solution. 
Example 3. In Table I, Table I (A) is the original table. 
Using the generalization hierarchy in Figure 1, under the 
condition of 52-anonymity, [11] generated the anonymous table 
in Table I (B). [10] generated the anonymous table in Table 
I(C). Item set {d,g} will be generalized in Table I (B) and item 
set {c,d,e,f,g,h} will be suppressed in Table I(C). 
TABLE I.  ORIGINAL MICRODATA TABLE AND ITS ANONYMIZATION 
USING VARIOUS ANONYMIZATION TECHNIQUES 
(A)THE ORIGINAL TABLE (B) THE GENERALIZED 
TABLE (52-ANONYMITY) 
(C) THE 
SUPPRESSED TABLE 
(52-ANONYMITY) 
TID Items 
1 a,b,c,d,e,f,g,h 
2 a,b,d,e,h 
3 a,b,c,f,h 
4 a,b,f,h 
5 a,b,c,d 
6 a,b,c,e 
7 a,e,f,g 
8 b,f,h 
9 f,h 
10 d,g 
 
TID Items 
1 (a,b,c,d,e), (f,g,h) 
2 (a,b,c,d,e), (f,g,h) 
3 (a,b,c,d,e), (f,g,h) 
4 (a,b,c,d,e), (f,g,h) 
5 (a,b,c,d,e) 
6 (a,b,c,d,e) 
7 (a,b,c,d,e), (f,g,h) 
8 (a,b,c,d,e), (f,g,h) 
9 (f,g,h) 
10 (a,b,c,d,e), (f,g,h) 
 
TID Items 
1 a,b 
2 a,b 
3 a,b 
4 a,b 
5 a,b 
6 a,b 
7 a 
8 b 
9  
10  

(D) THE MULTI-ANATOMIED 
TABLE(2-DIVERSITY) 
(E) THE MULTI-ANATOMIED 
TABLE(2-DIVERSITY) 
TID Items 
1 d,e,f,h a,b,c,g 
2 d,e,h a,b 
3 f,h a,b,c 
4 f,h a,b 
5 d a,b,c 
6 e a,b,c 
7 e,f a,g 
8 f,h b 
9 f,h  
10 d g 
 
TID Items 
1 d,f,h b,e,g a,c 
2 d,h b,e a 
3 f,h b a,c 
4 f,h b a 
5 d b a,c 
6  b,e a,c 
7 f e,g a 
8 f,h b  
9 f,h  a,c 
10 d g a 
 

 
Figure 1.  Generalization hierarchy for the Table I (B) 
When we use association rules analysis in Table I(B) and 
Table I(C), it’s easy to find out that generalization usually loss 
less information than suppression from data mining view. 
Suppression is usually considered as the highest generalization. 
These two methods all modify the original data. 
[12] proposes a simple and effective technique called 
anatomy to preserve privacy. In [12], anatomy releases all the 
quasi-identifier and sensitive values directly in two separate 
tables, met the l-diversity privacy requirement, we need not do 
any modification in the original table. The extensive 
experiments in [12] conrm that anatomy technique allows 
signicantly more effective data analysis than the conventional 
publication method based on generalization. The query 
accuracy of anatomy is unaffected by the dataset 
dimensionality, where as the accuracy of generalization decays 
severely as dimensionality increases. Furthermore, anatomized 
tables can be computed much faster than generalized tables. 
Transactional data is high-dimensional data, and our goal is to 
adopt this technique to transaction data. 
However, anatomy requires a clear separation between 
quasi-identifiers and sensitive attributes, for transaction data, 
we can not completely distinguish quasi-identifier between 
sensitive attributes. Therefore, we modified anatomy technique 
so that it can be used in transaction data. 
The remainder of the paper is organized as follows. In 
section 2, the preliminaries for our method are reviewed. In 
section 3, the privacy preservation model based on anatomy 
technique is proposed. A linear-time anonymous algorithm is 
illustrated in section 4. The experimental results of the 
proposed algorithms are argued in section 5. In section 6, we 
conclude the paper and discuss future work. 
II. PRELIMINARIES 
Definition 1 (p-item set). Let $={I1,I2,? ,Im} be the set 
consist of m different items where each item Ik(k=1,2,?,m) is 
equivalent to a attribute. Let D={T1,T2,? ,Tn} be the n 
transaction records in transaction data. Record Ti (i=1,2,?,n) is 
also called item set. Each record Ti is a subset of attributes and 
Ti ? A. The length of item set is the number of items in the 
item set. If the length is p, this item set is called p-item set. 
Definition 2 (item partition and columns). An item partition 
consists of several subsets of A, and each item belongs to 
exactly one subset. Each subset of items is called a column. Let 
there be p columns C1,C2,…,Cp, then AU pi ==1  and for any 1
?i?j?p, ?=? ji CC . 
In transaction data, it is difficult to distinguish quasi-
identifier between sensitive attributes. In this paper, we view 
each item in transaction data as the same type that is quasi-
identifiers.  
Definition 3 (record partition and buckets). A record 
partition consists of several subsets of D, and each record 
belongs to exactly one subset. Each subset of record is called a 
bucket. Let there be q buckets B1,B2,…,Bq, then DU qi ==1  
and for any 1?i?j?q, ?=? ji BB . 
 174 
WeP2.5
         
Definition 4 (multi-dimension anatomy). Given a 
transaction table T, a multi-dimension anatomy of T consists of 
item partition and record partition. 
Definition 5 (l-diverse multi-dimension anatomy). A multi-
dimension is l-diverse, if each bucket Bi(1?i?q) satisfies the 
following conditions. Let vij be the most frequent item set in 
bucket Bi and column Cj, and c(vij) the number of records with 
T[Cj] = vij; then  
c(vij)/|Bi|?1/l                                             (1) 
where |Bi| is the size (the number of records) of Bi. 
Example 4. Table I(D) and Table I(E) are two multi-
dimension anatomy table. In Table I(D), the item partition is 
{{d,e,f,h},{a,b,c,g}}, and the record partition is 
{{t1,t2,t3,t4,t5},{t6,t7,t8,t9,t10}}. In Table I(E), the item partition is 
{{a,c},{b,e,g},{d,f,h}}, and the record partition is 
{{t1,t2,t3,t4,t5},{t6,t7,t8,t9,t10}}. In Table I(E), item {b} appears 3 
times and |B1| equal to 5, while 3/5?1/2, so Table I(E) satisfies 
2-diverse multi-dimension anatomy. Similarly, Table I(D) 
satisfies 2-diverse multi-dimension anatomy too. 
Definition 7 (matching buckets). Let C1,C2,…,Cp be the p 
columns of a multi-dimension anatomy table. Let t be a record, 
and t[Ci] be the Ci value of t. Let B be a bucket in the anatomy 
table, and B[Ci] be the multiset of Ci values in B. We say that B 
is a matching bucket of t iff for all 1?i?p?t[Ci]?B[Ci]? 
III. PRIVACY PRESERVATION MODEL BASED ON ANATOMY 
TECHNIQUE 
In this section, we show how multi-dimension anatomy can 
be used to prevent privacy leak, based on the privacy 
requirement of l-diversity. 
LEMMA 1. Given an l-diverse multi-anatomy transaction 
table T, let vij be the most frequent item set in bucket Bi and 
column Cj, and c(vij) the number of records with T[Cj] = vij. 
The attacker attempts to get the privacy information in column 
Cj, when s/he gets the information in other column except 
column Cj. Then, from the attacker’s perspective, 
              Pr{T[Cj]=vij}=c(vij)/|Bi|.                                     (2) 
PROOF. Consider any record t?D, while t does not 
contain the information in column Cj. The attacker who 
attempts to get the privacy information in column Cj, however, 
does not have the column Cj data. Hence, the attacker can only 
conjecture that equals one of the values in column Cj. Without 
any other information, the attacker assumes that every item in 
column Cj has an equal probability, which leads to (2). 
Example 5. Table I(E) satisfies the 2-diverse multi-
dimension anatomy. Consider the item set {d,f,h} in t2. To 
determine the privacy information of t2, we have to examine 
t2’s matching buckets. When we examine C1 in Table I(E), we 
knows that t2 must be in the first bucket B1, because there are 
no matches items in bucket B2. Therefore, we can conclude that 
t2 must be in bucket B1. Then, by examining the second column 
C2 in bucket B1, we know that the column value for t2 must be 
either {b},{b,e} or {b,e,g}. Therefore, the probability of 
learning the information of t2 is bounded by 1/3. By examining 
the third column C3 in bucket B1, we know that the column 
value for t2 must be either {a} or {a,c}. Therefore, the 
probability of learning the information of t2 is bounded by 1/2. 
Totally, the probability to determine t2 is equal to 1/3*1/2=1/6. 
COROLLARY 1. Given an l-diverse multi-anatomy 
transaction table T, the attacker can correctly re-construct any 
record t?D with a probability at most 1/l. 
PROOF. Record t is correctly re-constructed. If and only if 
the attacker precisely obtains the all information otherwise the 
column Cj, when s/he attempts to infer the information in Cj 
column, by (2), we know that  Pr{T[Cj]= vij}=c(vij)/|Bi|, where 
Bi is the unique bucket containing t. Recall that table T is 
obtained from a l-diverse multi-dimension partition(Definition 
5). Hence, by (1), c(vij)/|Bi|?1/l.  
THEOREM 1. Given an l-diverse multi-anatomy 
transaction table T, the attacker’s background knowledge is no 
more than p columns, he/she can correctly infer the information 
in other columns with a probability at most 1/l. 
PROOF. Let column Cj be the privacy information the 
attacker attempts to obtain, let record o be the attacker’s 
background knowledge. Consider record o is equivalent to 
those of totally f records t1,t2,…,tf in table T. Assume that 
record ti(1?i?f) belongs to bucket ijB (1? ij ?q, 1?i?f), 
where q is the total number of buckets. Let vreal be the real 
column Cj value of record o. 
The attacker infers vreal in two steps. First, s/he guesses that 
each of t1,…,tf belongs to o with probability 1/f. Then, by 
Lemma 1, s/he figures out that vreal is the column Cj value of 
record o with probability ( )
ii jrealj
Bvc / . Hence, the overall 
probability that the column Cj value of record o is inferred 
equals 
( ) ( )
ii j
f
i
realj Bfvc ?
=
/
1
 
Recall that, by the property of l-diverse multi-dimension 
anatomy(Definition 5), ( )
ii jrealj
Bvc / ?1/l. Hence, the above 
formula is at most ( ) lf
i lf
/1
1
11
=?

=
. 
THEOREM 2. Given an l-diverse multi-anatomy 
transaction table T that has p columns, each bucket at lease 
introduce as many as lp records (true record and faked record). 
PROOF. After l-diverse multi-dimension anatomy, for a 
bucket Bi, we can re-construct |Bi|p records through 
permutations and combinations. Recall the property of l-diverse 
multi-dimension anatomy(Definition 5), the number of 
different item set for each column in each bucket is at least l, so 
we would get as many as lp records. 
 175 
WeP2.5
         
IV. ANONYMOUS ALGORITHM BASED ON ANATOMY 
TECHNIQUE 
In this section, we show an effective anonymous algorithm 
based on anatomy technique that meets the privacy requirement 
of l-diversity. Our algorithm consists of two phases: item 
partition and record partition. 
A. Item partition 
Our algorithm first split item set so that highly-correlated 
item set are in the same column. It is helpful to data utility and 
privacy. For data utility, grouping highly-correlated item set 
together helps protect the relationship between item set. For 
data privacy, the association of uncorrelated item set presents 
high identification risks because its values is much less 
frequent and thus more vulnerable to attack.  
1) Correlation measure 
Mean-square contingency coefficient [13] is used for 
measuring correlations between two categorical attributes. We 
choose to use this measure because the transaction data can be 
viewed as categorical attributes containing only two values. 
Given two attributes I1 and I2 with value domains {u1,u2,…,ud1} 
and {v1,v2,…,vd2} respectively. Their domain sizes are d1 and 
d2. The mean-square contingency coefficient between I1 and I2 
is defined as: 
( ) ( )

= =
?
??
?
=
1 2 2
21
1 1
1},min{
1
21
2 ,
d
i
d
j
ff
fff
dd ji
jiijII?                      (3) 
Here, fi and fj are the fraction of occurrences of ui and vj in 
the data, respectively. fij is the fraction of occurrences of ui and 
vj in the data. For transaction data, the dimension is very large, 
but only contains two value 0 and 1, 0 indicates there is no 
value in this item and 1 indicates there is a value in this item. 
So (3) can be rewritten as: 
( ) ( )
ji
jiij
ff
fffII
?
??
=
2
21
2 ,?
                                  (4) 
Here, fi and fj are the fraction of occurrences of ui=1 and 
vj=1in the data, respectively. fij is the fraction of occurrences of 
ui=1 and vj=1 in the data. Because value 0 is meaningless, so 
we only calculate the value 1. It is easy to know 
that ( ) 1,0 212 ?? II? . 
2) Item clustering 
Having computed the relationship between each pair of 
attributes, we use clustering to divide attributes into columns. 
In our algorithm, each item is a point in the clustering space. 
The distance between two items is defined as d(I1,I2)=1-( )212 , II? . When two attributes are highly-correlated, the 
distance between them is smaller. 
We use the k-medoid methods to achieve item clustering. 
We use the well-known k-medioid algorithm PAM (Partition 
Around Medoids) algorithm [14]. PAM algorithm first 
randomly select k objects as the initial medoids, the remaining 
points will be assigned to the nearest medoid. Then, PAM 
chooses one medoid point and one non-medoid point and 
swaps them as long as the cost of clutering decreases. Here, the 
clustering cost is measured as the sum of the cost of each 
cluster, which is measured as the sum of the distance from each 
non-medioid point to the medoid point in the same cluster. 
When no points can be swapped, program terminates. PAM's 
time complexity is O((m-k)2), where m is the size of attributes 
and k is the number of cluster. PAM is suitable only for small 
amounts of data, however, the cluster space here is the number 
of attributes, therefore, PAM will not cost too much. 
B. Record partition 
In the record partition phase, records are partitioned into 
buckets. Here we use a simple linear-time algorithm to handle 
record partition. Our algorithm is described in Figure 2. 
Algorithm Multi-Anatomy(T,l,C,p) 
1. Multi-B= ? ; Bcnt = 0;  
2. Initialize p hash buckets Hi(1?i?p) 
3. For each record t in T  
4. For each column Ci in t, hash its value in hash buckets Hi 
5. if the most frequent value in each Hi satisfy c(Hi)/|Hi|?1/l 
6.     BBcnt=all record t in hash buckets Hi 
7.     Multi-B=Multi-B?BBcnt 
8.     Bcnt=Bcnt+1 
9.     Clear all hash buckets 
10.For each non-empty hash bucket  
11.    t=the record in hash bucket 
12.   assign t to a random bucket in Bi if the most frequent 
value in each column Cj of Bi satisfy c(vij)/|Bi|?1/l when add t  
13.Retrun Multi-B 
Figure 2.  Anonymous algorithm 
At first, we initialize p hash buckets where p is the number 
of columns (line 1-2). Then we scan each record in the 
transaction table T, for each column we hash its value in the 
corresponding hash bucket. If the table after partitioning 
satisfies l-diversity (line 3-5), we add the records in hash 
bucket to Multi-B where Multi-B is the union of each buckets. 
Then we clear all hash buckets (line 6-9). Finally, we randomly 
assign the left records to bucket if it satisfies l-diversity (line 
10-12). After that, the function returns the result Multi-B. 
We now analyze the time complexity of the record partition. 
We use p hash bucket and the complexity of hash is O(1). And 
we only scan each record once which takes O(n) time where n 
is the number of records. Totally, the time complexity of our 
algorithm is O(n)+O(m), for m<<n, so the total time 
complexity is therefore O(n). 
V. EXPERIMENTS 
In this section, we evaluated experimentally the proposed 
anonymization techniques. We evaluated three aspects: privacy 
leakage, data utility and execution time. 
A. Experimental setup  
The experiments were performed on a 2.66 GHz Intel IV 
processor machine with RAM of 1 GB. The operating system 
was Windows XP Professional Edition, and the implementation 
was built and run in Visual C++ 6.0. We used two different 
datasets: Connect and T40I10D100K, all can be publicly 
 176 
WeP2.5
         
available from FIMI Repository (http://fimi.cs.helsinki.fi/data/). 
Connect is a real dataset containing game state information. 
T40I10D100K is a synthetic dataset. T40I10D100K have a 
very large item set that is extremely larger than a relation table. 
Table II provides a brief description of these datasets. 
TABLE II.  DATASET STATISTICS
Dataset Transactions|D| Average Length Items 
Data 
size(K 
bytes) 
Connect 67,557 43 129 9,225 
T40I10D100K 100,000 39.6 942 15,478 
 
In our algorithm, attributes are partitioned into two or more 
columns. For a bucket that contains k records and p columns, 
we generate k records as follows. We randomly permutated the 
values in each column because many data mining algorithms 
cannot handle anatomy table well currently. 
B. Privacy leakages 
By Theorem 2, through l-diversity multi-dimension 
anatomy a table is partition into p columns. The number of 
faked records would be very large.  
Figure 3 is the number of faked records of T40I10D100K. 
As expected, the number of faked records is so large that we 
have to use function ln. As shown in the figure 3, when we 
increase the value of l where l is the l-diverse, the number of 
fake records becomes larger. In particular, when we increase 
the value of p where p is the number of columns, the number of 
fake records becomes exponentially larger.  
Figure 3.  Number of faked records of T40I10D100K 
C. Data utility 
In data utility, we use Apriori algorithm to mining 
association rules of anonymous data. 
Because Connect is very dense, so we limit the length of 
association rules where the minimum length is 2 and maximum 
length is 4. Figure 4 shows the number of association rules of 
the anonymous data Connect when p=10, l=5,6,8,10. It shows 
that the different between anonymous data and original data is 
much small indicating that our algorithm for dense date set 
introduces little information. 
Figure 5 shows the number of association rules of the 
anonymous data T40I10D100K when p=20,l=6,8,10,12. It 
shows that when the confident is low, such as confident=10%, 
the difference between anonymous data and original data is 
very small. When confident increases, the gap increases slowly, 
but the difference usually maintain at 40% -60%. 
Figure 4.  Number of association rules of Connect  
Figure 5.  Number of association rules of T40I10D100K  
Figure 6.  Accuracy radio of T40I10D100K 
 177 
WeP2.5
         
The number of association rules is part of data utility, the 
correct number of association rules is also a key part of data 
utility.  
So we introduce the following equation AR (accuracy radio) 
= M / N where N is the number of association rules for original 
data and M is the number of common association rules for 
anonymous data. 
Figure 6 is the accuracy radio of T40I10D100K. It shows 
that, when confident decreases, the accuracy radio increases. 
Because our algorithm losses the information of unusual 
association rules while maintains the information of usual 
association rules. 
D. Execution time 
Figure 7 is the time cost of T40I10D100K. It shows that our 
algorithm is very efficient, when the l value increases, the time 
cost will slightly increases because it costs a little more time to 
meet l-diversity. 
Figure 7.  Time Cost of T40I10D100K 
VI. CONCLUSION AND FUTURE WORK 
In this paper, we study the privacy issues in transaction data 
publication. Based on anatomy technique, we propose a new 
privacy model called multi-dimension anatomy that meets the 
privacy requirement of l-diversity and suits to transaction data. 
We introduce a simple linear-time anonymous algorithm. 
Experiments show that our algorithm can safely and effectively 
protect privacy in transaction data. 
There are still a number of promising areas for future work. 
First, the linear-time algorithm proposed in this paper seems a 
little simple, some new heuristic algorithm needs to further 
research. Second, while an anatomized table has been 
generated, it remains an open problem on how to use the 
anonymized data. 
ACKNOWLEDGMENT 
The authors gratefully acknowledge financial support for 
this research by the NFS of Fujian Porvince under grants No. 
2009J01295, the NFS of Fujian Province under grants No. 
2010J01330 and scientific project of Fujian Provincial 
Department of Education under grants No. JA09004. 
REFERENCES 
[1] K. Hafner. Researchers Yearn to Use AOL Logs, but They Hesitate. 
New York Times, August 23, 2006. 
[2] M. Barbaro, T. Zeller and S. Hansell. A Face Is Exposed for AOL 
Searcher No. 4417749. New York Times, Aug 9, 2006.  
[3] R. Agrawal, T. Imielinski, and A. N. Swami. Mining  Association Rules 
between Sets of Items in Large Databases. SIGMOD 1993.   
[4] P. Samarati and L. Sweeney. Protecting privacy when disclosing 
information: k-anonymity and its enforcement through generalization 
and suppression. Technical report, CMU, SRI, 1998. 
[5] L. Sweeney. Achieving k-anonymity privacy protection using 
generalization and suppression. International journal on uncertainty, 
Fuzziness and knowldege based systems, 10(5):571 – 588, 2002. 
[6] L. Sweeney. k-anonymity: a model for protecting privacy. International 
journal on uncertainty, Fuzziness and knowldege based systems, 
10(5):557 – 570, 2002. 
[7] A. Machanavajjhala, J. Gehrke, and D. Kifer. l-diversity: privacy beyond 
k-anonymity. In To appear in the 22st International Conference on Data 
Engineering (ICDE06), 2006. 
[8] N. Li, T. Li, and S. Venkatasubramanian. t-closeness: Privacy beyond k-
anonymity and l-diversity. In Proc. of the 21st IEEE International 
Conference on Data Engineering (ICDE), Istanbul, Turkey, April 2007. 
[9] C. C. Aggarwal. On k-Anonymity and the Curse of Dimensionality. In 
VLDB, pages 901–909, 2005. 
[10] Y. Xu, K. Wang, A. W. C. Fu, and P. S. Yu. Anonymizing transaction 
databases for publication. In Proc. of the 14th ACM SIGKDD, August 
2008. 
[11] M. Terrovitis, N. Mamoulis and P. Kalnis. Anonymity in unstructured 
data. Technical Report, Hong Kong University, 2008. 
[12] X.Xiao and Y.Tao. Anatomy:simple and effective privacy preservation. 
In VLDB,2006,pages139–150. 
[13] H.Cramt’er. Mathematical Methods of Statistics. Princeton,1948. 
[14] L.Kaufmanand P.Rousueeuw. Finding Groups in Data: an Introduction 
to Cluster Analysis.John Wiley &Sons,1990. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 178 
WeP2.5
