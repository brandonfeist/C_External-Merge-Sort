 A New Method for Eliminating Redundant Association Rules 
 
Ye Xin, Wang Na 
Institute of Information and Decision Technology 
Dalian University of Technology 
Dalian, P.R.China 
yejstar@gmail.com 
Wang Chunyu, 
Science&Technology Department of  
Dalian Bureau of Public Security  
PHD in Dalian University of Technology 
wcy1969@hotmail.com 
 
 
Abstract—As one of the fundamental data mining methods, the 
association rule mining has widely been used in many fields. 
However, the existence of massive redundant rules has made 
the analysis very difficult, and has been a main barrier to 
efficient utilization of discovered association rules. This paper 
studies the characteristic of commonsense knowledge which is 
use to eliminate redundant association rules, and analyzes the 
impact of commonsense knowledge and the special rules whose 
confidence is 100% on the generation of redundant rules. Some 
theorems and corollaries of redundant rules are proposed and 
a new method for eliminating redundant rules based on these 
theories is proposed. This new method can prune some 
redundant rules by using commonsense knowledge and the 
special rules without calculating confidence, so it improved the 
efficiency of mining and the utilization of discovered 
association rules. 
Keywords-Association Rule Mining; Redundant Rules; 
Commonsense Knowledge 
I.  INTRODUCTION 
Association rule mining was proposed for the first time 
in 1993 [1], and today this method as a prominent data 
analysis tools has widely been used in many fields such as 
network intrusion detection [2], customer relationship 
management [3], analysis of traffic accidents [4], medical 
diagnosis [5], protein structure analysis [6] and so on. 
However, the existence of massive redundant rules has 
made the analysis very difficult, and has been a main barrier 
to efficient utilization of discovered association rules. Many 
meaningless rules are easily generated even with a high 
support and confidence threshold [7]. This paper is 
concerned with the following two types of meaningless 
rules: firstly, some rules correspond to the prior knowledge, 
thus they are meaningless for end user to make decisions [7]. 
This kind of rules is called the first redundant rule in this 
paper. Secondly, some rules are considered to be 
meaningless when the information or knowledge conveyed 
in which corresponds to or is covered by other discovered 
rules [12]. This kind of rules is called the second redundant 
rule in this paper. 
Many previous works have paid attention to eliminate 
redundant rules. The method using metadata information to 
eliminate redundant rules was proposed in [8]. The methods 
using semantic knowledge to eliminate redundant rules were 
proposed in [9][10]. The methods for eliminating the second 
redundant rules were proposed in [11][12][13][14][15].But 
those studies don’t consider the following questions: Which 
kind of prior knowledge can be used to eliminate redundant 
rules? What is the characteristic of this knowledge? What is 
the impact of this kind of knowledge or the special rules (in 
this paper, the “special rules” refers to the discovered 
association rules whose confidence is 100%) on the 
generation of the second redundant rules? Based on those 
questions and research results mentioned above, this paper 
proposes a new method for eliminating redundant rules by 
using commonsense knowledge and the special rules. 
The remainder of this paper is organized as follows. In 
section 2, this paper presents a brief introduction of 
association rule mining. In section 3, this paper presents the 
characteristic of commonsense knowledge and some 
theorems and corollaries of redundant rules. In section 4, a 
new method for eliminating redundant rules is proposed in 
detail. In section 5, a practical example proves the effective 
of this new method, and then conclusion is described in the 
last section. 
II. ASSOCIATION RULE MINING 
The association rule mining task can be stated as follows: 
let D be a transaction dataset, and let ^ `1 2 3, , ... nI x x x x 
i
 
be the items appear in the dataset. We denote an itemset 
contains i items as X x ? i where x X? . We denote 
transaction set, in which each transaction contains 
itemset X , as , note 
that
( )t X
( ) ( ) ( )i it X t x t x ?  ?
( )t X
( )i i
,i.e., the transaction set 
can be generated by intersection operation of 
transaction set t x ,where x  is the each item in itemset 
X .We use the notation t X  to refer transaction 
set is the subset of 
( ) ( )i jt X?
( )it X ( )jt X . We use notation D  to 
refer the number of transactions in the dataset, use notation 
( )t X to refer the number of transactions that contain 
itemset X . 
An association rule is an expression A Bo , where A(B) 
is an itemset. Two important constraints of association rule 
mining are support and confidence [1], where 
( )
sup ( )
t AB
port A B
( )
( )
( )
t AB
confidence A B
t A
o  , . An 
D
o  
2010 International Conference on Intelligent Computation Technology and Automation
978-0-7695-4077-1/10 $26.00 © 2010 IEEE
DOI 10.1109/ICICTA.2010.129
32
 association rule is considered to be a strong rule if 
 and , 
where min_sup and min_conf are user-specified minimum 
thresholds. More detailed instructions about association rule 
mining methods can be found in 
sup ( ) min_ support A Bo t ( ) min_coconfidence A Bo t nf
?
? ?
[12][16]
III. REDUNDANT ASSOCIATION RULES 
A. The First Redundant Rules 
Rules are considered to be no interesting if they 
correspond to prior knowledge [7]. Commonsense 
knowledge is one kind of prior knowledge, and has 
following characteristics: 
I) Necessity: If the antecedent of knowledge occurs the 
consequent of knowledge will inevitably occur and the 
consequent has the unique value. This characteristic can be 
expressed in the form of association rule like 
, where CK.A stands for 
the antecedent of commonsense knowledge; CK.C stands 
for the consequent of commonsense knowledge. CK.A and 
CK.C may be a (an) concept (behavior, object, attribute) or 
a (an) concept (behavior, object, attribute) set. 
( . . ) 100%confidence CK A CK Co  
II) Correctness: The probability that CK.C occurs given 
that CK.A has occurred is 100%, and in most case, this value 
is correct.  
III) Universality: Commonsense knowledge is widely 
known, or in some professional fields, it is familiar for the 
most of users in those fields. 
Commonsense knowledge is widely accepted as correct, 
it may be the axiom, the theorem, the relationship between 
the object and its essential attribute, or the accumulate 
experience that has be proved to be right by practice and so 
on. For example, ?
?  are all 
commonsense knowledge.  
apple fruito? ? ?
chlorine is toxico? ? ? lady femaleo? ? ?
According to the characteristics of commonsense 
knowledge, the following definition is proposed. 
Definition 1?Rule A Bo  is the first redundant rule if 
 and.A CK A .B CK C . 
B. The Second Redundant Rules 
If all the rules in a collection R have the same support 
and confidence, the simplest rules in the collection should 
suffice to represent the whole set. Thus the non-redundant 
rules in the collection R are those most general, i.e., those 
having minimal antecedents and consequents [12] , and the 
other rules in the collection are redundant rules. Three 
theorems about the second redundant rules are proposed as 
follows. 
Theorem 1: If  then the 
rule
confidence A Xo? ? 
AX o B  is equivalent to the rule A Bo  and is the 
second redundant rule. 
Proof: 
If , it means that X always 
occurs in the transaction where  occurs, put another way, 
the transaction set where A  occurs must be a subset of the 
transaction set where X occurs. This is can be given as 
confidence A Xo? ? 
A
( ) ( )t A t X? [12]. 
( ) ( ) ( ) ( )
( ) ( ) ( ) ( ) ( ) ( )
( ) ( )
( ) ( )
sup ( )
sup ( )
( ) ( )
( )
( ) ( )
( )
rule has the same support and confid
t AX t A t X t A
t ABX t AX t B t A t B t AB
t ABX t AB
t AXB t AB
port AX B
D D
port A B
t AXB t AB
confidence AX B
t AX t A
confidence A B
AX B
?  ?  
?  ?  ?  
?  
? o   
 o
o   
 o
? o ence
with rule and rule has minimal antecedent
is redundant rule.
A B A B
AX B
o o  
? o
?
Theorem 2: If  then the 
rule  is equivalent to the rule and is 
redundant rule. 
100%confidence A Xo  ? ?
B AXo B Ao
Proof? 
( ) 100%
( ) ( )
( ) ( ) ( ) ( )
( ) ( ) ( ) ( ) ( ) ( )
( ) ( )
( ) ( )
sup ( )
sup ( )
( ) ( )
( )
( ) ( )
( )
confidence A X
t A t X
t AX t A t X t A
t ABX t AX t B t A t B t AB
t ABX t AB
t AXB t AB
port B AX
D D
port B A
t AXB t AB
confidence B AX
t B t B
confidence B A
o  
? ?
?  ?  
?  ?  ?  
?  
? o   
 o
o   
 o
'
 
rule has the same support and confidence
with rule and rule has minimal consequent
is redundant rule.
B AX
B A B A
B AX
s 
? o
o o
? o
?  
Theorem 3: If  then the 
rule
100%confidence A Xo  ? ?
A BXo  is equivalent to the rule A Bo  and is the 
second redundant rule. 
Proof: 
33
 ( ) 100%
( ) ( )
( ) ( ) ( ) ( )
( ) ( ) ( ) ( ) ( ) ( )
( ) ( )
( ) ( )
sup ( )
sup ( )
( ) ( )
( )
( ) ( )
( )
rule
confidence A X
t A t X
t AX t A t X t A
t ABX t AX t B t A t B t AB
t ABX t AB
t AXB t AB
port A BX
D D
port A B
t AXB t AB
confidence A BX
t A t A
confidence A B
A
o  
? ?
?  ?  
?  ?  ?  
?  
? o   
 o
o   
 o
?
'
has the same support and confidence
with rule and rule has minimal consequents.
is redundant rule.
BX
A B A B
A BX
o
o o  
? o
?
 
From the characteristics of commonsense knowledge we 
have know that , so we 
can get the following corollaries: 
( . . ) 100%confidence CK A CK Co  
Corollary 1: 
Rule is equivalent to the 
rule , and is the second redundant rule. 
. .CK A CK C B? o
.CK A Bo
Corollary 2: 
Rule is equivalent to the 
rule , and is the second redundant rule. 
.B CK A CK Co ? .
.
.B CK Ao
Corollary 3: 
Rule is equivalent to the rule 
 and is the second redundant rule. 
.CK A B CK Co ?
.CK A Bo
IV. A NEW REDUNDANT RULE ELIMINATE METHOD  
Based on the theorems and corollaries proposed in 
section 3, a new method for eliminating redundant 
association rules is proposed in detail in this section. This 
method can eliminate two kinds of redundant rules by using 
commonsense knowledge and the special rules without 
calculating confidence (as shown in Figure 1). 
x Step1: Preprocess data and find all frequent itemset 
using Apriori algorithm method. 
x Step2: For each frequent itemset , judge whether can 
generate redundant rule with commonsense 
knowledge and the special rules  
x Step3: If a frequent itemset will not generate 
redundant rules then calculate confidence and output 
strong association rules and store the rules whose 
confidence is 100% into the RB, where RB stands 
for Rule Base which is used to store the special rules. 
Note that the simple commonsense knowledge such as 
the hierarchical relationship among objects, or the attribute 
relationship between an object and its attribute can be 
inferred by using domain ontology (ontology is a formal 
representation of a set of concepts within a domain and the 
relationships between those concepts. It is used to reason 
about the properties of that domain, and may be used to 
define the domain [17]) and inference rules. The other 
complex knowledge can be inputted by users .Both two 
kinds of commonsense knowledge are stored in KB, where 
KB stands for Knowledge Base which is used to store 
commonsense knowledge. 
 
Figure 1 A new method for eliminating redundant rules 
The redundant rule eliminate algorithm is the core part 
of this new method, and can be described as follows. 
Algorithm: Generate non-redundant association rules 
Input: Lkmin_conf, KB, RB  //Lk is frequent k-itemsets; 
Output: non-redundant association rules
Method: 
RB  ? ; 
for each Kl L?  {      // l  is a k-itemset in LK.
for each s l?  {      //  is the subset of l . s
if (! ( , , )RedundantRuleJudging l s KB ) then{ 
if RB  ?  then 
( , ,min_ , )GenerateRule l s conf RB ; 
else if (! ( , , )RedundantRuleJudging l s RB ) then 
( , ,min_ , )GenerateRule l s conf RB ; 
} 
34
 } 
} 
( , , )RedundantRuleJudging l s base 
//Judge whether itemset l will generate redundant rules. 
boolean flag=FALSE; 
for each r in base { 
//r is a commonsense knowledge or a special rule 
//stored in base. 
if   . .s r antecedent r consequent ?
       flag=TRUE; 
if  . .l s r antecedent r consequent  ?
       flag=TRUE; 
      if ( .s r antecedent ) and ( .r consequent l s?  ) 
flag=TRUE ; 
return flag; 
} 
( , ,min_ , )GenerateRule l s conf RB 
//generate strong association rules and store the rules whose 
//confidence is 100% into RB. 
RULE r=new RULE (); //instantiate a new rule. 
if ( ) min_
( )
t l
conf
t s
t  then{ 
.r antecedent s ; 
.r consequent l s  ; 
.sup ( )r port t l ; 
( )
.
( )
t l
r confident
t s
 ; 
output r ; 
if  then . 100%r confidence  
add r into RB; 
} 
V. EXPERIMENTAL RESULT 
We performed the experiment on real datasets which are 
from the fraud cases database (2007-2008) of city Y .The 
confidence threshold was set to 65%.Figure 2-3 show the 
effect of pruning for the discovered association rules. 
We have got the commonsense knowledge that “in city 
Y, region A and region B both are the city proper”. Among 
rule 14-16(as shown in figure 2), rule 15 is identified to be 
redundant rule according to Corollary 1; and rule 16 is 
identified to be redundant rule according to Corollary 3. 
Both of them should be eliminated. 
14. Region=B 504 ==> Criminal Motive=covet wealth 493    
conf :( 0.98) 
15. Region=B Region Attribute = city proper 504 ==> 
Criminal Motive=covet wealth 493    conf :( 0.98) 
16. Region=B 504 ==> Criminal Motive=covet wealth 
Region Attribute = city proper 493    conf :( 0.98) 
Figure 2 Rule 14-16 
Because rule 5 has the confidence of 100%, among 
rule29-31 (as shown in figure 3), rule 30 is identified to be 
redundant rule according to Theorem 1, and rule 31 is 
identified to be redundant rule according to Theorem 3 . 
Both of them should be eliminated. 
5. Region=A Value=1000-10000 290 ==> Region Attribute 
= city proper 290    conf :( 1) 
29. Region=A Value=1000-10000 290 ==> Criminal 
Motive=covet wealth 279    conf :( 0.96) 
 30. Region=A Region Attribute = city proper Value=1000-
10000 290 ==> Criminal Motive=covet wealth 279    
conf :( 0.96) 
 31. Region=A Value=1000-10000 290 ==> Criminal 
Motive=covet wealth Region Attribute = city proper 279    
conf :( 0.96) 
Figure 3 Rule5, 29-31 
This new method for eliminating redundant association 
rules was been proved to be effective. 
VI. CONCLUSIONS 
This paper mainly studies the characteristic of 
commonsense knowledge, and then analyzes the impact of 
commonsense knowledge and the special rules on the 
generation of redundant rules by giving three theorems and 
three corollaries. A new method for eliminating redundant 
rules is proposed. This new method can prune redundant 
rules by using commonsense knowledge and the special 
rules without calculating confidence, so it improved the 
efficiency of mining and the utilization of discovered 
association rules. In the end, this method was proved to be 
effective by a real experiment. 
REFERENCES 
[1] R.Agrawal,T.Imielinski,A.Swami. ? Mining association rules 
between sets of items in large databases”.In SIGMOD’93, 
Washington,D.C.,pp.207-216,1993 
[2] Zhu Qiuping, Mao Pingping and Luo Jun, “The Intrusion Detection 
System Based on Association Rules”, Computer Engineering and 
Applications,vol.40, 2004,pp160-162. 
[3] Wang Fudong, Li Bing, Xue Jinsong and Zhu Yunlong, “Constraint-
based Association Rule Mining in CRM”,Computer Integrated 
Manufacturing Systems,Vol.10 No.4,Apr.2004,pp.465-470. 
[4] Shang Wei, Shang Ning, Qin Minggui, Cui Zhongfa, Cui Yan and 
Zhu Yangyong, “THE ANALYSIS OF MULTIDIMENSIONAL 
ASSOCIATION RULE IN TRAFFIC ACCIDENTS”, Computer 
Applications and Software,Vol.23,No.2,Feb.2006,pp.40-42. 
[5] Li Xiaoyi and Xu Zhaodi , “Application of Association Rules Mining 
in Medical Diagnosis ”, JOURNAL OF LIAONING NORMAL 
UNIVERSITY(NATURAL SCIENCE EDITION),Vol.29,No 2,Jun. 
2006,pp.133-135 
[6] Zou Xianxia, Chen Xiaowei, Xu Longfei, “Protein Secondary 
Structure Prediction Based on Association Rules and Genetic 
Algorithm”, Computer Engineering and 
Applications,Vol.42,2006,pp.152-155 
[7] H Toivonen, M Klemettinen, P Ronkainen, K Hatonen and H Mannila, 
“Pruning and Grouping Discovered Association Rules”, In MLnet 
Wkshp. on Statistics,Machine Learning, and Discovery in 
Databases,1995 
35
 [8] LI Guoqi, Shanghai Jiao Tong University, “Research of Ontology-
Aided Method for Integrating Prior Knowledge into Bioinformatics 
Data Mining”,2007 
[9] Sheng Jiagen and Liu Sifeng, “Ontology-based Method for Mining 
Association Rules”, Joumal of Nanjing University of Science and 
Technology (Natural Science),Vol.32,No.4,Aug.2008,pp.401-405 
[10] Joanna Jozefowska, Agnieszka Lawrynowicz and Tomasz 
Lukaszewski, “On Reducing Redundancy in Mining Relational 
Association Rules from the Semantic Web”, Web Reasoning and 
Rule Systems,Vol.5341,2008,pp.205-213,doi: 10.1007/978-3-540-
88737-9_16 
[11] Marzena Kryszkiewicz,“Representative association rules and 
minimum condition maximum consequence association rules”. 
Principles of Data Mining and Knowledge Discovery, 
Vol.1510,1998,pp.361-369,doi:10.1007/BFb0094839 
[12] Mohammed J.Zaki, “Mining non-redundant association rules”, Data 
Mining and knowledge Discovery, Vol.9(3), Nov.2004,pp.223-248, 
doi: 10.1023/B:DAMI.0000040429.96086.c7. 
[13] Guichong Li and Howard J.Hamilton, “Basic association rules”, 
Proceedings of the Fourth SIAM International conference on Data 
Mining (SDM),2004,pp.166-177 
[14] Mafruz Zaman Ashrafi, David Taniar and Kate Smith, “Redundant 
Association Rules Reduction Techniques”, AI 2005: Advances in 
Artificial Intelligence,Vol.3809,2005,pp.254-263,doi: 
10.1007/11589990_28 
[15] Lu Liu, Yin Chen, Siqing Shan and Lu Yin, “Mining Condensed and 
Lossless Association Rules by Pruning Redundancy”,Proc. 
Proceedings of the 2008 Fifth International Conference on Fuzzy 
Systems and Knowledge Discovery,Vol.02, Oct.2008,pp.591-595,doi: 
10.1109/FSKD.2008.8 
[16] Han J and Kamber M, Data mining concepts and techniques, 2nd edn. 
Kaufmann, San Mateo,2005,pp150-184 
[17] http://en.wikipedia.org/wiki/Ontology_(information_science) 
 
 
36
