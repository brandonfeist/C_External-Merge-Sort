- 1511 - 
978-1-4244-3971-3/09/$25.00 ©2009 IEEE 
 
 
 
 
Predicting Trend in Futures Prices Time Series 
Using a New Association Rules Algorithm 
 
QIN Li-ping1?BAI Mei2 
1 Information Engineering College, Capital Normal University, P.R.China, 100048 
2 Institute of Industrial Economics, Chinese Academy of Social Sciences, P.R.China, 100836 
 
Abstract: Predicting trend in futures prices time 
series has always been one of the hottest topics in 
research, as well as a challenging problem due to time 
series’ volatility. In this paper we propose a new 
association rules mining algorithm, TB-SCM, which is 
based on Transaction Bool Matrix and Support Count 
Matrix, for predicting trend in futures prices to meet this 
challenge. Here, our algorithm mainly considers the 
preprocessing and analyzing of data. 
We develop a novel time series association rules 
mining prototype system based on the TB-SCM 
algorithm and C++ STL technology, and investigate the 
efficiency of the system using West Texas Intermediate 
(WTI) crude oil futures prices time series listed on the 
Energy Information Administration (EIA) website, as 
well as Shanghai Futures Exchange (SHFE) fuel oil 
futures’ closing prices time series on hexun website. The 
empirical study shows that TB-SCM algorithm 
out-perform classical Apriori algorithm available in 
Weka data mining software which is developed by 
Waikato University in terms of generating time series 
association rules without redundancy.  
Keywords: association rules, data mining, futures 
prices predicting, time series 
 
1 Introduction 
 
Futures prices time series has its own particularity 
besides the universal characteristics of data sets, and its 
volatility makes prediction a challenging task, whereas 
the analysis of it has always been a hotspot of Economics 
and Statistics as its findings is essential in the 
formulation of exact pricing and the decision-making. 
Presently, a great deal of effort has been devoted to 
developing time series predicting models[1,2,3]. 
Well-established and applied techniques include: (a) 
linear models, such as the Autoregressive Integrated 
Moving Average (ARIMA)[4]; (b) non-linear models, 
such as the Artificial Neural Networks (ANN)[5,6,7], fuzzy 
system models and Support Vector Machines 
(SVM)[8,9,10]; (c) a combination of linear and non-linear 
models[11,12,13]. 
Recently, there has been increasing interest in 
applying data mining technology to time series analysis. 
Mining association rules [14, 15], as one of the important 
topics in data mining, aimed at finding interesting 
relationships between items from data sets, the rules 
found can not only describe the law of the related data 
objects’ historical development, but also can be used to 
predict the future development trend according to the 
current status of the data objects. Thus, the exploratory 
research of applying the association rules approach to 
discover the potential, useful pattern from time series is 
of great significance in trend predicting[16]. In the futures 
market, the association rules mining can be used to find 
the linkage relations between different futures, common 
rules found can be described as “In a certain time frame, 
if WTI (West Texas Intermediate) crude oil price rises, 
then the possibility of SHFE (Shanghai Futures 
Exchange) fuel oil price rises at the same time is 80%”, 
however, investors may be more interested in this kind of 
rules like “In a certain time frame, if WTI crude oil and 
SHFE fuel oil prices rise on the first day, and WTI crude 
oil price falls, but SHFE fuel oil price rises on the second 
day, then the possibility of SHFE fuel oil price falls on 
the third day is 80%”. Rules in the second form, called 
time series association rules, contain more information, 
as the former and latter cases of the rules have time 
constraints, and are more important in making invest 
decisions. 
In this paper, after study the exist literatures of 
association rules mining algorithm or 
related[17,18,19,20,21,22,23,24,25,26], we realize this idea and 
introduce a novel algorithm TB-SCM which is based on 
Transaction Bool Matrix and Support Count Matrix for 
extracting time series association rules in a more 
effective way without redundancy. This approach first 
discrete the prices time series with a user-defined 
threshold that define the up, fair and down trend of prices, 
then carry out data preprocess with a sliding time 
window. After preprocessing, the algorithm carries on, 
finds the time series association rules and displays them 
in a visual way. 
The remainder of this paper is organized as follows: 
Section 2 introduces the time series association rules 
mining algorithm TB-SCM. In section 3, experiments 
and results are described in detail using WTI Crude oil 
futures and SHFE fuel oil futures prices. Section 4 
concludes this paper and indentifies potential future 
research directions. 
   
2009 International Conference on Management Science & Engineering (16th) 
September 14-16, 2009                              Moscow, Russia 
- 1512 - 
 
2 Algorithm 
 
The process of data mining includes data 
preprocessing, data mining, model evaluation and 
knowledge representation. In this section, we first 
introduce the method of futures prices time series 
preprocessing, then describe the novel algorithm 
TB-SCM, which involves the last three phrase of data 
mining. 
 
2.1 Data preprocessing 
Suppose we have a time series data set DS={T?P1?
P2?…?Pn}, where T is time, Pi>0(i [1,n]? )represents a 
price of a certain futures, each record is composed of Tj, 
a value of T, and every futures’ price under Tj. Futures 
P’s prices under Tj and Tj-1 is P[Tj] and P[Tj-1], then: 
If P[Tj] - P[Tj-1]??, futures P’s incident under Tj is 
“up” 
If ???P[Tj] - P[Tj-1]??, futures P’s incident under 
Tj “fair” 
If P[Tj] - P[Tj-1]???, futures P’s incident under Tj 
is “down”  
Here, ?>0 is a user-defined value. After discretion, 
we get a new data set DS'?{T?P1'?P2'?…?Pn'}, where 
Tj is the same as in DS, Pi' is futures P’s incident under 
time Tj(up, fair, down).  
Consider the sample data set containing 8 records in 
Tab.1. Let ?=2, after discretion, we get a new data set 
containing 7 records, see in Tab.2. In the new data set, 
we link the futures’ name and its incident by “:” to form 
an item, different items generated by different futures are 
separated by a comma. 
 
Tab.1 Sample data set 
Time P1 P2 
1 32 22 
2 30 25 
3 33 25 
4 37 28 
5 40 26 
6 38 23 
7 35 27 
8 39 30 
 
Tab.2 Data discretion 
Time Items 
1 -- 
2 P1:down,P2:up 
3 P1:up, P2:fair 
4 P1:up, P2:up 
5 P1:up, P2:down 
6 P1:down, P2:down 
7 P1:down, P2:up 
8 P1:up, P2:up 
 
Time Sliding Window (STW) is composed of w 
property values under consecutive time points, recorded 
as STW[1], STW[2], …, STW[w]. All the property 
values in the time sliding window consist of a Sliding 
Time Transaction Set (STTS), and STTS={1:STW[1], 
2:STW[2], …, w:STW[w]}, the prefix number 
indentifies the position of the item in the time sliding 
window. If STW[i](1?i?w) has more than one item, then 
its prefix number will be assigned to each of them. 
Consider the data set in Tab.2, let w=3, and there 
are 5 time sliding windows Win1, Win2, Win3, Win4, 
Win5. Each time sliding window covers 3 time points, 
consist of 3 property values, see in Fig.1.  
Fig.1 Time sliding window 
 
All the property values in a window make up a 
sliding time transaction set, so we get 5 records after 
processing, see in Tab.3. 
 
Tab.3 Sliding time transaction set 
Items 
P1:down,1:P2:up,2:P1:up,2:P2:fair,3:P1:up,3:P2:up 
P1:up,1:P2:fair,2:P1:up,2:P2:up,3:P1:up,3:P2:down 
P1:up,1:P2:up,2:P1:up,2:P2:down,3:P1:down,3:P2:down 
P1:up,1:P2:down,2:P1:down,2:P2:down,3:P1:down,3:P2:up
P1:down,1:P2:down,2:P1:down,2:P2:up,3:P1:up,3:P2:up 
 
2.2 Time series association rules mining 
The data structures mainly used by TB-SCM are 
Transaction Bool Matrix and Support Count Matrix. 
Transaction Bool Matrix[27,28] (TBM) is an N×M 
matrix, where N is the total record number of the data set, 
and M is the number of items involved in it. If item Ij is 
contained by transaction Ti, then the value of TBM[i][j] 
is 1, otherwise, its value is 0. For every itemset, we 
introduce two fields support index and support count, 
where the index is composed of values 0 and 1, the ith 
value of it indicates whether the ith record in the data set 
contains this itemset or not. For example, we have a 
14-record data set (see in Fig.2), consider itemset {I1}, 
its support index {I1}.index=10011011110011, and 
{I2}.index=11110101101011, and their support count can 
be obtained by simply calculating the number of 1 appear 
in the index, such as {I1}.SupportCount=9, 
Time Items      
2 P1:down,P2:up 
Win1 
    
3 P1:up,P2:fair 
Win2 
   
4 P1:up,P2:up 
Win3 
  
5 P1:up,P2:down  
Win4
 
6 P1:down,P2:down   
Win57 P1:down,P2:up    
8 P1:up,P2:up     
- 1513 - 
 
{I2}.SupportCount=10, while through the logic “and” 
operation of {I1}.index and {I2}.index, we can easily get 
the index of another composition itemset, e.g. 
{I1,I2}.index {I1}.index&{I2}.index=10010001100011. 
 
TID Items  TID I1 I2 I3 I4 I5 I6 I7 I8 I9
T101 I1,I2,I5,I6,I9 T101 1 1 0 0 1 1 0 0 1
T102 I2,I4,I8  T102 0 1 0 1 0 0 0 1 0
T103 I2,I3,I7,I9  T103 0 1 1 0 0 0 1 0 1
T104 I1,I2,I4  T104 1 1 0 1 0 0 0 0 0
T105 I1,I3,I4,I6,I8 T105 1 0 1 1 0 1 0 1 0
T106 I2,I3,I6,I9  T106 0 1 1 0 0 1 0 0 1
T107 I1,I3,I6,I7  T107 1 0 1 0 0 1 1 0 0
T108 I1,I2,I3,I5,I8 T108 1 1 1 0 1 0 0 1 0
T109 I1,I2,I3,I9  T109 1 1 1 0 0 0 0 0 1
T110 I1,I3,I6,I9  T110 1 0 1 0 0 1 0 0 1
T111 I2,I5,I7,I9  T111 0 1 0 0 1 0 1 0 1
T112 I3,I5,I7  T112 0 0 1 0 1 0 1 0 0
T113 I1,I2,I4,I7  T113 1 1 0 1 0 0 1 0 0
T114 I1,I2,I5,I8  T114 1 1 0 0 1 0 0 1 0
Fig.2 Sample data set and transaction bool matrix 
 
Support Count Matrix (SCM) is an M×M upper 
triangular matrix, whose rows and columns are identified 
by the names of items, and M means the same as in TBM. 
Thus, the element in row i and column j can be mark as 
SCM[Ii][Ij], and its value represents Item Ij’s appear 
times as suffix of item Ii. All the items involved in SCM 
matrix’s rows and columns are arranged by dictionary 
order. Consider the data set in Fig.2, its Support Count 
Matrix is in Fig.3. 
Fig.3 Support count matrix 
 
TB-SCM algorithm uses the fundamental nature of 
frequent itemsets, that is, “All the none-empty subsets of 
frequent itemsets must be frequent” and “None of the 
super-sets of nonfrequent itemsets can be frequent”. The 
process of the algorithm, see in Fig. 4.   
The algorithm works through three steps: 
step1: Create the Support Count Matrix and 
Transaction Bool Matrix. Initial the two matrixes TBM 
and SCM, and scan each record of the data set and 
update them according to the items appearance in the 
record.
 
Fig.4 Process of TB-SCM 
 
CreateMatrix?TBM, SCM, T?                      
{ 
  Initial TBM[N][M] and SCM[M][M]; 
// M is the number of items involved and 
// N is the number of the record sets 
for each record Ti dataset  ?  
//  Ti is the ith record of the dataset 
{//  process current record 
update the ith row in TBM  
{ 
    for each item Ij  //  Ij is the jth column of TBM  
      if Ij T? i  //Ti contains Ij 
      then TBM[i][j] = 1; 
      else TBM[i][j] = 0; 
} 
// update SCM, the rows and columns of SCM are  
//identified by the items 
For each item Ik T? i 
{ 
SCM[Ik][ Ik]= SCM[Ik][ Ik]+1; 
 //process the suffix of Ik in Ti 
For each (Ih T? i )>Ik   
         SCM[Ik][ Ih]= SCM[Ik][ Ih]+1; 
      } 
} 
} 
step2: Find all the frequent Itemsets meet the 
requirement that the first item’s prefix number must be 
“1” in every frequent itemset. We can find the 1-frequent 
itemsets and 2-frequent itemsets directly from SCM with 
min_sup. 
Find_All_Frequent_Itemsets(T, min_sup) 
{ // find the 1-frequent itemsets and 
// 2-frequent itemsets directly from SCM, L?L1 L? 2 
L=Find_Frequent_Itemsets?SCM, min_sup?; 
// find k-frequent itemsets?k>=3?Lk? 
// until Lk is empty 
K = 3; 
While(Lk-1 is not empty) 
{// find Lk according to Lk-1, TBM and SCM 
    Lk=Find_kFrequent_Itemsets(k, Lk-1, TBM, SCM, 
min_sup); 
L =L? k; 
k++; 
} 
} 
    This function finds 1-frequent itemsets and 
2-frequent itemsets directly from SCM with min_sup: 
Find_Frequent_Itemsets?SCM, min_sup? 
Item I1 I2 I3 I4 I5 I6 I7 I8 I9
I1 9 6 5 3 3 4 2 3 3
I2  10 4 3 4 2 3 3 5
I3   8 1 2 4 3 2 4
I4    4 0 1 1 2 0
I5     5 1 2 2 2
I6      5 1 1 3
I7       5 0 2
I8        4 0
I9         6
- 1514 - 
 
// find 1 and two frequent itemsets directly from SCM 
{  
for?i=1; i<=M; i++?// scan SCM row by row 
{ 
    if (Ii’s prefix number != 1) 
       break; 
    for(j=1; j<=M; j++)//scan every column of SCM 
{ 
If(SCM[Ii][Ij]>=min_sup)  
{// get 1-frequent itemsets in the diagonal 
         if(i==j)  
then L1 ={I? i }; 
         else  L2 ={I? i , Ij }; 
       } 
} 
} 
} 
    This function finds k-frequent itemsets (k>=3) 
through k-1-frequent itemsets, TBM and SCM matrix 
with min_sup: 
Find_kFrequent_Itemsets(k, Lk-1, TBM, SCM, min_sup) 
{ // find Lk on the basic of Lk-1, TBM and SCM (k>=3) 
For each?k-1={I1,I2,…,Ik-1 } L? k-1 
{ 
If?SCM[Ik-1][Ij]>=min_sup? 
    {  
Candidate=?k-1 I? j; //generate a candidate 
// get the support count index 
      Candidate.Index=?k-1.Index&{Ij}.Index ?
//calculate the support count 
      If(Candidate.Index.Count(1)>=min_sup)  
      then  Lk =Candidate;?  
     } 
   } 
} 
Step3: Generate time series association rules from 
frequent itemsets L with time window width w and 
minimum confidence min_conf. To avoid redundant rules, 
we check every k-frequent itemset {I1, I2, …, Ik} (k>=2), 
if Ik’s prefix number is w (Sliding Time Window’ width) , 
and Ik-1’s prefix number is less than w, then calculate the 
potential rule’s support, sup={I1, I2, …, 
Ik}.SupportCount/N, where N is the number of records in 
the data set, and its confidence, conf={I1, I2, …, 
Ik}.SupportCount/{I1,I2,…,Ik-1}.SupportCount. If sup >= 
min_sup and conf>=min_conf, generate a new rule 
“{I1,I2,…,Ik-1}=>{Ik}[support=sup, confidence=conf]”. 
Generate_Timeseries_AssociationRules(L, w, min_conf) 
{ 
  // k is the largest itemset’s size 
  for each k-frequent itemset Lk={I1,I2,…,Ik} 
{  
if(Ik’s prefix number =w  
&& Ik-1’s prefix number !=w) 
{ 
//calculate the potential rule’s support and confidence 
  sup={I1,I2,…,Ik}.SupportCount/N;  
conf={I1,I2,…,Ik}.SupportCount/ 
{I1,I2,…,Ik-1}.SupportCount; 
if(sup?min_sup&&conf?min_conf) 
// R is the set of time series association rules  
R =? {I1,I2,…,Ik-1}=> 
{Ik}[support=sup,confidence=conf]; 
       } 
  } 
} 
 
3 Experiments and results 
 
We develop a novel time series association rules 
mining prototype system including data preprocessing, 
association rules mining and knowledge presentation 
based on the TB-SCM algorithm and C++ STL 
technology under Visual Studio 2005 Development 
platform, the system’s framework see in Fig.5.  
 
 
 
Fig.5 Frame work of time series association 
rules mining system 
 
To investigate the efficiency of the novel algorithm 
and the prototype system, we conduct an experiment 
using West Texas Intermediate (WTI) crude oil futures 
prices time series(793 instances) listed on the 
EIA(Energy Information Administration) website, as 
well as (SHFE) Shanghai Futures Exchange fuel oil 
futures prices closing prices time series(629 instances) 
on hexun website, see in Fig.6. 
 
 
 
Fig.6 Data set of WTI and SHFE 
- 1515 - 
 
The current pricing adjustment mechanism for 
refined oil in China is adjusted by the National 
Development and Reform Commission in accordance 
with the prices of New York, Singapore and Rotterdam, 
therefore, the oil price in China is mainly impacted by 
the three places’ oil prices, including the WTI Crude oil 
futures, which is one of the three crude oil benchmarks, 
in New York Mercantile Exchange. Our experiment will 
give some proofs about this. 
    After preprocessing (the ? of WTI is 0.2, SHFE is 2, 
time window width is 3), we have 601 instances. We set 
the min_sup and min_conf as 0.05 and 0.70, and 
discover 15 time series association rules. See in Fig.7. 
The first time series association rule found is: 
1:SHFE:up,1:WTI:down,2:SHFE:down,2:WTI:up=
>3:SHFE:up[support=6.32%,confidence=84.4%] 
This rule indicates that if SHFE fuel oil futures 
price is up and WTI Crude oil futures price is down on 
the first day, and on the second day SHFE is down and 
WTI is up, then on the third day SHFE is up’s support is 
6.32%, confidence is 84.4%. We can also find that all the 
latter cases in the rules found are about SHFE, that 
means the SHFE fuel oil futures price has a strong 
correlation with the WTI Crude oil futures price. 
For comparison, we conduct another experiment 
using the same data set in Weka data mining software 
which is developed by Waikato University, the results are 
show in Fig.8. Check these rules, such as “101.
2=WTI:up 3=SHFE:down 3=WTI:down 47 ==> 
2=SHFE:up 33    conf:(0.7)”(where 47 is support 
count of items contained in the former case, 33 is the 
whole rules’ items support count), this rule predicts the 
second day’s trend by the incident of the third day, it’s 
not practical, hence this rule is redundant. Out of the 101 
rules found by Weka, we can find 15 rules useful the 
same as in our system. 
    This shows that our Time Series Association Rules 
Mining System based on TB-SCM algorithm is more 
effective, it can generate time series association rules 
without redundancy. 
 
4 Summary and future work 
 
This paper presented a novel association rules 
mining algorithm TB-SCM for mining futures prices 
time series association rules, it’s more effective than the 
classical Apriori, and can generate the aimed rules 
without redundancy.  
Futures market has not only a large amount of data, 
but also a considerable number of real-time data, 
opportunities are fleeting, how to timely discover the 
relevant rules, and how to find the new rules without 
re-mining the whole data set when data is updated is of 
great importance. Therefore, the next step of our research 
work is to realize the dynamic updates and incremental 
association rules mining.
 
Fig.7 Results 
 
- 1516 - 
 
 
Fig.8 Results in weka 
 
References 
 
[1]Lon-Mu Liu. Time series analysis and forecasting[M]. 
Second Edition. U.S.A.:Scientific Computing Associates 
Corp, 2006:1-565. 
[2]Victor Lavrenko, Matt Schmill, Dawn Lawrie, Paul 
Ogilvie, David Jensen, James Allan. Mining of 
concurrent text and time series[C]. In proceedings of the 
6th ACM SIGKDD Int'l Conference on Knowledge 
Discovery and Data Mining Workshop on Text Mining, 
2000:37-44. 
[3]Tekbas O. H.. Modeling of chaotic time series using a 
valuable length windowing approach[J]. Chaos, 
Solutions & Fractals, 2006, 29(2):277-281. 
[4]Wang, Xi-tao. Study on the application of ARIMA 
model in time-bargain forecast[J].E-Commerce and 
Logistics, 2006, 22(15):139-140. 
[5]Chen, A. S., Leung, M. T., Daouk, H.. Application of 
Neural Networks to an emerging financial market: 
Forecasting and trading the taiwan stock index[J]. 
Computers & Operations Research, 2003, 30(6):901-923. 
[6]Somesh Selvaratnam, Michael Kirley. Predicting 
stock market time series using evolutionary Artificial 
Neural Networks with hurst exponent input windows[C]. 
AI2006:Advances in Artificial Intelligence, 2006: 
617-626. 
[7]Lendasse, A., de Bodt, E., Wertz, V., Verleysen, M. 
Non-linear financial time series forecasting-application 
to the bel 20 sock market index[J]. European Journal of 
Economic and Social Systems, 2000, 14(1):81-91. 
[8]Wen Xie, Lean Yu, Shanying Xu, Shouyang Wang. A 
new method for crude oil price forecasting based on 
Support Vector Machines[C]. The 6th International 
Conference on Computational Science, 2006:444-451. 
[9]Huang, W., Nakamori, Y., Wang, S.Y. Forecasting 
stock market movement direction with support vector 
machine[J]. Computers & Operations Researh, 2005, 
32(10):2513-2522. 
[10]Muller, K. R., Smola, J. A., Scholkopf, B. Prediction 
time series with support vector machines[C]. In 
Proceedings of International Conference on Artificial 
Neural Networks, Lausanne, 1997:999-1004.  
[11]Weimin Tong, Yijun Li. Wavelet method combining 
BP networks and time series ARMA modeling for data 
mining forecasting[C]. ICNC: International Conference 
on Advances in Natural Computation, 2005:123-134. 
[12]Monahan, John F. Fully Bayesian analysis of 
ARIMA time series models[J]. Journal of Econometrics, 
1983, 21(3):307-331. 
[13]Daijin Kim, Chulhyun Kim. Forecasting time series 
with genetic fuzzy predictior ensembles[C]. IEEE 
Transactions on Fuzzy Systems, 1997, 5(4):523-535. 
[14]R. Agrawal, R. Srikant. Fast algorithms for mining 
association rules in large databases[C]. In Proceedings of 
the 20th Int’l Conference of Very Large 
Databases(VLDB’94), 1994: 478-499. 
[15]R. J. Bayardo, R. Agrawal. Mining the most 
interesting rules[C]. In 5th ACM SIGKDD Int’l Conf. 
- 1517 - 
 
On Knowledge Discovery And Data Mining, 
1999:145-154. 
[16]Sacchi, Cristiana, Larizza. Carlo, Combi. Riccardo 
Bellazzi. Data Mining with temporal 
abstractions:learning rules from time series[C]. Data 
Mining and Knowledge Discovery, 2007, 15(2):217-247. 
[17]Mingjun Song, Sanguthevar Rajasekaran, Member, 
IEEE. A transaction mapping algorithm for frequent item 
sets mining[C]. IEEE Transactions on Knowledge and 
Data Engineering, 2006, 18(4):472-481. 
[18]Y. Bastide, R. Taouil, N. Pasquier, G. Stumme, L. 
Lakhal. Mining frequent patterns with counting 
inference[J].In SIGKDD Explorations, 2000,2(2):66-75. 
[19]Bashir, S.   Shuaib, M.   Sultan, Y.   Baig, A.R. 
Improving frequent itemset mining algorithms  
performance using efficient implementation techniques: 
A benchmark solution[C]. In Proc. 2006 2nd Int. Conf. 
on Emerging Technologies (IEEE-ICET'06), Peshawar, 
Pakistan, 2006:257-262. 
[20]Wassim AYADI, Khedija AROUR. A binary decision 
diagram to discover low threshold support frequent 
itemsets[C].18th International Workshop on Database 
and Expert Systems Applications, 2007:509-513. 
[21]C. Borgelt. Efficient implementation of apriori and 
eclat[C]. In FIMI’03: Proceedings of the IEEE ICDM 
Workshop on Frequent Item Set Mining Implementations, 
Meldourne, USA, 2003, 80:1-9. 
[22]Chedy Raissi, Pascal Poncelet, Maguelonne Teisseire. 
SPEED: Mining maximal sequential patterns over data 
streams[C].3rd International IEEE Conference on 
Intelligent Systems, 2006:546-552. 
[23]J. Pei, J. Han, W. Wang. Mining sequential patterns 
with constraints in large databases[C]. In Proceedings of 
the 10th International Conference on Information and 
Knowledge Management(CIKM02), MCLean, USA, 
2002:18-25. 
[24]M. Klemettinen, H.Mannila, P. Ronkainen, H. 
Toivonen, A. I. Verkamo. Finding interesting rules from 
large sets of discovered association rules[C]. In 3rd Int’l 
Conference on Information and Knowledge Management, 
1994:401-407. 
[25]Mohammed J. Zaki. Scalable algorithms for 
association mining[C]. IEEE Transactions on Knowledge 
and Data Mining, 2000, 12(3):372-390. 
[26]R. Srikant, R. Agrawal. Mining sequential patterns: 
Generalizations and performance improvements[C]. In 
Proceedings of the 5th International Conference on 
Extending Database Technology (EDBT96), Avignon, 
France, 1996:3-17. 
[27]Doug Burdick, Manuel Calimlim, Johannes Gehrke. 
MAFIA: A maximal frequent itemset algorithm for 
transactional databases[C]. In Proceedings of the 17th 
International Conference on Data Egineering, Heidelberg, 
Germany, 2001:443-452.  
[28]J. F. Boulicaut, A. Bykowski, C. Rigotti. Free-sets: 
A condensed representation of boolean data for the 
approximation of frequency queries[J].Data Mining and 
Knowledge Discovery, 2003,7(1):5-23.
 
