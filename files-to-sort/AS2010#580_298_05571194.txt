An Improved Method of Outlier Detection based on Frequent Pattern 
Weiwei Zhang 
Department of Computer Science 
Zhuhai College, Jinan University 
Zhuhai 519070, P.R.China 
E-mail: zww16@yahoo.com.cn 
Jianhua Wu 
Department of Computer Science 
Zhuhai College, Jinan University 
Zhuhai 519070, P.R.China 
E-mail: tjhwu@jnu.edu.cn 
Jie Yu 
Department of Computer Science 
Zhuhai College, Jinan University 
Zhuhai 519070, P.R.China 
E-mail: jifish@foxmail.com 
 
Abstract—Outlier detection is an interesting data mining task, 
which detects rare events. This paper focuses on the method of 
outlier detection based on frequent pattern (FP method for 
short). First we analyze the drawback of this method, and then 
an improved method (LFP method for short) has been 
presented. Finally, we evaluate the two methods by using 
several datasets and the experiment results show that LFP 
method outperforms FP method. 
Keywords- data mining; association rules; frequent pattern; 
outlier detection 
I.  INTRODUCTION 
Data mining is the process of extracting interesting 
patterns from large amounts of data [1]. Outlier detection and 
analysis is an interesting data mining task, which detects rare 
events, deviant objects, and exceptions. It has been widely 
used in many practices, such as fraud detection, marketing 
analysis, medical analysis and network intrusion. In the field 
of data mining, there are many useful methods of outlier 
detection [3-6]. They are useful techniques on outlier 
detection available for numerical data. However, they 
perform not well in discrete data or transaction data. This 
paper proposes a method especially for dicovering outliers in 
discrete datasets, which performs well in transaction datasets 
and is efficent and easy to implement. 
In this paper, we focus on the method of outlier detection 
based on frequent patterns (FP method for short). First we 
describe the core algorithm and analyze the drawback of this 
method, and then we propose an improved method (LFP 
method for short) and also present its algorithm. Finally, we 
evaluate the two methods by using several datasets and the 
experiment results show that the LFP method outperforms 
the FP method. 
This paper mainly makes the following contributions: 
a) Summarize the FPOF measure and the FP 
algorithm for outlier detection. Zengyou He et al. propose 
this outlier detection method based on frequent patterns in 
[8], we name it FP method for convenience. 
b) Analyze the drawback of FP method. FP method has 
duplicate computing problem so that it couldnot detect 
outliers precisely. 
c) Propose an improving method, LFP method. In this 
method we define a new outlier measure LFPOF, and we 
offer a new algorithm to detect outliers. 
d) The proposed LFP algorithm is easy to implement 
and efficent in time complexity. 
e) Experimental evaluation. We evaluate the two 
methods by using several datasets which are real world 
dataset and the experiment results show that LFP method 
outperforms FP method. 
II. FREQUENT PATTERN BASED OUTLIER DETECTION 
A. Frequent Pattern based Outlier Detection 
Zengyou He et al. proposed a frequent pattern based 
outlier detection method [8]. This method regards as outliers 
those data points which contain infrequent patterns. In other 
words, if a data object contains more frequent patterns, it 
means that this data object is unlikely to be an outlier. 
1) FPOF Measure for Outliers 
FP method defines a measure called FPOF that reflects 
the normal degree of a transaction. Let F be a complete set of 
frequent itemsets mined from input data with a given 
threshold min_sup and let sup(X) be a support value of an 
frequent itemset X and X?F. The normal degree FPOF(t) of 
a transactions t is derived as: 
 
sup( )
FPOF(t)=
| |
X t X F
X
F
? ? ?
?
 (1) 
The numerator of this formula (1) represents the sum of 
support degree of all frequent patterns contained in 
transaction X. The denominator defines the number of 
frequent patterns that F contains. Therefore, a transaction 
that contains more frequent patterns is more normal, while 
one that contains less frequent patterns is more abnormal and 
more possible to be an outlier.  
2) FP Algorithm 
This FP algorithm is listed in Table ? . First the 
algorithm generates the frequent pattern set F from the 
dataset with a given minisupport. Then, for each transaction t 
in the dataset T, traverse every frequent pattern X in F, if 
t?X, then FPOF(t) = FPOF(t) + support(X). When the 
traversing is finished, the sum of support degrees of all 
satisfied frequent patterns is clear, and the final value of t’s 
FPOF is computed. After all transacion in T is computed, 
Order all the transactions by their FPOF value in ascend. 
Finally, the top-k FP-outliers are output. 
TABLE I.  FP ALGORITHM DESCRIPTION 
2010 WASE International Conference on Information Engineering
978-0-7695-4080-1/10 $26.00 © 2010 IEEE
DOI 10.1109/ICIE.2010.97
3
Input: transaction dataset T, 
            user defined threshold minimal support min_sup, 
            user defined threshold value for top k fp-outlier 
Output: top k outliers corresponded with the k lowest FPOF values 
1. Mining the set of frequent patterns F on database T using 
minisupport min_sup 
2. for each transaction t?T 
3.       FPOF(t) = 0 
4.       for each frequent pattern X?F 
5.             if t?X 
6.                   FPOF(t) = FPOF(t) + support(X) 
7.             end if 
8.       end for 
9.       FPOF(t) = FPOF(t) / F.size() 
10. end for 
11. Order the transactions in the ascending by their FPOF values. 
12. Output the top k transactions as outliers 
B. Drawback of FP Method 
Let t be a transaction in transaction dataset T, t?T, let X = 
{I1, I2, I5}, Ii?I, I is the itemset of T. We suppose X is a 
frequent pattern of frequent pattern set F, X?F. All the 
nonempty subsets of X are derived as: {I1, I2}, {I1, I5}, {I2, 
I5}, {I1}, {I2}, {I5}. Let t contains X, so that t?X, and t also 
contains all the subsets of X. Because X is a frequent pattern, 
the subsets of X must be frequent patterns too. Therefore, 
when FP algorithm is used to compute t’s FPOF value, the 
support degrees of X and X’s subsets are duplicate added. 
This duplicate computing will enlarge the differentials of 
normal degrees among transactions. In such a case, the 
outlier measure FPOF cannot reflect the normal degree of 
transactions accurately.  
Targeting at the above drawback of FP method, we 
propose an improved method, named LFP method. LFP 
method redefines the outlier measure and has solved 
duplicate added problem well, so this method could detect 
outliers more precisely and increase the rate of accuracy. 
III. AN IMPROVED METHOD 
A. LFPOF Measure for Outliers 
We assume that here exist frequent pattern fp1: {I1, I3, 
I5, I6}?fp2: {I3, I5}?fp3: {I5, I6} and fp1?fp2?fp1?fp3, 
then frequent pattern fp1 is defined as a superset frequent 
pattern of fp2 and fp3, frequent pattern fp2 and fp3 are 
defined as subsets frequent pattern of fp1. 
Importantly in the frequent pattern mining process, a 
superset frequent pattern that contains more items (has long 
length) is combined by subset frequent pattens that contains 
less items (has short length). So the longer a superset 
frequent pattern is, the more its subset frequent patterns are. 
Then we could conclude that a transaction that contains 
longer superset frequent patterns is more likely to be a 
normal transaction because it has more subset frequent 
patterns than other transactions. In contrast, a transaction that 
contains short frequent patterns is more likely to be an 
outlier. 
According to the above idea, we define a new measure 
called LFPOF that reflects the normal degree of a 
transaction. Let t be a transaction in T, let F be a complete 
set of frequent itemsets, F(t) is a frequent pattern set which 
composes of  frequent patterns contained in t. F(t) is derived 
as: F(t) = {X | X?F ? t?X}. 
Let Xmax be the longest frequent pattern in F(t). |Xmax| 
represents the length of Xmax, |t| represents the length of 
transaction t, then we have: 
  
max| |( )
| |
XLFPOF t
t
=
 (2) 
The numerator shows that a transaction contains longer 
frequent pattern is more normal.  
B. LFP Algorithm 
This LFP algorithm is shown in Table ?. The process of 
LFP algorithm is as follows. First the algorithm using FP-
growth algorithm to generate the frequent pattern set F. 
Then, for each transaction t in the dataset T, get t’s frequent 
pattern set F(t). Find the longest frequent pattern Xmax in F(t). 
After that, we could compute t’s normal degree LFPOF(t). 
When the traversing is over, the value of every t’s LFPOF is 
computed. Then order all the transactions by their LFPOF 
value in ascend. At the end, the top-k FP-outliers are output. 
TABLE II.  LFP ALGORITHM DESCRIPTION 
Input: transaction dataset T,  
            user defined threshold minimal support min_sup, 
            user defined threshold value for top k lfp-outlier 
Output: top k outliers corresponded with the k lowest LFPOF values 
1. Using FP-growth algorithm to mine the frequent pattern set F on 
database T using minisupport min_sup 
2. for each transaction t?T 
3.       LFPOF(t) = 0 
4.       for each frequent pattern X?F 
5.             if t?X 
6.                   F(t).add(X)       /* add frequent pattern X to F(t) */ 
7.             end if 
8.       end for 
9.       Find the longest frequent pattern Xmax in F(t) 
10.       LFPOF(t) = | Xmax | / |t| 
11. end for 
12. Order the transactions in the ascending by their LFPOF value 
13. Output the top k transactions as outliers  
C. LFP Algorithm Performance Analysis 
The computational cost of LFP algorithm is mainly 
composed of two parts: fisrt, the cost of generating frequent 
pattern set using FP-growth algorithm [9]; second, the cost of 
double circulation in line 2–9. The time complexity of 
generating frequent pattern set using FP-growth algorithm 
increases fast as the scale of the transaction dataset gets 
larger. When the scale of dataset is extremely large, the 
algorithm’s computational time will get quite long. Anyway, 
FP-growth algorithm is much more efficent than Apriori 
algorithm. The double circulation has O(|T|×|F|) time 
complexity. When |T| and |F| are getting larger, the running 
time of algorithm is getting longer, however, this O(|T|×| F|) 
time complexity is acceptable as long as |T| and |F| are 
limited in certain scale. 
4
IV. EXPERIMENTAL RESULTS 
In this section, we make experiments to compare FP 
method and LFP method on the detecting accuracy. We run 
the two algorithms on 3 real world datasets all obtained from 
the UCI Machine Learning Repository [10]. 
A. Experimental Environment 
The experimental environments: Windows XP?Intel(R) 
2.66GHz CPU?1G main memory and JDK 1.6.0. 
B. Data Sets 
These 3 datasets are: Intrusion dataset, breast-cancer-
winsconsin dataset, lymphography dataset. 
Intrusion dataset is a network connection records dataset 
that includes a variety of intrusions from U.S. military, 
Attributes include length of the connection, the type of 
protocol, network service on the destination and so on, each 
record is classified into the normal class or one of the 
intrusion classes such as guess password, warezmaster and 
so on. Most attributes take continuous values, we discretize 
them into 5 levels using AlphaMiner [11] software. The 
treated experimental dataset is combined of the guess 
password class as the true outlier records and the normal 
records. It contains 97% normal records and 3% outlier 
records, in total 1000 records. We converted this record data 
to transaction data in which each item corresponds to a pair 
of an attribute and its value. The final experimental dataset is 
shown in Table ?. 
TABLE III.  CLASS DISTRIBUTION OF INTRUSION DATASET 
Class Number Percentage Total number  
Normals 970 97% 1000 Outliers 30 3% 
The second dataset used is breast-cancer-winsconsin 
dataset, which contains 699 records with 9 attributes. All 
attributes are considered as categorical. Each record was 
labeled as benign or malignant. In our experiment, We pick 
up 14 records (3%) of the malignant records and 443 records 
(97%) of the benign records. The 14 malignant records are 
treated as outliers and others are normal records. The final 
transaction form dataset is listed in Table ?. 
TABLE IV.  CLASS DISTRIBUTION OF BREAST-CANCER-WINSCONSIN 
DATASET 
Class Number Percentage Total number 
Normals 443 97% 457 Outliers 14 3% 
The third dataset is the Lymphography data set, which 
contains 148 records with 18 attributes. All records in the 
dataset are categorized into 4 classes. Classes 2 and 3 have 
the largest number of records. The remained classes were 
regarded as outlier class labels. The corresponding class 
distribution is illustrated in Table ?. 
TABLE V.  CLASS DISTRIBUTION OF LYMPHOGRAPHY DATASET 
Class Number Percentage Total number 
Normals 142 96% 148 Outliers 6 4% 
C. Accuracy Comparisons 
In order to evaluate LFP method proposed by this paper, 
we adopt Kazuyo Narita’s experiment method [6] to 
compare FP method and LFP method. We take two accuracy 
measures, the detection rate (D_rate) and detection precision 
(D_prec) defined by the following formulas: 
number of  detected true outliersD_rate =
number of  all true outliers  
number of  detected true outliersD_prec=
number of  detected transactions as outliers    
For fair evaluation, we provide fixed parameters for each 
method, and regard transactions which have the top-k lowest 
normal degree as outliers. Changing the k value, we draw a 
comparison chart. Fig. 1 shows the change in D_prec as 
D_rate increases of two methods, and the horizontal axis of 
this figure represents detection rate, the vertical axis 
represents detection precision. The parameter min_sup is set 
50%, which is most proper for the two methods. We could 
find that LFP method’s D_prec keeps maintaining higher 
values than FP method as the D_rate increases (or k value 
increases), especially under the circumstance that D_rate is 
quite low. Through this phenomenon we can deduce that the 
top outliers detected by FP method contain much normal 
records so that its detection precision gets low. In contrast, 
when D_rate is quite low, LFP’s D_prec is quite high 
because the top outliers detected by LFP method are almost 
correct. Therefore, we can see that LFP method gets a higher 
accuracy than FP method. 
Accuracy Comparison of LFP Algorithm and FP Algorithm (Intrusion)
0
10
20
30
40
50
60
70
80
90
100
5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100
Detection Rate(%)
De
te
ct
io
n 
Pr
ec
is
io
n(
%)
LFP(min_sup=50%)
FP(min_sup=50%)
 
Figure 1.  Accuracy Comparison between LFP Algorithm and FP 
Algorithm (Intrusion) 
In the second experiment, we use breast-cancer-
winsconsin dataset and the result is shown in Fig. 2. 
Accuracy Comparison between LFP Algorithm and FP Algorithm (breast-
cancer-winsconsin)
0
10
20
30
40
50
60
70
80
90
100
5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100
Detection Rate(%)
De
te
ct
io
n 
Pr
ec
is
io
n(
%)
LFP(min_sup=25%)
FP(min_sup=25%)
 
5
Figure 2.  Accuracy Comparison between LFP Algorithm and FP 
Algorithm (breast-cancer-winsconsin) 
It is clear that the detection precisions of LFP method 
and FP method are both high when D_rate is low, however, 
as D_rate increases, the curves of two methods split apart 
gradually and LFP method’s D_prec is higher than FP 
method’s.  
In the third experiment, we use lymphography dataset 
and the result is shown in Fig. 3. 
Accuracy Comparison between LFP Algorithm and FP Algorithm (lymphograhy)
0
10
20
30
40
50
60
70
80
90
100
5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100
Detection Rate(%)
De
te
ct
io
n 
Pr
ec
is
io
n(
%)
LFP(min_sup=50%)
FP(min_sup=50%)
 
Figure 3.  Accuracy Comparison between LFP Algorithm and FP 
Algorithm (lymphography) 
We can see that the detection precisions of LFP method 
and FP method are both quite high when D_rate is low. But, 
when D_rate is more than 75%, LFP method’s detection 
precision gets higher than FP method’s a little bit. 
D. Parameter Sensitivities 
The detection result of LFP method depends on the user 
threshold min_sup, so it is necessary to provide an analysis 
with regard to parameter sensitivities. Fig. 4 shows that LFP 
method may detect a different set of transactions, when 
different minimal supports, 12.5%?25%?50%?75%, are 
provided. From this analysis, although the proposed method 
has excellent performance on outlier detection, it is sensitive 
to the parameter given by the user. The problem of how to 
select the proper parameters for input data is important.  
LFP Algorithm Accuracy Comparison under Different Min_sups (breast-cancer-
winsconsin)
0
10
20
30
40
50
60
70
80
90
100
5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100
Detection Rate(%)
De
te
ct
io
n 
Pr
ec
is
io
n(
%)
LFP(min_sup=50%)
LFP(min_sup=75%)
LFP(min_sup=25%)
LFP(min_sup=12.5%)
 
Figure 4.  LFP Algorithm Accuracy Comparison under Different 
Min_sups (breast-cancer-winsconsin) 
V. CONCLUSIONS 
In this paper, we focus on the method of outlier detection 
based on frequent patterns proposed by Zengyou He et al, we 
name it FP method. First we describe the core algorithm, 
summarize the FPOF measure and the FP algorithm for 
outlier detection, and then we analyze the drawbacks of FP 
method. We find that FP method has duplicate computing 
problem so that it couldnot detect outliers precisely. 
Targeting at this drawback, we propose an improved method 
(LFP method) and also present its algorithm. LFP method 
solves the problem above well and it is easy to implement 
and efficent in time complexity. Finally, we evaluate the two 
methods by using several datasets and the experiment results 
show that the LFP method outperforms the FP method. A 
future work is to solve the parameter sensitivity problem of 
LFP method, figure out how to fix the most proper min_sup 
for LFP method. 
ACKNOWLEDGMENT 
This work is funded by the Youth Foundation of the Jina
n University under Grant No.51208030. 
REFERENCES 
[1] Jiawei Han, and Micheline Kamber, “Date mining: concepts and 
techniques,” 2001, pp. 3-5. 
[2] D. Hawkins, “Identification of Outliers,” London: Chapman and Hall, 
1980, pp. 1-3. 
[3] Barnett V, and Lewis T, “Outliers in Statistical Data,” New York: 
John Wiley& Sons, 1994. 
[4] Knorr. E. M, and NgR. T. A, “Unified Notion of outliers: ProPerties 
and ComPutation,” In proc. of KDD 97, 1997, pp. 219-222. 
[5] M. M. Breunig, H. P. Kriegel, R. Ng, and J. Sander, “LOF: 
Identifying Density-Based Local Outliers,” In ACM SIGMOD 
Conference Proceedings, 2000, pp. 150-165. 
[6] Kazuyo Narita, and Hiroyuki Kitagawa, “Outlier Detection for 
Transaction Databases using Association Rules,” Lecture Notes in 
Computer Science, 2008, pp. 1-7. 
[7] R. Agrawal, and R. Srikant, “Fast algorithms for mining association 
rules in large databases,” In VLDB, 1994, pp. 487–499. 
[8] Zengyou He, and Xiaofei Xu, “FP-Outlier: Frequent Pattern Based 
Outlier Detection,” Computer Science and Information Systems, 2005, 
pp. 1-6. 
[9] Jiawei Han, Jian Pei, and Yiwen Yin, “Mining Frequent Patterns 
without Candidate Generation,” Data Mining and Knowledge 
Discovery, 2004, pp. 1-8. 
[10] Uci machine learning repository. 
http://www.ics.uci.edu/˜mlearn/MLRepository.html. 
[11] AlphaMiner.http://bi.hitsz.edu.cn/alphaminer/index.htm. 
6
