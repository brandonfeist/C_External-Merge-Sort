An Association Rule Mining Approach for Intelligent Tutoring System 
Yuemin Li  
Department of Chemistry and Life Science 
Chuzhou University Chuzhou, China 
nana2003_li@yahoo.com.cn 
Shenghui Zhao 
Department of Computer Science and Technology 
Chuzhou University Chuzhou, China 
sh_727@hotmail.com 
Abstract—Intelligent tutoring system (ITS) creates a new 
teaching mode, but most ITS are merely e-learning platforms 
that provide course study, without considering learning 
processes of learners, which can't effectively help learners to 
consolidate and review the unmastered knowledge points. Data 
mining techniques can extract the potential, valuable pattern 
or regulation from a great quantity of data. An intelligent 
tutoring system has been designed based on data mining 
technology that could return the learners feedback about 
knowledge points. In order to quickly find all frequent 
patterns, i.e., knowledge points, an improved algorithm for 
mining association rules based on FP-growth is presented. 
Experimental results show that the improved algorithm can 
provide effective decision support, and help learners to 
improve their learning efficiency.  
Keywords-data mining; intelligent tutoring system; 
association rule; frequent itemset 
I. INTRODUCTION 
In the popularization of Internet today, teaching aided 
systems about exercise and examination based on Web have 
been used widely. These systems' learners usually take out 
exercises from exercises database according to some
principles, then be graded by normal answers, but it can't
acquire the dynamic information at the time of exercising. In 
fact, analyzing corresponding information from practice 
process can make learners know the shortage of courses 
knowledge, and return to the learners some chapters that 
learners don't master well. Furthermore, the analysis results 
make teachers clear about the courses' difficulty and 
deficiency in teaching, and grasp teaching emphases and 
difficulties. In addition, the analysis results can measure and 
supervise quality of teaching, too. The above analysis 
technique can be implemented by data mining process.  
Along with the advancement of education 
informatization, the data mining technology was applied in 
education environment [1]. It becomes an imperative and 
important research topic that discovering hidden and useful 
knowledge from such an extensive quantity of data to guide 
and develop education. Data mining provides key techniques 
to realize a new-style intelligent tutoring system (ITS) for us. 
ITS is an integrated topic which involves artificial 
intelligence, computer science, cognitive science, pedagogic, 
psychics and behavioral science and so on. Ultimate purpose 
of ITS is guide and help learners using computer system, 
which gives computer system intelligent and makes 
computer system instead of teachers in a certain extent so 
that to achieve the best teaching effect. 
Application of ITS has changed the traditional teaching 
pattern, which brings into the student's study enthusiasm and 
go-aheadism, improves teaching efficiency and help students 
to develop intelligence and ability.                                                                  
II. RELATED WORKS
Research on data mining techniques applied in tutoring 
system had been existed many years. Ochi[2] presented a 
method of picking up and studying relative knowledge using 
data mining in 1998. Tiffany[3] proposed using data mining 
techniques discovered clusters of students with similar 
learning characteristics. The literature [4] explained an 
example that using data mining techniques mined the 
aggregated data in teaching, which guided the selection on 
tuition ways and evaluated students' study behaviors, etc. In 
literature [5], a method that learner's related information 
exerting data mining techniques acquired individuation 
instruction for learners was presented. Hamalainen et al. [6] 
designed a data mining system (DMS) to construct a model 
for individual learning in distance education. An intelligent 
tutoring system was established using data mining 
techniques based on BP-nerve network and clustering 
analysis [7]. Pan et al. [8] used association rules of data 
mining to build the reasonable evaluation index system and 
teaching index method based on data mining. 
 The data mining techniques being widely used in 
teaching system is association rules mining. Apriori 
algorithm [9] is the first and best-known for association rules 
mining. It is an iterative algorithm to calculate the specific 
length of item collection of given database to produce 
frequent item sets. It cut down candidate item sets using the 
character that all non empty subsets in frequent item sets are 
frequent too. Focus on improving Apriori algorithm was to 
control the sizes of candidate item sets or to reduce the times 
of scanning database or sizes. Aiming to improvement of 
Apriori algorithm, AprioriTid algorithm [10] was proposed 
that it only scanned transaction database once and initialized 
a transaction sets. Mannila et al. proposed a Sampling 
algorithm [11] that tried to use less scanning times or scan less 
transaction records to achieve performance of ascension. 
Relative to Apriori algorithm, Jiawei Han et al. [12] presented 
a FP-growth (frequent pattern growth) algorithm based on 
FP-tree that it didn't produce candidate item sets. FP-growth 
uses an extended prefix-tree (FP-tree) structure to store the 
database in the form of compressed. 
In the proposed intelligent tutoring system, most were a 
platform about course learning or teaching management. 
This paper will merge data mining techniques with 
traditional computer aided system, and design a novel 
V6-460978-1-4244-6349-7/10/$26.00 c©2010 IEEE
intelligent tutoring system based on data mining-ITSDM; In 
order to find quickly all frequent patterns and perfect 
tutoring system intelligently, as well as this system with the 
characteristics of field, we improve the association rule 
discovery algorithm based on FP-growth (IARAFP), and 
apply it to our ITSDM. 
III. IMPROVED ASSOCIATION RULES DISCOVERY 
ALGORITHM 
A. Association Rules 
To find the inherent correlation of data is helpful for 
manager to make correct and reasonable decision. 
Association rules model belongs to description model, and 
the algorithm to find association rules belongs to 
unsupervised learning methods. 
Association rule reflects the relative degree among data 
sets. Given { , , ,..., }2 3 n1I = i i i i is an itemset, let 
1 2 3 n{t , t , i ,..., t }D =  be a set of transaction called database. 
Each transaction T  in D (T D? ) contains a subset of the 
items, and it has a unique identifier TID. An association rule 
is an implication formula such as A B? , and 
A I,B I,A B? ? ? = ? . The name A is the condition of 
rule, i.e. antecedent, and B is the result of rule, i.e. 
consequent.  
To select significant rules from the set of all possible 
rules, two significant definitions were set up.  
Support Degree, the rule A B?  to D , namely 
support(A B)? , is defined as the proportion of transactions 
in the data set D  which contain both A and B. 
Confidence Degree, the rule A B?  to D , namely 
confidence(A B)? , is defined as the following 
equation: /confidence(A B) support(A B) support(A)? = ? .  
Both support degree and confidence degree have 
minimum thresholds. Association rules are required to 
satisfy a user-specified minimum support and a user-
specified minimum confidence as well. 
B. Improved association rules algorithm based on FP-
growth: IARAFP 
In the known association rules mining algorithms, 
Apriori algorithm generated large numbers of candidate item 
sets and scanned databases many times, wasting storage 
space and time. Though FP-growth algorithm scanned 
databases only two times, generated FP-tree left a great deal 
of non frequent pattern, and storage space was wasted 
seriously too. So, we improve FP-growth algorithm, when it 
creates FP-tree and sorts the items without in term of support 
degree in L1, and needs not creating condition FP-tree in the 
pattern mining, which shortens the runtime.  
In addition, because of the algorithm is applied to 
teaching system and each student is almost impossible same, 
we put the FP-tree store in a document, later, this FP-tree can 
be merged into other FP-tree when the data can be used 
directly. Therefore, the size of FP-trees is more important. In 
our system, through ameliorating FP-growth algorithm, that 
generated FP-trees only include all frequent patterns, and 
enables the storage space condense. 
Assuming p,q  are two nodes in a FP-tree, the path from 
root to p is 1 2 kp , p ,..., p< > , and from root to q is 
1 2 mq ,q ,...,q< > . 
Definition 1 Uniform Path 
If there exists same nodes in two paths which represent 
as 1 2 kp , p ,..., p< >  and 1 2 mq ,q ,...,q< > , we call the list 
composed of these same nodes as nodes p and q's uniform 
path. 
Definition 2 Common Path 
If there exits 21 1 2 h hp q , p q ,..., p q= = = in two paths 
which represent 1 2 kp , p ,..., p< >  and 1 2 mq ,q ,...,q< > , 
,h k h m< < , we call the path 1 2 hp , p ,..., p< > composed of 
these same nodes as p and q's common path. 
In order to facilitate the data mining, it needs to clean and 
pretreatment of operation before mining of data. The aim is 
to get clear suitable itemsets for mining. The data in itemsets 
are ranked in the order, while the items in the transaction D
are on the dictionary in order.  
Input data: Transaction databases D ; The minimum 
support threshold: min_sup. 
Output data: Complete set L  of frequent patterns. 
There are three backbone steps. 
Step 1: Constructing FP-trees 
Figure 1.  FP-tree before pruning 
• Scan database D , and collect frequent items into 
collection F and items' support degree; 
• Create an item head-table M, and put items of F
into M. Set a pointer plink representing the locality 
of each item and initialize them with ? ; 
In a head table, the first column represents identifier of 
an item; the second is the number of an item. Others 
represent k nodes to which plink will point. In the 
beginning, plink  points the first node. 
For example, as the FP-tree showed in Fig 1, its head 
table is expressed as following: 
plink
I
D
a
b
c
d
e
coun
t
6 
7 
6 
2 
2 
plink
d:
1
c:
2
c:0
roo
a:
6
b:
3
b:
4
c:
2
e:
1
e:
1
c:
2
d:
1
e:
0
d:
0
[Volume 6] 2010 2nd International Conference on Computer Engineering and Technology V6-461
ID Count d1 d2 ... dk
a 6
b 7
...
        
• Create a root node of FP-tree, as well as the roots of 
sub-trees according to the order of item-head table 
below root node; 
• Set some variables as the emergence times of each 
item, named as count and initialize them with 0; 
• Set a market bit for each node, initialize them with 0; 
• Scan database D ;  
• set a pointer qq, qq  plink? ; 
• for each transaction I in D
{ 
  qq  first  item in I? ; 
add 1 to the variable count of the corresponding sub-
tree below root node; 
for (pp second  item in I; pp <> null; pp next  item)? ?    
 { 
    if a son node of qq  and p  are same  
add 1 to the variable count of son node; 
else  
              create a son node pp ; 
qq pp? ;
}   
} 
• Finally, delete those nodes which their counters are 
zero under root node, and link all plink . 
The result of constructing FP-tree is like as  Fig.1. 
Step 2: Pruning FP-tree 
There are a large number of non frequent patterns in FP-
trees generated from step 1. Purpose of pruning FP-tree is 
deleting those non frequent patterns to make FP-tree only 
preserving frequent patterns. 
The process is  as following: 
pointer W points to the last line in head-table; 
for (Q W; Q is not empty; Q Q - 1)? ?
{ check each node id  linking to pointer Q. plink; 
 if i i d .support degree < min_supp and d .market bit = 0
  {  ;ip d=                //name id  as  p ; 
search the path Z =< root, ..., p > from root to node p; 
      search and store the paths{ }1 2 kz ,z ,..., z  from root to 
others nodes plink linked; 
   repeat  
{ if node g ' path among { }1 2 kz ,z ,..., z have uniform 
path with Z  
            g.support degree = g.support degree+1 ; 
if g.support degree < min_supp 
.  0g market bit = ; 
        else   
.  1g market bit = ;  
if two paths in { }1 2 jz ,z ,...,z share a common path 
           insert a node g into the common path; 
.  1g market bit = ; 
g.support degree = g.support degree 1? ; 
          delete node p from FP-tree; 
   until  (all nodes satisfied with market bit=1 or  
support degree>min_sup, and linked with plink); 
} 
} 
} 
Figure 2.  FP-tree after pruning 
After pruning, the FP-tree is like as Fig.2.
Step 3: Mining Frequent Patterns 
After pruning, FP-tree only contains frequent pattern. 
The goal of mining is to finding all frequent rules in FP-tree. 
The mining algorithm is described as following: 
L? ? ;   // L represents the set of rule 
pointer W  points to the last line in head-table; 
for (Q W; Q is not empty; Q Q - 1)? ?
{  for each node id  linking to pointer Q. plink
       search and store the paths 1 2, , ,...,i md v v v< > from id
to the sub-node of root;    //every node is a item 
form many combinations like as 
1 2 1 2 2 3 1 2, , , ,..., , , , , , ..., , , ,...,i i i i i md v d v d v v d v v d v v v< > < > < > < > < > ;       
each combination constructs a rule rl ; 
i id .counter d .support degree? ; 
     L rl L? ? ;   
     if there is a rule rl  in L 
di.support degree+ rl.support degree- > rl.support degree ; 
} 
Comparing with FP-growth algorithm, our algorithm has 
the following traits. First, the itemsets are not ranked in 
terms of the size of support degree but the order of alphabets. 
So, the rank can be accomplished at the time of data 
collection before data mining, and short the time of creating 
FP-trees. Secondly, the FP-tree only contains frequent 
patterns after pattern trees pruning, which condenses data 
furthest and reduces the storage space maximum. At the last, 
in the process of pattern discovery, it doesn't need 
considering whether or not the pattern is frequent and it need 
not to create condition FP-trees, which makes the process 
more simple and convenient, and lessen the mining time. 
I
D
a
b
c
d
e
coun
t
6 
7 
6 
2 
2 
plink
c:2
b:3
b:4
d:2
root 
a:6
c:2
c:2
e:2
V6-462 2010 2nd International Conference on Computer Engineering and Technology [Volume 6]
C. Application and Argumentation  of IARAFP in 
Intelligent Tutoring System  
An intelligent tutoring system based on association rules 
(ITSAR) is designed as Fig.3. ITSAR includes four 
subsystems or modules: an interface module, an expert 
module, a student module, and a teacher module. It provides 
a test and studying platform that learners could examine 
themselves by doing the test questions, and gain the feedback 
results of grade and evaluation that can guide learners to 
review weak knowledge points. There are many databases 
stored relative itemsets in each module.  
Figure 3.  An intelligent tutoring system based on association rules 
Before association rules mining, preprocessing should be 
done. First, the test questions are decomposed into many 
knowledge points be looked as items according to Chinese 
word segmentation dictionary algorithm [13]. Then, some 
fields can be represented by code name respectively in order 
to mine expediently and take off useless fields. After 
preprocessing, each record has an itemset, the data in temset 
are ranked by alphabets. Association rules mining are 
executed on itemsets. 
We implement IARAFP at the environment of Delphi 7.0 
and Access 2003 of DBMS. In our experiments, we select a 
course-data structure as test object. The database gathered 
382 knowledge points and 1469 unique test questions and 
196 students. Through a round test, the number of records is 
32 what the grade is excellent. Assuming min-supp is 2%, as 
well as known antecedent and consequent, then running the 
IARAFP algorithm, we get Table 1. 
From Table 1, we can deduce the association degree 
between the right knowledge points (listed in antecedent) and 
the excellent grade (listed in consequent). Through setting 
dissimilar antecedents, consequents and minimum support 
degree, different mining outcomes can be gained. And from 
those outcomes, the relations between teachers and student's 
grade, students' study habit and grades and so on can be 
analyzed. 
Rules on mining can be made process on different 
granularity, such as class, specialty and teacher and things. 
According to the association at different granularity, we can 
judge the sorts of results, for example, a class of learning, a 
teacher's teaching, and then curricular difficulties could be 
found which can advise proposals to students and teachers. 
Fig.4 is a learner exercise's feedback interface in our system, 
as feedback results, the learner gains proposals of further 
learning
TABLE I. ASSOCIATION RULES OF  GRADE=“EXCELLENT” 
sequence 
number 
antecedent ( Knowledge points of answer is  right) consequent support confidence 
1 circular linked lists \stack \ character string \binary tree storage \preorder traversal of binary 
tree \postorder traversal of binary tree\undirected graph \graph adjacency lists storage 
\depth-first traversal graph \minimum spanning tree \sequential search \selection sort \ 
bubble sorting 
grade=“Excellent” 3.57% 87.50% 
2 circular linked lists \stack \ character string \binary tree storage \preorder traversal of binary 
tree \postorder traversal of binary tree \undirected graph \graph adjacency lists storage 
\depth-first traversal of graph \minimum spanning tree \sequential search \selection sort 
\quick sort 
grade= 
“Excellent” 
3.06% 66.67% 
3 circular linked lists \stack \ character string \binary tree storage \preorder traversal of binary 
tree \postorder traversal of binary tree \undirected graph \graph adjacency lists storage 
\depth-first traversal of graph \minimum spanning tree \Sequential Search \binary search  
grade= 
”Excellent” 
2.55% 35.71% 
4 stack \ character string \binary tree storage \preorder traversal of binary tree \postorder 
traversal of binary tree \undirected graph \graph adjacency lists storage \depth-first 
traversal of graph \minimum spanning tree \sequential search \selection sort 
grade= 
”Excellent” 
2.55% 29.41% 
5 binary tree storage \preorder traversal of binary tree \inorder traversal of binary tree 
\undirected graph \graph adjacency lists storage \depth-first traversal of graph \minimum 
spanning tree \sequential search \selection sort 
grade= 
”Excellent” 
2.55% 20.83% 
6 binary tree storage \inorder traversal of binary tree \undirected graph \graph adjacency lists 
storage \depth-first traversal of graph \minimum spanning tree \sequential search \selection 
sort 
grade= 
”Excellent” 
2.04% 12.90% 
.  
[Volume 6] 2010 2nd International Conference on Computer Engineering and Technology V6-463
Figure 4.  A feedback interface of exercise 
The results of experiments show that our algorithm can 
be applied to ITS and manifest its accuracy and robustness 
while mine association rules among the data in the ITS. 
IV. CONCLUSION
ITS based on data mining can guide students autonomic 
learning, and help students discover weakness in knowledge 
structures, so that it can advance students' comprehensive use 
of intellectual ability to solve problems. A large number of 
data in the system will also help students learning some 
common problems, even the personalized, so as to improve 
teaching effect. This paper proposed an improved association 
rules mining algorithm based on FP-growth –IARAFP which 
applied to our designed ITSDM. The results of practical 
application proved that IARAFP can accelerate the speed of 
discovering frequent patterns and enable learners quickly 
find unmastered knowledge. Further, the system can help 
learners to consolidate and review, and effectively improve 
the teachers' teaching level, at the same time, enhance the 
teaching quality monitoring. 
ACKNOWLEDGMENT
The work presented in this paper is supported by the 
Education Research Project of Anhui Provincial Education 
Department (No. 2007jyxm448 and 2007jyxm115).  
REFERENCES
[1] A. Ingram,"Using web server logs in evaluating instructional web 
sites", Journal of Educational Technology Systems, vol. 28, n.2 
pp.137-157, 2000. 
[2] Y. Ochi, Y.Yano Y, T.Hayashi T, R.Wakita, "JUPITER: A Kanji 
Learning Environment Focusing on a Learner's Browsing". Proc. of 
the 3rd Asia Pacific Conference on Computer Human 
Interaction.Volume , Issue , 15-17 Jul 1998 ,pp.446 – 
451, 10.1109/APCHI.1998.704485. 
[3] Tiffany Y Tang, Gordon McCalla. "Student Modeling for a Web-
based Learning Environment: A  Data Mining Approach", Proc. of 
the Eighteenth national conference on Artificial intelligence ,pp.967 – 
968, July 28,August 01, 2002, Edmonton, Alberta, Canada. 
[4] Yang Yongbin," The Application Research of Data Mining 
Technique in Education",Computer Science, Vol.33, No.12, 
2006,pp.284-286. 
[5] Luo Xinwen, Yan youbiao Cai haibin, " Study of personalized 
modern distance education system based on web mining", Computer 
Engineering and Design Vol.28, No.12,2007, pp.3016-3019. 
[6] W. Hamalainen,J. Suhonen, E. Sutinen, H. Toivonen, "Data mining in 
personalizing distance education courses". In World conference on 
open learning and distance education, 2004,pp.1-11,Hong Kong.  
[7] Qi Manfei Hou Dongmei Wang Wansen," Research on intelligent 
teaching system based on web and data-mining", Computer 
Engineering and Design,Vol.29, No.17,2008,pp.4571-4573. 
[8] Pan Qingxian, Qu Linjie, Lou Lanfang," Data Mining and 
Application of Teaching Evaluation Based on Association Rules". 
Proc. of 2009 4th International Conference on Computer Science & 
Education, Volume, Issue, 25-28 July 2009, pp. 1404-1407, 
10.1109/ICCSE.2009.5228194. 
[9] R. Agrawal,T. Imielinski,A. Swawi,"Mining association rules 
between sets of items in large database", Proc. of the ACM SIGMOD 
International Conference Management of Data , ACM press  New 
York, NY, USA ,1993, pp.207-216. 
[10] R. Agrawal , R. Srikant ,"Fast algorithms for mining association 
rules", Proc. of the 20th International Conference on Very Large Data 
Bases,Morgan Kaufmann Press, 1994,pp.487–499 
[11] H. Toivonen, "Sampling large databases for association rules", Proc. 
of the 22nd International Conference on Very LargeData Bases. 
Morgan Kaufmann Press, 1996,pp.134–145. 
[12] Han Jiawei, Pei Jian, Yin Yiwen, Mao Runying, "Mining frequent 
patterns without candidate generation : A frequent pattern tree 
approach",Data Mining and Knowledge Discovery , Vol.8, 
No.1,2004,pp.53 – 87. 
[13] Li Yuemin, Wang Hao, Zhao Shenghui, "Research on Chinese word 
Segment with Dictionary Algorithm" . Journal of Chuzhou 
University,Vol.10, No.3, 2008,pp.22-25. 
V6-464 2010 2nd International Conference on Computer Engineering and Technology [Volume 6]
