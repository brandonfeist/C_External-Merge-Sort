  
CHINESE QUESTION CLASSIFICATION BASED ON MINING ASSOCIATION 
RULES 
YONG-LE SUN 
School of Computer and Communication Engineering, Weifang University, Weifang 261061,China 
E-MAIL: sunny_bit@126.com 
Abstract: 
In this paper, a method of Chinese question classification 
based on the mining association rules is proposed. Words and 
Bi-gram are extracted from question as classific features. The 
method can mine the association rules between the type of the 
question and its classific features, to construct an association 
rules - based database. At last the type of the question is marked 
by choosing the type which the most association rules define. 
Experimental results show that the proposed method is feasible 
and can achieve good performance. 
Keywords: 
Nature Language Processing; Association rules; Question 
classification 
1. Introduction 
With the rapid development of Internet, people find it 
more and more difficult to get their requirements by search 
engine. Traditional document retrieval searches relevant 
documents according to keywords which are provided by 
users, and the results is a long ranked list of documents. The 
question answering system can give a correct and exact 
answer to a given question. So it has recently received much 
attention from natural language processing communities and 
it is one of the most important topic in TREC( Text REtrieval 
Conference). A typical question answering system includes 
four modules: question analysis, search module, answer 
candidate extraction and answer selection. Question analysis 
module extracts keywords, classifies question type and gives 
a kind of formal expression of a given question. Question 
classification system can sign one class to a given question 
based on the expected answer type. It could restrict the 
candidate’s space of the answer according to the semantic 
category of the answer and could select the appropriate 
approach to extract the answer. So the precision of the 
question classification could affect the quality of question 
answering systems. 
There are two kinds of question classification method. 
One was based on handcrafted rules [1][2][3][4] which was 
used in the past years. By all appearances, its shortage is 
time-consuming and labor-intensive to get these rules. And it 
is difficult that hand-crafted rules which could work perfectly 
on a specific questions set are applied to another one. 
Recently more and more question classification methods have 
been researched and applied which were based on statistical 
method and machine learning techniques, such as SVM 
[5][6][7][8], SNoW [9][10], Maximum Entropy Model [11], 
Modified Bayesian [12] and etc. Jun Suzuki’s question 
classification system was based on SVM [6] which used 
HDAG kernel. Krystle Kocik[11] developed a new approach 
to question classification, which involved the application of 
statistical methods, namely Maximum Entropy models for 
classification. Yu Zhang [12] introduced a modified Bayesian 
model to classify the Chinese question in open-domain 
answering system which was based on analysis of the 
Bayesian model. Keliang JIA[13] proposed a method of 
Chinese question classification based on ensemble learning 
which takes full use of the generalization feasibility of 
ensemble learning to improve the precision of the Chinese 
question classification.  
This paper presents our research work on automatic 
question classification based on association rules. It is 
organized as follows: section 2 presents the Chinese question 
classification taxonomy; section 3 describes Chinese question 
classification based on association rules; section 4 presents 
experimental results for question classification and finally 
section 5 conclude the paper. 
2. Chinese question taxonomy 
There are numerous question taxonomies which were 
defined according to question answering system. There are 
three kinds of QA (question answering) task in TREC: 
definition task, factoid question task and list question task. In 
this paper, we focus attention on factoid questions. In most of 
these question taxonomies, question types are defined 
according to the semantic viewpoint of the answer in order to 
reduce the number of answer candidates. As there is no 
413
2010 IEEE978-1-4244-6527-9/10/$26.00 ©
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
  
standard Chinese question taxonomy, this paper builds 
Chinese question taxonomy by combining Chinese question 
features and some other question taxonomy [5][8][9][13] 
from previous researchers. Table 1 shows all question types. 
TABLE 1 . CHINESE QUESTION TAXONOMY 
Coarse Fine 
abbreviation abbreviation, explanation 
human 
Discoverer, person name, position, inventor, first person, human description, 
human others 
location 
city, continent, country, ocean, mountain, state, province, island, river, 
address, lake, sea 
numeric 
code, total, area, money, distance, length, order, percent, spend, 
temperature, size, weight, age, period, frequency, phone number, numeric other 
time date, time, day, month, season, year, time range, time list, time other 
entity 
animal, body, color, plant, creative, disease, substance, religion, press, event, 
food, instrument, language, product, Sport, vehicle, symbol, technique  
description definition, description, manner, reason, other description 
organization 
Party, sports-team, university,  bank, company, institute, union, other 
organization 
3. Question classification based on association rules 
3.1. Specification of the association rules 
To mine the association rules is to discover the 
important relevance between the items in a transaction 
database. In the association rules, the item sets I={i1,i2,…,in} 
includes n different items. Given a transaction database D, 
each transaction record is a subset of the sets I. The 
association rule is described as YX  , here IX ? , 
IY ?  and ?=YX . Its support degree and confidence 
degree are separately defined as follow formulas. 
{ } DTYT,XDT)YX(support ???=       (1) 
)X(support)YX(support)YX(confidence =    (2) 
The task to mine association rules is to discover all of 
the strong association rules. The support degree of the rules is 
no less than the minimize support degree determined by the 
users and the confidence degree is no less than the minimize 
confidence degree determined by the users.   
From formula (1), the support degree reflects the 
frequency of the item set occurring in the transaction 
database D. The item set, which frequency is more than the 
threshold, is a frequent item sets. So we think the frequent 
item sets means that there is some correlation between the 
corresponding items. 
3.2. Features extraction  
Given a Chinese question, our system first segments it 
and tags its words POS. After that the system then extracts 
 
 
pertinent features from the question. This step is very 
important part to any question classification system. Better 
feature sets can provide more accurate question 
representations and finally can be used to get better 
classification performance. After features extraction a feature 
vector is created, which is the basis for mining association 
rules. There are usually two kinds of features can be extracted 
from the question sets to construct the vector: lexical 
semantic features (word, POS and named entity types and so 
on) and structural features (Bi-gram and dependency relation 
and so on).  
To select the words and POS features, the research [8] 
introduces that POS is little effective of question 
classification, and Chinese POS tags is more difficult than 
English. So POS isn’t extracted as classific feature in this 
paper. 
To extract N-gram and dependency syntactic features, 
the research [8] shows the contribution of dependency 
relation is no better than that of Bi-gram because of the 
precision of the dependency parser. So Bi-gram is selected as 
classific feature in this paper. 
3.3. Basic idea of question classification based on mining 
association rules 
In the paper, questions set is regarded as a transaction 
database, and a question in it is regarded as a transaction 
record, the words and other features extracted from the 
questions are regarded as items. If some items frequently 
occur together in some transactions, then there must be some 
correlation between them. The paper redefines the meanings 
of the formula 1 and formula 2. Given a question, Y presents 
414
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
  
the set of the types of the question, X means the set of its 
classific features. The item sets I includes all question types 
and all question classific features. The database D is the 
question sets, each record T is a question. The association 
rule YX  means that the type Y of the question can be 
determined by its classific features set X. 
The basic idea of the question classification based on 
mining association rules is: to discover the frequent item sets 
composed of the question types and question classific 
features by scanning question database, which support degree 
is no less than the threshold of support degree; to produce the 
association rules YX   which confidence degree is no less 
than the threshold of the confidence degree based on 
maximum frequent item sets; at last to determine the type of 
the question by choosing the type which the most association 
rules deduced. 
In the research, there are more items in the frequent item 
sets, theirs frequency occurring in the question database is 
less, theirs support degree is less. But these frequent item sets 
are helpful to the classification. In order to avoid to loss these 
frequent item sets, the paper gives different min-support 
degree according to different N-frequent item sets. N is larger, 
the min-support degree is smaller. N is smaller, the degree is 
larger. The association rules YX  , which confidence 
degree is no less than the threshold of the confidence degree, 
is produced . 
3.4. Question classification based on mining association 
rules 
Given a question, firstly choose the association rules 
from the association rules database according to its classific 
features, the selected rules may be more than one, they are all 
used in question classification. At last the type of the question 
is determined by the rules committee voting, the type which 
is determined by the most rules is selected as the type of the 
question. The algorithm is as follows: 
Step1?Generate the frequent item sets. 
Step1.1 Generate the 1-candidate sets according to the 
question database, scan the database to obtain their support 
degree, select the candidate sets which support degree is no 
less than the threshold of support degree to formulate the 
1-frenquent item sets;  
Step1.2 ? Use N-frequent item sets to generate 
N+1-candidate sets, set a smaller threshold of support degree, 
rescan the database to obtain their support degree, select the 
candidate sets which degree is no less than the threshold to 
formulate the N+1-frenquent item sets;  
Step1.3?Try the step1.2 again and again, until no N+1 
candidate sets generates or N is more than 5. Get all frequent 
item sets which satisfy the condition.  
Step2?Produce the association rules YX   from 
maximum frequent item sets according to the threshold of the 
confidence degree;  
Step3?Given a question, choose the association rules 
according to its classific features. At last the type of the 
question is determined by the rules committee voting. The 
type, which is decided by the most rules, is selected as the 
type of the question.  
Step4?Output the type. End the program. 
4. Experiments and result analysis 
4.1. Data set  
There aren’t standard data sources for Chinese question 
classification. Here a data set is defined as a set of Chinese 
questions labeled with expected answer types according to 
some question taxonomy. So we collect our question set from 
the TREC QA track which was first introduced at TREC-8. 
We download the free test question set from TREC, translate 
them and modify them as our test question set. There are 
5500 questions.  
4.2. Experiments and results  
In order to test the classifier in this paper, we conduct 
the experiments under the fine grained category definition.  
We conduct evaluation in terms of precision shown as 
formula (3) : 
all
corr
num
numprecision =         (3) 
Here, numcorr is the number of the correct classified 
questions, while numall is the total of the testing questions.  
Experiment 1: comparison study of different scale of 
training set. The test set is 500 questions. The experimental 
results are shown in table 2. 
TABLE 2 . COMPARISON STUDY OF THE DIFFERENT SCALE QUESTION 
TRAINING SET 
feature 2000 3500 5000 
word 62.8% 68.8% 71.8%
Word+Bi-gram 69.2% 78.0% 83.8%
 
From table 2, we can find that the precision is better and 
better with the enlargement of the questions set. It is because 
that the association rules are based on the statistic of the 
feature frequency, and larger training set is more 
advantageous to compute the feature frequency and more 
coincident with the fact. So the classification result is more 
effective. The precision based on words and Bi-gram is 
improved by about 10% compared to classifier based on 
415
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
  
words only because Bi-gram is a kind of structural 
information and is more informative than words.  
Experiment 2: we design open test and close test based 
on KNN and AR(association rules). Open test: the test set is 
500 questions extracted randomly from 5500 question set and 
the rest 5000 question is as the training set. Close test: the 
training set is 5000 questions and the test set is 500 questions 
extracted randomly from the training set. The experimental 
results are shown in table 3. 
TABLE 3 . COMPARISON STUDY OF THE KNN AND THE AR 
Test manner KNN AR 
Close test 68.4% 86.4%
Open test 65.8% 83.8%
 
Table 3 shows that the AR method in this paper achieves 
better performance than the KNN method. As the table shows, 
the precisions of open test are close to the precisions of close 
test. It proves that the proposed method can achieve good 
performance in question classification for new question set.  
5. Conclusion 
This paper puts forward a new method for Chinese 
question classification based on the mining association rules. 
Words and Bi-gram are extracted from question as classific 
features. The method can mine the association rules between 
the question type and its features, and the type of the question 
is determined by choosing the type which the most 
association rules deduced. The experimental results show that 
the precision obtained by our algorithm is higher than other 
algorithms. In future, we will extract more features (including 
named entity, chunk, question focus, Bi-gram and so on) in 
order to be favorable to question classification and expect to 
improve the method of mining association rules. 
References 
[1] Hull, D.: 1999, Xerox TREC-8 question answering track 
report. In: Proceedings of the 8th Text Retrieval 
Conference (TREC-8). 
[2] Lee, K.-S., J.-H. Oh, J. Huang, J.-H. Kim, and K.-S. 
Choi: 2003, TREC-9 Experiments at KAIST: QA, CLIR 
and Batch Filtering. In: Proceedings of the 9th Text 
Retrieval Conference (TREC-9). 
[3] Prager, J., D. Radev, E. Brown, A. Coden, and V. Samn: 
1999, The use of predictive annotation for question 
answering in TREC. In: Proceedings of the 8th Text 
Retrieval Conference (TREC-8). 
[4] Pasca, M. and S. M. Harabagiu: 2001, High 
Performance Question/Answering. In: Research and 
Development in Information Retrieval. pp. 366-374. 
[5] Dell Zhang, and Wee Sun Lee. Question Classification 
using Support Vector Machines. In Proceedings of the 
26th annual international ACM SIGIR conference on 
Research and development in information retrieval, 
Page: 26–32, Toronto, Canada, 2003. 
[6] Jun Suzuki, Hirotoshi Taira, Yutaka Sasaki, and et al. 
Question Classification using HDAG Kernel. In 
Proceeding of 6th Information-Based Induction 
Sciences, pp. 217-222, 2003. 
[7] Donald Metzler and W. Bruce Croft. Analysis of 
Statistical Question Classification for Fact-based 
Questions. Source: Information Retrieval, Volume 8, 
Number 3, January 2005, pp. 481-504(24). 
[8] Youzheng Wu, Jun Zhao, and Bo Xu Chinese Question 
Classification from Approach and Semantic Views. 
Lecture notes in computer science, pp 485-490, 
Springer. 
[9] Xin.Li, and D Roth. Learning Question Classification. 
In Proceedings of the 19th International Conference on 
Computational Linguistics, Taibai, 2002. 
[10] Xin Li, Dan Roth, and Kevin Small. The Role of 
Semantic Information in Learning Question Classifiers. 
In Proceedings of NLPKE2003, Beijing, 2003. 
[11] Krystle Kocik. Question Classification using Maximum 
Entropy Models. Available at http: //www. it. usyd.edu. 
au/research/news/kociksummary.pdf. 
[12] Yu Zhang, Ting Liu, Xu Wen. Modified Bayesian 
Model Based Question Classification. In Proceeding of 
the First National Conference on Information Retrieval 
and Content Security, pp236-241, Shanghai, China, 
2003.?in Chinese?. 
[13] Keliang Jia, Kang Chen, Xiaozhong Fan, Yu Zhang, 
Chinese Question Classification Based on Ensemble 
Learning, Proceeding of the Eighth ACIS International 
Conference on Software Engineering, Artificial 
Intelligence, Networking, and Parallel/Distributed 
Computing(SNPD 2007), pp. 342-347, Qingdao, China, 
2007.7.
 
416
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
