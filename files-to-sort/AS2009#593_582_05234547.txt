A FUZZY MINING APPROACH FOR AN ENCODED TEMPORAL DATABASE
WITH LOWER COMPLEXITIES OF TIME AND COMPUTATION
C.Balasubramanian
Department of Computer Science and Engineering
K.S.Rangasamy College of Technology
Namakkal-Dt., Tamilnadu, India
rc.balasubramanian@rediffmail.com
Dr.K.Duraiswamy
Department of Computer Science and Engineering
K.S.Rangasamy College of Technology
Namakkal-Dt., Tamilnadu, India
drkduraiswamy@yahoo.co.in
Abstract— Databases and data warehouses have become a vital
part of many organizations. So useful information and helpful
knowledge have to be mined from transactions. The principle
of data mining is better to use complicative primitive patterns
and simple logical combination than simple primitive patterns
and complex logical form. This paper overviews the concept of
temporal database encoding, association rules mining. It
proposes an innovative approach of data mining to reduce the
size of the main database by an encoding method which in turn
reduces the memory required. The use of the anti-Apriori
algorithm reduces the number of scans over the database. A
graph based approach for identifying frequent large item sets
involves less time complexity. The fuzzy approach that
integrates fuzzy-set concepts with Apriori when used for
temporal mining involves less computational complexity.
Experimental study has proved that the fuzzy approach
performs better by resulting in lesser time and computational
complexity then the other approaches for rule mining on an
encoded temporal database.
Keywords- Anti-apriori algorithm; Association rules mining;
Data mining; Fuzzy approach; Graph based approach; Temporal
database encoding.
I. INTRODUCTION
Knowledge discovery in databases (KDD) is often called as
data mining. It discovers useful information from large
collections of data [1]. The discovered knowledge can be
rules describing properties of the data, frequently occurring
patterns, clusterings of the objects in the database, etc. The
amount of data stored in database is growing rapidly.
Intuitively, these large amounts of stored data contain
valuable hidden knowledge [2]. Data mining especially
association rule discovery tries to find interesting patterns
from databases that represent the meaningful relationships
between products and customers or other relationships in
some other applications. Because the amount of these
transaction data can be very large, an efficient algorithm
needs to be designed for discovering useful information.
An association rule describes the associations among
items in which when some items are purchased in a
transaction, the others are purchased, too. In order to find
association rules, we need to discover all large itemsets from
a large database of customer transactions. A large itemset is
a set of items which appear often enough within the same
transactions. The frequent itemset and association rules
mining problem has received a great deal of attention and
many algorithms have been proposed to solve this problem.
Discovering association rules in these algorithms are usually
done in two phases. In the first phase, the frequent itemset
are generated and in the second phase, the interesting rules
are extracted from these frequent itemset. If the support and
confidence of a rule is above the minimum threshold, the
rule will be interest. The task of discovering all frequent
itemset is quite challenging especially in the large database
because the database may be massive, containing millions of
transactions. A famous algorithm, called Apriori, was
proposed in [3], which generates (k+1)-candidates by
joining frequent k-itemset. So all subsets of every itemset
must be generated for finding superior frequent itemset,
although many of them may be not useful for finding
association rules because some of them have no interesting
antecedent or consequent in the rules. This process takes a
long time. And it also requires thousands of times of
database scan. The complexity of the calculation increases
exponentially. Additionally, the size of database is the main
problem of this algorithm. Some modified algorithms of
Apriori (AprioriTid and AprioriHybrid) are proposed to
solve this problem but these algorithms also have the
database size problem [2]. A method to encoding the
database and an algorithm, which is called anti-Apriori
algorithm, is brought into focus. By using this algorithm,
only the frequent itemset that are of interest and can be
converted into association rules are generated, so it has a
lower complexity of time and space. At the meantime, the
times of the database scan are also reduced [2].
In real life, media information has time attributes either
implicitly or explicitly. This kind of media data is called
temporal data. Temporal data exist extensively in
economical, financial, communication, and other areas such
as weather forecast. Unlike conventional data mining,
temporal data mining has its exclusive characteristics.
Temporal data mining can be classified into temporal
schema and similarity. Temporal schema mining focuses on
time-series schema mining, temporal causal relationship
mining, and association rules mining. While similarity study

_____________________________ 
978-1-4244-4520-2/09/$25.00 ©2009 IEEE 
is mainly concentrated on query algorithms, such as the
design of similarity query algorithms and the development
of similarity query language [4]. The paper focuses on a
fuzzy approach of association rule mining for temporal data
which has been encoded.
II. ENCODING AND APRIORI FAMILY
In this section, a discussion on the encoding method and the
application of the family of Apriori algorithms for
association rule mining on a static database is presented
A. The Encoding Method
The presentation of database is an important
consideration in almost all algorithms. The most commonly
used layout is the horizontal database layout and vertical
one [2]. In both layouts, the size of the database is very
large. A large database to be transformed into a smaller one
with all properties of its original layout is expected.
Database encoding is a new presentation, which can reduce
the size of database and improve the efficiency of
algorithms. Instead of maintaining a large table in the
transaction database, one table is created with only two
columns. The first one is the transaction identifier and
another is for the entire items that occur in the transaction.
All items in one transaction are converted into only one
number that has all properties of these items. By this way,
the new database is much smaller than the previous one and
can be loaded into memory easily. So the cost of memory is
reduced. According to the assumption that only one number
represents an itemset, when converting an itemset into a
number, a measure attribute is defined, which is a numerical
attribute associated with every item in each transaction in
the database layout. A binary number expresses a numerical
attribute, that is, those items that are occurring in one
transaction are depicted with 1 and all the other items are
represented with 0. The transaction measure value, denoted
as tmv(Ip , Tq ), is a value of a measure attribute related to
an item Ip in a transaction Tq . tmv (Ip , Tq )= 0 means item Ip
does not occur in the transaction Tq, while tmv (Ip , Tq)= 1
means item Ip occurs in the transaction Tq . In table 1, for
example, tmv (I4, T1) is equal to 1. Any item Ip in the set of
items is encoded as one prime number, denoted as E (Ip).
Prime numbers are used because any number except 1 and
themselves cannot divide them. For any item Ip in the
transaction Tq, a new measure denoted as M (Ip, Tq) is equal
to the product of tmv (Ip, Tq) and its encoding number E (Ip)
is assigned. This value is gotten by equation 1. After this
step, for all Ip and Tq, if M(Ip, Tq) equal to 0, then convert M
(Ip, Tq) into 1. This operation is described in equation 2. For
any transactions, the value MTq is equal to the multiplication
of all M (Ip, Tq). The value of MTq is represented in equation
3.
M (Ip, Tq)= tmv(Ip, Tq)×E(Ip) (1)
For all (Ip, Tq) If M (Ip, Tq ) =0 => M(I p, Tq ) =1 (2)
MTq= ?(Ip, Tq) (3)
For any itemset I=(Ip1, Ip2, …, Ipn), there is one value
denoted as MI is equal to the multiplication of all E(Ip) if its
Ip occur in I, as described in equation 4. The value MI shows
the number corresponding to itemset I. And then this
number can be used instead of itemset I.
MI =? E(IP ) (4)
IP? I
With this encoding, instead of maintaining all tmv(Ip,Tq) for
every item and transaction, the value MI can be stored for
every transaction. Example 1 shows the result of using this
technique.
Example 1: Convert vertical database layout
Table 1
Binary representation
TID I1 I2 I3 I4
1 1 0 0 1
2 0 0 0 1
3 1 1 1 0
4 0 0 1 1
Table 2
Prime number form
Ip EIp
I1 7
I2 5
I3 3
I4 2
Table 3
Single number representation
TID M
1 14
2 2
3 105
4 6
In the case of large databases, encoding an item to one
prime number may cause some problems especially in
computing the value M (which involves multiplication) for
any transaction [2]. As a solution, the database can be
divided into smaller parts vertically by having correlated
items in one part. Then every part of the database is encoded
to one column. Frequent itemset mining is done
independently and association rules in every part are
discovered. After an encoding of this form, the database has
a smaller number of columns which leads to better
performance and efficiency.
2.2  Anti-Apriori Algorithm
  All Apriori-like algorithms for itemset mining start from
finding frequent 1-itemset. In these algorithms, finding
frequent itemset is done in bottom up manner. Different
from these algorithms, a new algorithm called as anti-
Apriori is used, in which the discovery of frequent itemset is
done in up to down style. It means that the large frequent

itemset are found at first and then all of their subsets (that
are certainly frequent) are extracted. [2]. In this technique, it
is supposed that any frequent itemset must be at least one
time occurs in the transactions lonely (without any other
items that are not member of that itemset). In other words, if
itemset (I1, I2, I3) is frequent, the itemset at least in one
transaction without any other items, such as shown in table
4.
Table 4
Frequent itemset presentation
 I1 I2 I3 ……………
Tid 1 1 1 0000000000
In this method for every transaction Tq, the GCD(greatest
common divisors) between MTq and MT corresponding to
other transactions are computed and frequency of these
greatest common divisors are stored in GCD-set. GCD-set is
the candidate for frequent set. For any GCD in GCD-set, if
its frequency is above the required threshold, it will be
selected and inserted into the FGCD-set (frequent GCD
itemset). For every transaction maintained, a set is denoted
as GCDTid, composed of GCDs and frequency of any GCD.
For example, if GCD-set and frequency between first
transaction and other transactions is equal to GCD1={(42,3),
(6,8), (21,2), (15,4), (105,1)} and the required threshold for
support is equal to 7 and then the set (6,8) has a frequency
equal to 8, greater than 7, and then 6 is inserted into FGCD-
set.
 Discovering association rules is based on all FGCD,
which has been found in the previous phase. Measure M
corresponds to any frequent itemset maintained in FGCD-
set. Every measure M in FGCD-set is decomposed into the
multiplication of prime number and each prime number
corresponds to one item. The itemset that corresponds to M
is identical and frequent, and all subset of it must be
frequent. Every M in FGCD-set is decomposed into a
candidate head Y and a body X=M/Y. This algorithm
iteratively generates candidate heads Ck+1 of k+1 size,
starting with k=1. If the head and the body are interesting
and valuable, the confidence C of the rule X=>Y is
computed as the quotient of the supports for the itemset. C
=Support(M) /Support(X) (Support(X) is computed by
counting the number of MTid that can be divided by X). If
any rule has a C greater than or equal to the given threshold
for confidence, the rule will be appended into association
rules.
2.3 Apriori, AprioriTid, and AprioriHybrid
 The Apriori and AprioriTid algorithms generate the
candidate itemsets to be counted in a pass by using only the
itemsets found large in the previous pass, without
considering the transactions in the database. The basic
intuition is that any subset of a large itemset must be large.
Therefore the candidate itemsets having k items can be
generated by joining large itemsets having k-1 items, and
deleting those that contain any subset that is not large. This
procedure results in generation of a much smaller number of
candidate itemsets. The AprioriTid algorithm has the
additional property that the database is not used at all for
counting the support of candidate itemsets after the first pass
[5]. Rather, an encoding of the candidate itemsets used in
the previous pass is employed for this purpose. In later
passes, the size of this encoding can become much smaller
than the database, thus saving much reading effort. Based on
the observations of Apriori and AprioriTid, a hybrid
algorithm which is called as AprioriHybrid uses Apriori in
the initial passes and switches to AprioriTid when the
candidate itemset at the end of the pass will fit into the
memory.
III. DISCOVERY OF TEMPORAL ASSOCIATION RULES
In this section, the graph mining method for a temporal
database employs the Apriori algorithm with an added
feature (i.e.) time interval expansion and mergence [6]. Also
a fuzzy approach to a temporal database that integrates
fuzzy-set concepts and AprioriTid is discussed [7].
A. Time based extension of Apriori
Temporal association rules can be viewed as a factor of
derivative consideration time, when mining association rules.
Recently, the Apriori algorithm is adapted to temporal
association rules mining [4]. Time-interval expansion, and
mergence, is combined with the Apriori algorithm to
association rules mining on datasets that have valid-time
constraints. The key implementation is to add a valid-time
attribute on association patterns. If a given tuple owns
attribute A, the problem can be decomposed into two sub
problems. (1) Check if the valid-time attribute of a given
tuple matches another attributes. (2) Check whether the
tuple that does not attach any valid-time attribute has
attribute “A” [4]. The logical linkage between two sub
problems is that if the sub problem (1) holds, sub problem
(2) must hold; otherwise; if sub problem (2) doesn’t, sub
problem (1) mustn’t hold. According to the first case, we
can scan database to solve these two sub problems
simultaneously. Time complexity and space complexity of
this case are almost the same as those of Apriori algorithm.
B. Apriori for an encoded dynamic database
In this section, the graph mining algorithm is discussed
[4]. The algorithm contains two steps to mine temporal data.
The sample transaction is showed in Table5:
Table5
The general database model
TID Itemset Valid-time
100 ACD [40, 70]
200 BCE [60, 90]
300 ABCE [90, 120]

400 BE [30, 50]
500 ABC [400, 500]
It is found that frequent item sets do not have temporal
factor. The search process is listed as:
• First, enumerate all items. The numbers of A, B, C,
D, E are 1, 2, 3, 4, and 5 respectively.
• Second, generate the frequent 1-item set according
to support enough, and give numbers to frequent
itemset. Assume that the support enough is 2, the
frequent 1-item set are expressed as (1), (2), (3), (4)
and (5). Correspondingly, the numbers of BV1,
BV2, BV3, and BV5, are (1010), (0111), (1110) and
(0111) respectively.
• Third, create a relationship graph that shows the
relationships among items in frequent 1-item set;
and then generate frequent 2- item set.
• Fourth, create a searching frequent 3- item set.
During this process, we determine the execution
state of algorithm, because the count of items in
frequent 2-item set is 4, which is larger than 3, and
the number of the node of which the degree is
larger than 2 is 3, it is larger than 3. So the
algorithm continues execution. Finally, We travel
the list T of candidate frequent itemset to get the
tuple (2,3,5), in which x=3. This item can be used
to construct a complete graph. At the same time,
we check out the BV2 BV3 BV5 , the count of
number 1 in the result is less than support enough,
so it is a frequent itemset.
• Fifth, the count of the element in frequent 3-item
set is 1, which is less than 4, resulting in the
termination of the algorithm. Check out whether
the valid-time attribute of all frequent items meet
each other by making use of the technologies of
time-interval expansion and mergence, let
support=2, then scan the database. The checkout
result is that (1), (2), (3) (5), (1,3), (2,3), (2,5), (3,5)
and (2,3,5). These all meet temporal constraints of
frequent items. Generate temporal rules by
combining confidence enough with the frequent
items obtained above performance evaluation.
When the Apriori algorithm searches frequent n- itemset in
frequent n-1 item set, it firstly takes joint and pruning
operations to construct candidate frequent itemset CK , The
joint operation will be executed CS2 times, and the pruning
operation will be implemented K. CS2 times. The
intermediary result S is the count of candidate frequent
itemset. Let the time complexity of executing comparative
operation be O(t), The complexity of the algorithm is
dependent upon the O(t) order frequent set. Assuming that
there are 10-thousand frequent 1-item set, the Apriori
algorithm will produce more than ten-million frequent 2-
item sets. If we want search frequent schemas whose length
is 100, it will require 1030 candidate frequent itemset,
which will reduce the efficiency of Apriori algorithm. Also
the number of the elements in the candidate frequent itemset
is greatly decreased. For instance, the frequent 2- item sets
in this example are (1,3), (2,3), (2,5), and (3,5). From the
time-space complexity point of view, the performance of the
algorithm is better [6].
C. Proposed Fuzzy AprioriTid for an encoded dynamic
database
Fuzzy set theory is being used more and more frequently
in intelligent systems because of its simplicity and similarity
to human reasoning. Therefore to use fuzzy sets in data
mining, a mining approach that integrates fuzzy set concepts
with The AprioriTid mining algorithm has been identified.
It finds interesting itemsets and fuzzy association rules in
transaction data with quantitative values. The role of fuzzy
sets helps transform quantitative values into linguistic terms,
which reduces possible itemsets in the mining process. They
are used in the AprioriTid data mining algorithm to discover
useful association rules from quantitative values.
The fuzzy mining algorithm first transforms each
quantitative value into a fuzzy set with linguistic terms
using membership functions. The algorithm then calculates
the scalar cardinality of each linguistic term on all
transaction data using the temporary set. Each attribute uses
only the linguistic term with the maximum cardinality in
later mining processes, which keeps the number of items the
same as that of the original attributes. The mining process
based on fuzzy counts is then performed to find fuzzy
association rules.
IV. PERFORMANCE AND EVALUATION
The anti-Apriori algorithm in combination with the
encoding method decreases the size of the database and also
leads to reduction in the number of passes over the static
database. The performance of AprioriHybrid relative to
Apriori and AprioriTid for large datasets is as follows.
AprioriHybrid performs better than Apriori in almost all
cases. In general, the advantage of AprioriHybrid over
Apriori depends on the size of the candidate itemset that
declines in the later passes. If there is a gradual decline in
the size, AprioriTid can be used for a while after the switch,
and a significant improvement can be obtained in the
execution time. By using this encoding method the
efficiency of Apriori, AprioriTid and AprioriHybrid has
improved significantly.
The use of Apriori and anti-Apriori algorithm combined
with an encoding method for association rule mining in a
temporal database has been experimented on complaints
database. The encoding method reduced the size of the
database, which is depicted by figure1. The use of anti-
Apriori on databases with time constraints reduced the
number of scans over a temporal database.

Figure1: Effect of encoding
Database encoding has been applied to a static database
before applying Apriori or anti Apriori. To make it scalable,
the same is applied to a dynamic database which involves
time constraints. The fuzzy AprioriTid mining approach has
been found to reduce the computational time involved.
Figure2 shows the performance of these approaches in terms
of time.
Figure2: Performance comparison
V. CONCLUSION AND FUTURE WORK
 This paper studied the impact of the Apriori family of
algorithms on an encoded database for association rule
mining. Each of the algorithms has a different impact and
produces effective results. The effect of Apriori and anti-
Apriori algorithms on a temporal data base which has been
encoded by an encoding method provided advantageous
results in terms of lower complexities of time and space.
The graph mining method has been found to involve less
execution time. The fuzzy approach to data mining has been
found to be good enough to provide reduction in
computation time. As future work, the discovery of
association rules may be used to allow the user of a
knowledge discovery system to observe the changes and
fluctuations in the rules which could be considered as an
enhancement. It may also possible to observe the seasonal
or cyclical changes and fluctuations in the rules.
REFERENCES
[1] Abdullah Uz Tansel, Susan P. Imberman,
Discovery of Association Rules in Temporal
Databases, International Conference on
Information Technology, 2007.
[2] Tong Wang, Pi-Lian He, Database Encoding and
an Anti-Apriori Algorithm for association
Rules Mining, Proceedings of the Fifth
International Conference on Machine learning
and Cybernetics, August 2006.
[3] Margaret H Dunham, Data Mining Introductory
and Advanced Topics, Tsinghua University
Press, Beijing, 2003.
[4] Hui Ning, Haifeng Yuan, Shugang Chen, Temporal
Association Rules in Mining Method, Proceedings
of the First International Multi-Symposiums on
Computer and Computational Sciences, 2006.
[5] R. Agrawal, R. Srikant, Fast algorithms for Mining
Association Rules, Proceedings of the 20th
International Conference on Very Large Databases,
September 1994.
[6] Show-Jane Yen, Arbee L.P. Chen, A Graph Based
Approach for Discovering Various Types of
Association Rules, IEEE Transactions on
Knowledge and data Engineering, Vol.13, No.5,
September/October 2001.
[7] Tzung-Pei Hong, Chan-Sheng Kuo, Shyue-Liang
Wang a Fuzzy AprioriTid mining algorithm with
reduced computational time, Tenth International
Conference on Fuzzy Systems, 2004.

