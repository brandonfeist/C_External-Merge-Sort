Optimization of Asociation Rules with Genetic Algorithms
Avendan˜o J. Christian
School of Computer Engineering and Telecommunications
Diego Portales University
Santiago,Chile
Email:christian.avendano@mail.udp.cl
Gutie´rrez P. Mart?´n, MSc.
School of Computer Engineering and Telecommunications
Diego Portales University
Santiago,Chile
Email: martin.gutierrez@mail.udp.cl
Abstract—As databases grow in size, the interpretation of
data within them, is increasingly difficult to obtain, and often
only stored as backup of various transactions of records. In
these data there is new information which is present, but
requires a higher level of processing. The outcome of this
processing are association rules which are used to detect events
that occur together in a set of data. To find these rules,
a very popular algorithm in Data Mining is Apriori, which
aims to reduce the search space and increase efficiency. In
this paper, we will introduce new metrics like interestingness
and completeness with derived applications from Artificial
Intelligence, “Genetic Algorithms”, in order to reduce the
search space and execution time.
Keywords-data mining; asociation rules;artificial intelligence.
I. INTRODUCTION
“According to investigators two basic goals of Data
Mining [3] are prediction and description. Prediction uses
variables in the database to predict unknown features of
interest. Description focuses on the discovery of patterns
that describe data and subsequent submission to the
interpretation of the user. There are several techniques
that describe these objectives. Some of them can be
classified into the following categories: classification,
clustering, association rules mining, analysis and discovery
of sequential patterns.” [5].
This research will consider the Mining Association Rules
for Knowledge Discovery in conjunction with genetic algo-
rithms.
A. Rules of Association
Since its introduction in 1993 the task of association rule
mining has received a great deal of attention. Today the
mining of these rules is one of the most popular pattern
discovery methods in KDD.
An association rule is an expression X=?Y, where X
and Y are sets of items. The meaning of these rules is
quite intuitive: Given a database D of transactions, where
each transaction T ? D includes a set of items, X =? Y
expresses that whenever a transaction T contains X then T
probably contains Y also. The rule confidence is defined
as the percentage of transactions containing X plus Y in
relation to the total number of transactions that contain X.
That is, the confidence can be understood as the rule of
conditional probability p(Y ? T / X ? T).
The support of an association rule is the percentage /
fraction of records containing X and Y on total number of
records in the database. Support (s) = support (X =? Y) =
P(A ? B).
The idea of mining association rules originates from the
analysis of data from a market basket. A person buying
goods x1 and x2 could also buy another product with
probability c%. Direct application to business problems,
along with inherent intelligibility, even for non-experts in
data mining make the association rule mining a popular
method.
The main motivation for using genetic algorithms (fur-
thermore referred to as GAs) in the discovery of high-
level prediction rules is that they perform a global search
and cope better with attribute interaction than the greedy
rule induction algorithms often used in data mining. The
improvements associated to the use of GAs, as we will see
in this paper, definitely help the rule based systems used for
classification as described in results and conclusions.
B. The Problem
Obtaining mining association rules yields two main
problems which need to be dealt with: First, the algorithmic
complexity. The number of rules increases exponentially
with the number of items present in the database.
Fortunately, today’s algorithms are able to prune efficiently
this vast search space based on thresholds for quality
measures of the rules [4]. Second, rules of interest should
be collected from within the set of generated rules. This
approach also implies a high algorithmic cost because the
number of rules which are generated is very large, i.e.,
typically over 100,000 rules. However, the percentage of
usable rules is frequently only a small fraction [4].
XXIX International Conference of the Chilean Computer Science Society
1522-4902/10 $26.00 © 2010 IEEE
DOI 10.1109/SCCC.2010.32
193
Most of the research in the area focuses on reducing
computation times, but also takes into account the quality
of the generated rules. In this proposal, which will also
cover both issues, the main idea will be to implement the
algorithm used in Data Mining, Apriori, but in a more
limited form to reduce the cost of generating itemsets, and
furthermore apply GAs to optimize the quality of rules
based on the itemsets obtained by our version of Apriori.
II. GENETIC ALGORITHMS
As discussed in [6], in general the main motivation for
using GAs in the discovery of high-level prediction rules is
that they perform a global search and cope better with at-
tribute interaction than the greedy rule induction algorithms
often used in data mining. This section of the paper discusses
several aspects of GAs for rule discovery. The main areas of
discussion include individual representation of rules, genetic
operators involved and the choice of Fitness function.
A. Individual Representation
The first thing to consider is that an association rule is
an implication of the type X ? Y, where all the attributes
represented by X, are called antecedent and attributes
represented by Y is called consequent. Therefore, an
association rule can be represented by n attributes in the
antecedent and m attributes in the consequent.
To represent an individual, we will use the Java ArrayList
structure, which allows us to store a variable number of
attributes. In consequence, it is never necessary to know
how many attributes the rule has.
Rule class is defined, which contains:
• <String> ArrayList attributes: Contains all the
attributes of an association rule .
• <String> ArrayList values: Contains all allocation
values of the rule, in which ”00” denotes presence of
the attribute in the antecedent of the rule and ”11”
denotes presence of the attribute in the consequent of
the rule.
Considering the above, an association rule will be repre-
sented as it is shown in Figure 1.
B. Genetic Operators
1) Crossover: Based on the classic genetic operators, we
propose a new implementation, in order to obtain a greater
variety of rules, given the representation of the rule:
• Select two random elements from the rule container.
Figure 1. Chromosome Representation
• Of those elements, some number of attributes of
the antecedent and of the consequent are randomly
selected for crossover.
• Perform the exchange of the selected attributes,
maintaining the values of the attributes that were not
selected in the previous stage.
For example, consider the following rules:
• R1 :AB?CD
• R2 :EFG?HIJ
Applying the steps described in the previous stage we have:
• In R1, two items from the antecedent and one item
from the consequent will be randomly selected .
• From R2, one antecedent item and two consequent
items will be interchanged.
• Then, we randomly select elements of the antecedent
and consequent items, for example, AB for the
antecedent and D for the consequent in R1 and FH
for the antecedent and J for the consequent in R2.
Crossover is applied between both rules and the two
new rules are spawned:
• R
?
1 : F?CHJ
• R
?
2 : EGAB?ID
The new operator is obtained by randomizing the selection
of the sections to interchange and further enriching the
classical crossover genetic operator. It adds variability on
the size of the rule. By using a crossover operator as
defined above, it can be noted that unlike A-Priori, which
generates the k-itemsets - a process that can take a long
time-, M-GARM may obtain rules with a high number of
attributes with a single application of the crossover operator.
Note that validations are considered for the new rules, to
avoid falling into logical inconsistencies such as redundancy
attribute, empty rules, etc.
194
2) Mutation: For the mutation, a new strategy was also
implemented. It is defined as follows:
• Select a random element from the rule container.
• Randomly select what it mutates: antecedent or
consequent. Select and delete the corresponding
attribute. If the resulting rule is empty in the
antecedent or the consequent, then generate a new
random rule in its place.
• Update rule container, inserting the mutated rule.
Since the probability of mutation is low, mutated rules
automatically decrease the number of attributes. When
this occurs, the quality of the rule will probably diminish
greatly, therefore, it is likely that at the time of selection
such rule is discarded.
3) Evaluation: For evaluation of the rules we consider
two new metrics: the factor of interest (INF) and
completeness factor (CF).
Figure 2 shows the confusion matrix which defines the
performance of an association rule.
Figure 2. Confusion Matrix
The abbreviation of the labels used in the confusion
matrix have the following meaning:
• TP: True Positive ? Number of attributes satisfying
antecedent and consequent.
• FP: False Positive ? Number of attributes satisfying
antecedent but no consequent.
• FN: False Negative? Number of attributes satisfying
consequent but not antecedent.
• TN: True Negative ? Number of attributes not
satisfying antecedent nor consequent.
In our implementation, we used some quality measures
based on the previous definitions:
• Interestingness Factor (INF): TPTP?FP
• Completeness Factor (CF): TPTP?FN
Now, based on the previously mentioned measures and
[5], the fitness function is defined as:
Fitness =
TP 2
(TP ? FP )(TP ? FN)
The general idea is to maximize the number of rules which
comply with X ? Y. This occurs when the quality function
is close to 1, yielding values of FN and FP close to 0 for
the optimal case.
4) Selection: For selection, a fitness criterion is used.
Boundaries around the value of 1 are defined by the user,
for example [0.8 .. 1.2] , to only maintain high-quality rules.
5) Termination Criterion: If we consider a convergence
criterion for termination, the execution time might be very
large, which would affect the optimization. On the other
hand, a defined number of iterations will be the chosen
criterion, since it is a user-defined parameter and gives
mobility to the algorithm.
III. SCOPE
The proposed algorithm allows us to find Boolean
association rules, using metrics of interest and completeness.
However, the generation of the random population is
strongly dependent on the problem. Furthermore, this
algorithm can be used only for discrete nominal cases,
ongoing cases will be the subject of further work.
IV. RESULTS
A. Example Dataset
Consider a dataset from the Machine Learning Repository,
University of California, Irvine (UCI).
• Title: Evaluation of Automotive.
• No attributes: 6.
• No instances: 1728
For a demonstration of its utility, the analyzed database
was generated synthetically. A car evaluation database
was derived from a simple hierarchical decision model
originally developed for the demonstration of DEX1[2].
1An Expert System Shell for Multi-Attribute Decision Making
195
The model evaluates cars according to the following
concept structure:
• CAR: car acceptability.
– PRICE: overall price.
? Buying: buying price.
? Maint : price of the maintenance.
– TECH: technical characteristics.
? Doors : number of doors.
? Persons: capacity in terms of persons to carry.
? Lug boot: the size of luggage boot.
? Safety: estimated safety of the car.
• Attribute values2:
– Price:very high(A),high(B),medium(C),low(D).
– Maintenance:very high(E),high(F),medium(G),
low(H).
– Doors: 2(I),3(J),4(K),more(L).
– Persons: 2(M),4(N),more(O).
– Lug boot: small(P),medium(Q),big(R).
– Safety: low(S), medium(T),high(U).
– Acceptability:
unacceptable(V),acceptable(W),good(X),
very good(Y).
Figure 3 shows a sample of the original dataset and the
modified dataset. Each line represents a transaction.
Figure 3. Original and custom dataset
B. Quality of the Association Rules
For this analysis, we show the rules obtained on an
initial population of 10 individuals and 10 iterations of the
algorithm. Figure 4 shows the rules that were found.
2Are coded with a letter of the alphabet to distinguish them in the
implementation of the dataset.
Figure 4. Retrieved Rules
V. FUTURE WORK
Data mining is a young science, so this line of research has
yet to bear much fruit. In regard to the M-GARM algorithm,
further work may be done on it, some examples being:
• Improving the algorithm, incorporating extended at-
tribute analysis, and also allows attributes of different
types of data.
• P-GARM, a distributed version of the algorithm
M-GARM, which incorporates the division of tasks for
the analysis of the dataset is also object of future work.
• Implementation of metaheuristics such as Ant Colony,
Simulated Annealing, etc.
• Incorporate searching and analysis of negative
association rules like X ? ¬ Y which is of high
importance nowadays. For example, in seismology,
solving the problem could determine relations like
Tsunami ? ¬ Earthquake, considering the large
amount of data related to the topic.
• Retrieve and process data from research companies,
providing the ability to model datasets from their
transactional databases, to obtain datasets as real as
possible, with a large number of attributes and records.
VI. CONCLUSIONS
This research is based on a thorough study of mining
association rules in data mining, and has resulted in the
implementation of a new algorithm, M-GARM, which is
proposed as an alternative to the Apriori algorithm to search
for strong association rules.
From the standpoint of computational complexity, it
was calculated and tested that the algorithm M-GARM is
more efficient than A-Priori since it has a linear complexity
relative to the number of transactions times the number of
parameters analyzed in the dataset. However, the number of
196
generated rules, are clearly dependent on the quality criteria
that are set by metrics of interest and completeness, which
are calculated within the genetic algorithm at the selection
phase.
Moreover, concerning the power of genetic operators, our
definition of crossover and mutation work very efficiently.
Tests show that optimal settings for probabilities are of
80% for crossover and 1% for mutation.
Tests were performed on large datasets with many
parameters, but the calculation of the quality function
created a significant bottleneck when the size of the random
population was increased. There are no major differences
with A-Priori at this point.
The quality of the resulting rules, was considerably
higher due to an adequate evaluation function that correctly
relates attributes in addition to long associations which are
achieved by the crossover operator.
A factor which also influences a correct exploitation of
GAs is the randomness of the initial population.
Data mining is a discipline that is still evolving and will
certainly contribute to knowledge discovery. Integration
with ERP and Business Intelligence will be very helpful
to narrow the search space to obtain more structured
information.
REFERENCES
[1] Agrawal R. and Srikant R., Fast algorithms for mining associa-
tion rules. In Proceedings 20th International Conference Very
Large Data Bases, 1993. pp. 487-499
[2] M. Bohanec, V. Rajkovic Expert system for decision making.
Sistemica 1(1), pp. 145-157, 1990.
[3] Han, J., K. M. Data Mining: Concepts and techniques.2001
[4] Hipp J., Gu¨ntzer U., G. N. Algorithms for Association
Rule Mining. A general survey and comparison. SIGKDD
Explorations ACM SIGKDD. July 2000.
[5] Sanjeev S., Sudhir S., V. B. Optimization of association
rules using genetic algorithms. International Journal of Soft
Computing, Medwell Journals, 2007.
[6] Alex A. Freitas, “A Survey of Evolutionary Algorithms for
Data Mining and Knowledge Discovery” Postgraduate Pro-
gram in Computer Science, Pontificia Universidade Catolica
do Parana Rua Imaculada Conceicao, 1155. Curitiba - PR.
80215-901. Brazil.
197
