  
New Application of Association Rules in Teaching Evaluation System 
 
Lanfang Lou, Qingxian Pan, Xiuqin Qiu  
Institute of Computer Science and Technology, Yantai University 
Yantai, China, 264006 
Loulanfang@126.COM 
pqx@ytu.edu.cn 
 
Abstract—Data mining is the process of finding correlations or 
patterns among dozens of fields in large relational databases. 
In this paper we propose a novel association rules for data 
mining to improve the famous algorithm Apriori. The 
proposed approach uses the intersection operation to generate 
frequent item sets. It is different from the existing algorithm as 
it scans the database only one time and then uses the database 
to mine association rules. The proposed technique has been 
implemented in a teaching evaluation system, to enhance the 
foundation in performance evaluation for staff in teaching 
issues. 
Keyword-data dining, association rules; Apriori algorithm; 
teaching evaluation.  
I.  INTRODUCTION  
Data mining is a kind of process of decision support. It 
gets the potential and useful information and acknowledges 
from practical application data which is large, incomplete, 
noisy, ambiguous and random. Data mining relates to 
extracting a large of data from database, transforming, 
analyzing and modeling handling these data, and 
withdrawing the critical data to aid decision making. Mining 
association rules is an important issue in data mining [1]. R. 
Agrawal et al in 1993 proposed the famous the Apriori 
algorithm based on frequent item set [2, 3], then the most 
algorithms are all based on the basic algorithm for 
improvements or derivative variant of  the algorithm [4 , 5]. 
An improved association rule is proposed in this paper, 
which uses the intersection operation to generate frequent 
item sets. The method can be easily realized using SQL 
language, which lays the basis of enhancing the 
performance of mining algorithm based on association rules. 
This algorithm only needs to scan the database one time and 
then uses it to mine association rules in teaching evaluation 
system, which provides effective foundation to the 
scientificity of the teaching evaluation. 
II. DATA MINING ANALYSIS METHOD BASED 
ON ASSOCIATIONRULE 
A.  Association Rules 
The mining of association rules is the important research 
direction of data mining area. Association rules reflect the 
inherent correlation among data. To find the inherent 
correlation of data is helpful to maker to make correct and 
reasonable decision. Association rules model belongs to 
description model, and using the algorithm to find 
association rules belongs to unsupervised learning methods. 
The data mining of association can be formal described, as 
shown in the follows: 
Let I={i1, i2,…, im}, which is a collection consisting of  
of m different items. Given a transaction database D, and 
among it, every transaction T is a collection of a group 
items of I, namely T I, T has the unique identifier TID. An ?
association rule is an implication formula such as X=>Y, 
and X I, Y I, XY=. The conditions of association ? ?
rules to set up are: 
It has the support degree S, namely at least there are S% 
transactions in transaction database which contain X Y;?  
It has confidence level C, namely in all the transactions 
containing X of transaction database D, there are at least 
C% transactions which contain Y too. 
The basic task of association rules is to mine the strong 
rules (rules with high support degree and confidence level 
which are called strong rules). That mining association rules 
can be divided into two phases [6]: (1) mining big item 
collection, the transaction support degree S is higher than 
the pre-determined minimum threshold item. (2) using big 
item collection to produce the association rules whose 
confidence level C is higher than the pre-determined 
minimum threshold item in the database. The whole 
performance of mining association rules is decided by the 
first phase. After determining a big item collection, the 
corresponding association rules can be derived. So the key 
to improve association rule for data mining algorithm is to 
effectively calculate big item collection. 
B. Apriori Algorithm 
Apriori [7, 8, 9] is an algorithm to calculate the specific 
length of item collection of the given database. Apriori 
calculates the frequent item sets in the database iteratively 
level by level, the calculation in i-th iteration provides all 
the i-item frequent item sets. 
 
An improved Apriori is proposed in this paper. It needs 
to scan the database only one time and create a logo for each 
data item list. The support of frequent item sets is obtained 
International Conference on Computer and Information Application?ICCIA 2010?
13C978-1-4244-8598-7 /10/$26.00      2010 IEEE
  
by logo list intersection. This can reduce the scanning times. 
The method can be easily realized by using SQL language. 
III. IMPROVED APRIORI ALGORITHM 
The improved algorithm is mainly improved when 
generating frequent item sets. The main idea is based on the 
intersection operation. 
Definition 1 Lk*Lk={p q, and p? ,q?Lk,p.item1= 
q.item1,…, p.itemk-1 = q.itemk-1, p.itemk<q.itemk}         (1)                                                               
When k=1, the operator expresses single connection. 
For example :suppose L2={BC,BD},Support set of 
itemset {BC} is{002,003,004,006}, Support set of itemset 
{BD} is {002,003,004,006},According to according  to 
definition 1 we can get L2*L2={002,003,004} without 
scanning database. 
A. Description of Improved Apriori Algorithm[10] 
L1 = {large 1-sets};   
// L1 is made up of itemset , tset set and support. 
  for ( k = 2; Lk-1 ? ?; k++)  do  
      Ck = gen ( Lk-1);  
      //k length frequent itemsets are generated.   
  end 
Answer  := ?k Lk; 
 
Function gen()  is Lk-1 as input, and the results can be 
directly generated k-item frequent item sets. Function Gen  is 
as follows: 
 
Function Gen ( Lk-1) 
{ 
 Ck ={ Lk-1.Itemset * Lk-1.Itemset}  
// candidates are generate according  to definition 1. 
 Tk ={ Lk-1.Tset Lk-1.Tset} 
for all candidates c ? Ck do 
        c.support=Count(c.Tk);  
If c.support < minsup then  
delete c 
end   
 end 
} 
B. Applications 
We use table Ias an example to illustrate the algorithm. 
TABLE I.  A SIMPLE  TRANSACTION  DATABASE
Tran saction ID Itemset 
001 A, C, D 
002 A, B, C, D, E 
003 B, C, D 
004 A, B, C, F  
005 D, E, F 
006 B, C, D, F 
 
This algorithm only needs to scan the database once , 
then create the following database tables II. 
According to table II, we can calculate the elements 
number of each row (that is transaction support number), 
then delete those itemsets whose support number are less 
than that of a given threshold support of items set. And thus 
1-item frequent itemsets are got. In table II, itemset {E} is 
canceled because of its support number is 2,which is less 
than the given threshold. 
TABLE II.  NEW  CREATION  DATABASE 
Itemset Support Set  
?A? ?001,002,004? 
?B? ?002,003,004,006? 
?C? ?001,002,003,004,006? 
?D? ?001,002,003,005,006? 
?E? ?002,005? 
?F? ?004,005,006? 
According to the one length of large itemsets, support set 
of itemset uses intersection operation between each other, 
and calculate the row number of elements, then delete those 
whose support are less than a given threshold support of 
items set. And two length of large itemsets are got. 
TABLE III.  ONE LENGTH OF LARGE ITEM SETS 
Itemset Support Set Support 
?A? ?001,002,004? 3 
?B? ?002,003,004,006? 4 
?C? ?001,002,003,004,006? 5 
?D? ?001,002,003,005,006? 5 
?F? ?004,005,006? 3 
TABLE IV.  TWO  LENGTH  OF  LARGE ITEMSETS 
Itemset Support Set Support 
?A,C? ?001,002,004? 3 
?B,C? ?002,003,004,006? 4 
?B,D? ?002,003,006? 3 
?C,D? ?001,002,003?006? 4 
According to the two length of large itemsets, we can get 
three length of large itemsets. 
TABLE V.  THREE  LENGTH  OF  LARGE  ITEM SETS  
Itemset Support Set Support 
?B,C,D? ?002,003?006? 3 
There is only one three length of large item sets, so 
algorithm ends. 
IV. THE APPLICATION OF IMPROVED 
ALGORITHM IN THE TEACHING EVALUATION 
SYSTEM  
Teaching evaluation is a process of value judgment and 
improvement to teaching effect and the realization degree of 
teaching target according to the teaching target and teaching 
International Conference on Computer and Information Application?ICCIA 2010?
14
  
standards. Ever since a long time, the evaluation of teacher 
works only focused on quantity, not on quality, which leaded 
to unscientific evaluation and quantification. There are 
important theory meaning and practical application value to 
enhance teachers level and teaching quality, promote the 
development of education that how to scientifically, 
accurately, objectively evaluate the teaching effect of 
teachers.  
In database, the original data of students’ evaluation on 
2007-2008 spring semester’s teaching is shown in table VI. 
In data table, there are part of the data of student evaluation 
on teaching. Column heading bpr is teacher number, pgr is 
student number, pgnr is course number, zb1,zb2,zb3 and zb4 
are different indexes separately, zp is overall evaluation, zgpj 
is the subjective points of view of the  students.  
TABLE VI.  ORIGINAL RECORDS TABLE OF STUDENT EVALUATION ON 
TEACHING 
Bpr Pgr pgnr Zb0 zb1 zb2 Zb3 Zb4 zb5 zb6 zb7 zb8 zb9
25062 21505130 25011 B A A A A B A A A A
25006 25505131 25035 A A A A A A A A A A
25062 25605108 25011 A A B B A A A A A A
25022 25501101 25278 A C A A A A A A A B
21011 21501132 21218 A A A A A A B B B A
22067 21502191 22245 A A A A A A A B A A
Indicators 1 (zb0), indicator 2 (zb1)... indicator 9 (zb8), 
General Comments (zp9)are stored in the form of storage. 
For each indicator, it may appear four forms of assessment 
(A, B, C, D). Each indicator is given a corresponding number. 
For example: zb0 evaluation forms have A0, B0, C0 and D0 
four forms of assessment. 
Each Indicators has different weight power .  the weight 
power table as shown in table VII.  
TABLE VII.  WEIGHT POWER  OF EVERY INDICATORS 
NO. Evaluation index Weight power 
1 Zb0 11 
2 Zb1 11 
3 Zb2 8 
4 Zb3 8 
5 Zb4 11 
6 Zb5 11 
7 Zb6 10 
8 Zb7 12 
9 Zb8 8 
10 Zb9 10 
Four forms of assessment (A, B, C, D) values were 
0.95,0.8,0.65,0.4. 
We use Asp.net as the system's main development tools, 
Microsoft SQL Server 2000 as backend database. Figure 1 is 
evaluation of web pages. 
Some results screenshot are as follows. 
 
 
Figure 1.  Evaluation of web pages 
 

Figure 2.  Evaluation Results. 
So we can conclude that in all courses, the total 
curriculum is B closely related to them as teachers, warm 
and caring to students, strict requirements. 
V. CONCLUSIONS 
With the increase of teaching data information, data 
mining technology is applied into teaching evaluation, which 
can enhance the technology level, science, objectivity and 
impartiality of teaching evaluation and service teaching work 
better. The paper uses association rules of data mining to 
build the reasonable evaluation index system and teaching 
index method based on data mining. Through the feedback 
and investigation of 968 teaching evaluation results of 2007-
2008 autumn semester, the method of evaluation teaching 
has been approved by all teachers, which proves the method 
is valid. 
 
International Conference on Computer and Information Application?ICCIA 2010?
15
  
REFERENCES 
 
[1] David Hand,Heikki Mannila,Padhraic Smyth. Principles of Data 
Mining[M]. translater Yinkun Zhang. Beijing: Mechanical Industry 
Press. 2003: 272?284. 
[2] R Agrawal. Mining Association Rules Between Sets of Items in 
Large Databases[ C] .Washington :Proceedings of the ACM 
SIGMOD International Conference Management of Data,1993 :207- 
216. 
[3] Agrawal R, Srikant R. Fast algorithms for mining association rules 
in large databases [A].Proc. of the 20th Int’l Conf on Very Large 
Data Bases [C]. Santiago: Morgan Kaufmann, 1994:478~499 
[4] Z.Xu,S. Zhang. Mining Association Rules in an optimized Apriori 
algorithm [J] Computer Engineering.2003, 29(19):83-85. 
[5] G. Grahne, J.Zhu, Efficiently using prefix-trees in mining frequent 
itemsets. In Proc. ICDM’03 Int. Workshop on Frequent Itemsets 
Mining Implementations (FIMI’03), Melbourne, FL, Nov. 2003. 
[6]  Mao Guojun, Duan Li Juan, Wang. Data mining principles and 
algorithms [M]. Beijing: Tsinghua University Press. 2005:64-71. 
[7]  Liubing Xiang, Zhang Yi to, Fang Jun, et al. Teaching evaluation 
based on data mining methods [J]. Computer and Modernization, 
2005,20 (4) .87-89 
[8]  Mannila H, Toivonen H, Verkamo A. Efficient algorithm for 
discovering association  rules[C]. AAAI Workshop on Knowledge 
Discovery in Databases, California:AAAI Press, 1994:181-192. 
[9]  NengBin Wang. Database system [M]. Beijing: Electronic Industry 
Press, 1995. 
[10] Lou Lanfang  Pan Qingxian,An improved algorithm based on sets 
operation for mining frequent itemsets[J].Journal of Shandong 
University(Natural Science).2008,11: 54-57. 
International Conference on Computer and Information Application?ICCIA 2010?
16
