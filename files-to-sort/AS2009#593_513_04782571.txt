Massive Pruning for Building an Operational Set of Association Rules: 
Metarules for Eliminating Conflicting and Redundant Rules. 
 
 
 Martine Cadot Alain Lelu  
 Université Henri Poincaré / 
LORIA, Nancy, France 
Martine.Cadot@loria.fr 
http://www.loria.fr/~cadot 
Université de Franche-Comté / 
LORIA, France 
Alain.Lelu@loria.fr 
 
 
 
Abstract 
 
Extracting a set of Association Rules (AR) is a 
common method for representing knowledge embedded 
in a database. As long as many authors have aimed at 
improving the individual quality of these rules, not so 
many have considered their global quality and 
cohesiveness: Our objective is to provide the user with 
a set of rules he/she may combine to reason with, a 
consistent set as regards to “common sense logic”. As 
local quality measures offer no warranty in this 
respect, we have defined patterns of major 
incoherencies and have associated metarules to them, 
resulting in a post-treatment cleaning phase for 
tracking down incoherencies and proposing 
corrections. We show that on the artificial Lucas0 
database of the Causality Challenge [11], starting 
from 100 000 rules, we have reduced this rule set by 
three orders of magnitude, to 69 high-quality 
condensed rules embedding most of the structure 
designed by the challenge organizers.  
 
1. Introduction 
 
We will consider a database as an incidence table 
between objects (or transactions) and properties (or 
variables).  For example, in the domain of supermarket 
consumer behavior, objects are shopping carts, 
variables are articles, and an article is (or not) in a 
shopping cart. An association rule (AR) is an oriented 
relation between several variables. In this framework 
the rule ABCÆDE for example is fully characterized 
by four numbers: p (resp. q) is the number of objects 
simultaneously verifying the properties A, B and C 
(resp. D and E) amongst the N ones of the collection, r 
is the number of objects verifying simultaneously all 
the above-mentioned properties. The quality of a rule 
may be evaluated with a bunch of measures depending 
on the sole N, p, q and r. The most notorious ones are 
support (r or r/N) and confidence (r/p) [9].  
As the number of ARs may increase exponentially 
with the number of variables, pioneers [1] proposed to 
extract only those with a large support and confidence. 
In the sequel, other authors proposed a more drastic 
pruning along two different directions: 1) keeping the 
only rules which have large values as regard to some 
other measures of quality [9], 2) using algebraic 
properties of itemsets (Galois lattices) to extract a 
minimal generator set of AR ([2, 9, 15]), also called 
“non-redundant ARs” by Zaki [21]. The first way 
strengthens the individual quality of each rule, and the 
second way ensures a global quality of the rule set. 
 Another research line, which is ours, consists in 
shifting to an upper level: Once a baseline rule set has 
been extracted, the authors have proposed to look for 
contradictions, necessarily of non-algebraic kind, as 
shown in [4] and specified below, either thoroughly 
inspecting each one for individual discussions and 
interpretations of these “inconsistent KD nuggets” [7, 
18], or globally eliminating all of them, in an OLAP 
(On-Line Analytical Process) and data-cube view [6, 8, 
22]. Let us consider more thoroughly these two 
domains. 
In the first domain we must mention the problem of 
exceptions retrieval in databases, where the objective is 
to bring them to light, for studying, not for cleaning: 
the reader may refer to the exceptions rules of Suzuki 
1998, or to the occurrences of the Simpson’s paradox 
[7], as well as to the methods for building the sole rules 
corresponding to a pattern of interest, using a SQL-like 
request, as Botta [3] does. 
The second OLAP domain harbours a bunch of 
contributions, particularly the works supervised by 
Jiawei Han at Simon Fraser University (Canada). 
Amongst other works, Yongjian Fu [8] is mining the 
« multi-level AR’s », Hua Zhu [23] is mining the 
« intra-dimensional AR’s », Qing Chen [6] looks for 
« sub-rules » within « data cubes »; these data 
structures are typical members of the OLAP family, 
where one can cross variables such as Locations, 
Products, Quantity and Costs. The complexity of such 
International Conference on Information, Process, and Knowledge Management
978-0-7695-3531-9/09 $25.00 © 2009 IEEE
DOI 10.1109/eKNOW.2009.12
90
data mining does not result from the number of 
variables (e.g. 4), termed dimensions in this context, 
but from the structure of their values, in case of 
categorical variables. For example, the Location 
variable fractionates into a hierarchy with several 
levels (continents, states, regions, towns), with many 
values at each level. The inconsistencies between rules 
that the authors detect and try to correct happen when 
their components are located in several levels of the 
hierarchy, or are issued from operations of aggregation 
within a given level. Depending on the case, they 
enforce constraints for the extraction of itemsets or 
AR’s, or cleanse the rule set using meta-rules. 
Compared to ours, their meta-rules do not take into 
account, as far as we know, the problem of negation, 
more or less specific to binary variables, nor the 
method for organizing the operation of meta-rules 
when numerous variables may contradict in many 
ways. 
 
On the more specific side of statistics and machine 
learning, some works are focussing on the special case 
of classification rules, i.e. AR’s with the same 
dependent variable in their right sides. Let us point out 
Toivonen [19] who describes a pruning algorithm 
(RuleCover) for XÆY rules where Y is a target 
variable. The principle is to reduce iteratively a rule 
set, in such a way as every individual confirms at least 
one rule. This kind of a “subject-oriented” pruning 
does not consider the components of the rules, nor their 
support or confidence. Their rule set may be 
inconsistent, considered with our variable-oriented 
criteria. Conversely a side effect of our pruning process 
may be that some subjects confirm no rule. 
Moreover, the Jakulin’s approach [14] is to be 
mentioned also. This author keeps clear of tackling 
directly the consistency of rules by considering their 
components; in a pre-processing stage, he avoids 
inconsistencies rising from the interaction of the 
descriptive variables with the target variable, by 
building new variables taking the place of the 
disputable original ones. This way of seizing the 
problem is common with the statistical experiment 
[12]. Unfortunately this method cannot be generalized 
outside the classification problem. 
 
We propose here a unified approach tackling in the 
same mathematical framework both issues of 
redundancy and contradiction. Our objective is to 
provide the domain expert with a set of rules he/she 
may combine in order to reason with. In order to stick 
to « common sense logic », we define a concept of 
similarity between rules, instead of the highly 
restrictive equivalence concept of Zaki [21]. 
 
2. “Common sense logic”. 
 
“Common sense logic” refers to the structuring 
principles of a form of deduction-based reasoning 
which make the logic indisputable for anybody gifted 
with common sense. We propose three principles for 
individual rules, and a fourth for a rule set. 
 
2.1. Three first principles 
 
Here are some principles which every rule used in 
this type of reasoning must verify: 
- P1 : a valid rule is broken in very few instances : 
for example, the rule “crows are black” is accepted 
by all, and cannot be doubted because of the 
spotting of one white crow.  It would require a 
certain number of crows of a different colour from 
black to make the rule questionable.  
- P2 : a rule must be applicable in a sufficient 
number of cases : for example, the rule “three-
legged crows are white” would be refused by this 
type of logic since three-legged crows do not exist 
or too rarely so. 
- P3 : a rule is valid in a given place at a given time : 
for example, it is possible to imagine that in other 
worlds, in other times, there could be differently 
coloured crows. 
 
These first three principles show that this common 
sense logic differs from formal logic in its fuzziness 
(note expressions such as “a sufficient number ”, 
“rarely”, “a given place ”) and its utility (P2). These 
three principles which establish the validity of one rule 
without reference to the other ones are verified by the 
ARs usually extracted from a database (P1: a 
confidence threshold is decided, P2: a support 
threshold too, and P3: the set of rules represents only 
the database on which it is built).  
 
2.2. The fourth principle 
 
Now it is worth looking into a more complex 
example which infringes this common sense logic: 
“Simpson’s paradox”.  It was related for the first time 
in 1903 [20], but it has cropped up regularly since then 
and each time caused as much surprise [16]. 
In an exam taken by pupils in various schools 
girls obtained better results than boys in each 
of the schools. At the same time the 
published overall results showed that girls 
had obtained less good results.  Although 
there is a perfectly clear mathematical 
explanation for this phenomenon, which 
defies common sense (Simpson 1951 [17]), 
indignation was expressed in the media by 
supporters of the feminist cause.  
91
To formalize the situation with binary variables, let 
A be “being a girl”, B “being a pupil at school E” and 
C “passing”; the 3 rules of this paradox in common 
sense logic are noted 
 ABÆC and AnonBÆC and AÆnonC. 
The paradox comes from the fact that the user gifted 
with common sense naturally summarizes the first two 
rules, ABÆC and A nonBÆC, into the more general 
rule AÆC, which conflicts with the third rule 
AÆnonC.  
Our fourth principle prevents both contradictions 
(of Simpson’s type, amongst others), as well as 
redundancies: 
- P4 : validation of a rule takes place after being 
confronted to rules with the same variables, except 
one, in the same positions, and/or one variable 
shifted into its negation. In each case a decision of 
deleting the rule or not follows. 
As for the above example of the paradox with three 
rules, the pairs of rules which need to be controlled in 
accordance with P4 are: p1={ABÆC and A 
nonBÆC}, p2={ABÆC and AÆnonC} and p3={A 
nonBÆC and AÆnonC} 
This principle detects and suppresses not only 
possible redundancies and contradictions but also 
interaction effects familiar to statisticians [5]. A 
detailed description of activating the P4 principle is 
provided below. 
 
3. The general method for automatic 
cleansing using P4 
 
P4 covers several elementary problems.  A meta-
rule mri is attributed to each of these problems. Its role 
is to determine which couples contain two incoherent 
rules and then to decide whether to reject both, one or 
none.  When both rules are considered incoherent and 
of an uneven quality, the poorer one is dropped.  
Bearing in mind, however, that the quality measures of 
AR’s are numerous (currently more than 50 [10]) the 
user is advised to choose a suitable sub-set of 
measures.  The choice of several measures means that 
the better of two rules as determined by one measure 
may be the worse by another.  When this case occurs 
the rules are called non-comparable.  Moreover if the 
quality differences between the two rules are not larger 
than thresholds defined by the user, they are said to be 
similar. Users must indicate the required level of 
cleansing. For a demanding expert, similar and non-
comparable rules are both cleansed by the meta-rule 
rules (this case is termed demanding in the meta-rule 
definition), whereas for a less demanding expert, the 
meta-rule will only cleanse the similar rules.  
 
To sum up, the decision taken by a meta-rule mri 
for a given couple of rules {r1,r2} depends on three 
elements : 
- the coherency level of the couple of two rules 
determined by two values (coherent/incoherent). Its 
calculation modality is part of the definition of a 
meta-rule mri. 
- the requirement level of the user determined by 
himself with two  values, demanding/ 
undemanding. 
- the quality order of the rules of the couple {r1,r2} 
determined by four values (non-comparable, 
similar, r1 prevalent over r2, r2 prevalent over r1). 
This order is calculated using an AR comparison 
function parametered by the user and common to 
all the meta-rules. 
 
Before defining the meta-rules presented later here 
follows an analysis of how two rules are compared. 
 
4. Comparing two rules 
 
Two rules are compared using their quality 
measures.  Let I be the sub-set of measures chosen by 
the expert, supposed to be increasing functions of the 
quality of the rules, e(I) their difference thresholds (for 
each measure the largest difference deemed negligible 
by the expert). The difference dI between two rules r1 
and r2 for a measure I element of I, is defined by: 
 
 
 
Then the result of the comparison of two rules is: 
1. r1 and r2 are similar if ? I ? I, dI(r1,r2)=0. 
2. r1 is prevalent over r2 if ? I ? I, dI(r1,r2)?0, and 
? I ? I, dI(r1,r2)=1. 
3.  r2 is prevalent over r1 if ? I ? I, dI(r1,r2)?0, and 
? I ? I, dI(r1,r2)=-1. 
4. r1 and r2 are non-comparable if ? I,J ? I, 
dI(r1,r2)=-1, dJ(r1,r2)=1.  
 
With these definitions, each couple of rules 
corresponds to one and only one of these four cases.  
An example of rules compared using this technique is 
in table 1. As this example shows, this choice of a 
fuzzy and multidimensional comparison cannot equip 
the set of AR’s with a satisfactory algebraic structure 
(absence of transitivity).  Consequently an algorithmic 
operating mode has been chosen for the meta-rules. 
Here are now the definitions of four first meta-rules 
determined by the principle P4.  
 
92
Consider a set I of three quality measures which could be 
support, confidence, difference1, with respective thresholds 
of 10, 0.1, 0.2, and the following five rules with the 
corresponding values of measures : r1(10; 0.77; -0.08), 
r2(17; 0.70; 0.10), r3(25; 0.59; 0.26), r4(29; 0.65; 0), r5(15; 
0.72 ; -0.15), the following results2 are obtained in table 1: 
 
Table 1. A comparison of the 5 rules 2 by 2 
 
 
The table shows the non-transitivity 3 of the three relations : 
- r2 and r1 are similar, r1 and r5 too, but not r2 and r5. 
- r2 is prevalent over r3, r3 over r4, but r2 is not prevalent 
over r4 (r4 is prevalent over r2). 
- r3 and r1 are non-comparable, and r1 and r4, but r3 is 
prevalent over r4..  
 
 
5. Definitions of four meta-rules 
 
Meta-rule mr1 : order 1 contradiction  
Imagine a set of rules in which there are the 
following two rules: “Town girls pass and register” and 
“Town girls fail and register”.  Anybody gifted with 
the least common sense is aware of a contradiction 
because the value of one attribute on the right side 
changes while the others do not.  The aim of the meta-
rule mr1 is to eradicate this type of contradiction. 
These two rules are expressed in the following 
formalised manner, linking 4 binary attributes: 
  r1: G1L1ÆR1I1 “Town girls fail and register.” 
  r2: G1L1ÆR0I1 “Town girls pass and register.” 
The four attributes are the following: 
- gender : G1=“girl”, G0=“boy” 
- location : L1=“town”, L0=“country” 
- pass : R1=“pass”, R0=“fail” 
- register : I1= “register”, I0= “do not register” 
Definition of mr1 : Let {r1,r2} be a couple of 
rules, it is said to be incoherent for the meta-rule mr1 if 
r1 and r2 differ only by the value of an attribute on the 
right side. It is coherent for mr1 in the contrary case. 
The corresponding set of rules to eradicate mr1({r1, 
r2}) is defined by : 
                                                           
1 The “difference” of the rule AÆB is the difference between its 
confidence and the percentage of subjects which verify B among the 
set of N subjects. 
2 Detailed calculation for the couple {r1,r4}: the differences of 
values with the three quality measures are (-19, 0.12, -0.08).  The 
deviation thresholds for these three measures being (10, 0.1, 0.2), as 
(-19<-10, 0.12>0.1, -0.2<=-0.08<=0.2), the result is (-1,1,0).  Since 
the first two differences are of opposite signs, r1 and r4 are non-
comparable. 
3 A relation R on a set E is transitive when, for all elements x,y,z of 
E, if xRy and yRz then xRz.  
- Ø    if {r1, r2} coherent. 
- Ø    if ({r1, r2} incoherent), and (r1 and r2 non-
comparable), and undemanding user.  
- {r1, r2} if ({r1, r2} incoherent), and (r1 and r2 
similar). 
- {r1, r2} if ({r1, r2} incoherent), and (r1 and r2 non 
comparable), and demanding user. 
- {r1} if ({r1, r2} incoherent), and (r2 is prevalent 
over r1). 
- {r2} if ({r1, r2} incoherent), and (r1 is prevalent 
over r2). 
 
For example4, if rules r1: G1L1ÆR1I1, r2: 
G1L1ÆR0I1, r3: G1L1ÆR1I0, r4: G1L1ÆR0I0 are 
considered, the resulting incoherent sets for meta-rule 
mr1 are {r1,r3}, {r1,r3}, {r2,r4}, {r3,r4}. If the expert 
is undemanding and if the result of their 2 by 2 
comparisons is that which appears in table 1, r1 and r2 
will be eradicated because similar, so 
mrl({r1,r2})={r1,r2}, r1 and r3 are non-comparable, so 
mrl({r1,r3})=Ø, r4 is prevalent over r2, so 
mrl({r1,r4})={r2}, and r3 is prevalent over r4, so 
mrl({r3,r4})={r4}. Grouping these sets makes it clear 
that rules r1, r2 and r4 are eradicated. 
 
Meta-rule mr2 : order 1 redundancy 
Consider the example of the following two rules: 
  r1: G1L1ÆR1I1 “Town girls pass and register.”  
  r2: G1L0ÆR1I1 “Country girls pass and register.” 
Rule r1 brings information to which r2 adds 
nothing.  On the contrary it causes the loss of part if the 
value of the initial information concerning the setting.  
The meta-rule mr2 aims to eradicate this type of 
redundancy. To define it the former meta-rule mr1 is 
re-used but “left side” is substituted for “right side”. 
 
Meta-rule mr3 : order 1 local/global contradiction 
Consider the example of the following two rules: 
r1: G1L1ÆR1I1, “Town girls pass and register.”  
r2: G1ÆR0I1, “Girls fail and register.” 
Rule r1 brings information in a particular situation 
(the setting being town), and rule r2, being more 
general, contradicts it. 
Sources of inspiration for knowing how to amend the 
situation can be the way statisticians deal with the 
problem of interpreting interactions between variables 
[13]. If the statisticians’ generalised linear model is 
adopted and the rules are re-expressed in terms of 
interactions which are simplified for clarity, the 
following is obtained [5]: 
                                                           
4  Detailed calculation: rule r1 and rule r2 only differ by R1 which 
becomes R0 on the right side, so they are incoherent for mr1. In the 
table, the couple {r1, r2} corresponds to the three 0 quality 
differences so they are similar.  r1 and r2 must be eradicated.  Rule 
r1 and rule r4, however, differ by two variables on the right side.  
They are not incoherent by mr1.   
93
- r1 : ABÆC corresponds to the effect of the 
interaction of A and of B (level 2 interaction) on C. 
- r2 : AÆnonC corresponds to the principal effect of 
A (level 1 interaction) on C. 
 
Since C appears in r1 and nonC in r2, the two 
effects contradict each other, provided nonetheless that 
both appear significant5, since only significant effects 
are taken into account by statisticians.  In this case, 
many statisticians would neglect the simple effect 
corresponding to rule r2 and only interpret the 
interaction (rule r1). If only one of the two is 
significant, it alone is interpreted and the other one 
discarded. 
Let’s transpose as follows: when one of the two 
rules is prevalent over the other, it corresponds to a 
significant relation; and the other rule is eliminated. 
When the rules r1 and r2 are similar, they are both 
deemed significant and the rule r2, with smaller 
number of attributes and therefore being the most 
“general”, is dropped. 
 
Definition of mr3 : Let {r1,r2} be a couple of 
rules, it is said to be incoherent for the meta-rule mr3 if 
the set of attributes of the left side of either is strictly 
included in the set of attributes of the left side of the 
other, with the same values, and if the right sides have 
the same attributes, with the same values for all except 
one. If r2 has less attributes than r1 on the left side and 
so is more general mr3 ({r1, r2}) is defined by : 
- Ø    if {r1, r2} coherent. 
- Ø  if ({r1, r2} incoherent), and (r1 and r2 non-
comparable) and undemanding user.  
- {r2} if ({r1, r2} incoherent), and (r1 and r2 
similar). 
- {r2} if ({r1, r2} incoherent), and (r1 and r2 non 
comparable), and demanding user. 
- {r1} if ({r1, r2} incoherent), and (r2 is prevalent 
over r1). 
- {r2} if ({r1, r2} incoherent), and (r1 is prevalent 
over r2). 
 
Meta-rule mr4 : order 1 local/global redundancy 
Consider the example of the following two rules: 
  r1: G1L1ÆR1I1 “Town girls pass and register.”  
  r2: G1ÆR1I1 “Girls pass and register.” 
The meta-rule mr4 looks like mr3 but it aims to 
eradicate redundancy instead of contradiction. To 
define it, the former meta-rule is re-used but if the 
incoherent rules are similar or non-comparable, the 
                                                           
5 For a statistical definition of the word significant, the reader my 
refer to an abundant specialised literature.  It is enough for now to 
say that a significant event is one that cannot reasonably be attributed 
to chance.  When such an event occurs the statistical model indicates 
the variables to which it can be attributed. 
most local rule (r1 for this example) is suppressed, and 
not to the most global one as in mr3.  
 
6. Simultaneous action of meta-rules 
 
The decision to eradicate a rule that is determined 
incoherent by a meta-rule is not immediately put into 
effect, rather the rule is annotated: a tag marks the 
imperativeness with which the rule may be suppressed.  
After all the meta-rules have been applied, the rules 
without any tag are kept, the other rules, having one 
tag, or multiple ones, are considered for suppression.   
This way of operating implies that the result 
obtained remains independent of the order in which the 
rules of the set are treated.  A rule, even if it has been 
tagged for suppressing at one stage, can still contribute 
to the dropping of another at the next stage. Looking at 
example 1 and imagining that for each of the sets 
{r2,r3}, {r3,r4}, {r2,r4}, a meta-rule for which they are 
incoherent can be found, as r2 is prevalent over r3, r3 
is prevalent over r4, and r4 is prevalent over r2, the 
three rules will be dropped in the end, as common 
sense suggests. 
 
 
7. Application  
 
7.1. The dataset 
 
The LUCAS0 dataset has been created in the 
framework of the Causality Challenge 
(www.causality.inf.ethz.ch) as a “toy” workbench for 
adjusting and testing causality extraction methods, 
before dealing with real life datasets.  
 
 
 
Figure 1 : Graph for LUCAS0 (see 
www.causality.inf.ethz.ch for details). 
 
We have not used the whole causality workbench, but 
the only LUCA0 training set, which consists of 2000 
examples described by 12 binary variables such as 
anxiety, smoking, fatigue… The graphic model 
sketched in fig. 1 is a Bayesian network used for 
generating these examples. It has been designed so as 
94
to mimic a few causes and consequences of lung 
cancer. One control variable (“Born in even day”) is 
related to none of the others. 
 
7.2. Our objective. 
 
We are not trying to tackle the complex problem of 
causal relationships – several “manipulated” test sets 
are provided for this purpose in the Causality 
Challenge – but the only problem of detecting the 
minimal set of relevant and non-redundant relations in 
the training set. Which translates, in this context, as 
representing the diverse links between variables as an 
association rule set cleansed and condensed by our 
meta-rules. 
 
7.3. Our project scheme. 
 
Our work has been structured as follows: the names 
of the 12 variables have been condensed with the two 
first letters of their labels (see table 3) and an extra 
digit, 1 or 0, corresponding to the variable itself or its 
negation. We have extracted 100 000 association rules 
or so with support >= 100 and confidence >=0.1, and 
with a unique variable in their right size. 
 
Table 3: Variable labels and their 
abbreviations. 
Al 
An 
At 
Bo 
Ca 
Co 
Allergy 
Anxiety 
Attention Disorder 
Born an Even Day 
Car Accident 
Coughing 
Fa 
Ge 
Lu 
Pe 
Sm 
Ye 
Fatigue 
Genetics 
Lung Cancer 
Peer Pressure 
Smoking 
Yellow Fingers 
 
We have then applied each of our meta-rules 
independently on the resulting rule set. We chose the 
support and confidence as quality measures, and the 
thresholds for significant difference: 100 for support, 
0.1 for confidence. 
When a couple of rules is deemed consistent by a 
meta-rule, no digit is added to their tags. If it is not, the 
digits 0, 1, or “nc” are appended to one or both in 
accordance to their degree of requirement for 
elimination: 
- the digit 1 if one of the two has much less credit 
(appended to this rule), 
- the digit 0 if both are equally reliable as regard to 
the meta-rule (appended to both rules in the case of 
mr1 and mr2, to the most general rule in the case of 
mr3, to the most local in the case of mr4). 
- the digit “nc” if they cannot be compared, 
appended in the same manner than the digit 0. 
 
When all the meta-rules have been used on the 
whole rule set, tags of each tagged rule are examined, 
with a precedence order: the digit 1 is chosen if one 
digit 1 at least is present; if not, the digit 0 is chosen if 
one digit 0 at least is present; “nc” is chosen in the 
remaining case if one digit “nc” at least is present.  
These tags are useful in the interpretative stage of 
our workflow: all the non-tagged rules remain for 
interpretation, but “nc” rules may be useful if the set of 
non-tagged rules is judged defective. If it is still not 
enough, the rules tagged “0” may be examined. For the 
occasion, the parameters of the meta-rules may be 
revised (relative weights of the different measures, 
difference thresholds). 
 
7.4. Results  
 
We have shown in table 4 below a few examples of 
rule couples assessed as inconsistent according to one 
meta-rule or another, and their resulting tags. 
The first column identifies the involved meta-rule; 
the next two columns list the couple of rules to be 
compared (between brackets: support and confidence). 
In the fourth column are displayed the differences of 
quality measures, to be compared with the thresholds. 
The fifth column sketches the results of the fourth: -1 if 
the first is by far lower than the second, 1 if the 
opposite is true, 0 else. The conclusion is drawn in 
column 6, translated in column 7 into the resulting 
digit, with the code of the rule to which it is attached. 
The first row of the table 4 reads as follows: 
according to the mr1 meta-rule the couple of rules     
Yellow_FingersÆno Lung Cancer and 
Yellow_Fingers ÆLung Cancer has been estimated 
inconsistent. The support of the first rule is 296 and its 
confidence is 0.189, far beyond the corresponding 
values of the second rule (1268 and 0.811). The 
differences overpass the values considered significant, 
as stated in the fourth column and sketched in the fifth 
one. The differences for this couple are marked (-1,-1) 
(see §4), which means that the first rule is poorer than 
the second, due both to support and confidence. In 
column 6, we conclude that r2 prevails on r1, and in 
column 7 the ”1” tag is attributed to r1 (“first to be 
dropped” type).  
 
The table 5 shows the results obtained when 
tagging the 100,000 rules: each row of the table gives 
the cumulative count of the rules tagged for a possible 
elimination, dispatched by number of variables in the 
left part. Almost all of the rules (96,981) have been 
tagged “1” because of contradiction (mr1 or mr3) or 
redundancy (mr2 or mr4), when compared to better 
rules. 268 rules have been tagged “0” because of 
contradiction or redundancy as regard to rules of 
similar quality. The latter will be eliminated if one 
specially cares for consistency of the rule set. 
95
At last, 69 high-quality rules remain, all of them with a 
single variable in each side; 61 non-comparable rules, 
while supporting interesting information, may also be 
considered. 
 
Table 4 : Five cleansing examples 
Col1 
Col2 : rule r1 
(supp., conf.) 
Col3: rule r2 
(supp., conf.) Col4: index(r1)-index(r2) 
Col5: 
Diff(r1,r2) Col6: comparison result Col7: tag 
mr1 Ye_1 Æ Lu_0 (296, 0.189) 
Ye_1 Æ  Lu_1 
(1268, 0.811) 
296-1268<=-100 
0.189-0.811<=-0.1 (-1, -1) r2 prevails on r1 r1 : 1 
mr2 Al_0 Æ Lu_0 (202, 0.294) 
Al_1 Æ Lu_0 
(355, 0.363) 
202-355<=-100 
-0.1<0.294-0.363<0.1 (-1, 0) r2 prevails on r1 r1 : 1 
mr2 Bo_0 Æ Lu_1 (742, 0.727) 
Bo_1 Æ Lu_1 
(701, 0.716) 
-100<742-701<100 
-0.1<0.727-0.716<0.1 (0, 0) r1 and r2 similar 
r1 : 0 
r2 : 0 
mr2 Ge_0 Æ Lu_1 (1171, 0.680) 
Ge_1 Æ Lu_1 
(272, 0.975) 
1171-272>=100 
0.680-0.975<=-0.1 (1, -1) 
r1 and r2 not 
comparable 
r1 : nc 
r2 : nc 
mr3 Lu_0 Æ Ye_0 (261, 0.469) 
Lu_0 ; An_1Æ Ye_1 
(188, 0.699) 
-100<261-188<100 
0.469-0.699<=-0.1 (0,-1) r2 prevails on r1 r1 : 1 
 
 
Table 5 : Cumulative effects of tagging the set of 100,000 rules with four meta-rules. 
 
 Variable number in the left side of the rule 
Initial rule number 1 2 3 4 5 6 7 8 9 10 total
506 3872 12786 22385 24486 18970 10208 3483 650 33 97379
             
Meta-rule, tag  Number of rules tagged for a possible suppression 
mr1 
1 212 1203 2641 3334 2773 1544 536 100 7 0 12350
0 60 526 1502 2040 1862 1318 670 228 40 0 8246
nc 0 0 0 0 0 0 0 0 0 0 0
mr2 
1 314 2556 7800 12490 11273 6047 2034 360 23 0 42897
0 52 609 2896 6192 9790 10946 7277 2762 486 0 41010
nc 32 205 539 785 633 339 112 18 1 0 2664
mr3 
1 321 2906 9173 14506 13150 7476 2788 614 70 2 51006
0 46 338 1878 4775 8206 9553 6534 2520 446 0 34296
nc 61 223 528 760 615 335 112 18 1 0 2653
mr4 
1 360 3809 12704 22305 24459 18970 10208 3483 650 33 96981
0 32 47 82 80 27 0 0 0 0 0 268
nc 45 16 0 0 0 0 0 0 0 0 61
  
Final Result Number of rules tagged for a possible suppression 
 69 0 0 0 0 0 0 0 0 0 69
 
Final evaluation: comparing the 69 final rules with 
the original model  
 
Strong similarities follow from the comparison: 
- The control variable Be: « Born_an_Even_Day » 
appears nowhere in the rule set. 
- Bi-directional rules link the main variable « Lung 
Cancer » to Coughing, Smoking, Fatigue, 
Yellow_Fingers with a support greater than 1200 
and a confidence of more than 0.80; similarly it is 
linked to Anxiety with a support of about 1000 and 
a confidence around 0.70. It is also strongly linked 
to Car_Accident (s=1111, c=0.77). 
- Bi-directional relations connect Car_Accident, 
Coughing, Fatigue, with a support superior to 1000 
and a confidence beyond 0.75. 
- The same type of relations link Smoking, Anxiety 
and Yellow_Fingers with a support superior to 
1000 and a confidence beyond 0.70; each one 
involves Car_Accident with the same quality. 
 
Additional knowledge follows from the association 
rules: 
- Lung Cancer implies no Allergy, no 
Attention_Disorder, no Peer_Pressure, with a 
96
support not far from 1000 and a confidence of 
about 0.65. 
- Smoking or Car_Accident implies no Allergy, with 
the same quality as stated above. 
- No Genetics is implied by Smoking, Anxiety, 
Fatigue et Yellow_Fingers, with a support 
exceeding 1000 and a confidence around 0.85. 
 
Missing elements: 
- The link between Genetics et Lung Cancer is just 
pointed out by Ge_1 Æ Lu_1  (272, 0.975) tagged 
as ‘nc’, as shown in table 4 as an example for the 
metarule mr2. 
- The same is true between Allergy and Coughing, 
the rule Al_1 Æ Co_1  (614, 0.895) being tagged 
‘nc’. 
- The links between Genetics and the other variables 
are just pointed out negatively, as stated in the 
above subsection. 
- The only interaction embedded in the model, the 
one of Smoking + Genetics on Lung Cancer does 
not come to light, because the corresponding rule 
Ge_1 ; Sm_1 Æ Lu_1, (s=213, c=1) has been 
tagged ‘nc’, being appreciated non-comparable to 
Ge_1 Æ Lu_1  (272, 0.975) by the mr4 metarule. 
 
8. Comments and discussion   
 
Starting from 100,000 association rules, 69 ones 
remain after our cleansing process. The differences 
between the generating model and this operational and 
condensed rule set concern essentially 1) the direction 
of the rules, which seldom contradicts causality, 2) the 
loss of a few links with small support despite of strong 
confidence, such as Genetics Æ Lung Cancer, 3) the 
loss of interaction rules, with two variables at the left 
side and one at the right one (Smoking + Genetics vs. 
Lung Cancer). 
The first point is a general problem for knowledge 
extraction from observational data. Mere observation 
seems not enough for establishing causal links, and 
experimental manipulation of some variables seems 
unavoidable, as in statistical “design of experiment”, or 
as in the variants embedded in the test sets of the 
Causality Challenge [11]. 
As the second point is concerned, the meta-rule 
could be changed in order to favour confidence instead 
of support. In this example, the choice of support could 
eliminate rare illnesses or effects, which is 
questionable in a medical context… 
Concerning the third point, the non-identification of 
an interaction follows from the choice of measures – 
chosen in this first application because of their simple 
computation and clear interpretation – and from the 
choice of the difference thresholds: these options 
prevent small interaction effects, such as the one built 
in the data, from being detected. 
As a whole, our method retrieves the essential part 
of the structure of the data, but an effort remains to 
propose to the user different choices of parameters. 
 
9. Assessment and Perspectives 
 
Our global mining method is incompatible with an 
incremental cleaning procedure, as follows from 
section 6 above; the essence of our method is to 
consider a rule set as a whole first, before the cleansing 
phase. It is to be noticed that this feature enables us to 
cleanse sets of rules obtained by the fusion of rule sets 
extracted from different sets of subjects for the same 
properties, or suggested by an expert. 
 
The meta-rules presented here are easy to use by 
anybody since they rest on common sense.  They apply 
to the complete set of rules extracted from data and the 
only requirement for these rules is their having a non-
zero support.  They reduce the size of the set by 
eliminating contradictions and redundancies.  We also 
pointed out that the user had to choose parameters such 
as extra quality measures or different thresholds, 
according to the type of knowledge he/she wants to 
mine in the data. He/she should be helped in this matter 
by being suggested various parameter sets adapted to 
diverse situations. One perspective of research in this 
area is the progressive building of a coherent cleansing 
system, developing its generality and enhancing the 
performance and scalability of the corresponding 
software. 
One criticism against this technique may be the use 
of properties with negations, which greatly weigh 
down the research algorithms with the frequent 
itemsets and association rules if the properties with 
negations are not planned for from the start. There are, 
however, numerous cases where coding leads to both 
the property and its negation being present in the base 
(for example coding the variable “Gender” into two 
variables “female”, “male”). In some other cases 
coding produces a series of properties which form a 
partition of the subjects determined by the various 
values of one and the same property (for example, 
coding the quantitative variable “Blood Pressure” into 
“Normal BP”, “High BP”, and “Low BP”). This 
coding into more than two categories also produces 
incoherencies in the sets of rules, as it is an extension 
of the case of a property and its negation which has 
been dealt with in this chapter.  The meta-rules must 
then be re-written in a more generalising manner.  This 
is another direction research can take. 
97
 
10. Acknowledgments  
 
The authors are deeply indebted to Isabelle Guyon 
and her team for designing the problematics of the 
Causality Challenge, and for providing the Lucas0 test 
data. 
 
11. References  
  
[1] Agrawal, R. Srikant, H,  Fast algorithms for mining 
association rules in large databases, Research Report RJ 
9839, IBM Almaden Research Center, San Jose, California, 
June 1994. 
 
[2] Bastide Y., Data mining : algorithmes par niveau, 
techniques d'implantation et applications, Doctoral 
dissertation, Université Blaise Pascal, Clermont-Ferrand, 
2000. 
 
[3] Botta M., Boulicaut J.-F., Masson C., Meo R. : A 
Comparison between Query Languages for the Extraction of 
Association Rules. DaWaK 2002, 1-10 
 
[4] Cadot, M. (2006). Extraire et valider les relations 
complexes en sciences humaines : statistiques, motifs et 
règles d'association. Doctoral dissertation, University of 
Franche-Comté, France. Available online at 
<http://www.loria.fr/~cadot/cadot_these_2006.pdf> 
  
[5] Cadot, M., Maj, J.-B., & Ziadé T. (2005). Association 
Rules and Statistics, in J. Wang (Ed.), Encyclopedia of Data 
Warehousing and Mining (pp. 74-77). Hershey, US, Idea 
Group Publishing. 
 
[6] Chen Q. Mining Exceptions and Quantitative Association 
Rules in Olap Data Cube, Master Thesis, Simon Fraser 
University, 1999 
 
[7] Fabris C.C., A.A. Freitas. Discovery of surprising 
patterns by detecting occurrences of Simpson's paradox. 
Research and developpement in intelligent systems XVI (Proc 
ES99. The 19th SGES Int. Conf. on Knowledge-based 
systems and applied artificial intelligence). 148-160. 
Springer-Verlag, 1999. 
 
[8] Fu Y., Discovery of multiple-Level Rules from large 
Databases, Master Thesis, Simon Fraser University, 1996 
 
[9] Guigues J.L. et Duquenne V. (1986) , Familles minimales 
d'implications informatives résultant d'un tableau de données 
binaires, Math. Sci. Hum. n°95, 5-18 
 
[10] Guillet F., Hamilton H., (2007) Quality Measures in 
data mining, Springer. 
 
[11] Guyon I., Causality Challenge #1: Causation and 
Prediction, 2008, http://www.causality.inf.ethz.ch/challenge.php 
 
[12] Hoc J.-M., L'analyse planifiée des données en 
psychologie. PUF, Paris, 1983. 
 
[13] Howel D.C., Statistical Methods for Psychology, 
Duxbury, A Division of International Thomson Publishing 
Inc., 1997 
 
[14] Jakulin A., Attribute Interactions in Machine Learning 
Master's thesis University of Ljubljana, Slovenija, 2003 
 
[15] Luxenburger M., Implications partielles dans un 
contexte, Mathématiques, Informatique et Sciences 
humaines, n°113,  35-55, 1991 
 
[16] Pearl J., Causality models, reasoning, and inference, 
Cambridge University Press, 2000, 267 - 279 
 
[17] Simpson, E. H., The interpretation of interaction in 
contingency tables, Journal of the Royal Statistical Society, 
Series B, 13, 238-241, 1951. 
 
[18] Suzuki E., Kodratoff Y., Discovery of Surprising 
Exception Rules Based on Intensity of Implication. Second 
European Symposium on Principles of Data Mining and 
Knowledge Discovery. Springer-Verlag, London, UK. Source 
Lecture Notes In Computer Science. 1998, p. 10-18. 
 
[19] Toivonen H., Klementtinen M., Ronkainen P., Hatönen 
K., Mannila H., Pruning and Grouping Discovered 
Association Rules, ECML'95 
 
[20] Winer B.J., Brown D.R., Michels K.M., Statistical 
principles in experimental design (third edition), New York: 
McGraw–Hill, 1991 
 
[21] Zaki, M., Mining Non-Redundant Association Rules, 
Data Mining and Knowledge Discovery, 9, 223-248, 2004, 
Kluwer Academic Publishers, Netherlands. 
 
[22] Zhu H., On-Line Analytical Mining of Association 
Rules, Master Thesis, Simon Fraser University, 1998 
 
98
