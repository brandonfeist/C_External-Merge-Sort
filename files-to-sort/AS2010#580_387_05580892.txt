  
THE APPLICATION OF DATA MINING IN ONLINE BOOKSTORE 
LIN-YAN XUE1, HONG WANG2, SHUANG LIU1, CHAO LI1  
1College of Quality and Technique Supervising, Hebei University, Baoding, China 
2College of Electronic and Information Engineering, Hebei University, Baoding, China 
E-MAIL: lyxue@hbu.cn 
Abstract: 
With the rapid development of Internet technology in 
recent years, Electronic Commerce has been an inevitable 
product of the economy, the science and the technology. This 
paper takes an online bookstore platform as a background, 
introduces the definition, functions, process and common 
analytical techniques of data mining. In the end, the 
experiment on association rules mining from the order data of 
online bookstore is completed by Apriori algorithm. 
Keywords: 
Online bookstore; Data mining; Association rule; Apriori 
Algorithm 
1. Introduction 
Along with the development of the computer and the 
database technology, all trades and professions start to 
adopt the computer and corresponding information 
technology to carry on the management and the operation. 
It has greatly improved the ability of producing, collecting, 
storing and processing data. Under such a background, 
people urgently need new computing technology and tools 
to excavate the knowledge contained in database, which 
guides technological decision and strengthens the 
competitiveness of enterprises.  
Data mining has emerged as a means for identifying 
patterns and trends from a large amount of data [1]. The 
major reason that data mining has attracted a great deal of 
attention in the information industry in recent years is due 
to the wide availability of huge amounts of data and the 
imminent need for turning such data into useful information 
and knowledge. Data mining can be viewed as a result of 
the natural evolution of information technology. 
The paper is organized as follows. The definition, 
process and techniques of data mining are introduced in 
section 2. The design and implement of online bookstore is 
introduced in section 3. In section 4, association rules 
mining and Apriori Algorithm is introduced and 
experiments are conducted. The conclusions are discussed 
in Section 5. 
2. Data Mining Theory 
2.1. Definition of Data Mining 
Simply stated, data mining refers to extracting or 
“mining” knowledge from large amounts of data [1]. Data 
mining is the process of discovering actionable information 
from large sets of data. It uses mathematical analysis to 
derive patterns and trends that exist in data. Typically, these 
patterns cannot be discovered by traditional data 
exploration because the relationships are too complex or 
because there is too much data.   
These patterns and trends can be collected and defined 
as a data mining model. Mining models can be applied to 
specific business scenarios, such as: 
• Forecasting sales. 
• Targeting mailings toward specific customers. 
• Determining which products are likely to be sold 
together. 
2.2. Data Mining Process 
Building a mining model is part of a larger process that 
includes everything from asking questions about the data 
and creating a model to answer those questions, to 
deploying the model into a working environment. This 
process can be defined by using the following six basic 
steps. 
• Defining the Problem  
• Preparing Data  
• Exploring Data  
• Building Models  
• Exploring and Validating Models  
• Deploying and Updating Models  
The following Figure 1 describes the relationships 
between each step in the process, and the technologies in 
Microsoft SQL Server that can be used to complete each 
step. 
1294
2010 IEEE978-1-4244-6527-9/10/$26.00 ©
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
  
Although the process illustrated in the diagram is 
circular, each step does not necessarily lead directly to the 
next step. Creating a data mining model is a dynamic and 
iterative process. After exploring the data, one may find that 
the data is insufficient to create the appropriate mining 
models, and that one therefore have to look for more data. 
Alternatively, you may build several models and then 
realize that the models do not adequately answer the 
problem you defined, and that you therefore must redefine 
the problem. You may have to update the models after they 
have been deployed because more data has become 
available. Each step in the process might need to be 
repeated many times in order to create a good model. 
 
Figure 1. Relationships between six steps 
2.3. Data Mining Techniques 
1) Classification: discovery of a predictive learning 
function that classifies a data item into one of several 
predefined classes. The typical method is fuzzy decision 
tree [5], [6], [7]. 
2) Regression: discovery of a predictive learning 
function, which maps a data item to a real-value prediction 
variable [8]. 
3) Clustering: a common descriptive task in which one 
seeks to identify a finite set of categories or clusters to 
describe the data. 
4) Summarization: an additional descriptive task that 
involves methods for finding a compact description for a set 
(or subset) of data. 
5) Dependency Modeling: finding a local model that 
describes significant dependencies between variables or 
between the values of a feature in a data set or in a part of a 
data set. 
6) Change and Deviation Detection:  discovering the 
most significant changes in the data set. 
2.4. Data warehouses 
The data warehouse is a collection of integrated, 
subject-oriented databases designed to support the 
decision-support functions (DSF), where each unit of data 
is relevant to some moment in time. The function of the 
data warehouse is to store the historical data of an 
organization in an integrated manner that reflects the 
various facets of the organization and business. 
A three-stage data-warehousing development process 
is summarized through the following basic steps: 
1) Modeling: In simple terms, to take the time to 
understand business processes, the information 
requirements of these processes, and the decisions that are 
currently made within processes. 
2) Building: To establish requirements for tools that 
suit the types of decision support necessary for the targeted 
business process; to create a data model that helps further 
define information requirements; to decompose problems 
into data specifications and the actual data store, which will, 
in its final form, represent either a data mart or a more 
comprehensive data warehouse. 
3) Deploying: To implement, relatively early in the 
overall process, the nature of the data to be warehoused and 
the various business intelligence tools to be employed; to 
begin by training users. The deploy stage explicitly contains 
a time during which users explore both the repository (to 
understand data that are and should be available) and early 
versions of the actual data warehouse. This can lead to an 
evolution of the data warehouse, which involves adding 
more data, extending historical periods, or returning to the 
build stage to expand the scope of the data warehouse 
through a data model. 
3. Design and Implement of Online Bookstore Based 
on ASP.Net 
An online bookstore is formed by the front and back 
business subsystem. The website is built by Dreamweaver, 
ASP.net, Microsoft SQL Server, etc. Visitors can  log in 
the online bookstore and choose books to buy. The whole 
shopping flowchart is as the following Figure 2. 
4. The application of data mining in online bookstore 
As the running of online bookstore, it will produce a 
large number of order lists which contain customer's 
shopping information on the net. It is very important to find  
Defining the 
Problem 
Preparing 
Data 
Exploring 
Data 
Validating 
models 
Deploying and 
updating models 
Building 
Models 
1295
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
  
valuable information or knowledge from all lists. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2. System overall design flowchart 
4.1. Association Rules Mining 
Association rules, first introduced in [2], are used to 
identify relationships among a set of items in a database. 
These relationships are not based on inherent properties of 
the data themselves (as with functional dependencies), but 
rather based on co-occurrence of the data items [10].  
Definition 1: Let I ={I1, I2, … , Im} be a set of m 
distinct attributes, also called literals. Let D be a database, 
where each record T has a unique identifier, and contains a 
set of items such that T ? I An association rule is an 
implication of the form X  Y, where X, Y ? I, are sets of 
items called itemsets, and X Y? = ? . Here, X is called 
antecedent, and Y consequent. 
Two important measures for association rules, support 
(S) and confidence (C), can be defined as follows. 
Definition 2: The support (S) of an association rule is 
the ratio (in percent) of the records that contain X Y?  to 
the total number of records in the database. 
( ) ( )
X Y
S X Y P X Y
D
?
 = ? =        (1) 
Therefore, if we say that the support of a rule is 5% 
then it means that 5% of the total records contain X ? Y. 
Support is the statistical significance of an association rule. 
Grocery store managers probably would not be concerned 
about how peanut butter and bread are related if less than 
5% of store transactions have this combination of purchases. 
While a high support is often desirable for association rules, 
this is not always the case. For example, if we were using 
association rules to predict the failure of 
telecommunications switching nodes based on what set of 
events occur prior to failure, even if these events do not 
occur very frequently association rules showing this 
relationship would still be important. 
Definition 3: For a given number of records, 
confidence (C) is the ratio (in percent) of the number of 
records that contain X ? Y to the number of records that 
contain X. 
( ) ( | )
X Y
C X Y P Y X
X
?
 = =       (2) 
Thus, if we say that a rule has a confidence of 85%, it 
means that 85% of the records containing X also contain Y. 
The confidence of a rule indicates the degree of correlation 
in the dataset between X and Y. Confidence is a measure of 
a rule’s strength. Often a large confidence is required for 
association rules. If a set of events occur a small percentage 
of the time before a switch failure or if a product is 
purchased only very rarely with peanut butter, these 
relationships may not be of much use for management. 
Definition 4: The form of mining rule is: 
( : , ) ( , ) ( , )[sup , ]P X customer W Q X Y buys X Z port confidence? 
    In above form, X  is the keyword of relationship 
“customer”, P and Q are predicate variables, W , Y and 
Z are Object variables and their values are in the range of 
customer  X . 
For example, a rule of age(X, “20…29”) income(X, ?
“40000…50000”)  buys(X “?economic books”)[2 6?0%] 
can tell us that a customer who is 20 years old and has a 
revenue between 40,000 to 50,000 most probably chooses 
economic books (confidence is 60%). 
4.2. Apriori Algorithm 
The Apriori algorithm developed by [3] is a great 
achievement in the history of mining association rules [4]. 
It is by far the most well-known association rule algorithm.  
Yes 
Registered users? 
Index page 
To pick out and purchase
Put selected goods into shopping cart 
To confirm quantity 
Go to cash desk 
To register 
To Log in 
Confirm the order and submit 
Fill in personal detailed information 
Finish shopping 
No
1296
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
  
The Apriori algorithm has two steps, During the first 
step, Lk-1 is joined with itself to obtain Ck. In the second 
step, apriori_gen() deletes all itemsets from the join result, 
which have some (k-1)-subset that is not in Lk-1. Then, it 
returns the remaining large k-itemsets [11]. 
Algorithm : Apriori // To search all frequent itemsets 
Input: Database, D, of transactions; minimum support 
threshold, min_sup. 
Output: L, frequent itemsets in D. 
Method: 
1) L1={largel-itemsets}; 
2) FOR{k=2; Lk-1 ?? ; k++} DO BEGIN 
3) Ck=apriori-gen ( Lk-1, min_sup );  
// Ck is the candidate set of k elements 
4)    FOR all transactions t D DO BEGIN?   
//scan D for counts 
5)      Ct=subset( Ck, t );  
// get the subsets of t that are candidates  
6)      FOR all candidates c C? t DO 
7)       c. count++; 
8)    END 
9)    Lk={c?Ck |c.countmin_sup} 
10)  END 
11) Answer=UkLk; 
Procedure apriori-gen( Lk-1 ) // generate candidate sets 
1) FOR all itemset p?Lk-1 DO BEGIN 
2) FOR all itemset q?Lk-1 DO BEGIN 
3)  IF p.item1= q.item1, ...,p.itemk-2= q.itemk-2,  
p.itemk-1<q.itemk-1 THEN BEGIN 
4)    c=pq; //join step: generate candidates 
5)   IF has_infrequent_subset(c, Lk-1) THEN 
6)   delete c; //prune step: remove unfruitful  
//candidate 
7)  ELSE add c to Ck; 
8) END 
9) Return Ck 
Procedure has_infrequent_subset(c, Lk-1)  
//use prior knowledge 
1) FOR all (k-1)-subset s of c DO 
2) IF s?  Lk-1 THEN 
3)  Return TURE; 
4) Return FALSE; 
4.3. Experiments 
The experiment on association rules mining from the 
order data of online bookstore is completed by Apriori 
algorithm.  We set 623 sales records in database as the 
data source and set up the following four tables to support 
the algorithm.  
1) Table BookName: To store book ID and book name. 
TABLE 1. BOOKNAME 
Column Name Data Type Length
ID int 4 
Name nvarchar 255 
 
2) Table OrderList: To store book order lists 
TABLE 2.  ORDERLIST 
Column Name Data Type Length 
ID int 4 
Orders nvarchar 255 
 
3) Table RealItemList: To store frequent itemsets and 
their supports 
TABLE 3. REALITEMLIST 
Column Name Data Type Length 
ID int 4 
ListNumber int 4 
RealOrders nvarchar 255 
Support int 4 
 
4) Table ConfidenceDegreeList: To store all items 
above confidence  
TABLE 4. CONFIDENCEDEGREELIST 
Column Name Data Type Length 
ID int 4 
NowBooks nvarchar 255 
MoreBooks nvarchar 255 
ConfidenceDegree float 8 
 
Rule support and confidence respectively reflect the 
usefulness and certainty of discovered rules. In our 
experiment, The parameter support is set to 2%  and 
confidence is taken to be 60%. We set 623 items in the data 
source of customers’ orders table and get 286 association 
rules. Finally, part of frequent itemsets is as the figure 3 and 
part of  association rules is as the figure 4. 
5. Conclusions 
In this paper, an online bookstore was created based on 
Asp.net. Then an experiment analyzes customer buying 
habits by finding associations between the order items in 
database. The discovery of such associations can help 
retailers develop marketing strategies by gaining insight 
into which items are frequently purchased together by 
1297
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
  
customers. The information from the experiment can lead to 
increased sales by helping retailers do selective marketing 
and plan the bookshop space. 
 
 
Figure 3. frequent itemsets 
 
Figure 4. association rules 
Acknowledgements 
This paper is supported by the Project of Hebei 
Education Department under Grant No. 2008417. 
References 
[1] J. Han, and M. Kamber, “Data Mining Concepts and 
Techniques”, Morgan Kaufmann Publishers,   
pp.1-35, 2001. 
[2] R. Agrawal, T. Imielinski, and A. N. Swami, “Mining 
association rules between sets of items in large 
databases,”  Proceedings of the 1993 ACM SIGMOD 
International Conference on Management of Data, 
pp.207-216, 1993.  
[3] R. Agrawal, and R. Srikant, “Fast Algorithms for 
Mining Association Rules in Large Databases,” 
Proceedings of the Twentieth International Conference 
on Very Large Databases, pp.487-499, 1994. 
[4] D. W. Cheung, V. T. Ng, and B. W. Tam, 
“Maintenance of Discovered Knowledge: A Case in 
Multi-level Association Rules,” Proceedings of the 
Second International KDD Conference, pp.307-310, 
1996. 
[5] J.R. Quinlan, “Induction of Decision Trees”, Machine 
Learning, Vol. 1, No. 1, pp. 81-106, 1986. 
[6] Yufei Yuan, and M.J.Shaw, “Induction of fuzzy 
decision trees,” Fuzzy Sets and System, Vol. 69, No. 2,  
pp. 125-139, 1995. 
[7] M. Umano, H. Okamoto, I. Hatono, H. Tamura, F. 
Kawachi, S. Umezu, and J. Kinoshita, “Fuzzy 
Decision Trees by Fuzzy ID3 Algorithm and Its 
Application to Diagnosis System”, Proceedings of 
Third IEEE International Conference on Fuzzy 
Systems, Vol. 3, pp. 2113-2118, 1994. 
[8] Mehmed Kantardzie, “Data Mining: Concepts, Models, 
Methods, and Algorithms, Computing and Information 
Science in Engineering, Vol. 5, No. 4, 
pp.394-395, 2005. 
[9] Mehmed Kantardzie, “Data Mining: Concepts, Models, 
Methods, and Algorithms, Computing and Information 
Science in Engineering”, Vol. 5, No. 4, 
pp.394-395, 2005. 
[10] R. Agrawal, T. Imielinski, and A. Swami, “Mining 
association rules between sets of items in large 
databases”, Proceedings of the ACM SIGMOD 
Conference on Management of data, pp.207-216, 
1993. 
[11] R. Srikant, and R. Agrawal, “Mining generalized 
association rules”, Proceedings of the 21st 
International Conference on Very Large Database, pp. 
407-419, 1995.
 
1298
Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010
