  
An Effective Algorithm Based on Association Graph 
and Matrix for Mining Association Rules 
 
Haiwei Pan  
College of Computer Science and Technology 
Harbin Engineering University 
Harbin, China 
heaven_007cn@yahoo.com.cn 
Xiaolei Tan, Qilong Han, Guisheng Yin 
College of Computer Science and Technology 
Harbin Engineering University 
Harbin, China 
{tanxiaolei,  hanqilong, yinguisheng}@hrbeu.edu.cn
 
Abstract—Association rule mining is a very important research 
topic in the field of data mining.  Discovering frequent itemsets is 
the key process in association rule mining. Traditional association 
rule algorithms adopt an iterative method, which requires very 
large calculations and a complicated transaction process. FAR 
(Feature Matrix Based Association Rules) algorithm solves this 
problem. However, FAR algorithm is not efficient when the value 
of the minimum support is small or the number of column of the 
feature matrix is very large. So we proposed a new algorithm 
(GMA) which based on association graph and matrix pruning to 
reduce the amount of candidate itemsets. Experimental results 
show that our algorithm is more efficient for different values of 
minimum support.  
Keywords-medical image; data mining; association rule; 
relational calculus;   association graph 
I.  INTRODUCTION  
Image mining is more than just an extension of data mining 
to image domain but an interdisciplinary endeavor. This 
domain includes computer vision, image processing, image 
retrieval, machine learning, artificial intelligence, pattern 
recognition, database and data mining and so on. Although 
these areas mentioned above have a relatively mature theories 
and techniques, but the image mining is still in its infancy, and 
gradually attended by more and more people. The medical 
images contain a wealth of hidden useful information that can 
be exploited by physicians in making correct decision for a 
patient. However, how to extract this relevant valuable 
information and use it in medical diagnosis is difficult. Data 
mining technique is indispensable for researching medical 
images. 
Association rule mining is a very important research topic 
in the data mining field. Finding association rules is typically 
done in two steps: discovering frequent itemsets and generating 
association rules. The second step is rather straightforward, and 
the first step dominates the processing time, so we focus this 
paper on the first step.  A number of efficient association rule 
mining algorithms have been proposed in the last few years. 
Among these, the Apriori algorithm by Agrawal, R., Imielinski, 
T [1][2] has been very influential. Later, many scholars have 
improved and optimized the Apriori algorithm and have 
presented new Apriori-like algorithms, [3][4][5]. The Apriori-
like algorithms consist of two major procedures: the join 
procedure and the prune procedure. These algorithms require a 
huge calculation and a complicated transaction process during 
the two procedures. Therefore, the mining efficiency of the 
Apriori-like algorithms is not very good when transaction 
database is very large. 
L.Jaba Sheela proposed the FAR algorithm [6] in 2009. 
This algorithm transforms a transaction database into a Feature 
matrix stored in bits. Meanwhile it uses the Boolean vector 
“relational calculus” method to discover frequent itemsets. This 
method uses the fast and simple “and calculus” in the Feature 
matrix to replace the calculations and complicated transactions 
that deal with large number of itemsets. But there is a great 
shortcoming in FAR algorithm. The generating of candidate 
itemsets relies on the combination of column of feature matrix. 
When the number of column of feature matrix is very large, 
FAR algorithm will cost much time to do useless calculus.  
We proposed the GMA (association graph and matrix 
pruning algorithm) algorithm to solution this problem. GMA 
algorithm adopts both association graph [7] and matrix pruning 
to reduce the generation of candidate itemsets. It scans database 
only once and generates frequent itemsets by the “and 
calculus’’. 
The remaining of the paper is organized as follows. Section 
? introduces the pre-processing of medical images. Section ? 
gives the details of GMA algorithm, pseudo code and an 
example. Section ? gives the experiment results and analysis. 
Section ? concludes our study.  
II. MEDICAL IMAGE PREPROCESSING 
We use the CT images of brain as our research object. First, 
we use the adaptive water immersion algorithm [8] to extract 
the ROI (interest of region) from the CT images of brain (as 
shown in Fig.1). Second, we need to extract relevant 
information as the features for each ROI, such as the symmetry, 
area, location of ROI. Last, we clustered these ROI using 
simple clustering algorithm. We assume that ROI can be 
clustered into five categories: A, B, C, D, E. Each CT image 
can be regarded as a combination of ROI. So the CT images of 
brain can be expressed into the form of Table?. 
 
978-1-4244-6977-2/10/$26.00 ©2010 IEEE
  
  
(a) (b) 
  
(c) (d) 
Figure 1.  Figure (a) and Figure (c) are the two original images of the brain, 
the dotted line of Figure (b) and Figure (d) are the ROI marked by using the 
adaptive water immersion algorithm. 
TABLE I.  CT IMAGES IMPRESSION IN TRANSACTION DATABASE 
Image ID Items 
IM1 BCD 
IM2 AC 
IM3 CDE 
IM4 BD 
IM5 ACE 
… … 
III. ASSOCIATION GRAPH AND MATRIX ALGORITHM (GMA) 
A. Basic Concept 
Definition 1: Association Rules 
In general, the I = (I1, I2, ..., Im) is the collection of items, 
D is the transaction database, each transaction T is a subset of 
items(T? I). We say that the T contains the item set X, if X? 
T. Association rules is logic implication pattern in form of 
X?Y, in which, X?T, Y?T, and X?Y=?. If the database 
contains the s% of the X?Y transaction, then we say that 
association rules X?Y's support is s; If the database contains 
X transaction, and also s% transaction contains Y, we say that 
the confidence of association rules X?Y is c. 
Definition 2: Association Graph.  
For a transaction database D. Let L2 is the set of frequent-
2 itemsets. G is the association graph of D. G is a direct graph 
which each edge mapped to an itemset of L2. For each itemset 
{IiIj} of L2, where i<j, there is a direct edge and only one edge 
from vertex i to vertex j in G. 
B. GMA algorithm 
This paper proposed the GMA algorithm to mine the 
association rules from medical images. In this section, we will 
give the algorithm details. In general, the GMA algorithm 
consists of four phases as follows: 
• Transforming the medical image transaction database 
into the ROI matrix and storing it by bit. 
• Generating the set of frequent-1 itemsets L1. 
• Generating the set of frequent-2 itemsets, constructing 
the association graph.  
• Generating the set of frequent-k itemsets Lk(k>2)  
First, GMA algorithm transforms the medical image 
transaction database into the ROI matrix. Assume that the 
mined medical image transaction database is D, with D having 
m images and n categories of ROI. Let T={T1,T2,…,Tm} be the 
set of transactions and I={I1,I2,…,In}be  the  set of items. So the 
D can be mapped to a matrix Am*n relative to ROI which has m 
rows and n columns. Scanning the image transaction database 
D, if item Ij is in transaction Ti , where 1?j?n,1?i?m, the 
element value of Aij is ‘1’, otherwise the value of Aij is ‘ 0’. 
After transforming, GMA algorithm scans the ROI matrix, 
computes the supports of all items, and generates the set of 
frequent-1 itemsets L1 and prunes the matrix. The support 
number Ij.support of item Ij is the number of ‘1’ in the jth 
column of the ROI matrix Am*n. If Ij.support is not smaller than 
the minimum support, Ij.support?min_sup, Ij will be added to 
the set of frequent-1 itemsets L1. Otherwise the column of the 
jth will be deleted from the ROI matrix. For the ROI matrix, 
the counts of 1 in each row (denote as sum (Ai)) is computed. If 
sum(Ai) < 2, the ith row of the ROI matrix will be deleted. 
Then the set of frequent-2 itemsets is generated to construct 
the association graph. For each itemset Ii of L1, a node is 
allocated for item Ii and Ii.link = NULL. For every combination 
of Ii and Ij (i<j) in L1, the ith and jth column of matrix are two 
vectors, the “and” relational calculus Ii?Ij is done. If the sum 
of element values in the “and” calculation result is not smaller   
than the minimum support number min_sup, sum(Ii?Ij) ?
min_sup, a directed edge from item Ii to item Ij is constructed 
and add itemset {IiIj} to the set of frequent-2 itemset L2. So 
after generating the L2, we can get the association graph. 
The most important phase in GMA algorithm is to generate 
the set of frequent-k itemsets Lk (k>2). In order to find the set 
of frequent-k (k>2) itemset, GMA algorithm firstly optimizes 
the matrix. Afterwards it generates the candidate-k itemsets 
using the information of association graph and matrix pruning. 
At last it verifies whether the candidate-k itemset is a frequent-
k itemset. The details of above procedures are described as 
follows. 
Pruning the matrix means deleting some rows and columns 
from it. First, the column of the ROI matrix is pruned. This is 
described in detail as: Let I’ be the set of all items in the 
frequent set Lk-1, where k>2. Compute all |Lk-1(j)| where j?I’, 
and delete the column of correspondence item j if |Lk-1(j)| is 
smaller than k-1. Second recompute the sum of the element 
values in each row in the ROI matrix. These rows of the ROI 
matrix whose sum of element values is smaller than k are 
deleted from this matrix. 
In order to generate candidate-k itemsets, we need to 
consider all itemsets of Lk-1. However, if there is a column of 
matrix has been deleted by optimizing matrix, we will not 
consider the itemset of Lk-1 which contains the corresponding 
of item. Otherwise, for each itemset {I1, I2, …, Ik-1} of Lk-1, 
finding edges that from vertex Ik-1 to other vertex in association 
graph. If there is an edge from vertex Ik-1 to vertex u, the 
itemset {I1, I2, …, Ik-1, u} is a candidate-k itemset.  
GMA algorithm does the “and” relational calculus to verify 
whether the candidate-k itemset is a frequent-k itemset of Lk. 
The “and” relational calculus is for combination of k vectors 
  
which corresponding to the candidate-k itemset {I1, I2, …, Ik-1, 
u}. If the sum of element values in the “and” calculation result 
is not smaller than the minimum support number min_sup, the 
k-itemsets corresponding to this combination of k-vectors are 
the frequent-k itemsets and are added to the set of frequent-k 
itemsets Lk. Then make k=k+1, do this again to find all 
frequent-k itemsets. 
GMA algorithm is described as follows. 
Input: An image transaction database D, the minimum 
support min_sup. 
Output: The set of frequent itemsets Lk. 
Transform transaction database into Matrix A; 
 \*frequent-1 itemsets generation phase *\ 
L1=?; 
if the 1’s counts of the column of Aj (denote as sum(Aj)), 
sum(Aj) ? min_sup 
L1=L1?{Ij}; 
else delete Aj from A. 
for each row Am from A 
          If sum(Am) < 2 
delete the row of Am from A.  
\* frequent-2 itemsets and association graph construction 
phase *\ 
if L1 ? ?  begin 
allocate a node for each item Ii of L1, and do  
item[Ii].link = NULL;  then do  
produce every 2-vectors Ai, Aj(i?j) combination begin  
B=Ai ? Aj 
 for the 1’counts of vector B, if sum(B) ? min_sup do 
begin  
allocate a node p; 
p.link = Item[Ii].link; 
p.Item = Item[Ij]; 
Item[Ii].link = p; 
L2 = L2 ?{Ii,Ij}; 
end 
            end 
end 
 \*Frequent –K(K?3) itemsets generation phase *\ 
K = 3; 
while (|Lk-1| ? k) do begin 
           Lk=?; 
OptMatrix( ); 
for all itemsets {I1, I2, …, Ik-1}of Lk-1,  
if {I1, I2, …, Ik-1}?Lk-1&& {I1, I2, …, Ik-1} not contain 
item Id which the corresponding column of matrix was deleted 
do begin 
 pointer =  Item[Ik-1].link; 
while (pointer ? NULL) do begin  
u = pointer.Item; 
if sum (A1?A2?…?Ak-1?Au) ? min_sup then 
Lk = Lk ? {I1, I2, …, Ik-1,Iu} 
pointer = pointer.link; 
end 
end 
k= k+1; 
end 
\*OptMatrix, optmizing the matrix before mining the frequent-
k (k>2) itemsets*\ 
for every column Aj of matrix, compute the |Lk-1(Aj)|,  
if |Lk-1(Aj)| < k-1; 
Delete the column Aj of matrix; 
for every row of Am of matrix, compute the 1 counts of 
Am,  
 if sum(Am) < k; 
   Delete the row Am of matrix; 
C. Example for GMA 
 We give a sample execution of the GMA algorithm in this 
section. The transaction data of transaction database D are 
given in Table ?. The itemset of database is the categories of 
ROI. Assume the minimum support min_sup=2, the m=4 is the 
number of transactions. There are 5 categories of ROI in 
medical images transaction database D. Therefore, n = 5 is the 
number of items. We have given the execution of the GMA 
algorithm in the following. 
TABLE II.  IMAGE TRANSACTION DATABASE 
Image ID Itemset 
IM1 I1,I3,I4 
IM2 I2,I3,I5 
IM3 I1,I2,I3,I5 
IM4 I2,I5 
The transaction database D is transformed into the ROI 
matrix A4*5. We delete the column of the ROI matrix which 
counts of 1 is smaller than min_sup. Otherwise, add the 
corresponding item to the set of frequent-1 itemset L1. So we 
can obtain L1= {I1, I2, I3, I5}. 
The fourth column of the matrix A4*5 is deleted because the 
support number of item I4 is smaller than the min_sup. We then 
compute the sum of the element values of each row in the 
matrix and delete all rows where the sum of the element values 
is smaller than 2.  So, the ROI matrix A4*4 is generated. 
10010T
10111T
10110T
01101T
IIIII
4
3
2
1
54321
                    
1010T
1111T
1110T
0101T
IIII
4
3
2
1
5321
 
A4*5                                                                   A4*4 
Then, we mine the set of frequent-2 itemsets L2 and 
construct the association graph. For each item Ii of L1, allocate 
a node and make Ii.link=NULL. Next we compute the counts of 
1 for all the combination of 2-vectors after doing the “and” 
relational calculus. For example, for the combination of itemset 
{I1I3}, we know that itemset {I1I3} is a frequent-2 itemset of L2 
and construct a direct edge from I1 to I3. So we can obtain the 
L2= {I1I3}, {I2I3}, {I2I5}, {I3I5}} and the association graph as 
shown in Fig. 2.  
We need optimize the matrix before generating the set of 
frequent-k(k>2) itemset. Next we mine the set of frequent-3 
itemset L3. Because we find that |L2(I1)| = 1< 2, we delete the 
  
first column of matrix. Therefore, the itemset {I1I3} of L2 
cannot be extended to candidate-3 itemsets. At last, the number 
of candidate-3 itemsets is only one, {I2I3I5}. We do “and” 
relational calculus to verify the candidate-3 itemset and find it 
is a frequent-3 itemset. Then we make k=k+1 to mine the set of 
frequent-4 itemset L4. After computing we know |L3|=1 < 4, so 
we terminate the execution of the GMA algorithm.  
 
Figure 2.  The association graph  
In this example, it generates only one candidate-3 itemset 
both GMA algorithm and FRA algorithm, that is {I2I3I5}. It will 
generate two candidate-3 itemset {I1I3I5} and {I2I3I5} using 
DLG algorithm. However, candidate itemsets generated by 
GMA algorithm is less than FAR algorithm when the number 
of item is very large. GMA algorithm reduces the generating 
candidate itemsets by two aspects. One is the information of 
association graph; the other is the matrix optimizing.  
IV. EXPERIMENT AND ANALYSIS 
In order to appraise the performance of the GMA 
algorithm, we conducted an experiment using the DLG 
algorithm, the FAR algorithm and GMA algorithm. These 
algorithms were implemented in C and tested on Windows XP 
SP3 Operating system, Mobile Intel Pentium 4 1.89GHz CPU
?1024MB DDR RAM?VC++6.0 compiler platform. The test 
database T10I4D100K was generated   synthetically by an 
algorithm designed by the IBM Quest project. The number of 
items N is set to 1000; |D| is the number of transactions; |T| is 
the averages size of transactions, and |I| is the average size of 
the maximum frequent itemsets. Fig. 3 presents the 
experimental results for different values of minimum supports.  
 
Figure 3.  The performance comparisons of DLG,FAR and GMA 
Experiment shows that, we can get the same set of frequent-
k itemset using three algorithms. However, the run_time of the 
algorithms execution is not same. DLG algorithm is better than 
FAR algorithm when the min_sup is small. FAR algorithm 
excels DLG algorithm as the value of min_sup increasing. 
Because when the min_sup increase, the efficiency of matrix 
pruning is better. In general, GMA algorithm is outperform the 
two algorithms whatever the value of min_sup is. 
V. CONCLUSION 
This paper proposed GMA algorithm by improving the 
FAR algorithm. The GMA algorithm draws on the advantages 
both association graph and matrix pruning to reduce the 
candidate itemsets generation. In actually, it greatly reduces the 
candidate itemsets and has improved the efficiency of frequent 
itemset mining. Experiment shows that GMA algorithm can 
adapt and adjust better to the change of the value of min_sup.  
ACKNOWLEDGMENT 
The paper is supported by the National Natural Science 
Foundation of China under Grant No.60803036, No.60803037, 
Natural Science Foundation of Heilongjiang Province under 
Grant No.F200903, the Fundamental Research Funds for 
Central Universities No. HEUCFZ1010, the National High-
tech R&D Program of China under Grant No. 2009AA01Z143, 
and Nuclear Safety & Simulation Tech. Lab Foundation under 
Grant No.HEUFN0802. 
REFERENCES 
[1] Rakesh Agrawal, Tomasz Imielinski and Arun N. Swami, “Data Mining: 
A Performance perspective,” IEEE Transactions on Knowledge and 
Data Engineering, 1993, Vol.5, pp.914-925.  
[2] Rakesh Agrawal and Ramakrishnan Srikant, “Fast Algorithms for 
Mining Association Rules in Large Databases,” Proceedings of the 
Twentieth International Conference on Very Large Databases, Santiago, 
Chile,1994,  pp.487-499. 
[3] J.S. Park, M.S. Chen, P.S. Yu, “An effective hash-based algorithm for 
mining association rules,”  Proc. 1995 ACM-SIGMOD Int.Conf. 
Management of Data (SIGMOD’95), San Jose, CA, l995, pp.175-186. 
[4] Jiawei Han, Jian Pei, Yiwen Yin, “Mining frequent patterns candidate 
generation,” In proceedings of the 2000 ACM SIGMOD International 
Conference on Management of Data (SIGMOD’2000), Dallas, TX, 
2000, pp.1-12. 
[5] Liu,  D. & Kedem,  Z., “An  Efficient  Algorithm  for Discovering The 
Maximum Frequent Set,” IEEE Transaction on Knowledge and Data 
Engineering, 2002, Vol.14, No.3, pp.553-566. 
[6] L.Jaba Sheela , V. Shanthi , D.Jeba Singh, “Image Mining using 
Association rules derived from Feature Matrix,” In proceedings of the 
2009 International Conference on Advances in Computing, 
Communication and Control (ICAC3’09), Mumbai, Maharashtra, India, 
2009, pp.440~443. 
[7] YEN SJ, CHEN ALP, “A Graph-Based Approach for Discovering 
Various Types of Association Rules,” IEEE Transactions on Knowledge 
and Data Engineering, 2001, Vol.13, No.5, pp.839~845.  
[8] Haiwei Pan, Jianzhong Li, Wei Zhang, “Incorporating domain  
knowledge into medical image clustering,” Applied Mathematics and 
Computation, 2007, Vol.185, No.2, pp.844-856. 
   
I1 
I5 
I3 
I2 
