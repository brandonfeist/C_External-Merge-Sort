Support driven opportunistic aggregation
for generalized itemset extraction
Elena Baralis, Luca Cagliero, Tania Cerquitelli, Vincenzo D’Elia, and Paolo Garza
Abstract—Association rule extraction is a widely used ex-
ploratory technique which has been exploited in different contexts
(e.g., biological data, medical images). However, association rule
extraction, driven by support and confidence constraints, entails
(i) generating a huge number of rules which are difficult to
analyze, or (ii) pruning rare itemsets, even if their hidden
knowledge might be relevant. To address the above issues, this
paper presents a novel frequent itemset mining algorithm, called
GENIO (GENeralized Itemset DiscOverer), to analyze correlation
among data by means of generalized itemsets, which provide a
powerful tool to efficiently extract hidden knowledge, discarded
by previous approaches. The proposed technique exploits a
(user provided) taxonomy to drive the pruning phase of the
extraction process. Instead of extracting itemsets for all levels
of the taxonomy and post-pruning them, the GenIO algorithm
performs a support driven opportunistic aggregation of itemsets.
Generalized itemsets are extracted only if itemsets at a lower level
in the taxonomy are below the support threshold. Experiments
performed in the network traffic domain show the efficiency and
the effectiveness of the proposed algorithm.
Index Terms—Generalized itemset mining, knowledge discov-
ery, data mining techniques, network traffic data analysis.
I. INTRODUCTION
Association rule extraction [1] is a powerful data mining
technique to effectively discover correlation among data. As-
sociation rules are usually represented in the form A ? B
, where A and B are itemsets, i.e., sets of data items. Each
rule is usually characterized by the support and confidence
quality indices [1]. The support is the probability of A and B
(i.e., its observed frequency in the dataset). The confidence is
the conditional probability of B given A and characterizes the
“strength” of a rule. Since association rules identify pairs of
itemsets that are statistically related (i.e., frequently together in
transactions), they find application in a wide range of different
domains, including medical images [3], and biological data [6].
Association rule mining [1] is a two-step process: (i) Frequent
itemset extraction and (ii) association rule generation from fre-
quent itemsets. Research activity usually focuses on defining
efficient algorithms for itemset extraction, which represents
the most computationally intensive knowledge extraction task
in association rule mining [2].
The traditional itemset mining problem can be described
as follows. Given a dataset of transactions and a minimum
support threshold, find all itemsets whose support is above
the given threshold. However, such a threshold may prevent
E. Baralis, L. Cagliero, T. Cerquitelli, V. D’Elia, and P. Garza
are with the Dipartimento di Automatica e Informatica, Politecnico di
Torino, Italy {elena.baralis, luca.cagliero, tania.cerquitelli, vincenzo.delia,
paolo.garza}@polito.it
infrequent, but potentially relevant, itemsets from being ex-
tracted, while enforcing a very low threshold makes the task
computationally expensive and the mined knowledge too large
to be analyzed.
This paper proposes a novel algorithm, called GENIO
(GENeralized Itemset DiscOverer) to support data analysis by
automatically extracting higher level, more abstract correla-
tions from data. GENIO extends the concept of multiple-level
itemsets [7], [10], [13] by performing an opportunistic extrac-
tion of generalized itemsets. The proposed algorithm exploits
a (user provided) taxonomy to drive the pruning phase of the
extraction process and efficiently extract generalized itemsets.
Instead of extracting itemsets for all levels of the taxonomy
and post-pruning them [7], the proposed generalization tech-
nique over the taxonomy is support driven, i.e., it generalizes
an itemset only if the itemsets at a lower level in the taxonomy
are below the support threshold. Thus, GENIO automatically
performs generalization only when needed to exceed the
support threshold. Furthermore, the proposed approach should
be exploited in every application context in which meaningful
taxonomies might be inferred from structured data sources
(e.g., network traffic analysis, context-aware applications).
GENIO has been designed by customizing the Apriori
algorithm [2] to efficiently extract generalized itemsets, with
variable support thresholds, from structured data. It has been
tested on network traffic data for two reasons: (i) A huge
amount of data may be collected in a short time, (ii) in very
large traffic network traces it is hard to detect correlations
among data and identify anomalies because of the excessively
detailed granularity of information (e.g., IP addresses). In
this context, the proposed generalization approach proves to
be particularly effective. Experiments, performed on different
network dumps, show the efficiency and the effectiveness of
the proposed algorithm.
The paper is organized as follows. Section II defines the
problem statement addressed in this paper. Section III de-
scribes the proposed approach for generalized frequent itemset
mining, where taxonomies are lazily evaluated to effectively
handle rare itemsets. Section IV discusses the experiments per-
formed to evaluate the effectiveness of the proposed algorithm
in discovering frequent generalized itemsets in network traffic
domain. Section V compares our approach with previous
works. Finally, Section VI draws conclusions and presents
future developments of the proposed approach.
A. Motivating example
Consider an ftp server on port 21 having address
130.192.15.17. To describe the activity of a client
978-1-4244-5164-7/10/$26.00 ©2010 IEEE 
(154.125.3.2) connecting to this server, an itemset in
the form
(i) (source-IP-address = 154.125.3.2,
destination-IP-address = 130.192.15.17,
destination-port = 21) (sup = 1.15%)
should be extracted. Since such triplet is infrequent in a
very large traffic network trace, extracting this itemset would
require enforcing a very low support threshold, which makes
the task unfeasible. However, an opportunistic taxonomy eval-
uation may be more effective in mining valuable knowledge.
Suppose to set the minimum support threshold at 2%. A higher
level view of the network may be provided by the following
generalized itemset
(ii) (source-IP-address = 154.125.3.0/17,
destination-IP-address = 130.192.15.17,
destination-port = 21) (sup = 2.4%)
which shows a generalization of the source-IP-address at-
tribute (i.e., a subnet including IP addresses 154.125.3.0/17).
This itemset is characterized by a larger support which fulfills
the support constraint and shows that the subnet detected
by the generalization process is actually generating most of
the traffic. Thus, it provides valuable knowledge for network
monitoring. Furthermore, the number of different items (e.g.,
source-IP-address = 154.125.3.2) in network traffic may be
very large. Hence, itemsets at this detail level may provide
hardly interpretable knowledge. Our generalization approach
allows preserving a detailed view of frequent items (e.g.,
destination-IP-address = 130.192.15.17), while generalizing
at a higher taxonomy level infrequent items (e.g. source-IP-
address = 154.125.3.2).
Consider again itemset (i). If it would have support 2.15%
instead of 1.15%, by enforcing the same minimum support
threshold equal to 2%, the itemset becomes frequent, thus,
it is extracted since it provides valuable knowledge. Further
generalization steps to generate itemset (ii) are prevented
because they do not enrich the actual mined set anymore.
II. PROBLEM STATEMENT
Let T ={t1, t2, . . . , tn} be a set of labels, called attributes,
which describe data features, and ?={?1,?2, . . . ,?n} be the
correspondent attribute domains. An item is a pair ti = valuei
which assigns value valuei ? ?i to attribute ti. The attributes
may have either a categorical or a continuous domain. In the
case of continuous attributes, the value range is discretized into
intervals, and the intervals are also mapped into consecutive
positive integers.
In the network traffic domain, valuei are values captured
from the net (e.g., the IP address 130.192.15.17), and ti are
the descriptions of the represented information.
A structured dataset D (e.g., network trace) is a collection
of records (e.g., network flows), where each record r is a set
of items and contains at most one item for each attribute in T .
Let I be the enumeration of all items in D, an itemset X ? I
is a set of items. Each attribute ti may occur at most once in
X .
Fig. 1. A rewriting rule tree RRport for the source and destination port
attributes
Over each attribute ti it is defined at most one pre-
determined hierarchy of aggregations over values in ?i. Each
hierarchy is called a rewriting rule tree RRi. RRi is a tree
whose leaves are values in ?i, while each non-leaf node in
the tree is an aggregation of its children, which may be further
generalized by its father. The root node aggregates all values
for attribute ti. The set of rewriting rules RRi defined over
the attributes of D is called taxonomy (?).
Consider, for example, the destination-port address at-
tribute. A simple rewriting rule tree RRport, defined over
the destination-port address attribute, is shown in Figure 1.
The RRport assigns well known if the destination-port value
is lower than 1024, registered if in the range 1024-49151,
dynamic otherwise.
A generalized item is a pair ti = expressioni, where ti is
an attribute, ?i the correspondent domain, and expressioni
a not-leaf node in RRi defining an aggregation value over
values in ?i. leaves(expressioni) ? ?i defines the set of
leaf nodes descendants of expressioni in RRi. Usually the
quality of a generalized item ti = expressioni is measured
by its support, which is the sum of the (observed) frequency
in D of leaves(expressioni).
A generalized itemset X is a set of items and/or generalized
items. Each attribute ti ? T may occur at most once in X . Its
support is the (observed) frequency of X in D.
Given a structured dataset D, a minimum support threshold
min sup, and a taxonomy ?, the GENIO algorithm extracts:
(i) All itemsets whose support exceeds min sup and (ii) all
generalized itemsets whose (a) descendants include at least an
infrequent itemset (i.e., a descendant whose support is lower
than min sup) and (b) support exceeds min sup.
III. THE GENIO ALGORITHM
GENIO discovers all frequent itemsets and all generalized
itemsets having at least an infrequent descendant. The gener-
alization process, driven by the taxonomy ?, is support driven,
i.e., it generalizes an itemset only if it is infrequent with
respect to the mininum support threshold. The pseudo-code of
GENIO is given by Algorithm 1. GENIO implementation is
based on Apriori [2]. Apriori is a level-wise algorithm, which,
at each iteration, generates all frequent itemsets of a given
length. At arbitrary iteration k, two steps are performed: (i)
Candidate generation, the most computationally and memory
Algorithm 1 Generalized Itemset Discoverer
Input: minimum support min sup, taxonomy ?, dataset D
Output: L, set of generalized frequent itemsets
1: k = 1, L = ?
2: C1 = set of items in D
3: repeat
4: scan D and count support for each c ? Ck
5: Gen = ? // generalized itemset container
6: for all c in Ck do
7: if support of c <min sup then
8: new gen itemset = taxonomy evaluation( ?, c )
9: update Gen with new gen itemset
10: end if
11: end for
12: if Gen 6= ? then
13: scan D and count support for each itemset in Gen
14: end if
15: Lk = { itemsets in {Ck ? Gen} whose support ? min sup }
16: k = k + 1
17: Ck = candidate generation( Lk?1 )
18: until Ck 6= ?
19: return L
intensive step, in which all possible k-itemsets are generated
from (k-1)-itemsets, (ii) candidate pruning, which is based
on the property that all subsets of frequent itemsets must
also be frequent, to discard candidate itemsets which cannot
be frequent. Finally, actual candidate support is counted by
reading the dataset.
GENIO approach follows the same level-wise pattern. How-
ever, it (i) manages rare itemsets by lazily evaluating the
taxonomy ? (lines 6-11), and (ii) exploits the characteristics of
the structured datasets to effectively prune candidates (line 17).
Once the support of each candidate itemset in Ck has been
computed (line 4), generalized versions of infrequent ones are
generated by evaluating the taxonomy (line 8) and inserted in
the Gen set (line 9). In particular, by applying on each item
tj = valuej in itemset c the corresponding rewriting rule tree
RRj , the generalized versions of each item in c is generated
(line 8). All the itemsets obtained by replacing one or more
items in c with their generalized versions are generalized
itemsets of c. Hence, the taxonomy evaluation on itemset c
potentially generates a set of generalized itemsets. The gener-
alization process of c is triggered if and only if c is infrequent
with respect to the mininum support threshold (line 7). Once
triggered, the generalization process is repeated until a com-
plete taxonomy evaluation has been performed. For example,
let (destination-IP-address = 130.192.15.17, destination-port =
21) be an infrequent itemset in Ck. By applying on destination
port the rewriting rule tree RRport shown in Figure 1 and on
destination IP address RRIP?address shown in Figure 2, the
following generalized itemsets are generated:
• (destination-IP-address = 130.192.15.0/24, destination-
port = 21)
• (destination-IP-address = 130.192.15.17, destination-port
= Well-known)
• (destination-IP-address = 130.192.15.0/24, destination-
port = Well-known)
The insertion of redundant generalized itemsets (i.e., gen-
eralized itemsets previously generated by different infrequent
descendants) in Gen is prevented by the update procedure
in line 9. If the Gen set is not empty, the support of each
generalized itemset in Gen is computed by performing a
ID Number of records Number of different items
D1 18051 32143
D2 17374 30617
D3 16783 30072
D4 3802 9350
D5 2074 5825
TABLE I
CHARACTERISTICS OF THE DATASETS
Fig. 2. A rewriting rule tree RRIP?address for the source and destination
IP address attributes
further scan of the dataset (line 13).
During the candidate generation step (line 17), GENIO
exploits the uniqueness of attributes in a given record of a
structured dataset to further prune candidate itemsets (e.g., in
the traffic network domain a flow, i.e., a record of the network
trace, with multiple destination-IP-address cannot be defined).
For example, suppose that after the first dataset traversal, we
have m frequent 1-itemsets tagged source-IP-address and n
tagged destination-IP-address. Apriori exhaustive candidate
generation would produce
(
m+n
2
)
possible combinations. Since
each attribute could appear only once in each record, only m·n
2-itemsets (obtained by combining one item tagged source-
IP-address and one item tagged destination-IP-address) are
relevant combinations. Hence, GENIO generates only this
subset of candidates. Thus, the required computational and
memory cost is reduced.
IV. EXPERIMENTAL RESULTS
We evaluated the performance of the GENIO algorithm by
means of a significant set of experiments which analyze (i)
the performance of the proposed frequent generalized itemset
miner, (ii) the number and relevance of the extracted itemsets,
and (iii) the algorithm scalability by varying the number of
transactions.
A. Experimental setting
Experiments have been performed on an AMD Sempron
TM
2400+ PC with 1666 MHz CPU and 512 Mb main mem-
ory, Linux operating system. Five real datasets have been
exploited to validate the efficiency and effectiveness of the
(a) Execution time (b) Number of extracted itemsets
 90
 92
 94
 96
 98
 100
 0  0.25  0.5  0.75  1  1.25  1.5  1.75  2
It
e
m
s
e
ts
 c
o
n
ta
in
in
g
 g
e
n
e
ra
li
z
e
d
 i
te
m
s
 (
%
)
Minimum support threshold (%)
D1 D2 D3 D4 D5
(c) Aggregation impact factor
Fig. 3. Performance of the GENIO algorithm
GENIO algorithm. These datasets were obtained by perform-
ing different capture sessions using the open-source Network
Analyzer tool [11] on a backbone link of the campus network.
Captured traffic has been aggregated in traffic flows, i.e.,
records which summarize a group of similar and temporally
contiguous packets. Each flow is a transaction characterized
by six attributes: Source IP address, destination IP address,
source port, destination port, flow size (i.e., the size of the
flow expressed in byte), and number of IP packets aggregated
in that flow. We will refer to each dataset using the ID shown
in the first column of Table I. Table I reports the number of
records and the number of different items for each dataset.
The used datasets have significantly different characteristics
in terms of cardinality and number of different items. Dataset
ids are sorted by decreasing cardinality.
The taxonomy used in the experiments aggregates infre-
quent items according to the following rewriting rule trees. (1)
Source and destination ports are aggregated by exploiting the
rewriting rule tree shown in Figure 1, which introduces three
aggregation values (i.e., well known, registered, dynamic).
(2) Source and destination IP addresses are aggregated by
exploiting the rewriting rule tree shown in Figure 2. IP
addresses are aggregated in subnet if they are local to the
campus network. IP addresses which do not belong to the
campus network are aggregated in a more general external
address node. Furthermore, both the flow size (bytes) and
number of IP packets attributes are uniformly discretized in 4
bins, whose intervals are [1,1000), [1000, 2000), [2000, 3000),
and equal or greater than 3000.
B. Frequent generalized itemset extraction performance
To evaluate the proposed algorithm, the following issues
have been addressed: (i) Performance of the proposed gener-
alized itemset miner, in terms of execution time, number of
extracted itemsets, and aggregation impact factor, (ii) compar-
ison between GENIO and an optimized version of the well-
known multiple-level algorithm, namely Cumulate, proposed
in [13], in terms of time reduction and pruning selectivity.
1) The GENIO algorithm performance: Figure 3 shows the
execution time (Figure 3(a)), the number of extracted gener-
alized itemsets (see Figure 3(b)), and the aggregation impact
factor (see Figure 3(c)) yielded by the GENIO algorithm by
enforcing different support thresholds. GENIO execution time,
shown in Figure 3(a), is mainly due to the generalization
process and the dataset scans. While the first factor depends
on taxonomy features (e.g., number of aggregation levels),
the latter is proportional to the number of transactions. Since
the taxonomy exploited in the network traffic analysis is
characterized by few aggregation levels, the time spent for
dataset scans is dominant. Furthermore, the execution time
increases for larger datasets and lower support thresholds, for
which dataset scans require much more time.
Figure 3(b) shows the number of extracted generalized
itemsets by enforcing different support thresholds. When
support threshold decreases the number of mined itemsets
increases. For high support thresholds, the number of extracted
generalized itemsets is quite constant. When low support
thresholds are enforced, the number of generalized itemsets
significantly increases especially when the data distribution
becomes sparser (see datasets D4 and D5 in Figure 3(b)). This
effect is given by the high number of low frequency items
characterizing a sparse dataset. These items become frequent
when the mining process is performed by enforcing a low
support threshold.
We also analyzed the impact of the aggregation process on
the number of mined itemsets for each dataset. In particular,
Figure 3(c) reports the percentage of itemsets arising from
the generalization process with respect to the total number of
extracted itemsets by varying the minimum support threshold.
Since generalization is a support driven process, the number
of itemsets containing terms at higher level of the taxonomy
increases by enforcing higher support thresholds.
2) Comparison between GENIO and Cumulate: We com-
pared GENIO with our optimized implementation of Cu-
mulate [13], a traditional well-known generalized itemset
mining algorithm. Figure 4 shows the time reduction for
generalized itemset extraction yielded by GENIO with respect
to Cumulate. Experiments, on all considered datasets, have
been performed by enforcing different support thresholds.
Cumulate did not correctly terminate the extraction task on
datasets D1, D2, D3 for the lowest considered support (see
Figure 4). GENIO algorithm yields a significant reduction of
 0
 20
 40
 60
 80
 100
 0  0.25  0.5  0.75  1  1.25  1.5  1.75  2
T
im
e
 r
e
d
u
c
ti
o
n
 (
%
)
Minimum support threshold (%)
D1 D2 D3 D4 D5
Fig. 4. GENIO w.r.t. Cumulate: Time reduction (%)
 0
 1
 2
 3
 4
 5
 6
 7
 0  0.25  0.5  0.75  1  1.25  1.5  1.75  2
P
ru
n
e
d
 g
e
n
e
ra
liz
e
d
 i
te
m
s
e
ts
 (
%
)
Minimum support threshold (%)
D1 D2 D3 D4 D5
Fig. 5. GENIO w.r.t. Cumulate: Pruned generalized itemsets (%)
the execution time for any considered datasets and for all
support thresholds. The reduction is mainly due to the support
driven opportunistic aggregation, which reduces the number
of extracted generalized itemsets (as shown in Figure 5), and
to the exploited strategy to further prune candidate itemsets
(see Section III).
To evaluate the pruning selectivity of our approach, we have
analyzed the corresponding percentage of pruned generalized
itemsets with respect to Cumulate. Since the GENIO algo-
rithm performs a support driven opportunistic aggregation of
itemsets, it extracts a smaller number of generalized itemsets
than Cumulate. Figure 5 shows the percentage of pruned
generalized itemsets for all datasets. GENIO yields a good
percentage of pruned itemsets for any considered support
thresholds. For high support thresholds, since the absolute
number of generalized itemsets is small (see Figure 3(b))
the corresponding percentage of pruned generalized itemset
is about 4%-6% (see Figure 5). For low support thresholds,
a high number of low frequency items become frequent.
Thus, the absolute number of generalized itemsets significantly
increases (see Figure 3(b)), while the percentage of pruned
generalized itemsets (see Figure 5) preserves its trend. Hence,
the GENIO algorithm significantly reduces the cardinality of
the extracted knowledge. The Cumulate algorithm could obtain
the same knowledge mined by GENIO only through a very
expensive post-processing analysis over a very large set of
itemsets.
C. Analysis of the extracted generalized itemsets
In the following we analyze the meaning of the extracted
generalized itemsets in the network traffic domain.
 0
 1
 2
 3
 4
 5
 6
 7
 8
1
3
0
.1
9
2
.A
.*
1
3
0
.1
9
2
.A
.a
1
3
0
.1
9
2
.B
.*
1
3
0
.1
9
2
.B
.b
1
3
0
.1
9
2
.C
.*
1
3
0
.1
9
2
.D
.*
1
3
0
.1
9
2
.E
.*
1
3
0
.1
9
2
.F
.*
1
3
0
.1
9
2
.G
.*
1
3
0
.1
9
2
.H
.*
1
3
0
.1
9
2
.I
.*
1
3
0
.1
9
2
.J
.*
1
3
0
.1
9
2
.J
.j
1
3
0
.1
9
2
.K
.*
1
3
0
.1
9
2
.L
.*
1
3
0
.1
9
2
.M
.*
1
3
0
.1
9
2
.N
.*
1
3
0
.1
9
2
.O
.o
1
3
0
.1
9
2
.P
.*
1
3
0
.1
9
2
.Q
.q
1
3
0
.1
9
2
.R
.*
1
3
0
.1
9
2
.S
.*
1
3
0
.1
9
2
.T
.*
1
3
0
.1
9
2
.U
.*
1
3
0
.1
9
2
.V
.*
1
3
0
.1
9
2
.W
.w
1
3
0
.1
9
2
.X
.*
1
3
0
.1
9
2
.X
.x
1
3
0
.1
9
2
.Y
.*
1
3
0
.1
9
2
.Z
.*
1
3
0
.1
9
2
.A
A
.*
S
u
p
p
o
rt
 (
%
)
Destination-IP-address
destination-port:well-known
destination-port:registered
destination-port:dynamic
destination-port:57403
Fig. 6. Support of extracted 2-itemsets for different destination IP addresses
and ports
Figure 6 shows the support of the generalized 2-itemsets
in the form (destination-IP-address, destination-port) obtained
from dataset D1. For better visualization, results have been
restricted to addresses of the campus network. Thus, no
external IP address has been considered. The address is
automatically aggregated to the subnet when the single IP
address support is under the minimum support threshold (set
to 1%). Figure 6 provides a characterization of the traffic
on the campus network. Many extracted itemsets describe
general network features. For example, the first top supported
generalized itemset identifies the VPN concentrator of the
campus network.
Larger generalized itemsets (i.e., itemsets with more than 2
items) can be exploited to focus the analysis on specific traffic
behaviors. For example, the 4-itemsets (destination-IP-address
= 130.192.O.o, destination-port = 57403, source-IP-address
= x.x.x.x, source-port = registered-port), having support equal
to 2.3%, highlights an unconventional high-volume traffic
towards a specific host of the campus network, whereas the
4-itemsets (destination-IP-address = 130.192.A.a, destination-
port = registered-port, source-IP-address = y.y.y.y, source-
port = well-known), having support equal to 2%, identifies
connections to the VPN concentrator by means of a client
using well-known source ports.
D. Scalability
We analyzed the scalability of the GENIO algorithm with
respect to the cardinality of records on synthetic datasets gen-
erated by means of the TPC-H generator [15]. By varying the
scale factor parameter, tables with different cardinalities are
generated. We generated datasets of size ranging from 30,000
to 210,000 records with 12 categorical attributes. We mined
generalized itemsets from the lineitem table and we exploited
the part, nation, and region tables to define taxonomies on
line items.
Figure 7, which plots the extraction time for various sup-
ports, shows that the proposed algorithm scales well also for
large datasets. Since the number of extracted itemsets grows
for low supports (e.g., 1%), the process becomes computation-
ally more expensive. However, the overall CPU time is still
low, less than 7600 s for the lowest considered support and
largest dataset.
 0
 1000
 2000
 3000
 4000
 5000
 6000
 7000
 8000
 30  60  90  120  150  180  210
E
x
e
c
u
ti
o
n
 t
im
e
 (
s
)
Number of records (x 1000)
minsup=1% minsup=2% minsup=5%
Fig. 7. Scalability on TPC-H datasets
V. RELATED WORK
The problem of generalized association rules was firstly
introduced in [13]. Given a dataset, where each transaction
is a set of items, and a taxonomy defined on the items,
generalized association rule mining consists in finding associ-
ations between items at any level of the taxonomy. Proposed
algorithms [13] generate generalized itemsets by considering,
for each item, its parents in the hierarchy. Hence, candidate
frequent itemsets are exhaustively generated by producing a
large amount of unnecessary item combinations.
One step towards a more efficient extraction process for
generalized itemset extraction have been proposed in [7],
[9], [12], [14]. [7] firstly proposes a top-down hierarchy
traversal, based on the Apriori principle, to efficiently identify
infrequent itemsets. When a more general term is infrequent
its descendants are ignored during the candidate generation.
However, appopriate support thresholds have to be enforced
to properly handle different data granularity in the taxonomy.
A more efficient approach, based on the FP-tree struc-
ture [8], has been proposed in [12]. First the FP-tree containing
all frequent multiple-level items is built. Then, frequent gen-
eralized itemsets are generated by using a divide-an-conquer
strategy as in FP-growth algorithm [8]. An ancestor list for
the items belonging to the currently mined itemset is exploited
to efficiently prune itemsets containing both an item and its
ancestor.
All the state-of-the-art approaches perform a similar exhaus-
tive taxonomy evaluation by extracting most of all possible
itemsets at all levels of abstraction. A huge amount of itemsets
is mined and valuable pattern discovery is, often, left as
post-processing step, limiting support threshold enforcement
effectiveness. GENIO aims at overcoming such an issue by
performing an opportunistic extraction of generalized itemsets.
It exploits a user provided taxonomy to drive the pruning phase
of the extraction process. Instead of extracting itemsets for all
levels of the taxonomy and post-pruning them, the proposed
generalization technique over the taxonomy is support driven,
i.e., it generalizes an itemset only if it is below the support
threshold. Thus, GENIO automatically performs generalization
only when needed.
A preliminary version of the GENIO algorithm was ex-
ploited in context-aware [5] and network traffic [4] domains.
The focus in [5] is on profiling users and services in a mobile
context-aware application, while in [4] is on the characteriza-
tion of stream network data. Both in [4] and [5], the GENIO
algorithm is shortly introduced as a tool to extract generalized
itemsets, while this paper thoroughly describes the GENIO
algorithm and extensively analyzes its performance both on
synthetic and real datasets.
VI. CONCLUSION AND FUTURE WORK
In this paper, we proposed the GENIO algorithm to effi-
ciently address generalized itemset extraction. An user pro-
vided taxonomy is exploited to merge rare patterns in more
general expressions. The behavior of the GENIO algorithm
has been tested on real network traffic data. The experimental
results show the effectiveness of the proposed approach in
discovering unexpected and generalized hidden knowledge in
network traffic data.
Future works will address (i) the extention of GENIO to
incrementally update the extracted knowledge when new data
become available, (ii) the exploitation of multiple taxonomies
over a single attribute, and (iii) the application of the op-
portunistic generalization approach to more efficient itemset
extraction algorithms (e.g., LCM v.2 [16]).
REFERENCES
[1] R. Agrawal, T. Imielinski, and Swami. Mining association rules between
sets of items in large databases. In ACM SIGMOD 1993, pages 207–216,
1993.
[2] R. Agrawal and R. Srikant. Fast algorithm for mining association rules.
In VLDB 1994, 1994.
[3] M. L. Antonie, O. R. Zaiane, and A. Coman. Application of data mining
techniques for medical image classification. In MDM/KDD 2001, 2001.
[4] D. Apiletti, E. Baralis, T. Cerquitelli, and V. D’Elia. Characterizing
network traffic by means of the netmine framework. Computer Networks,
53(6):774–789, 2009.
[5] E. Baralis, L. Cagliero, T. Cerquitelli, P. Garza, and M. Marchetti.
Context-aware user and service profiling by means of generalized
association rules. In KES ’09, 2009.
[6] G. Cong, A. K. H. Tung, X. Xu, F. Pan, and J. Yang. Farmer: finding
interesting rule groups in microarray datasets. In ACM SIGMOD 2004,
2004.
[7] J. Han and Y. Fu. Mining multiple-level association rules in large
databases. IEEE TKDE, 11(5):798–805, 1999.
[8] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate
generation. In ACM SIGMOD 2000, 2000.
[9] J. Hipp, A. Myka, R. Wirth, and U. Guntzer. A new algorithm for faster
mining of generalized association rules. In PKDD 1998, pages 74–82,
1998.
[10] M. Kaya and R. Alhajj. Mining multi-cross level fuzzy weighted
association rules. In IEEE Conf. on Intell. Systems, pages 225–230,
2004.
[11] NetGroup. Analyzer 3.0, 2009.
[12] I. Pramudiono and M. Kitsuregawa. FP-tax: tree structure based
generalized association rule mining. In DMKD ’04: ACM SIGMOD
workshop on Research issues in data mining and knowledge discovery,
2004.
[13] R. Srikant and R. Agrawal. Mining generalized association rules. In
VLDB 1995, 1995.
[14] K. Sriphaew and T. Theeramunkong. A new method for finding
generalized frequent itemsets in association rule mining. In Proceeding
of the VII International Symposium on Computers and Communications,
pages 420–431, 2002.
[15] TPC-H. The TPC benchmark H. Transaction Processing Performance
Council, 2009. http://www.tpc.org/tpch/default.asp.
[16] T. Uno, L. Kiyomi, and H. Arimura. LCM (ver 2): Efficient mining
algorithms for frequent/closed/maximal itemsets. In FIMI ’04, 2004.
