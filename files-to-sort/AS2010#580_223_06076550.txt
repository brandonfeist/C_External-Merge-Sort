Research on Mining Positive and Negative Association Rules  
Based on Dual Confidence  
 
Xiufeng Piao 
College of Computer Science and 
Technology 
Harbin Engineering University 
Harbin , China 
xfpiao@126.com 
 
Zhanlong Wang  
College of Computer Science and 
Technology 
Harbin Engineering University 
Harbin , China 
wangzhanlong@hrbeu.edu.cn 
 
Gang Liu 
College of Computer Science and 
Technology 
Harbin Engineering University 
Harbin , China 
liugang@hrbeu.edu.cn 
 
Abstract—Mining of association rules has become an important 
area in the research on data mining. However the traditional 
approaches based on support-confidence framework maybe 
generate a great number of redundant and wrong association 
rules. In order to solve the problems , a correlation measure is 
defined and added to the mining algorithm for association 
rules. According to the value of correlation measure, 
association rules are classified into positive and negative 
association rules. Therefore,the new algorithm can mine the 
negative-item-contained rules. In the paper, the algorithm 
which based on the correlation and dual confidence, can mine 
the positive and negative association rules.The experimental 
result shows that positive and negative association rules mining 
algorithm can reduce the scale of meaningless association 
rules, and mine a lot of interesting negative association rules.  
Keywords- data mining; positive and negative association 
rules; dual confidence; minimum correlation 
I. 0BINTRODUCTION 
Association rules was proposed by Rakesh Agrawal et al 
[1] in 1993 for initially, which is an important technique in 
data mining. Traditional association rules, mainly for mining 
customer transaction database relationship between sets of 
items, that is of the form A B? , high frequency, high 
correlation rules, which we call positive association rules, is 
a strong correlation of the dominant model, and there are 
many mining algorithms[2-7]. In fact, many databases which 
use these mining technology can not find the hidden patterns, 
one of these important hidden pattern is the negative 
association rules, which has a low frequency and strong 
correlations, showing the HpropertyH of the strong correlations 
in the data itemsets which is hard to find. The rules tell us 
that which data items less to occur together, and they share a 
very strong correlation, and contain very valuable 
information, such as rules A B? ¬ ? A B¬ ? ?
A B¬ ? ¬ ,so mining negative association rules is very 
important. 
Currently used for the negative association rules mining 
algorithm is not too much, such as [3] proposed a positive 
and negative association rules mining algorithm based on 
interestingness,a negative association rules mining algorithm 
based on support, confidence, correlation coefficient in [4], 
and a negative association rules mining algorithm based on 
matrix in [5]. 
Negative association rules of the search space for all non-
frequent itemsets, and the non-frequent itemsets in the 
database D is exponential, which is also the main reason of 
study negative association rules more difficult than  positive 
association rules.While obtained the support of all non-
frequent itemsets is unrealistic, but also meaningless. For 
example, for the negative association rules A B? ¬ , 
A B? is the non-frequent itemsets, but both A and B are 
frequent itemsets, Therefore, a negative association rules 
mining can be divided into two sub-problems: ?  the 
database D, find all the frequent itemsets L; ? Determine 
negative association rules based on frequent itemsets L. 
There are many algorithms can be used directly to solve the 
first sub-problems, such as the Apriori algorithm, FP-growth 
algorithm. This paper gives a negative association rules 
mining algorithm to find hidden rules in massive data. 
Negative association rules are used to discover the 
meaningful association beteween the itemsets and others in 
the large data,  giving the interesting relationship between 
these items. 
II. 1BPROBLEM  FORMULATION 
Set I={iR1R,iR2R,…,iRmR}that contains a collection of m 
different items. Given a transaction database D, where each 
transaction T is a group itemsets of I. If A is a subset of 
I,with A T? , we can say that a transaction T contains A. A 
negative association rules are an implication of the form 
A B¬ ?  (or A B? ¬ ,or A B¬ ? ¬ ) ,Where ,A B T? , and 
A B? = ? . 
Given support s and confidence c. If D has (100 × s)% of 
the transaction contains B but does not contain A, the support 
of negative association rules A B¬ ?  is s,denoted as 
sup( A B¬ ? )=s. If the transaction does not contain A, there 
are (100 × c)% of the transaction contains B, the confidence 
of negative association rules A B¬ ?  is c, denoted as 
conf( A B¬ ? )=c. So the support and confidence of negative 
association rules A B? ¬ ? A B¬ ? ¬  can also be defined. 
Negative association rule discovery seeks rules of the 
form A B¬ ?  (or A B? ¬ ,or A B¬ ? ¬ ) with support and 
2010 Fifth International Conference on Internet Computing for Science and Engineering
978-0-7695-4339-0/10 $26.00 © 2010 IEEE
DOI 10.1109/ICICSE.2010.28
79102
confidence greater than, or equal to, user-specified minimum 
support (minsup) and minimum confidence (minconf) 
thresholds respectively, where A and B are frequent itemsets. 
In this paper,  introducting the minimum correlation theory, 
so it can reduce the production of the meaningless 
association rules. 
III. 2BALGORITHM DESIGN 
A. 4BConfidence  
With goods A?B, by sup(A) and sup(B) small (e.g. less 
than 5%), then sup(A ? B) is smaller , while the confidence 
( )conf A B?  may be large, may also be small, but 
( )conf A B¬ ? ¬ positive large. If the uniform rules for all 
the confidence bound, there will be such an embarrassing 
situation: If the less confidence, would be a lot of rules, the 
customer can not choose the genuine needs of the rules, even 
presence of a large A B¬ ? ¬  type rules are not necessarily 
meaningful; if confidence is greater, may miss many 
valuable positive association rules. Therefore, the best 
solution is to use different confidence thresholds, and we set 
two confidence thresholds, P_minconf and N_minconf. 
P_minconf show that the minimum confidence threshold of 
the rules A B?  and A B¬ ? ¬ ; N_minconf show that the 
minimum confidence threshold of the rules A B? ¬ and 
A B¬ ? . 
Property 1   
Let A I? , B I? , A B? = ?  then 
?sup( A¬ )=1 ? sup(A)  
?sup( A B¬ ? )=sup(B) ? sup( A B? ) 
?sup( A B? ¬ )=sup(A) ? sup( A B? ) 
?sup( A B¬ ? ¬ )=1 ? sup(A ) ?  sup(B)+ sup( A B? ) 
Property 2  Let A I? , B I? , A B? = ?  then 
conf( A B? ¬ )= sup( ) sup( )
sup( )
A A B
A
? ?  
=1 ( )conf A B? ?  
conf( A B¬ ? )= sup( ) sup( )
1 sup( )
B A B
A
? ?
?
   
1 sup( ) sup( ) sup( )( )
1 sup( )
A B A Bconf A B
A
? ? + ?
¬ ? ¬ =
?
 
=1 ( )conf A B? ¬ ?  
Where ( )conf X  as the confidence function, such as 
( )conf A B¬ ?  is the confidence of negative association 
rules A B¬ ? . 
The relationship between them as follows: 
(1) ( )conf A B? + ( )conf A B? ¬ =1 
(2) ( )conf A B¬ ? + ( )conf A B¬ ? ¬ =1 
Proof omitted. 
We can see from the above analysis, the two confidence 
P_minconf + N_minconf = 1 
B. 5BCorrelation  
Most association rules mining algorithms use the 
framework of support-confidence. Although it may exclude 
some meaningless rules, it still produce some rules which the 
users are not interested in. Suppose there are 10000 sales 
data items in the set , purchase of goods X denoted as the 
item A, purchase of goods Y denoted as the item B, purchase 
of X and Y denoted as item A ? B. Assume the purchase of 
goods X is 6000, purchase of goods is 5000, purchase of 
goods X and Y are 2500.Given minsup=0.2,minconf=0.3,then 
sup( )A B? =0.25>minsup, ( )conf A B? =0.42>minconf, so 
A B?  is a strong association rules. Then considering 
negative association rules A B? ¬ ,since sup(A ? B)=0.35 
>minsup, ( )conf A B? ¬ =0.58>minconf,therefore, A B? ¬  
also is strong association rules. This is in contradiction with 
the A B? , meanwhile, because of ( )conf A B? ¬  
> ( )conf A B? , so A B? ¬ should be more reliable. 
Because of ( )conf A B? =P(B?A)< ( )P B , the occurrence 
of A lead to probability B is decreased, so A and B should be 
a negative relation. For this, it introduced another measure of 
association rules - Correlation. The correlation of 
association rules show the relationship between the 
itemset.,through the correlation threshold, we can remove 
some meaningless  negative association rules. 
Definition 3.1  If ( ) ( ) ( )P A B P A P B? = ,then itemsets A 
and itemsets B are independent; Otherwise, itemsets A and 
itemsets B are correlated. 
The correlation of itemsets A and itemsets B:  
, sup( ) sup( )sup( )A Bcorr A B A B= ? ?  
Which ,A Bcorr is the correlation of itemsets A and B; 
sup(A ? B)?sup(A)?sup(B), respectively, the support of 
itemsets A ? B?A and B. 
There are three kinds of ,A Bcorr : 
If ,A Bcorr >0,then itemsets A and B is positive 
correlation;  
If ,A Bcorr <0,then itemsets A and B is negative 
correlation;  
If ,A Bcorr =0,then itemsets A and B is independent of 
each other. 
The correlation reflects the relationship between the 
itemsets A and B , when the correlation is equal to 0, 
indicating that two itemsets appear together does not have 
special meaning, namely, A and B are independent of each 
other, called the rules are not relevant rules; when the 
correlation less than 0, indicating that the possibility one of 
the itemsets would be decreased by another itemsets, Tcalled 
the rules are negative correlation rules;Twhen the correlation 
greater than 0, indicating that the possibility one of the 
itemsets would be increased by another itemsets, Tcalled the 
rules are positive correlation rulesT. 
Because of the meaning expressed by the three cases vary 
widely, according to the traditional rules generated by 
Apriori algorithm is no distinction for them, Tso some rules 
are contradictory or uninteresting 
80103
The paper [6] proposed that if a rules to meet sup(A ? B) 
? sup(A)sup(B)?0, then the rules are  no interesting, in 
other words, only the correlation of rules is greater than a 
certain threshold, the user will be interested in, Therefore, we 
set the minimum correlation threshold (mincorr), that only 
the association rules to meet sup(A ? B) ? sup(A)sup(B) 
? mincorr is our interest. mincorr specified by the user or 
expert. For the negative association rules, the value of  
sup(A ? B) ? sup(A)sup(B) may be less than 0, therefore, it 
need to join the absolute value on the left of the formula, that 
is, if A? B is interested in the rules, if and only if              
?sup(A ? B) ?  sup(A) sup(B)? ? mincorr. The following 
will discuss the relationship between the minimum 
correlation of four forms of association rules . 
Theorem 3.1  
 If?sup(A? B) ? sup(A)sup(B)?? mincorr, then  
(1)?sup( ¬ A? B) ? sup( ¬ A)sup(B)?? mincorr 
(2)?sup(A? ¬ B) ? sup(A)sup( ¬ B)?? mincorr 
(3)?sup( ¬ A? ¬ B) ? sup( ¬ A)sup( ¬ B)?? mincorr 
Proof.  (1)?sup( ¬ A? B) ? sup( ¬ A)sup(B)? 
=?sup(B)?sup(A?B) ?  (sup(B)?sup(A)sup(B))? 
=? ? sup(A?B)+sup(A)sup(B)? 
=?sup(A? B) ? sup(A)sup(B)?? mincorr 
(2), (3) for the same reason. 
The theorem show that select an appropriate minimum 
correlation can be prune to four association rules. 
C.  Algorithm Design 
In the PAR&NAR_Mining algorithm, assuming that the 
frequent itemsets have been obtained and saved in the set L. 
Input: frequent itemsets L, minimum confidence minconf, 
the minimum correlation mincorr; 
Output: positive association rules set of PAR, negative 
association rules set of NAR; 
PAR= ? ,NAR= ? ; 
For any frequent itemsets X in L do begin 
 For any itemsets A ? B=X and A ?  B= ?  do begin 
   If?sup(A ?  B) ? sup(A)sup(B)? ? mincorr do begin  
     If ,A Bcorr > 0 then begin   // Produce rules forms such 
as A? B and ¬ A? ¬ B 
        If conf(A? B) ? P_minconf  then 
           PAR=PAR ? {A? B}; 
        If conf( ¬ A? ¬ B) ? P_minconf  then 
           NAR=NAR ? { ¬ A? ¬ B}; 
     End; 
     If ,A Bcorr <0 then begin   // Produce rules forms such 
as A? ¬ B and ¬ A? B 
       If conf(A? ¬ B) ? N_minconf then 
          NAR=NAR ? {A? ¬ B}; 
       If conf( ¬ A? B) ? N_minconf then 
          NAR=NAR ? { ¬ A? B}; 
     End; 
   End; 
 End; 
End; 
Return PAR and NAR; 
The algorithm to generate Tpositive Tassociation rules set 
PAR and negative association rules set NAR. PAR and NAR 
is initialized to empty set. First, check ? sup(A ?  B) 
? sup(A)sup(B) ? , whether to meet the minimum 
correlation, and then, determine its relevance based on 
,A Bcorr ,and generate rules. Which, if A and B are positive 
correlation, production rules of the form A ? B and 
¬ A? ¬ B; if A and B are negative correlation, production 
rules of the form ¬ A? B and A? ¬ B. Finally back to 
PAR and NAR, and end of the algorithm. 
IV. 3BALGORITHM ANALYSIS 
Let n Tfrequent items in L, T Tfrequent itemsets X contains 
two frequent item, T Twhere X T ? T L? TA ? B=X and A ?  B=
?, Tthere are T 2nc T frequent itemsets X in L, T Teach X requires 
two comparative analysis, T so Tthe operation frequencyT of the 
aTlgorithm is T2* 2nc =n(n-1)T , T Tthat is the time complexity 
is TO(n P2P).T he TToperation frequencyTT of Apriori algorithm also 
reached the square level ,or even higher.T T herefore, in 
theory, the algorithm is feasible and effective. 
T o illustrate the algorithm efficiency and accuracy,T Tin the 
same experimental conditions,T Tto achieve PAR&NAR_ 
Mining algorithm and the positive and negative association 
rules mining algorithm in [7],T Tand using the same 
experimental data set to analyze and compare the 
performance of the algorithm.T  
T his experimental platform is the Intel (R) P4 dual-core 
processor, 1.5G RAM, WindowsXP operating system, 
programming language is JAVA, programming environment 
is JBuilder2006. Data set used in the experiments is the 
social security audit data set, which is a real data set. 
T here are two comparison for the experiments:T  
a) TPositive and negative association rules mining 
algorithm in  [7];  
b) T7BPAR&NAR_Mining algorithm based on TTcorrelation 
and dual confidence thresholdsTT. T  
Given minsupp=0.2,P_minconf=0.2,N_minconf=0.8T. T Tthe 
comparison results shown in Figure 1?2. 
0
1000
2000
3000
4000
5000
40% 35% 30% 25% 20% 15% 10%
minimum correlation
th
e
 
nu
m
be
r 
o
f A
R
 
 
the algorithm in literature[7]
the algorithm of PAR&NAR-Mining
 
Figure 1.  The number of AR change as minimum correlation 
As can be seen from Figure 1, the number of association 
rules generated by PAR&NAR_Mining algorithm is 
81104
significantly less than [7], this is because the algorithm 
introduction of the minimum correlation and double 
confidence theory, filter out the association rules  of 
meaningless, allowing the rules to become more objective 
and reasonable. 
0
200
400
600
800
1000
40% 35% 30% 25% 20% 15% 10%
minimum correlation
th
e 
ru
nt
im
e(s
)
 
 
the algorithm in literature[7]
the algorithm of PAR&NAR-Mining
 
Figure 2.  The runtime change of algorithems as minimum correlation 
TAs can be seen from Figure 2, PAR& NAR_Mining 
algorithm execution time is much better than [7] .TT hese 
experiments fully demonstrate that the algorithm is effective. 
V. TCONCLUSION 
TSince the topic of association rules mining proposed,T Thas 
proposed a number of association rules mining algorithm, 
but can be used for negative association rules mining are 
few. T T his paper TpresentsT a both positive and negative 
association rules mining algorithm based on relevance and 
confidence , TTexperiments show that the algorithm is effective 
and feasible.T TIn addition, this paper only discusses the 
problem of mining TTpositive and TT negative association rules, 
in the future, we will study the following two aspects: 
a) T8B o improve the efficiency of the algorithmT. 
b)  TDepth study of the issue of its updatedT . 
10BACKNOWLEDGMENT 
This work is sponsored by the National Natural Science 
Foundation of China under grant number 60873038, the 
Fundamental Research Funds for the Central Universities of 
China under grant number HEUCF100603 and the National 
Science & Technology Pillar Program under grant number 
2009BAH42B02. 
11BREFERENCES 
[1] Agrawal R,Imielinski T,Swami A, “Mining Association Rules 
between Sets of Items in Large Databases, ”In:Proc of the ACM 
SIGMOD International conference on Management of 
Data,Washington DC,1993,pp,207-216. 
[2] Agrawal R,Srikant R, “Fast algorithms for mining association rule, 
”In:Proe.20th Int. Conf.on VLDB.Santiago,Chile,1994,pp,487-499. 
[3] Mojdeh Jalali-Heravi, Osmar R. Zaïane, “A Study on Interestingness 
Measures for Associative Classifiers, ” TProceedings of the 2010 ACM 
Symposium on Applied Computing,2010,pp,T1039-1046. 
[4] He Jiang, Yuanyuan Zhao, Chunhua Yang, Xiangjun Dong, “Mining 
Both Positive and Negative Weighted Association Rules with 
Multiple Minimum Supports,” 2008 International Conference on 
Computer Science and Software Engineering,2008,pp,407-410. 
[5] Ling Zhou, Stephen Yau, “Association Rule and Quantitative 
Association Rule Mining among Infrequent Items,” Proceedings of 
the 8th international workshop on Multimedia data mining: associated 
with the ACM SIGKDD 2007. 
[6] HLiqiang GengH, H oward J.HamiltonH ,“Interestingness measures for data 
mining: A survey.” ACM Computing Surveys ,2006,pp,1-32. 
[7] SHANG Shi-ju,DONG Xiang-jun,LI Jie, “Algorithms for mining 
negative association rules in multi-database, ”Computer Engineering 
and Applications,2009,45(24),pp,150-152. 
 
 
 
82105
