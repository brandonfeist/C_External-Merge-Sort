An Association Rule Algorithm Generated By 
Minimal Head-Item Set  
Based On Set-Enumeration Tree *
Qing Wei 
School of Computer and 
Information Engineering, 
 Henan University of 
Finance and Economics, 
HNUFE 
Zhengzhou City, China 
weiqing.hnufe@gmail.com  
Li Ma 
Department of Information 
Technology Engineering, 
Yellow River Conservancy 
Technical Institute 
Kaifeng City, China 
Songyang Ding 
School of Computer and 
Information Engineering, 
 Henan University of 
Finance and Economics, 
HNUFE 
Zhengzhou City, China 
Huichao Mi 
School of Computer and 
Information Engineering, 
 Henan University of 
Finance and Economics, 
HNUFE 
Zhengzhou City, China
Abstract—A lot of association rules may be generated in the 
process of association rules mining?and much time may be 
wasted when a user analyzes the association rules. To solve this 
problem, an improved algorithm which based on the set-
enumeration tree for mining the association rules is introduced; 
and the algorithm reduces the number of association rules 
remarkably and generates a subset of association rules without 
any information loss. The number of association rules is 
decreased very much, so the space consumption in rules’ storage 
will be declined greatly, and the efficiency of analysis for 
association rules will be enhanced. ?
Keywords- frequent itemset ; association rule ; head-item set ; 
set-enumeration ; key rule   
I. INTRODUCTION
Association rule is a very important branch in the area of 
data mining. The mining of association rule is implemented by 
two steps, the first one is mining the frequent items; the second 
one is generating association rules that meet the condition of 
min-confidence (mc) [1-3]. The first step is usually the core 
step in the mining process of association rules, and the 
efficiency of data mining is affected mainly by finding of 
frequent item.    
In experience, there are a great number of association rules 
that generated via frequent items. For instance, there are more 
than 10 thousands of association rules results in one mining 
case on medical treatment, therefore, users have to spend a 
great deal of time on analyzing so many rules if they want to 
analyze an association relation on an illnesses case,  that 
means, it waste not only  time but also space. Actually, it is not 
necessary to generate all the rules, on the contrary, it is enough 
for us to generate some key rules only, which contain all the 
others information, that is to say, those key association rules 
are able to deduce all rules without any data loss.  
                                                          
* Supported by the Fund of Program for Tackling Key Problems in 
Science and Technology of the Department of Science and 
Technology of Henan Government (Grant No. 072102210066). 
GRSET is a kind of algorithm based on set-enumeration, 
its function is to generate all the association rules which based 
on one frequent item, and this method generates large numbers 
of association rules. For example, in table 1, the item I3I2I8I5 
is frequent item because it meets the condition of min-
confidence (mc) and min-support (ms). And according to 
GRSET algorithm, only one frequent item generates 10 
association rules, they are        
{I5?I3I2I8 ? I3I2?I8I5? I2I8?I3I5? I2I5?I3I8?
I3I5?I2I8 ? I8I5?I3I2 ? I3I2I8?I5 ? I3I2I5?I8 ?
I3I8I5?I2?I2I8I5?I3}. 
But in fact, it is a huge waste to generate so many rules. 
Each expression is a rule, and here, we call the string before 
the “?? a head-item, and the string after the “?? a tail-
item. For example, in the second line of the set, 'I3I2?I8I5', 
we call I3, I2 the head-item of the rule 'I3I2?I5I8', and I5, I8 
the tail-item of the rule 'I3I2?I5I8'.[4] Therefore, the whole 
set 
{I3I5?I2I8 ? I2I5?I3I8? I8I5?I3I2? I3I2I8?I5?
I3I2I5?I8?I3I8I5?I2?I2I8I5?I3}                                 (1) 
can be deduced by a set only includes 3 rules via a tail-to-head 
method , the set is  
{I5?I3I2I8 ?I3I2?I8I5? I2I8?I3I5}                        (2) 
For instance, the rule 'I5?I3I2I8',  'I5I3?I2I8' can be 
obtained via moving I3 to head; and 'I3I8I5?I2' can be 
obtained via moving I3,I8. So, it is not difficult to find that all 
the rules in (1) can be deduced by its subset (2). 
That indicates that no information will be lost in the 
moving process, and any rule in (1) is implied in the subset 
(key rules set).   
GSHS (Generate Subset of the Head-item Set) algorithm 
introduced in this paper is to reduce the number of association 
rules without any data loss, so as to save more storage 
consumption and time for analysis. 
978-1-4244-4994-1/09/$25.00 ©2009 IEEE
II. CONCEPTS AND THEOREMS
Some new concepts, theorems and symbols are introduced 
here to make it easy to explain the new algorithm, besides, we 
also inherit some concepts in GRSET algorithm in [1].    
Definition 1 The support of itemset A is denoted as sup (a), 
which means the number of transactions that include the 
itemset. Take quasi association rule [4] c? (l-c) as an 
example, l is a frequent itemset, and c is the subset of l.   
Definition 2 If quasi association rules c? (1-c) meets the 
condition of the min-confidence.  
Theorem 1 If itemset C is the subset of itemset D, then 
sup(c)?sup(d). 
Theorem 2 If quasi association rule c? (l-c) meets the 
condition of min-confidence (mc), then all the quasi 
association rules that head-item include C and be the subset of 
L meets the condition of mc. 
Proof: Let c be a proper subset d, and d is the subset of l, if 
c? (l-c) is true, then association rule d??l-d?is true.
?c??l-c?is true,?sup(l)/sup(c) ? mc, and because c 
is the proper subset of d, ? sup? c?? sup? d? , ?
sup(l)/sup(d) ?mc, ?quasi association rule d??l-d?is true 
too. QED. 
Therefore, by the theorem 2, given a frequent itemset l, if 
one of its proper subset c, as a head-item, meets the condition 
of association rule c? (l-c), then for any itemset d, which is 
the subset of l and includes c, as a head-item, meets the 
condition of association rule d? (l-d).  
By the property of Theorem 1 and 2, given an association 
rule, if move some tail-items to head-items, then the new quasi 
association rules meet the condition of mc. For example, let 
“abcde” be a frequent itemset, if ab?cde meets the condition 
of mc, and move the tail-item c to head, then the new 
association rule abc?de meet the condition of mc as well. 
Given a frequent itemset l, x denotes the head-item of quasi 
association rules that generated by l, if quasi association rule 
x? (l-x) is tenable, then sup(l)/sup(x) ?mc, namely  sup(x)?
sup(l)/mc. According to the analysis above, the problem to find 
the head-item that makes the association rules which generated 
by frequent itemset l tenable, in fact, is the problem to find the 
subset of item set? sub-item set for short? whose support is 
less than or equal to sup(l)/mc according to theorem 1 and 2. 
Therefore, in the process of finding the sub-itemset, if the 
support of a certain sub-itemset less than or equal to sup 
(l)/mc, then it is not necessary to judge whether the support of 
the superset of sub-itemset meets the condition. However, if 
the support of the sub-itemset is bigger than sup (l)/mc, it is 
still necessary to judge the support of the superset of the sub-
itemset by depth first algorithm.  
Example 1: in table 1, I3I2I8I5 is a frequent itemset, and its 
support is 9, because mc=80%, the condition meet 
x?I3I2I5I8-x is just sup(x)? sup(l)/mc, and sup(l)/mc = 
9/80% = 11.5. So sup(x) ?11.5 is necessary and sufficient 
condition in this case.    
The GSHS algorithm in this paper is based on the theorem 
1 and 2, and its main idea is: firstly, generates the subset of the  
head-item set that makes quasi association rules that generated 
by frequent itemset l tenable; and secondly, adds the subset of 
the head-item set to the Subset of the Head-item Set (SHS ). 
III. GENERATE SUBSET OF THE HEAD-ITEM SET 
ALGORITHM
GSHS is acronyms of Generate Subset of the Head-item 
Set, and it is a recursive algorithm for the function of 
generating a minimal expression-a subset of the head-itemset. 
Algorithm 1 GSHS 
Input: frequent itemset l, min-confidence mc; 
Output: Subset of the Head-item Set (SHS) of association 
rules  
Method:   
?1? m=||l|| 
?2? SHS=?;
?3? get SHS ??;
procedure getSHS(h?s) 
Parameters:  
  H: substring of l, the quasi association rule with the head-
item h, and the rule meets the condition of mc. 
  S: the beginning location to be connected in l, and p (l, 
h[||h||])+1? s? m. 
  Method: 
?1? n=||h||; 
?2? if n < m-1; 
?3?   if sup (h+l[s])? sup (l)/mc 
?4?     if (! (Superset Check (SHS, h+l[s]) then 
?5?        SHS=SHS ? {h+l[s]} 
?6?      else SHS=SHS ? {SuperSet of h+l[s]}-
{h+l[s] } 
?7?   else { 
?8?         j=s, 
?9?         h=h+l[s] 
?10?        do  
?11?         j=j+1 
?12?        while sup (h+l[j]) > sup (l)/mc 
?13?           if (! (Superset Check (SHS, h+l[j])) 
?14?             SHS=SHS ? {h+l[s]} 
?15?            else SHS=SHS ? {SuperSet of 
h+l[s]}-{h+l[s]  
?16? }  
Procedure supsetcheck(SHS, a) 
Parameters:  
  SHS: Subset of the Head-item Set 
  A: an itemset found just recently 
  Method: 
(1) If   Superset (a)?SHS 
(2)   { 
(3)     Sus=Superset (a); 
(4)     Prune (sus) according to Theorem 1, 2; 
(5)     Return 1; 
(6)    } 
(7) Else 
(8)   Return 0 
Explanation: In the line 4,5,6,13,14,15 of algorithm GSHS, 
the Superset Check(SHS, a) is run because if the sub-itemset in 
a certain recursive procedure meets the condition of sup(x) ?
sup(l)/mc, it needs to judge whether SHS has superset, if it is 
true, then the superset will be pruned according to Theorem 1 
and 2, and at the same time, adds the new head-item to the set 
SHS, and a new set SHS will be obtained. 
IV. EXAMPLE AND ANALYSIS
Example 2
Given a data set, table 1, 
Let ms=50%?mc=80%. Sup (I3I2I8I5) =9. 
Question: output the minimal expression of association rules 
generated by frequent item sets f=I3I2I8I5.  
The mining process is as follows?
TABLE I. TRANSACTIONAL DATA SET
TID          Item 
T1 I1I2I3I4I5I7I8 
T2 I2I3I5I6I7I8 
T3 I3I4I6 
T4 I1I2I3I4I5I6I7I8 
T5 I1I2I3I5I6I7I8 
T6 I1I3I4I5I7I8 
T7 I2I3I4I6I7I8 
T8 I1I2I3I5I6I8 
T9 I1I2I3I4I5I6I7I8 
T10 I3I5I7I8 
T11 I1I2I4I6 
T12 I1I2I4I6 
T13 I3I4I7 
T14 I1I2I3I4I5I6I7I8 
T15 I2I3I4I5I6I7I8 
T16 I2I3I5I6I8 
(1) m=4 
(2) SHS=?
(3) Sup(f)/mc=11  
(4) Sup(I3)=14 > 11 
(5) Sup(I3I2)=10 < 11 SHS= SHS ? {I3I2}={I3,I2} 
(6) Sup(I3I8)=12 > 11 
(7) Sup(I3I8I5)=11 ?  11 SHS= SHS ? { 
I3I8I5}={I3I2,I3I8I5} 
(8) Sup(I3I5)=11 ?  11  SHS= SHS ? { I3I5}-
{I3I8I5}={I3I2,I3I5} 
(9) Sup(I2)=12 > 11 
(10)Sup(I2I8)=10 ?  11 SHS= SHS ? { 
I2I8}={I3I2,I3I5,I2I8} 
(11)Sup(I2I5)=9  < 11 SHS= SHS ? { 
I2I5}={I3I2,I3I5,I2I8,I2I5} 
(12)Sup(I8)=12 > 11 
(13)Sup(I8I5)=11 ? 11 SHS= SHS ? { 
I8I5}={I3I2,I3I5,I2I8,I2I5,I8I5} 
(14)Sup(I5)=11 ? 11  
(15)SHS=SHS?{I5}-{I3I5,I2I5,I8I5} ={I3I2,I2I8,I5} 
(16)According to GSHS, the subset {I3I2,I2I8,I5} of 
head-item set of association rule can be generated via 
the frequent itemset I3I2I8I5, and the association 
rules with the head-items in {I3I2,I2I8,I5} are  { 
I3I2?I8I5?I2I8?I3I5 ?I5?I3I2I8}. 
Algorithm analysis 
In example 2, in regard to the frequent itemset {I3I2I8I5}, 
if by GRSET algorithm, then all the 10 association rules 
should be generated, namely  
{I5?I3I2I8 ?I3I2?I5I8? I3I5?I2I8 ?I2I8?I3I5?
I2I5?I3I8 ?  I8I5?I3I2 ? I3I2I8?I5 ? I3I2I5?I8 ?
I3I8I5?I2?I2I8I5?I3}. 
So as to the whole database, the number of association 
rules will be huge, and the consumption of time, space and 
power will be enormous. 
However, the GSHS algorithm here just generates 3 rules 
with head-item in set {I3I2?I2I8?I5}, the rules are  
 {I3I2?I8I5?I2I8?I3I5 ?I5?I3I2I8}, 
and other 7 rules generated by I3I2I8I5 in GRSET can be 
obtained by moving tail-items to head-items via the 3 rules 
above. For example, 2 rules {I3I2I8?I5?I3I2I5?I8} can be 
obtained by tail-to-head method based on rule I3I2?I8I5; and 
{I2I8I3?I5, I2I8I5?I3} can be deduced by I2I8?I3I5; and 
rules 
{I5I3?I2I8? I5I2?I3I8?  I5I8?I3I2? I5I3I2?I8?
I5I3I8?I2?I5I2I8?I3} can also be deduced by I5?I3I2I8. 
So it is not difficult to find that the 3 key rules 
{I3I2?I8I5? I2I8?I3I5 ? I5?I3I2I8} implies totally all 
other 7 rules without any data loss. 
A Hasse diagram, Fig.1, is able to indicate the structure of 
Boolean associationrules set [5] thatgenerated by the 
frequent itemset I3I2I8I5, the first line in brackets indicates 
the head-items of association rules, and the second line in 
brackets means the tail-items of association rules. It is not  
Figure 1. Hasse diagram
difficult to get a conclusion that the association rules with 
head-items {I3I2?I2I8?I5} constitute the maximal element 
in Fig.1. 
V. PERFORMANCE ANALYSIS
The performance of the GSHS algorithm was tested 
comparing with the GREST and Apriori algorithm with the 
same data set. The algorithm is implemented by Java, and the 
running environment mainly includes: a CPU of P4 2.0GHz, 
storage memory of 1.0G and the Windows XP system. We 
have tested the number of rules that generated via GRSET 
algorithm and GSHS algorithm respectively, the data set used 
in this case are shown in table 1. 
Let ms=50% ,and mc=80%, then Table1 and Fig.2 show 
the number of rules in GRSET and GSHS algorithm for the 
data in Table 1. 
As it shown from the experimental results in Table 2 and 
Fig.2, for the same dataset and the minimum support 
threshold, the number of the key rules generated by GSHS 
TABLE II. NUMBER OF ASSOCIATION RULES
 Apriori GRSET GSHS 
Number of 
Rules 258 140 86 
1XPEHURI$VVRFLDWLRQ5XOHV







$SULRUL *56(7 *6+6
$OJRULWKP1DPH
1X
PE
HU
R
I
5X
OH
V
1XPEHURI5XOHV
Figure 2. Number of Association Rules
algorithm are much less than the rules that generated by 
GRSET algorithm, so the storage usage are decreased than 
that of GRSET, the GSHS algorithm almost saves 40% 
storage consumption compared with the GRSET, and saves 
66% space to Apriori. Therefore, the experiment indicates that 
the GSHS algorithm is more effective in saving storage 
consumption than the GRSET and Apriori algorithm. 
VI. CONLUSIONS
In this paper, a new algorithm named GSHS is introduced; 
it only generates some key rules of association rules 
comparing with GRSET algorithm. It is shown on theory and 
experiments that GSHS has three advantages. Firstly, the key 
rules generated by GSHS are much less than that generated by 
GRSET, it can save more space consumption for user. 
Secondly, the subset built by key rules is a maximal element 
of all association rules which generated by the same frequent 
itemset, so it implies all the rules. Thirdly, the key rules can 
deduce all the association rules base on the same frequent 
itemset without any information loss.    
Because the property of frequent closed itemset is helpful 
for reducing the number of redundant rules in the process of 
generating the association rules, the studies on generating 
association rules based on frequent closed itemset will be 
carried out. 
ACKNOWLEDGMENT 
The authors are grateful to the referee for their valuable 
comments and suggestions. This work has been supported by 
the Supported by the Fund of Program for Tackling Key 
Problems in Science and Technology of the Department of 
Science and Technology of Henan Government. (Grant No. 
072102210066).  
REFERENCES
[1] R Agrawal , Mannila H , Srikant R , et al Fast discovery rules[A]. 
Fayyad U. Advances in Knowledge Discovery and Data Mining [C]. 
Menlo Park: AAA I Press , 1996 307-328. 
[2] Cercone V , Tsuchiya M. Luesy editor’s introduction [J] . IEEE 
Transaction on Knowledge and Data Engineering , 1993 , 5(6) : 901-
902. 
[3] Brin S , Motwani R , Ullman J, etal Dynamic itemset counting and 
implication rules for market basket data[EB/OL] . http:// citeseer . 
njnec.com/ brin97dynamic html, 1999-05-23/2002-05-09 .  
[4] Kun Wu, Baoqing Jiang, Qing Wei. A Depth-First Algorithm of Finding 
All Association Rules Generated By A Frequent Itemset. 2006 
International Conference on Intelligent Systems And Knowledge 
Engineering, April 6-7,2006, Shanghai, China. 
[5] Jiang Baoqing, Li Jian, Xu Yang. A Structure of Boolean Association 
Rules Set (in Chinese). Natrual Science Edition, Journals of Henan 
University. 2006?36(1):88-90. 
[6] Pasquier N, Bastide Y, Taouil R , etal Discovering frequent closed 
itmesets for association rules [EB/OL] . http: // citeseer. Njnec.com / 
pasquier99 discovering html, 1999-11-23/2002-04-18. 
[7] J.-W. Han and M. Kamber, Data mining concepts and techniques, First 
edition, Beijing: Higher Education Press,2001. 
[8] X.-F. Li and J. Li, Data mining and knowledge discovery (in Chinese), 
Fist Edition, Beijing: Higher Education Press, 2003. 
[9] Y.-J. Yan, Z.-J. Li, and H.-W. Chen, Frequent item sets mining 
algorithms (in Chinese), Computer Science, 2004, 112-114. 
