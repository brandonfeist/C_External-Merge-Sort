I-FAC: Efficient Fuzzy Associative Classifier for Object Classes in Images
Ashish Mangalampalli1
1IIIT, Hyderabad, India
ashish m@research.iiit.ac.in
Vineet Chaoji2 Subhajit Sanyal2
2Yahoo! Labs, Bangalore, India
{chaojv, subhajit}@yahoo-inc.com
Abstract
We present I-FAC, a novel fuzzy associative classifica-
tion algorithm for object class detection in images using
interest points. In object class detection, the negative class
CN is generally vague (CN = U ? CP ; where U and
CP are the universal and positive classes respectively).
But, image classification necessarily requires both posi-
tive and negative classes for training. I-FAC is a single-
class image classifier that relies only on the positive class
for training. Because of its fuzzy nature, I-FAC also han-
dles polysemy and synonymy (common problems in most
crisp (non-fuzzy) image classifiers) very well. As asso-
ciative classification leverages frequent patterns mined
from a given dataset, its performance as adjudged from its
false-positive-rate(FPR)-versus-recall curve is very good,
especially at lower FPRs when its recall is even better. I-
FAC has the added advantage that the rules used for clas-
sification have clear semantics, and can be comprehended
easily, unlike other classifiers, such as SVM, which act as
black-boxes. From an empirical perspective (on standard
public datasets), the performance of I-FAC is much better,
especially at lower FPRs, than that of either bag-of-words
(BOW) or SVM (both using interest points).
1. Introduction
Association Rule Mining (ARM) enables the extraction
of latent frequent patterns which are based on their respec-
tive frequencies, and thus represent the dominant trends in
the given dataset. A new classification approach called
associative classification [12], [13], [14] has gained pop-
ularity of late, because of its accuracy, which can be at-
tributed to its ability to mine huge amounts of data in order
to build a classifier based on frequent patterns in a dataset.
The advantages of associative classifiers are that frequent
itemsets capture all dominant relationships between items
in a dataset, and that they deal only with statistically sig-
nificant associations. Thus, the classification framework
is robust because low-frequency patterns (noise) are elim-
inated during the ARM stage. But associative classifica-
tion, like many other classifiers, cannot be used directly on
datasets and domains which make heavy use of numerical
attributes (like image classification), as it expects categori-
cal/binary attributes. One method to circumvent this prob-
lem is to use binning or clustering to convert numerical
attributes to categorical attributes. But using crisp binning
or crisp clustering introduces uncertainty especially at the
boundaries of bins or clusters, leading to loss of informa-
tion. Small changes in the selection of number of bins or
clusters may lead to polysemy (one bin or cluster contain-
ing features with different meanings) and synonymy (two
features with same meaning mapped into different bins or
clusters), thus generating misleading results. A more ef-
fective way to solve this problem is having features be-
long to clusters with some membership value in the in-
terval [0, 1], instead of belonging entirely to a particular
cluster. Thus, fuzzy features replace categorical ones.
In this paper we present our algorithm I-FAC which
adapts fuzzy associative classification to fit the image clas-
sification perspective, by leveraging Speeded-Up Robust
Features (SURF) that can be extracted from images [1].
SURF is a fast scale and rotation-invariant interest point
detector and descriptor for images. These interest points
which can vary in number from image to image, can be
used for further processing, like clustering and classifica-
tion. Generally, obtaining the negative class set CN is an
issue in image classification due to its ill-defined nature as
compared to the positive class CP . Effectively, the nega-
tive class set CN = U ? CP , where U is the universal set
of all images. But, conventional classifiers need both pos-
itive and negative classes for training. Because CN is not
well-defined, classifiers so trained (on a subset of the neg-
ative class) may not perform well on disparate test images.
The advantage of I-FAC is that only positive class samples
are required to train the classifier, with no reliance on neg-
ative class samples for training and without the need for
unlabelled examples or outliers. In the literature, one-class
classifiers which rely on unlabelled examples [6] or treat
outliers and noise as negative examples for training [7],
have been proposed.
In the bag-of-words (BOW) approach, each SURF
point belongs only to one of the clusters in the code-
book, which is created by applying crisp clustering (like
k-means) on a sizeable set of images. Using fewer num-
ber of clusters would avoid synonymy, but would at the
same time give rise to polysemy. Thus, in BOW deciding
upon the number of clusters that should be used is an im-
portant but difficult task, because of which ?1000-3000
are generally used. But, I-FAC relies on fuzzy c-means
(FCM) clustering [5] and creates far less number of clus-
ters (?100) using only the positive class training images,
as compared to the number of clusters used for the code-
book in BOW, thus avoiding synonymy. Due to the fuzzy
nature of clusters, it is able to address polysemy as well.
The main contributions of this work are – a) use of
fuzzy sets and logic in object class classification in im-
2010 International Conference on Pattern Recognition
1051-4651/10 $26.00 © 2010 IEEE
DOI 10.1109/ICPR.2010.1067
43729688
c1 ? µ1,1, c2 ? µ1,2, . . . , ck ? µ1,k, positive class label
. . .
c1 ? µn,1, c2 ? µn,2, . . . , ck ? µn,k, positive class label
Figure 1. Fuzzy-cluster based representation
ages. By doing so we can deal with polysemy and syn-
onymy better as compared to crisp sets. This is reflected in
the experiments section (Section 4 where usage of fuzzy
sets yields better results than obtained using crisp sets, b)
I-FAC is an associative classifier, which relies on frequent
itemsets. Frequent itemsets capture all dominant relation-
ships between items in a dataset. This helps in making the
algorithm more resilient to noise.
2. Related Work
[9] and [10] describe the application of ARM in de-
tecting features in images and videos respectively, with
the help of spatial configurations and local neighborhoods.
The video mining method proposed in [11] builds on local
neighborhoods of quantized local features. [3] is based on
the bag-of-words approach for generic visual categoriza-
tion.
3. I-FAC and Image Classification
This section describes key components of I-FAC for
image classification. SURF points extracted from CP
are clustered using FCM clustering, followed by fuzzy
ARM. The fuzzy association rules are then transformed
into fuzzy classification rules during training. For actual
classification, membership values for the SURF points ex-
tracted from a test image are interpolated (using cosine-
similarity) with the centers of the fuzzy clusters gener-
ated previously in the training phase. The classification
is then done by calculating the cumulative fuzzy informa-
tion gain, in conjunction with a threshold ?.
3.1. SURF Point Generation
The first step in I-FAC extracts SURF points from im-
ages in the positive class training dataset, with no nega-
tive class images being used. Assuming we need k fuzzy
clusters, we run FCM (cosine distance metric is used) on
all the n SURF points extracted from the training im-
ages. From the k fuzzy clusters, for each SURF point
we have its membership value (µ) in each of the k fuzzy
clusters. The k membership values for each SURF point
are then used to transform SURF-point-based representa-
tion of the images into a fuzzy-cluster-based representa-
tion. Each SURF point is represented as a separate record,
with each record consisting of k cluster (attribute) ids and
corresponding µ pairs <cluster id, µ>, followed by the
positive class label, as shown in Figure 1.
3.2. Fuzzy Association Rule Mining
Subsequently we use the fuzzy ARM algorithm (with
appropriate minimum support) described in [8] to extract
latent patterns in the form of fuzzy association rules from
the fuzzy-cluster-based representation of the SURF points,
as shown in Fig. 1. This algorithm is optimized to ex-
tract rules from very large datasets having many attributes
(high dimensions), which is common in the image domain.
The support supp(I) of an itemset I , in the crisp domain,
is defined as the proportion of transactions in the dataset
which contain I . During fuzzy ARM, each of the k dimen-
sions corresponding to k clusters is taken as an attribute.
The membership values of a SURF point in each of the k
clusters provide the values for these k attributes (Fig. 1).
Moreover, support, as defined for crisp association rules,
has been generalized in a suitable way for the fuzzy envi-
ronment [2], [4]. A t-norm T , given by Eq. 1, satisfies the
condition T (x, 1) = x,?x ? [0, 1], with fuzzy sets A and
B (in a finite universe D) lying in the range [0, 1]. The
cardinality of a fuzzy set in D is defined by Eq. 2. Using
Equations 1 and 2, we get fuzzy support, defined in Eq. 3.
TM (min) t-norm, the most popular t-norm, has been used
in I-FAC to derive the rule-set R (with m? rules) from the
fuzzy-cluster-based representation of SURF points.
A(x) ?T B(x) = T (A(x), B(x)) (1)
| A |=
?
x?D
A(x) (2)
sup(A? B) =
1
| X |
?
x?D
(A ?T B)(x) (3)
H(Y ) = ?
z?
i=0
pi log pi (4)
H(Y | X) =
?
Prob(X)H(Y | X) (5)
IG(Y | X) = H(Y )?H(Y | X) (6)
3.3. Fuzzy Associative Classifier Training
Entropy and information gain are calculated for each
rule in the rule set R. Given a rule of the form X ? Yi,
where X is an itemset composed of varying number of at-
tributes a1, a2, . . . , al, the entropy of X is given by Eq. 4,
where z is the number of classes being considered. Yi is
the class label pertaining to the rule. In the crisp case, the
fraction of records in the dataset where Yi occurs is de-
noted by pi. But, in the fuzzy case, pi of Yi is calculated
by taking the maximum membership value among all at-
tributes (clusters) in each record in which Yi exists. The
average conditional entropy H(Y |X) for Y , with respect
to X , is given by Eq. 5. In the fuzzy case, H(Y |X) is
calculated using a t-norm (TM t-norm in this case). The
frequency for each record involving Y is a function of the
43739789
minimum membership value of all attributes (fuzzy clus-
ters) a1, a2, . . . , al that are involved in X . The informa-
tion gain IG(Y |X) is given by Eq. 6.
ARM generates a large number of rules, most of which
are redundant, and are pruned by I-FAC. The information
gain of each rule and rule length i.e. number of attributes
in each rule, is used for the pruning process. Each rule rq
is compared to all rq+1 to r?m rules. A given rule rq (with
information gain IGq and rule length rlq) is pruned (R =
R ? rq) if there exists another rule rs (with information
gain IGs and rule length rls) which is a superset of rq,
and rlq < rls and IGq < IGs. After pruning, the size of
R reduces from m? to m??.
3.4. Image Classification
The actual classification stage is relatively straightfor-
ward, and is dependent upon the rule set R derived in the
training stage. But before that, we identify all the n? SURF
points in the image being classified. The centers of the k
clusters generated during the training phase are used to
calculate the fuzzy membership of each of the n? SURF
points in each of the k clusters. For each SURF point
s, cosine similarity values are calculated between s and
each of the k cluster centers. The normalized similarity
between each cluster center c and s is denoted as fuzzy
membership value µsc. Similar procedure is followed for
all the n? SURF points, at the end of which we have a
record (in fuzzy cluster format representation) for each of
the n? SURF points. The membership value µij for each
cluster ci in each of the n? records is aggregated to get one
record cr with cumulative membership values in each of
the k clusters of the whole image (Eq. 7).
Then, each rule r in the rule set R (with m?? rules) is
applied to this cumulative record cr. When r is applied,
we identify each of the t attributes (clusters) that are a part
of the precedent (right hand side of the rule) of r. The
cumulative fuzzy membership value (cµ) for each of these
t clusters is extracted from cr. The product (Eq. 8) of
the arithmetic mean of these cumulative fuzzy member-
ship values and the information gain (IG) associated with
r is used to come up with a derived metric we call fuzzy
information gain (FIG). The cumulative fuzzy informa-
tion gain is calculated (Eq. 9) as each rule is applied on
cr. If at the end cumulative FIG ? threshold ?, then
the image in question belongs to the positive class, or else
it belongs to the negative class.
µi =
n?
j=1
µij where i = 1 to k (7)
FIG =
?
(IG)
(?t
i=1 cµi
t
) (8)
cumulative FIG =
m???
f=1
FIGf (9)
4. Performance Study and Results
We have compared I-FAC (with minimum support
supp between 0.005 and 0.05, depending on dataset,
fuzzification factor m = 1.5 and 100 fuzzy clusters) to two
baseline approaches, namely BOW and SVM, both based
on SURF points. The support value relies on how dense
or sparse the dataset is, the number of items (singletons)
involved in the dataset, and the average length of transac-
tions in the dataset ( [15]). In BOW, we count how many
times each visual word in the code-book occurs in an im-
age. A feature vector consisting of weighted frequency
of each ‘word’ from the bag of words is used for training
and testing. The results for BOW have been taken from
the baseline of [10], which uses 3000 clusters to create
the code-book. To generate a single feature vector per im-
age for SVM (libSVM implementation using RBF ker-
nel) classification, SURF points from an image are com-
bined using Latent Semantic Hashing. FPR-versus-recall
for SVM was calculated using a threshold for the probabil-
ity of positive class. CALTECH Cars (Rear) background
dataset was used as negative training set for BOW and
SVM. I-FAC does not expect any negative class training
set. The other datasets used are:
CALTECH Cars Rear: The positive class training, posi-
tive class test, and negative class test datasets respectively
are cars markus, cars brad, and the first 200 images from
CALTECH-101 background class.
TUD Motorbikes: CALTECH-4 motorbikes, TUD mo-
torbikes, and 200 random images from CALTECH-256
clutter class were used for positive class training, positive
class testing, and negative class testing respectively.
ETHZ Giraffes: Training was done on 93 images of
giraffes downloaded from Google Images. The positive
class test and negative class test datasets were 87 giraffe
images and the rest 168 images respectively from the
ETHZ Shape Classes dataset.
GRAZ Bikes: The positive class training and positive
class test sets respectively are randomly picked 25 and 38
images from the GRAZ bikes dataset. The first 200 im-
ages from CALTECH-101 background class dataset were
used as negative class test set.
CALTECH Faces: 52 randomly picked images from the
CALTECH Human Faces (Front) dataset were used for
each of the positive class training and test sets. The
first 200 images from CALTECH-101 background class
dataset were used as negative class test set.
I-FAC consistently performs well on the basis of FPR-
versus-recall when compared to either BOW (by high mar-
gins on all five datasets) or SVM (by high margins on
three datasets - Cars, Faces, and Giraffes, and by rea-
sonable margins on the remaining two datasets - Fig. 2).
It especially performs very well at low FPRs (? 0.3),
which is highly desirable for an image classifier. The per-
formance of I-FAC can be attributed to two broad rea-
sons. First, its fuzzy nature helps avoid polysemy and
4374980
synonymy, which are common problems with BOW. Sec-
ond, SVM has to deal with a lot of noise in the train-
ing images, which hampers the creation of a clear hyper-
plane, affecting the assignment of probability with which
the positive class occurs in a given image. This problem
does not occur in I-FAC which uses only the positive class
for training, and makes a classification decision based on
cumulative FIG in conjunction with a threshold ?. For
each dataset, ? has been determined by cross-validation
on the respective positive and negative classes test sets.
The variation in ? influences the variation of FPR-versus-
recall curve for I-FAC in each dataset. Fig. 3 shows FPR-
versus-recall variation as number of clusters and m of
FCM is varied (for the Cars dataset), with best results
achieved when 100 clusters and m = 1.5 were used. At
m = 1.001(m ? 1), FCM reduces to k-means, i.e. crisp
clustering. Higher values of m (e.g. m = 2) gave worse
results than those shown in Fig. 3.
References
[1] H. Bay, A. Ess, T. Tuytelaars, and L. J. V. Gool. Speeded-
up robust features (SURF). Computer Vision and Image
Understanding, 110(3):346–359, 2008.
[2] M. D. Cock, C. Cornelis, and E. E. Kerre. Elicitation of
fuzzy association rules from positive and negative exam-
ples. Fuzzy Sets and Systems, 149(1):73–85, 2005.
[3] C. Dance, J. Willamowski, L. Fan, C. Bray, and G. Csurka.
Visual categorization with bags of keypoints. In ECCV In-
ternational Workshop on Statistical Learning in Computer
Vision, 2004.
[4] D. Dubois, E. Hu¨llermeier, and H. Prade. A systematic ap-
proach to the assessment of fuzzy association rules. Data
Mining Knowledge Discovery, 13(2):167–192, 2006.
[5] J. C. Dunn. A fuzzy relative of the isodata process and its
use in detecting compact well-separated clusters. Journal
of Cybernetics, 3:32–57, 1973.
[6] G. P. C. Fung, J. X. Yu, H. Lu, and P. S. Yu. Text classifica-
tion without labeled negative documents. In ICDE, pages
594–605, 2005.
[7] L. M. Manevitz and M. Yousef. One-class svms for doc-
ument classification. Journal of Machine Learning Re-
search, 2:139–154, 2001.
[8] A. Mangalampalli and V. Pudi. Fuzzy association rule min-
ing algorithm for fast and efficient performance on very
large datasets. In FUZZ-IEEE, pages 1163–1168, 2009.
[9] T. Quack, V. Ferrari, and L. J. V. Gool. Video mining with
frequent itemset configurations. In CIVR, pages 360–369,
2006.
[10] T. Quack, V. Ferrari, B. Leibe, and L. J. V. Gool. Efficient
mining of frequent and distinctive feature configurations.
In ICCV, pages 1–8, 2007.
[11] J. Sivic and A. Zisserman. Video data mining using con-
figurations of viewpoint invariant regions. In CVPR, pages
488–495, 2004.
[12] F. A. Thabtah. A review of associative classification min-
ing. Knowledge Engineering Review, 22(1):37–65, 2007.
[13] A. Veloso, W. M. Jr., and M. J. Zaki. Lazy associative
classification. In ICDM, pages 645–654, 2006.
[14] X. Yin and J. Han. CPAR: Classification based on predic-
tive association rules. In SDM, 2003.
[15] Z. Zheng, R. Kohavi, and L. Mason. Real world perfor-
mance of association rule algorithms. In KDD, pages 401–
406, 2001.
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5
R
ec
al
l
False Positive Rate
I-FAC
BOW
SVM
(a) CARS Dataset
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5
R
ec
al
l
False Positive Rate
I-FAC
BOW
SVM
(b) TUD Bikes Dataset
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5
R
ec
al
l
False Positive Rate
I-FAC
BOW
SVM
(c) Giraffe Dataset
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  0.1  0.2  0.3  0.4  0.5
R
ec
al
l
False Positive Rate
I-FAC
BOW
SVM
(d) GRAZ Bikes Dataset
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  0.1  0.2  0.3  0.4  0.5
R
ec
al
l
False Positive Rate
I-FAC
SVM
(e) Faces Dataset
Figure 2. Results on Standard Datasets
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5
Re
ca
ll
False Positive Rate
cl=100,m=1.001
cl=100,m=1.1
cl=100,m=1.5
cl=50,m=1.1
cl=50,m=1.5
cl=25,m=1.1
cl=25,m=1.5
cl=10,m=1.1
cl=10,m=1.5
Figure 3. FPR versus Recall for varying clusters and m
4375991
