An intruder detection approach based on infrequent rating pattern
mining
Jose´ Mar?´a Luna, Aurora Ram?´rez, Jose´ Rau´l Romero and Sebastia´n Ventura
Dept. Of Computer Science and Numerical Analysis, University of Co´rdoba
Abstract—This work presents a novel proposal for incremental
intruder detection in collaborative recommender systems. We
explore the use of rare association rule mining to reveal the
existence of a suspected raid of attackers that would alter the
normal behaviour of a rating-based system. In this position paper
we have extended our previous G3PARM algorithm, which has
already proven to serve as a solid method for extracting frequent
association rules. G3PARM is an evolutionary algorithm that uses
G3P (Grammar Guided Genetic Programming), which provides
expressiveness and ?exibility enough to adapt and apply the base
context-free grammar to each speci?c problem or domain. We
fully outline, moreover, the complete exploration and detection
model, which includes some further post-analysis steps. Finally,
as a proof of concept, we validate the scalability, ef?ciency
and accuracy of our proposal showing the results obtained
when different malicious intruders want to attack an on line
recommender system.
I. INTRODUCTION
In our daily life, it is customary to take our decisions based
on the opinions and suggestions of others whose tastes are
apparently similar to ours. So, with the advance of virtual
communities and collaborative recommender systems (CRS),
to share views and interests among users has become a routine
activity, and it is usual for users to act on the basis of
what they hear from others (e.g., when purchasing goods,
booking a flight, etc.). Thus, CRS use historical data on user
preferences to recommend items. A common way to generate
these recommendations is to analyze how other users behave,
and predict the afinity for items that were not rated yet by
the target user. An user-based collaborative recommendation
algorithm [1] attends to such predictions, which are usually
calculated based on the similarity between neighbors to the
target user.
Nevertheless, these systems are not free of problems, and
prediction models have to face the manipulation and fraudulent
use of the system by malicious parties (aka. attackers), which
may inject fake user profiles in order to influence the rating of
certain items that want to be promoted or demoted. Although
most systems apply different techniques to prematurely detect
attackers and restrict their registration, it is really difficult to
anticipate the attackers’ behaviour once they have successfully
joined the application. In consequence, most current propos-
J.M. Luna (Student Member, IEEE), A. Ram?´rez, J.R. Romero (Member,
IEEE) and S. Ventura (Senior Member, IEEE) are with the Dept. of Com-
puter Science and Numerical Analysis, University of Co´rdoba, Rabanales
Campus, 14071 Co´rdoba, Spain. Email: {i32luarj, i72raqua, jrromero, sven-
tura}@uco.es.
als [2], [3], [4] are actually based on the analysis of the system
data sources and existing user profiles.
A profile-injection attack is a common way to distort
recommendations. Basically, it consists in adding several new
users to the system using different fictitious identities. Each
of these users will rate a target item, as well as other random
items that other regular users belonging to the group of interest
would also rate. In this way, real intentions are concealed, and
it makes the attack more difficult to trace. There are different
types of profile-injection attacks [5], depending on whether
the target item should be promoted (push attack) or demoted
(nuke attack).
Intrusion detection does not only concern rating-based sys-
tems. Indeed, there exists many other application domains for
which anomaly detection [6] is an important issue too. Exam-
ples include network intrusion, frauds (e.g., banking, assurance
companies, etc.), medical anomalies, industrial damages, sen-
sor networks, text processing, and so on. In general, anomaly
detection searches for patterns in data that do not follow
the behaviour expected. Therefore, different approaches for
intrusion detection have been proposed (e.g., neural networks,
statistical techniques, etc.), data mining (DM) being a widely
used process to explore and extract comprehensible and useful
knowledge from these large data sources.
More precisely, association rule mining (ARM) is a very
well-known method for discovering interesting patterns and
close relations between items in datasets. An association rule
[7] is an expression of the form ?? ?, where ? and ? are
sets of items and ? ? ? = ?, ? being the antecedent and ?
the consequent. So, an association rule should be interpreted as
follows: if all items in ? exist in a transaction, then it is highly
probable that all items in ? are also in the transaction, and ?
and ? should not have any common items. Rare association
rule mining (RARM) is a recent trend in ARM that, on the
contrary, searches for non-frequent, unusual or exceptional
association rules by mining rare (or infrequent) itemsets, i.e.,
itemsets that do not occur frequently in the data.
RARM deserves our special attention, since searching for
non-ordinary items can help to discover potential intruders
throughout the dataset maintained by the rating system. Many
techniques have been already proposed to mine association
rules, Apriori [8], [9] and FP-Growth [10] being the most ref-
erenced classical algorithms. Furthermore, evolutionary pro-
posals are also remarkable, and their results usually go beyond
the performance achieved by the former, e.g., in terms of
scalability. Precisely, G3PARM (Grammar Guided Genetic
682978-1-4244-8136-1/10/$26.00 c©2010 IEEE
Programming for Association Rule Mining) [11] is a novel
evolutionary approach in this field. Its behaviour is based on a
context-free grammar (CFG) that permits us to adapt the rules
syntax to each specific application domain. G3PARM makes
use of a fixed size auxiliary population comprised of those
individuals (each individual represents an association rule) that
exceed a certain support and confidence threshold.
On the other hand, most current RARM proposals are based
on variations of these classical approaches. Apriori-Inverse
[12], ARIMA [13] or Rarity [14] are some relevant examples.
In this position paper we explore the use of RARM to detect
and extract infrequent rating patterns from CRS-specific data
sources. To do this, we have developed an extension of the
G3PARM, specially devoted to the discovery of infrequent (or
rare) rules. However, this is just a first but core step in the
entire process, as explained later. Note that it is necessary to
analyze the rules mined too, and subsequently to apply this
knowledge to the dataset evolved over time, as it can contain
malicious ratings from an attacker.
This paper is structured as follows: Section II presents the
whole intrusion detection process, and describes the different
steps followed to fix the dataset after a potential malicious
attack until intruders are completely removed from the system.
Then, Section III details the experimentation, including a de-
scription of the dataset used, the experimental set-up, and how
the approach is applied to the case study. The results obtained
are also presented in this section. Finally, some concluding
remarks and future work are highlighted in Section IV.
II. THE SUSPICIOUS ATTACKER DETECTION PROCESS
In this section we outline an overview of the intruder
detection process and explore, with an example, each step
required to the process be successfully completed, including
the mining of rare rules, the analysis of rating patterns, and
the subsequent detection of suspicious attackers.
A. An overview of the approach
The process for detecting suspicious attackers in user-based
recommendation systems implies several different steps, as
shown in Figure 1. Originally, the ratings dataset only contains
uncorrupted user preferences per item, i.e., votes and scores
casted in the course of time by users concerning to a given
subject of matter (movies, books, music, or whatever). Table I,
extracted from [5], shows an example of ratings using some
generic kind of items, where each cell represents the specific
score given by the user to an item. Scores are bound from 1
(i.e., the user dislikes the item) to 5 (i.e., the user likes the
item). For the sake of clarity, this dataset will be used in this
section to facilitate comprehension of the approach.
A first step to perform over the uncorrupted dataset is to
mine those association rules that are comprised by infrequent
combinations of ratings. A modification of the G3PARM
algorithm is used with this purpose, as it returns the set of best
individuals (i.e., most infrequent association rules) obtained
from the final generation after the evolutionary process. Each
attribute of the rule is encoded as an item with a quantitative
Dataset
Dataset ’
Rare association
rules
Attack
injection
G3PARM
modified
Analysis of the rating patterns
List of attackers
A1           C1
A2           C2
      ...
An           Cn
Dataset ’’ Dataset ’ Attackers
Fig. 1. Overview of the intruder detection process
TABLE I
EXAMPLE OF A PUSH ATTACK FAVORING THE TARGET ITEM Item6
Item1 Item2 Item3 Item4 Item5 Item6
User1 5 2 3 3
User2 2 4 4 1
User3 3 1 3 1 2
User4 4 2 3 1 1
User5 3 3 2 1 3 1
User6 3 1 2
User7 4 3 3 3 2
User8 5 1 5 1
Attacker1 5 3 2 5
Attacker2 5 1 4 2 5
Attacker3 5 2 2 2 5
value that represents the rating of the item, the support of
the attribute being the number of user profiles that satisfy the
attribute rating.
With the elapse of time, the uncorrupted dataset evolves
and new suspicious user profiles are included (attack injec-
tion), containing malicious ratings that may alter the normal
behaviour of the recommendation system. For example, in
Table I three new attacker profiles (Attacker1-3) have been
injected to promote Item6. Then, using the rating rules pre-
viously obtained from the uncorrupted dataset, new recom-
mendations must be analyzed in this corrupted dataset, so we
determinate whether significant suspicious changes were made
2010 10th International Conference on Intelligent Systems Design and Applications 683
in rating patterns with time. More specifically, the support
variation of the attributes comprised by the infrequent rules
obtained in the previous step must be analyzed. Hence, if there
is a support variation greater than a minimum threshold, then
the item referred could probably be considered as attacked.
Finally, having these suspicious items, the list of attackers
is obtained, and their scores removed from the dataset. As a
result, a new uncorrupted dataset is obtained, so the detection
process cycle begins again.
B. Discovering infrequent rating patterns
The G3PARM algorithm (see Figure 2 for a general descrip-
tion) is a very efficient algorithm in mining knowledge, and
allows us to obtain feasible solutions without requiring large
amounts of memory. Precisely, this is a major advantage over
classical proposals, which are usually restricted in terms of
scalability and performance. G3PARM is an evolutionary al-
gorithm that makes use of G3P to define individuals and allows
us to obtain association rules from datasets with different types
of attributes (i.e., both categorical and numerical attributes).
G3P is an extension of Genetic Programming (GP) [15]
where each individual is a derivation tree that generates and
represents a solution using the language defined by a CFG.
It permits to adapt the rules mined to each specific scope of
application. In fact, in case of intruder detection, we will only
consider continuous attributes, since they represent the score
per rating. Figure 3 shows the CFG modified to only deal with
quantitative attributes.
Fig. 2. General description of the G3PARM algorithm
Fig. 3. Context-Free Grammar used by G3PARM in intruder detection
The evaluation of each individual is performed by cal-
culating the value returned by the fitness function. Unlike
G3PARM, this variation of the algorithm searches for the
minimum support for each rule, this measure being defined
as the ratio of records that contain both the antecedent and
the consequent to the total number of records in the dataset.
Instead, our proposal defines a new fitness function (see
Equation 1) to be maximized, where ???? is the support value
of the association rule, and ??? states for the support threshold
predetermined by the configuration parameters. Notice that
G3PARM uses two genetic operators (i.e., crossover and
mutation) to generate new individuals in each generation of
the evolutionary process. The crossover obtains offsprings by
swapping the derivation subtrees of two parents from two
compatible selected nodes. On the other hand, the mutation
operator selects a node from a rule and acts according to the
node type. If the node is a non-terminal node, a new derivation
is performed from this node; if the node is a terminal node,
the genetic operator changes the value of this node at random.
??????? =
??
?
1
????? ??? if ???? > ???
0 otherwise
(1)
Once the new individuals are obtained by applying the
crossover and mutation operators, the algorithm updates an
auxiliary population by ranking individuals according to the
support measure and those that exceed a certain threshold
for this measure and confidence measure are included in
the auxiliary population. In order to update the auxiliary
population, two thresholds are applied to the support measure:
a minimum and a maximum threshold. Only those individuals
that have a confidence value greater than a minimum confi-
dence threshold, and a support value greater than the minimum
support threshold, but less than the maximum are included in
the auxiliary population.
Unlike the original G3PARM algorithm, this new proposal
performs an important postprocessing step once the algorithm
execution is completely finished. This step takes the resulting
individuals from the auxiliary population and simplifies rules
that contain redundant attributes or inconsistent expressions
(e.g., the rule ? > 3 ??? ? > 4 ? ? < 4 might be
simplified in the rule ? > 4 ? ? < 4). Furthermore, this
postprocessing also applies an order for the attributes that
comprise each rule (e.g., the rule ? > 3 ??? ? > 4 ?
? < 4 would be ordered as ? > 3 ??? ? > 4 ? ? < 4).
C. Analysis of the rating patterns
For each rare rule mined by the evolutionary algorithm using
the original uncorrupted rating dataset, the relative support, ?0,
of every attribute should be calculated. Later, once the dataset
has evolved comprising suspicious ratings, these calculations
should be computed again, so each attribute will have a new
support value, ?1. As a result, the increment of this relative
support measure, ????, is obtained for each attribute, and
serves as an input to calculate ??????? (defined by Equation 2),
i.e., the probability that an attribute (or item) is attacked.
Thus, those values of ??????? greater than any other value
and exceeding a minimum threshold should be considered as
a potential attack to this item.
684 2010 10th International Conference on Intelligent Systems Design and Applications
??????? =
????
???(??0 ? ???, ??1 ? ?? ?) (2)
where ?? is the relative support obtained by dividing the
absolute support (obtained by counting votes of the original
dataset) by the number of instances of the corrupted dataset,
i.e., none of the new instances of the dataset (the attack
injection) satisfies the attribute of the rule. Similarly, ??
represents the relative support obtained if all the instances of
the attack injection are satisfied by the attribute of the rule.
For example, based on Table I, the following infrequent
combinations of ratings are obtained and expressed in terms
of rare association rules:
Rule1: ????1 < 3 ??? ????2 > 3? ????6 ? 4
Rule2: ????3 ? 4 ??? ????5 > 3? ????4 < 2
Then, we first calculate absolute and relative supports for
each attribute that appears in those infrequent rules mined from
the uncorrupted dataset, i.e., counting votes of User1-8.
Rule1: absolute: [1, 1, 6] relative: [0.16, 0.14, 1.00 ]
Rule2: absolute: [1, 2, 4] relative: [0.20, 0.33, 0.66 ]
After a potential malicious attack, this measure is calculated
once again, but including the users Attacker1-3, too.
Rule1: absolute: [1, 1, 6] relative: [0.10, 0.10, 0.66 ]
Rule2: absolute: [2, 2, 4] relative: [0.25, 0.25, 0.57 ]
From these rules and measures, the values of ?0, ?1, ??,
??, ?? and ??????? can be calculated, as shown in Table II.
TABLE II
RESULTING MEASURE VALUES FROM THE EXAMPLE
Item1 Item2 Item3 Item4 Item5 Item6
?0 0.16 0.14 0.20 0.66 0.33 1.00
?1 0.10 0.10 0.25 0.57 0.25 0.66
???? 0.06 0.04 0.05 0.09 0.08 0.33
?? 0.11 0.10 0.12 0.44 0.22 0.66
?? 0.44 0.40 0.50 0.77 0.55 1.00
???(..) 0.28 0.26 0.30 0.22 0.33 0.33
??????? 0.23 0.15 0.16 0.40 0.24 1.00
Notice that, according to the previous results, Item6 is the
item that achieves the highest value of ??????? (i.e., a probabil-
ity of 100% is properly obtained by the item under attack), and
extremely difers from the other items. The attribute Item4 has
the second highest probability value. According to the original
scores of Item4, once the user Attacker3 votes as 3 in favor,
??????? is raised to 0.40. Whether this value is considered as
a potential attack or not depends on a predetermined threshold
for the value of ??????? that should be experimentally defined,
depending on the dataset-specific characteristics.
??????? indicates whether an attribute is being potentially
attacked or not. However, different factors may meddle in
this value, so a high value of ??????? does not always im-
ply that the item of interest was intentionally promoted by
malicious attackers. Therefore, it is also important to analyze
how effective the potential attack is in the dataset. With this
purpose, we define the influence measure, ????, as indicated
in Equation 3, where ???? and ???? are the minimum and
maximum values of the score rating scale allowed by the
recommendation system, respectively, and ?¯ is the increment
of the average score for an item before and after the potential
attack.
???? =
???¯
???? ? ???? (3)
Following the Mobasher’s example, Table III shows the
average rating ( 0¯) for each attribute using the original uncor-
rupted dataset, and the average rating ( 1¯) for each attribute
using the dataset evolved. Finally, ?¯ shows the increment
that the average score has undergone with time. Notice that
negative values imply that the average score of a given item has
decreased (i.e., the item has been demoted), whereas positive
values imply an increase (i.e., the item has been promoted).
TABLE III
ANALYSIS OF THE AVERAGE RATINGS
Item1 Item2 Item3 Item4 Item5 Item6
0¯ 3.50 2.71 3.00 1.66 3.00 1.33
1¯ 4.00 2.44 3.00 1.77 2.75 2.55
?¯ 0.50 -0.27 0.00 0.05 0.25 1.22
With these values, Table IV gives the resulting attack
influence on each attribute (or item). As can be noted, Item6
obtains the highest influence value (0.30), as well as the
highest attack probability (??????? = 1.00). In consequence,
we can assure that this item was promoted, despite its influence
in the entire dataset is too limited (noticed that only three
different attack profiles were injected). In any case, the value
of ???? obtained for Item6 is significantly greater than the
influence values obtained by the rest of attributes. Remember
that, according to ??????? in Table II, Item4 would have
been potentially attacked, too. However, the influence value
clarifies this point, since such an attack would not have any
influence on the dataset, i.e., no other item, except Item6, was
significantly influenced by the malicious users Attacker1-3.
TABLE IV
???? MEASURE VALUES FOR EACH ATTRIBUTE
Item1 Item2 Item3 Item4 Item5 Item6
0.029 -0.010 0.000 0.005 0.005 0.300
D. Extraction of the intruders list
The final step in the attacker detection process consists
in finding out which users should actually be considered as
intruders. A preliminary list of attackers can be experimentally
built by analyzing both the attack probability, ???????, and the
injection influence, ????, as previously done in Section II-C.
So, for each item potentially attacked, we need to carefully
study which new user profile satisfies the item. Then, those
2010 10th International Conference on Intelligent Systems Design and Applications 685
profiles that only appear in the potentially corrupted dataset
and stand out from others because of the values of both
measures will be considered as malicious intruders. Once
these profiles are completely removed from the dataset, a new
iteration of the process would start with the elapse of time.
In the Mobasher’s example, Item6 was clearly identified
as an attacker. Thus, according to Table I, we just need to
know which users voted for Item6 with a high score (if
a push attack is considered). Attacker1-3 are the malicious
users that interfere in the normal behaviour of the user-based
recomendation system.
III. EXPERIMENTATION AND RESULTS
Several different experiments have been carried out to detect
potential attacks over an user-based recommendation system.
With this purpose in mind, the aforementioned variation of the
G3PARM algorithm was executed using a specific rating-based
dataset. Moreover, the whole approach proposed in Section II
has been followed. All the experiments used in this study have
been performed on an Intel Core i7 machine with 12Gb main
memory and running CentOS 5.4. The algorithm proposed has
been written in Java using JCLEC [16], a Java library for
evolutionary computation.
In the following sections, we describe the dataset used,
detail the experimental set-up and introduce a brief description
of the attack profiles injected for the experimentation. Finally,
we show the results obtained by different experiments.
A. Dataset and experimental set-up
In our experiments we used the free available Jester dataset
(Anonymous Ratings from the online Jester Online Joke
Recommender System1). This dataset consists of 4.1 million
continuous ratings of 100 jokes from 73,421 users. Table V
summarizes the configuration parameters used for the experi-
mentation.
TABLE V
EXPERIMENTATION SET-UP
Parameter Value
Population size 50 individuals
Number of generations 100
?????????? 0.9
????????? 0.2
Maximum number of derivations (CFG) 24
Auxiliary population size 30 individuals
Confidence threshold 0.9
Minimum suppport threshold 0.0005
Maximum suppport threshold 0.125
???? -10
???? 10
B. Execution of the RARM algorithm
In order to obtain a diverse set of association rules, five
different executions of the G3PARM modified algorithm have
been carried out with five different seeds. Once the G3PARM
1Jester Collaborative Filtering Dataset. http://goldberg.berkeley.edu/
jester-data/
algorithm reaches a certain number of generations (100 gen-
erations in our proposal), individuals from the auxiliary pop-
ulation are returned. As explained before, this population
comprises the best individuals, i.e., those that exceed a mini-
mum threshold of confidence and support and have a support
value less than a maximum threshold. Finally, the set of
rules obtained from the auxiliary population are normalized by
using the post-processing step implemented in this G3PARM
algorithm version.
Table VI shows the average support and confidence of the
rules obtained in each experiment. The value ? ????? is the
number of rules that compose the auxiliary population once
the algorithm reaches the maximum number of generations.
TABLE VI
AVERAGE RESULTS FOR EACH MEASURE PER EXECUTION
Support Con?dence N Rules
Experiment1 0.0340 0.9796 146
Experiment2 0.0324 0.9864 146
Experiment3 0.0431 0.9742 149
Experiment4 0.0312 0.9814 149
Experiment5 0.0499 0.9835 148
Average 0.0381 0.9810 147.6000
Finally, we present some significant rules obtained in this
first step of the intruder detection process, described in this
paper:
Rule1: ????78 > ?2 ???
????57 ? ?6 ???
????57 ? ?8 ???
????67 < 2? ????54 ? ?6
Rule1 normalized: ????57 ? ?6 ???
????67 < 2 ???
????78 > ?2? ????54 ? ?6
Rule2: ????100 < ?6 ???
????82 ? ?2 ???
????98 ? ?6 ???
????10 ? ?6? ????52 ? 6
Rule2 normalized: ????10 ? ?6 ???
????82 ? ?2 ???
????98 ? ?6 ???
????100 < ?6? ????52 ? 6
These rules show the infrequent ratings of 100 different
jokes. Scores are bound from -10 (i.e., the user dislikes the
item) to 10 (i.e., the user likes the item).
C. Attack injection
As we know, the main goal of an attacker is to distort the
normal behavior of a filtering recommender system in order
to promote or demote a specific item. Formally, a profile-
injection attack has a set of profiles added to the system
through an attacker with different fictitious user identities. To
686 2010 10th International Conference on Intelligent Systems Design and Applications
conceal the real intentions of an attacker, it is necessary to
rate items that are not the target item.
This paper is focused on the use of push attacks that consist
in promoting an item selected by adding high ratings to the
target item. It also requires some filler rating in order to
simulate a normal user behavior, e.g., rating the most popular
items. There are many ways to create a push attack [5], [17]:
? Random attack. This attack assigns the highest rating to
the target item and random ratings to the filler items.
? Average attack. In this attack, a previously knowledge
about the system is required. The average rating of each
item is assigned to each filler item. In order to promote
the target item, the highest rating is assigned to this item.
? Bandwagon attack. The attacker inserts some filler ratings
like the random attack, but also high rating in the most
frequently rated items. This model allows the association
between the most visibility items and the target item.
? Segment attack. This attack tries to reduce the knowledge
needed to create a push attack by pushing an item to a
group of users with specific preferences.
Focusing on the average attack and in order to create
this kind of attacks (see Figure 4), a set of filler items, ?? ,
are randomly chosen and a random rating is generated in
the domain [¯ ? ?, ¯ + ?], ? being the average rating for
the item ? and ? being its standard deviation. On the other
hand, the highest rating is assigned to the target item. This
process must be repeated in order to generate a set of attack
profiles (the attack size). The cardinality of the set ?? , ?, can
also be different. In our experiments, we created six attacks
(with different ? values) over three items with a low number
of highest rating (joke58, joke74 and joke79). The attack
size used in these experiments was 2500 that approximately
represents the 10% of the dataset size. Then, every new attack
profile is inserted into the dataset and a new dataset with an
attack injection (dataset) is obtained.
Filler items Target
item
Null itemsl in-l-i
n items
If Io It
Fig. 4. Average attack schema
D. Detection of suspicious attackers
Once we have the dataset and a set of rare association
rules, we analyze the rating patterns. For each experiment,
we obtain a subset of rules that have undergone a significant
change in some attributes (higher than a user-defined threshold
probability). For these rules, the ???? measure will indicate
the current item attacked.
With a threshold probability of 80%, more than 30 rules
were obtained as shown in Table VII. All of these rules present
the item attacked in their expression (with 92% or 100% of
attack probability). In this case, no rules with a significant
change in a filler item have been found. The values of the ????
measure are always higher than zero in the attacked items.
For the rest of attributes (filler items) less than zero values are
obtained so the suspicious item (the item with a high attack
probability) is really the attacked item.
TABLE VII
NUMBER OF RULES WITH THE ATTACKED ITEM (P = 0.8)
Attacked item ? = 20 ? = 30 ? = 40 ? = 50 ? = 60
Joke58 32 32 32 32 32
Joke74 37 37 37 37 37
Joke79 36 36 36 36 36
Using this threshold probability, the number of filler items
inserted in the dataset is not significant, because the number
of rules obtained for each ? value is the same. With a high
value of the threshold probability, only the attacked item
presenting a great change in the corrupted dataset will exceed
this threshold, because the filler items are inserted with a less
frequency than the target item.
If we change the threshold probability to 50%, some new
rules are found with the item attacked (Table VIII). If the
number of filler items increases (? takes values over 50), there
will be some filler items that will appear in the new dataset
close to the frequency of the target item. Thus, these items
can be confused with the items attacked. Table IX shows
the number of rules with a higher change than the threshold
probability caused by the high appearance of filler items in
the attack. In these cases, the filler items can be considered
to be attacked items, because their attack probability is higher
than the real target item probability. When this happens, the
???? measure gives us the current influence of the attack in
the dataset. For example, one of the association rules obtained
in our experiments has one filler item with a probability to be
an attack of 50% and the target item of 20%. Yet the influence
measures obtained were -0.006 for the filler item and 0.022
for the target item.
TABLE VIII
NUMBER OF RULES WITH THE ITEM ATTACKED (P = 0.5)
Attacked item ? = 20 ? = 30 ? = 40 ? = 50 ? = 60
Joke58 44 44 44 44 44
Joke74 37 37 37 37 37
Joke79 39 39 39 39 39
TABLE IX
NUMBER OF RULES WITH FILLER ITEMS
Attacked item ? = 20 ? = 30 ? = 40 ? = 50 ? = 60
Joke58 0 0 0 51 265
Joke74 0 0 0 81 279
Joke79 0 0 0 143 359
2010 10th International Conference on Intelligent Systems Design and Applications 687
IV. CONCLUDING REMARKS AND FUTURE WORK
This position paper has shown a novel proposal for the
detection of malicious attack injections in user-based rec-
ommendation systems. A core step in this process consists
in mining infrequent combinations of user ratings on items
(e.g., movies, books, music, and so on). With this purpose,
we have introduced a variation of our previous algorithm
G3PARM, that is specially devoted to rare association rule
mining. Since G3PARM is an evolutionary algorithm that uses
G3P, we have taken advantage of some important character-
istics aforementioned, such as its adaptability to the scope of
application as well as its scalability, which allows it to face
up to large datasets comprising a great deal of attributes (or
items). Precisely, this latter point is an usual shortcoming of
current attack detection proposals.
The attack probability ??????? and the ???? measure used
in the analysis of the rating patterns allows us to extract the
suspicious attacked items, state the real influence of these
items and, finally, extract the target item that the attacker
promoted. In our experiments, both the attacked items and
some filler items were catalogued as suspicious, but the filler
items are discarded later thanks to the influence measure.
As a future work, we plan to test different types of attacks,
because CRD are susceptible to a wide range of attacks. In this
respect, we will be able to prove our new detection process in
more complex attack injections like the bandwagon attack.
Although most of the current proposals analyzed datasets
with attacks, we also propose to explore how this method
would react in non-simulated environments, i.e., where the
increment of the dataset presents both usual rating profiles
and attacker profiles.
ACKNOWLEDGMENT
This work has been supported by Spanish Research Projects
P08-TIC-3720, TIN2008-06681-C06-03, and FEDER founds.
REFERENCES
[1] F. Zhang, L. Bai, and F. Gao, A User Trust-Based Collaborative Filtering
Recommendation Algorithm, 2009, pp. 411–424.
[2] C. Williams, B. Mobasher, R. Burke, and R. Bhaumik, Detecting Profile
Injection Attacks in Collaborative Filtering: A Classification-Based
Approach, 2007, pp. 167–186.
[3] C. Williams, B. Mobasher, and R. Burke, “Defending Recommender
Systems: Detection of Profile Injection Attacks,” Service Oriented
Computing and Applications, vol. 1, no. 3, pp. 157–170, 2007.
[4] S. X. Wu and W. Banzhaf, “The use of computational intelligence in
intrusion detection systems: A review,” Applied Soft Computing, vol. 10,
no. 1, pp. 1–35, 2010.
[5] B. Mobasher, R. Burke, R. Bhaumik, and C. Williams, “Toward Trust-
worthy Recommender Systems: An Analysis of Attack Models and
Algorithm Robustness,” ACM Trans. Internet Technol., vol. 7, no. 4,
p. 23, 2007.
[6] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly Detection: A
Survey,” ACM Comput. Surv., vol. 41, no. 3, pp. 1–58, 2009.
[7] R. Agrawal, T. Imielinski, and A. N. Swami, “Mining Association
Rules between Sets of Items in Large Databases,” in Proceedings of
the 1993 ACM SIGMOD International Conference on Management of
Data (SIGMOD 93’), Washington, D.C., 1993, pp. 207–216.
[8] C. Borgelt, “Efficient Implementations of Apriori and Eclat,” in 1st
Workshop on Frequent Itemset Mining Implementations (FIMI’03), Mel-
bourne, Florida, USA, 2003.
[9] F. Bodon, “A Tire-based APRIORI Implementation for Mining Frequent
Item Sequences,” in 1st International Workshop on Open Source Data
Mining: Frequent Pattern Mining Implementation, 2005, pp. 56–65.
[10] J. Han, J. Pei, Y. Yin, and R. Mao, “Mining Frequent Patterns without
Candidate Generation: A Frequent-Pattern Tree Approach,” Data Mining
and Knowledge Discovery, vol. 8, pp. 53–87, 2004.
[11] J. M. Luna, J. R. Romero, and S. Ventura, “G3PARM: A Grammar
Guided Genetic Programming Algorithm for Mining Association Rules,”
in IEEE World Congress on Computational Intelligence (WCCI 2010),
Barcelona, Spain, 2010, pp. 2586–2593.
[12] Y. Koh and N. Rountree, Finding Sporadic Rules Using Apriori-Inverse,
2005, pp. 97–106.
[13] L. Szathmary, A. Napoli, and P. Valtchev, “Towards Rare Itemset
Mining,” in 19th IEEE International Conference on Tools with Artificial
Intelligence (ICTAI ’07), vol. 1, 2007, pp. 305–312.
[14] L. Troiano, G. Scibelli, and C. Birtolo, “A Fast Algorithm for Mining
Rare Itemsets,” in Proceedings of the Ninth Intl. Conference on Intelli-
gent Systems Design and Applications, 2009, pp. 1149–1155.
[15] J. R. Koza, Genetic Programming: On the Programming of Computers
by Means of Natural Selection (Complex Adaptive Systems). The MIT
Press, December 1992.
[16] S. Ventura, C. Romero, A. Zafra, J. Delgado, and C. Herva´s, JCLEC:
a Framework for Evolutionary Computation, ser. Soft Computing.
Springer Berlin / Heidelberg, 2007, vol. 12, pp. 381–392.
[17] S. Lam and J. Riedl, “Shilling recommender systems for fun and profit,”
in Proceedings of the 13th International WWW Conference, New York,
NY, 2004.
688 2010 10th International Conference on Intelligent Systems Design and Applications
