 
 
 
? 
Abstract—Data mining is a very active and rapidly growing 
research area in the field of computer science. Its goal is to 
obtain useful knowledge for users from a database. Association 
rule mining from a database is one of the most well-known data 
mining techniques. In general, a large number of if-then rules 
are extracted by specifying minimum support and confidence 
levels. They are, however, too complicated as knowledge for 
users to understand many rules at one time. Multiobjective 
genetic fuzzy rule selection from Pareto-optimal and near 
Pareto-optimal rules is a promising approach which can obtain 
an accurate and simple rule set by considering the accuracy 
maximization and the complexity minimization. In this paper, 
we propose two extensions of multiobjective genetic fuzzy rule 
selection for designing more accurate fuzzy rule-based 
classifiers. One extension is to add compatible rules with 
misclassified patterns into candidate rules for genetic fuzzy rule 
selection. The other is to tune membership functions after 
genetic fuzzy rule selection. We examine the effects of these 
extensions through computational experiments on imbalanced 
data sets.  
I. INTRODUCTION 
SSOCIATION rule mining is one of the most well-known 
techniques in data mining. It finds all rules that satisfy 
the given minimum confidence and minimum support levels. 
A large number of rules are generated from a database. From 
the view point of human users, it must be very difficult to 
understand all the extracted rules at one time. That is, some 
pruning process is needed to choose a small number of 
interesting rules. A number of rule evaluation criteria which 
quantify the interestingness or goodness of a rule have been 
proposed. For example, gain, variance, chi-squared value, 
entropy gain, gini, laplace, lift, and conviction. It was shown 
in [1] that the best rule according to any of the above- 
mentioned criteria is included in the Pareto-optimal rules with 
respect to the maximization of confidence and support. In 
some recent studies [2], [3], association rule mining has been 
applied to the design of accurate fuzzy rule-based classifiers. 
In [4], we proposed genetic fuzzy rule selection from the 
Pareto-optimal rules to obtain simpler but more accurate 
classifiers than classifiers with all Pareto-optimal rules.  
Our genetic fuzzy rule selection is a simple two stage 
method for designing fuzzy classifiers [4]-[9]. In the first 
stage, a large number of short fuzzy rules are generated. The 
 
Y. Nojima, Y. Kaisho, and H. Ishibuchi are with the Department of 
Computer Science and Intelligent Systems, Osaka Prefecture University, 
Sakai, Osaka 599-8531, JAPAN. (phone: +81-72-254-9198; fax: +81-72- 
254-9915; e-mail: nojima@cs.osakafu-u.ac.jp, kaisho@ci.cs.osakafu-u.ac.jp, 
hisaoi@cs.osakafu-u.ac.jp).  
short rule means that the rule has a few antecedent conditions. 
In [8], [9], Pareto-optimal and near Pareto-optimal rules are 
chosen among the generated rules based on the ?-dominance 
relation with respect to the confidence and support of each 
rule. The chosen rules are referred to as candidate rules. In the 
second stage, we apply a genetic algorithm to a combinatorial 
optimization of the candidate rules. We use two criteria: 
accuracy maximization and complexity minimization. 
Although we successfully obtained simple and accurate 
classifiers by our method, the accuracy was not always high 
for some data sets, especially class imbalanced data sets. 
In this paper, we propose two extensions of our genetic 
fuzzy rule selection for designing more accurate classifiers. 
One extension is to add compatible rules with misclassified 
patterns into candidate rules for genetic fuzzy rule selection. 
The other extension is to tune membership functions after 
genetic fuzzy rule selection. We examine the effects of the 
proposed extensions through computational experiments on 
imbalanced data sets. 
This paper is organized as follows. In Section II, we briefly 
explain fuzzy if-then rules for pattern classification problems, 
and Pareto-optimal rules. We also explain genetic fuzzy rule 
selection for the design of fuzzy rule-based classifiers. In 
Section III, we propose the above-mentioned two extensions 
of genetic fuzzy rule selection. We examine the effects of the 
proposed extensions through computational experiments in 
Section IV. Finally, we conclude this paper in Section V. 
II. ASSOCIATION RULE MINING AND GENETIC FUZZY RULE 
SELECTION FOR DESIGNING FUZZY CLASSIFIERS 
A. Fuzzy If-then Rules 
Let us assume that we have m training (i.e., labeled) 
patterns xp = (xp1, …, xpn), p = 1, 2, …, m from M classes in the 
n-dimensional continuous pattern space where xpi is the 
attribute value of the p-th training pattern for the i-th attribute 
(i = 1, 2, ..., n). For the simplicity of explanation, we assume 
that all the attribute values have already been normalized into 
real numbers in [0, 1].  
For our n-dimensional pattern classification problem, we 
use fuzzy rules of the following type: 
Rule Rq: If x1 is Aq1 and  ...  and xn is Aqn 
  then Class Cq with CFq,   (1) 
where Rq is a rule label, x = (x1, …, xn) is an n-dimensional 
pattern vector, Aqi is an antecedent fuzzy set (i = 1, 2, …, n), 
Cq is a class label, and CFq is a rule weight. 
Accuracy Improvement of Genetic Fuzzy Rule Selection with 
Candidate Rule Addition and Membership Tuning 
Yusuke Nojima, Member, IEEE, Yutaka Kaisho, and Hisao Ishibuchi, Senior Member, IEEE 
A
978-1-4244-8126-2/10/$26.00 ©2010 IEEE
 
 
 
We simultaneously use multiple fuzzy partitions with 
different granularities in fuzzy rule generation. We use four 
homogeneous fuzzy partitions in Fig. 1 (i.e., 14 triangular 
fuzzy sets). We also use a domain interval [0, 1] as an 
antecedent fuzzy set to represent a don’t care condition. That 
is, we use the 15 antecedent fuzzy sets in total. 
 
0 1
1
M
em
be
rs
hi
p
Input value 0 1
1
M
em
be
rs
hi
p
Input value
0 1
1
M
em
be
rs
hi
p
Input value 0 1
1
M
em
be
rs
hi
p
Input value
S2 L2
S5 ML5SM5 L5M5S4 ML4SM4 L4
S3 L3L3
 
Fig. 1.  Four fuzzy partitions used in our computational experiments. 
The consequent class Cq and the rule weight CFq of each 
fuzzy rule Rq can be specified in a heuristic manner by 
compatible training patterns with the antecedent part of Rq. 
For details, see [10], [11]. 
Since we use the 15 antecedent fuzzy sets for each attribute 
of our n-dimensional pattern classification problem, the total 
number of possible fuzzy rules is 15n. For high-dimensional 
data sets, the total number of possible fuzzy rules becomes 
quite large. Moreover, it is very difficult to intuitively 
understand long fuzzy rules with many antecedent conditions. 
Thus, we generate short fuzzy rules with only a small number 
of antecedent conditions. In this paper, we examine short 
fuzzy rules of length Lmax or less (e.g., Lmax = 3) in order to 
generate understandable fuzzy rules as candidates in fuzzy 
rule selection. It should be noted that the length of a fuzzy 
rule is defined by the number of its antecedent conditions 
excluding don’t care. This limitation on the rule length also 
leads to short computation time for rule generation. It is much 
faster than GA-based optimization and tuning processes. 
Instead of specifying the maximum rule length, identifying 
the relevant variables for each data set may be a good 
alternative approach (e.g., [12]).  
B. Pareto-optimal and Near Pareto-optimal Rules 
In the data mining field, two rule evaluation criteria called 
confidence and support are frequently used to measure the 
goodness of rules. Confidence and support of rules for data 
with quantitative attributes are calculated by using fuzzy sets.  
Let us assume that we have m training patterns xp. The 
confidence of the rule Rq for class h is defined as follows: 
?
?
??
?
?
m
p
p
h
p
q
q
p
q
hconf
1
Class
)(
)(
)Class(
x
x
A
A
x
A
?
?
,      (2) 
where )( pq xA? is the membership value of the pattern xp to 
the antecedent part Aq = (Aq1, ..., Aqn). It is calculated with the  
product operator as: 
)()()( 11 pnApAp xx qnqq ??? ??? ?xA ,      (3) 
where )(?
qiA?  is the membership value to the Aqi . 
The confidence conf (Aq ? Class h) is the ratio of 
compatible patterns with both the antecedent part Aq and the 
consequent class h to compatible patterns with the antecedent 
part Aq. The confidence conf (Aq? Cq) measures the validity 
of the linguistic association rule Aq? Cq. The confidence can 
be viewed as the fuzzy conditional probability of class Cq. 
In the same manner, support of the rule Rq for class h is 
defined as follows: 
m
hsupp
h
p
q
p
q?
?? ?Class
)(
)Class( x
x
A
A?
.     (4) 
The support supp(Aq? Class h) is the ratio of compatible 
patterns with both the antecedent part Aq and the consequent 
class h to the given m training patterns. The support 
supp(Aq? Cq) measures the covered rate of training patterns 
by the linguistic association rule Aq ? Cq. In the same 
manner, the coverage covr(Aq? Class h) is calculated as:  
h
h
p
q m
hcovr p
q?
?? ?Class
)(
)Class(
x
A x
A
?
,     (5) 
where mh is the number of patterns in the class h. In this paper, 
we use coverage instead of support. This is because the range 
of support values is often very different among the classes for 
imbalance data sets.  
We generate all the possible rules of length Lmax or less. If 
the confidence and coverage of the generated rules are 
smaller than the minimum confidence and coverage levels, 
they are removed. Among the remaining rules, Pareto- 
optimal and near Pareto-optimal rules with respect to the 
maximization of confidence and coverage are extracted. 
In order to handle not only Pareto-optimal rules but also 
near Pareto-optimal rules, ?-Pareto-optimal rules using a 
dominance margin ? are defined [8]. Fig. 2 shows (a) 
Pareto-optimal rules and (b) near Pareto-optimal rules in the 
confidence-coverage space. Each circle represents a rule. A 
red line in Fig. 2 (a) indicates a Pareto front. 
 
Confidence
C
ov
er
ag
e
 ?conf
?covr
Confidence
C
ov
er
ag
e
 
    (a) Pareto-optimal rules               (b) Near Pareto-optimal rules 
Fig. 2.  Example of the distribution of Pareto-optimal and near Pareto-optimal 
rules with the dominance margin ?. 
 
 
 
A rule Ri is said to be ?-dominated by another rule Rj when 
at least one of the following two conditions are satisfied: 
covr(Ri) ? covr(Rj) + ?covr?? and  conf (Ri) ? conf (Rj) + ?conf, (6) 
covr(Ri) ? covr(Rj) + ?covr?? and  conf (Ri) ? conf (Rj) + ?conf, (7) 
where ?conf and ?covr are the ? margins for confidence and 
coverage, respectively. To adjust the ranges between 
confidence and coverage, ?covr is calculated as: 
conf
kk
kk
covr RconfRconf
RcovrRcovr ??
)(min)(max
)(min)(max
?
?? .    (8) 
When a rule Ri is not dominated by any other rules in the 
sense of ?-dominance in (6), (7), we refer the rule Ri as an ?-Pareto-optimal rule. We remove weak Pareto-optimal rules 
with the highest confidence (i.e., 1.00) and small coverage as 
in [8] because good results were obtained by removing them 
(i.e., to reduce the search space for rule selection).  
C. Classifier Design by Genetic Fuzzy Rule Selection 
In order to obtain simple and accurate classifiers, we use 
multiobjective genetic fuzzy rule selection. Let us assume 
that we have already extracted N rules by the association rule 
mining technique explained in the last section. Each binary 
string of length N is represented as NssssS ???? 321  where si 
= 1 and si = 0 mean that the i-th candidate rule is included in 
and excluded from the rule set S, respectively. 
Since any subsets of the N rules are represented by binary 
strings, we can use almost all evolutionary multiobjective 
optimization algorithms. In this paper, we use the NSGA-II 
algorithm [13] because it is a well-known high-performance 
EMO algorithm. Let P be the current population in NSGA-II. 
The outline of NSGA-II can be written as follows: 
1: P = Initialize(P) 
2: while a termination condition is not satisfied do 
3:  P’ = Selection(P) 
4:  P’’ = Genetic Operations(P’) 
5:  P = Replace(P?P’’) 
6: end while 
7: return non-dominated solutions (P) 
 
First, an initial population is generated in Line 1. In Line 3, 
parent individuals (i.e., P’) are selected from the current 
population P. The standard binary tournament selection is 
usually used to choose a pair of parent individuals. In Line 4, 
an offspring population P’’ is generated from the parent 
population P’ by uniform crossover and biased mutation. The 
biased mutation changes 0 to 1 with a small probability and 1 
to 0 with a large probability to decrease the number of 1’s in 
each offspring. In Line 5, the best individuals are chosen from 
the merged population (P ? P’’) to construct the next 
population P. For details of NSGA-II, see [13]. 
We use the following two objectives to find an accurate 
and simple fuzzy classifier S: 
f1(S): The arithmetic average of the classification rate for 
each class by S,  
f2(S): The number of selected fuzzy rules in S. 
Genetic rule selection is formulated as follows: 
Maximize  f1(S)  and  minimize  f2(S).      (9) 
We use a single winner-based (i.e., winner-take-all) 
classification method. A single winner rule is identified by 
using the product of the compatibility grade and the rule 
weight CF of each fuzzy rule. Each CF value is not changed 
during genetic rule selection. 
Since we use the single winner-based classification method, 
some rules may be used for the classification of no training 
patterns. Whereas the existence of such an unnecessary rule 
in the rule set S has no effect on the first objective (i.e., the 
arithmetic average of the classification rate for each class), it 
deteriorates the second objective. Thus we remove all the 
unnecessary rules responsible for the classification of no 
training patterns before calculating the second objective. 
III. TWO EXTENSIONS FOR ACCURACY IMPROVEMENT 
We propose two extensions of genetic fuzzy rule selection: 
candidate rule addition and membership function tuning.  
A. Candidate Rule Addition 
For class imbalanced data, the classification accuracy is 
often very worse. The reason may be that the necessary rules 
for correctly classifying patterns of a minority class are not 
extracted as candidate rules for genetic fuzzy rule selection. 
This means that there is no possibility to improve the 
accuracy for the minority class even if we found the optimal 
combination of candidate rules.  
To handle this issue, we propose a candidate rule addition 
procedure which adds compatible rules with misclassified 
patterns into candidate rules. The procedure is as follows: 
Step 1: A number of rules are generated from numerical data 
under the condition on the maximum rule length, the 
minimum confidence and coverage levels. Let us 
refer to the generated rules as R. 
Step 2: ?-Pareto optimal rules are extracted from R. Let us 
refer to these rules as RPareto.  
Step 3: Pre-classification of all the training patterns is 
performed by RPareto.  
Step 4: Rules compatible with misclassified patterns are 
extracted from R\RPareto. A single rule is extracted for 
each misclassified pattern. Let us refer to the 
additional rules as Radd. 
We use RPareto and Radd as candidate rules of our genetic fuzzy 
rule selection.  
As a rule addition criterion, we examine the following two 
cases in this paper.  
EC: For each misclassified pattern, we add a rule with the 
 
 
 
same class as that of the pattern and with the highest 
compatibility grade to the pattern. 
ECW: For each misclassified pattern, we add a rule with the 
same class as that of the pattern and with the highest 
product value of the compatibility grade and the rule 
weight. 
B. Membership Function Tuning 
A number of membership function tuning techniques have 
been already proposed in the literature [14]-[17]. In this paper, 
we employ genetic lateral tuning [14], [15] after genetic rule 
selection. We show the example of lateral tuning in Fig. 3. 
The vertex of the membership function is originally on x = 1/3 
in the unit space [0, 1] (i.e., it corresponds to SM4 in the 
fourth granularity in Fig. 1). The vertex of the membership 
function is laterally movable between 1/6 and 1/2 in genetic 
lateral tuning.  
Genetic lateral tuning does not lose the structure of the 
linguistic labels initially defined because the prespecified 
shape of the membership functions is preserved and the 
vertexes of the adjoining membership functions are not 
overlapped, see more details in [14], [15]. 
 
0 1/2 11/31/6  
Fig. 3.  The movable area of a membership function.  
We apply a single-objective genetic algorithm with real 
coding to the genetic lateral tuning. We tune the set of 14 
fuzzy sets for each attribute in the classifier obtained by 
genetic fuzzy rule selection. That is, each string length is 
14? (the number of attributes). 
The objective function in the genetic lateral tuning is the 
same as f1(S) of NSGA-II. Fig. 4 illustrates the genetic lateral 
tuning procedure. Each square plot represents a non- 
dominated classifier obtained by genetic rule selection. We 
perform the genetic lateral tuning for each non-dominated 
classifier obtained by genetic rule selection. Each circle 
represents a newly obtained classifier by the genetic lateral 
tuning from the classifier of the closed square. A closed circle 
means the best classifier among the new classifiers. After the 
genetic lateral tuning for all the non-dominated classifiers, we 
choose a classifier with the best training data accuracy. 
An initial population is generated by uniformly distributed 
random values within each movable area. One individual has 
the same values as the original vertex position. Tournament 
selection, BLX-? crossover (? = 0.1) and uniform mutation 
are used as genetic operations in our experiments.  
The CF value of each rule is specified as the original one 
and not changed by the genetic lateral tuning. The adaptation 
of the CF value during the genetic lateral tuning can be 
interesting alternative method.  
Rule 1
Rule 2
Rule 3
Rule 4
Class 1
Class 2
Class 3
Er
ro
r
Number of rules
Class 4
 
Fig. 4.  Illustration of genetic lateral tuning.  
IV. COMPUTATIONAL EXPERIMENTS 
In our computational experiments, we used two-class data 
sets shown in Table I. Some of the data sets are generated 
from original data sets with more than two classes available 
from UCI Machine Learning Repository. Table I shows the 
number of patterns, the number of attributes, and the 
imbalance ratio for each two-class data. “bal1” was also 
examined, but we eliminated this data set because we could 
not generate any minority class rules under the condition of 
the maximum rule length specified in this experiment. The 
imbalance ratio is the number of patterns of a majority class 
divided by that of a minority class.  
 
TABLE I 
DATA SETS USED IN OUR COMPUTATIONAL EXPERIMENTS 
Data set Number of patterns 
Number of 
attributes 
Imbalance 
ratio 
bal0 625 4 1.17 
bal2 625 4 1.17 
glass1 214 9 1.82 
pima 768 8 1.87 
glass0 214 9 2.06 
newt2 215 5 2.31 
haberman 306 3 2.78 
newt1 215 5 5.14 
newt0 215 5 6.17 
glass5 214 9 6.40 
glass2 214 9 11.6 
glass3 214 9 15.5 
glass4 214 9 22.8 
 
For rule extraction, we specified the minimum confidence 
and coverage levels as 0.60 and 0.01, respectively. We 
examined the effects of four specification of the dominance 
margin ?conf, ?conf = 0.00, 0.01, 0.05, 0.10. The ?covr was 
calculated by (8). 
The settings of computational experiments are as follows.  
[Genetic Fuzzy Rule Selection] 
Population size: 200, 
The number of generations: 1000, 
 
 
 
Crossover probability: 0.9, 
Mutation probability: pm(0?1) = 1/N  and  pm(1?0) = 0.1. 
(N: the number of candidate rules) 
[Lateral Tuning] 
Population size: 100, 
The number of generations: 100, 
Crossover probability: 1.0, 
Mutation probability: 1/L (L: the length of a string). 
We examined the following six approaches:  
Pareto:  Genetic rule selection with ?-Pareto optimal rules. 
EC:  Genetic rule selection with ?-Pareto optimal rules 
and additional rules according to the membership 
degree. 
ECW:  Genetic rule selection with ?-Pareto optimal rules 
and additional rules according to the product of the 
membership degree and the rule weight. 
Pareto*:  Pareto with genetic lateral tuning. 
EC*:  EC with genetic lateral tuning. 
ECW*:  ECW with genetic lateral tuning. 
We performed the three times of the ten-fold cross 
validation procedure (3?10CV). We chose the classifier with 
the best training accuracy after genetic fuzzy rule selection in 
the case of Pareto, EC, ECW, and after genetic lateral tuning 
in the case of Pareto*, EC*, ECW*. 
A. Experimental Results with ??= 0.0 
Table II shows the average training data accuracy over 30 
runs for each data set and the average training data accuracy 
over all the data sets. Although the average training data 
accuracy over all the data sets may be unfair statistics, we use 
this value for rough comparison among six approaches. Bold 
face indicates the best value in each row. 
From Table II, we can see a clear positive effect of 
candidate rule addition comparing Pareto with EC and ECW. 
We can also see further improvement by genetic lateral 
tuning. The best training data accuracy was improved from 
82.58 to 89.91 on average.  
According to the recommendation by Demšar [18], we 
performed the Freidman’s test [19] to test the null hypothesis 
that all the approaches work equivalently on average. 
Regarding the training data accuracy in Table II, the 
Friedman’s test rejected the null hypothesis. Each average 
rank is shown in Table II. A smaller rank value is better.  
 
TABLE II 
TRAINING DATA ACCURACY OF THE OBTAINED CLASSIFIERS (??= 0.0) 
Pareto EC ECW Pareto* EC* ECW*
bal0 93.51 96.33 97.92 96.23 97.50 98.72
bal2 93.50 96.42 98.03 96.17 97.74 98.88
glass1 71.02 77.72 79.28 81.79 88.80 89.18
pima 76.00 79.35 80.69 78.96 81.04 82.29
glass0 66.52 69.91 69.84 76.05 74.77 74.36
newt2 95.79 97.78 97.95 99.82 99.75 99.86
haberman 60.67 63.85 63.80 69.88 73.34 72.62
newt1 94.82 97.69 97.75 97.68 99.32 99.36
newt0 98.66 98.85 98.85 99.80 99.75 99.76
glass5 95.24 97.78 97.94 97.14 98.05 98.05
glass2 55.56 56.45 56.45 56.11 58.42 58.55
glass3 89.04 91.54 95.41 93.32 95.42 97.75
glass4 83.18 94.88 94.80 93.62 99.51 99.51
Average 82.58 86.04 86.82 87.43 89.49 89.91
Ave. Rank 6.00 4.15 3.54 3.77 2.15 1.38 
 
Since the Friedman’s test rejected the null hypothesis, we 
also performed pair-wise comparisons like Nemenyi’s test 
[20], Holm’s test [21], Shaffer’s test [22], and Bergmann and 
Hommel procedure [23]. We used the open source code 
 
TABLE III 
ADJUSTED P-VALUES OBTAINED BY NEMENYI’S TEST, HOLM’S TEST, SHAFFER’S TEST, AND BERGMANN-HOMMEL PROCEDURE FOR THE TRAINING DATA 
ACCURACY OBTAINED IN OUR COMPUTATIONAL EXPERIMENTS 
i Hypothesis Unadjusted p pNeme pHolm pShaf pBerg 
1 Pareto vs. ECW* 3.2 x10-10 4.8 x10-9 4.8 x10-9 4.8 x10-9 4.8 x10-9 
2 Pareto vs. EC* 1.6 x10-7 2.4 x10-6 2.2 x10-6 1.6 x10-6 1.6 x10-6 
3 EC vs. ECW* 0.0002 0.0024 0.0021 0.0016 0.0016 
4 Pareto vs. ECW 0.0008 0.0119 0.0095 0.0080 0.0056 
5 Pareto* vs. ECW* 0.0012 0.0173 0.0127 0.0116 0.0081 
6 Pareto vs. Pareto* 0.0024 0.0355 0.0237 0.0237 0.0142 
7 ECW vs. ECW* 0.0033 0.0500 0.0300 0.0237 0.0142 
8 EC vs. EC* 0.0064 0.0963 0.0514 0.0449 0.0385 
9 Pareto vs. EC 0.0119 0.1781 0.0831 0.0831 0.0475 
10 Pareto* vs. EC* 0.0277 0.4156 0.1663 0.1663 0.0831 
11 ECW vs. EC* 0.0592 0.8876 0.2959 0.2367 0.1183 
12 EC* vs. ECW* 0.2945 1.0000 1.0000 1.0000 1.0000 
13 EC vs. ECW 0.4017 1.0000 1.0000 1.0000 1.0000 
14 EC vs. Pareto* 0.6002 1.0000 1.0000 1.0000 1.0000 
15 ECW vs. Pareto* 0.7532 1.0000 1.0000 1.0000 1.0000 
 
 
 
developed by García and Herrera [24]. Table III shows the 
adjusted p-values of those statistical tests. The statistical 
results also show the effectiveness of the proposed candidate 
rule addition and genetic lateral tuning.  
Table IV shows the average number of rules in the 
obtained classifiers. From Table IV, we can see that each 
classifier has a very small number of rules. There are three 
interesting observations. One is that the number of rules was 
increased when we compared Pareto with EC and ECW. This 
means that the necessary rules were successfully added to the 
candidate rule set and selected by genetic rule selection. 
Another interesting observation is that the number of rules 
was reduced after genetic lateral tuning. This is a positive side 
effect of genetic lateral tuning. The other interesting 
observation is that the number of rules decreased as the 
imbalance rate became larger. We need further investigation 
in a future study.  
 
TABLE IV 
NUMBER OF FUZZY RULES IN THE OBTAINED CLASSIFIERS (??= 0.0) 
Pareto EC ECW Pareto* EC* ECW*
bal0 8.3 14.8 25.5 6.5 12.3 24.5 
bal2 8.0 14.8 27.5 4.6 12.5 25.8 
glass1 6.0 10.3 11.2 5.1 8.8 9.8 
pima 7.7 12.5 15.4 7.1 11.4 13.9 
glass0 3.0 2.8 2.8 2.9 2.6 2.4 
newt2 5.3 6.8 6.6 4.6 5.2 5.4 
haberman 7.3 8.4 8.1 6.6 7.5 7.2 
newt1 3.9 4.4 4.5 3.4 4.2 4.5 
newt0 3.8 3.8 3.8 2.4 2.1 2.2 
glass5 3.6 4.6 5.3 2.7 4.5 5.0 
glass2 3.6 3.5 3.5 2.7 2.9 2.9 
glass3 3.2 4.1 5.1 3.1 3.8 4.8 
glass4 3.7 4.6 4.3 2.7 3.6 3.0 
 
 
TABLE V 
TEST DATA ACCURACY OF THE OBTAINED CLASSIFIERS (??= 0.0) 
Pareto EC ECW Pareto* EC* ECW* 
bal0 88.35 91.51 89.22 92.26 92.68 89.79 
bal2 91.58 92.43 91.07 94.07 93.03 91.68 
glass1 63.97 68.35 67.65 72.19 76.62 74.45 
pima 73.99 72.14 73.51 74.19 73.36 72.28 
glass0 62.85 68.10 68.04 70.75 73.40 72.53 
newt2 94.77 92.48 92.98 97.09 96.44 95.57 
haberman 55.48 57.30 56.75 59.76 60.20 60.37 
newt1 95.28 95.56 94.86 95.19 97.04 96.67 
newt0 96.14 93.36 95.03 96.31 96.03 96.59 
glass5 93.53 93.05 93.14 92.05 91.10 93.69 
glass2 49.62 49.15 48.90 49.40 50.44 50.56 
glass3 80.71 81.26 83.59 81.76 87.00 82.32 
glass4 69.46 82.17 78.99 72.17 88.32 91.58 
Average 78.13 79.76 79.52 80.55 82.74 82.16 
Ave. Rank 4.54 4.31 4.62 3.00 2.23 2.31 
Table V shows the average test data accuracy over 30 runs 
for each data set and the average test data accuracy over all 
the data sets as Table II. From Table V, it seems that there is a 
less effect of candidate rule addition comparing the training 
data accuracy in Table II. On the other hand, we can see that 
genetic lateral tuning can improve the generalization ability 
for the test data. We performed the statistical tests in the same 
manner as the training data accuracy. The Friedman’s test 
rejected the null hypothesis. Thus, we performed Nemenyi’s 
test, Holm’s test, Shaffer’s test, and Bergmann-Hommel 
procedure. Table VI shows the adjusted p-values of those 
statistical tests. There are clear statistically significant 
differences between Pareto and all the approaches with 
genetic lateral tuning. We can also see that the combinational 
use of candidate rule addition and genetic lateral tuning can 
improve the generalization ability on the test data very well 
(e.g., see the p-values of Pareto vs. ECW* and Pareto vs. 
EC*).  
B. Comparison among Several the Dominance Margins 
We examined the effects of the dominance margin. Figs. 5 
and 6 show the overall training data accuracy and test data 
accuracy over all the data sets. While a larger ? value 
improved the training data accuracy thanks to a larger number 
of candidate rules, the test data accuracy was not improved by 
the larger ? value. Comparing the results in the same ?, we can 
see a clear improvement by genetic lateral tuning for both 
training and test data accuracy. 
 
Pareto
EC
ECW
Pareto*
EC*
ECW*
0.00 
0.01 
0.05 
0.10 
80
84
88
92
?
A
cc
ur
ac
y 
[%
]
 
Fig. 5.  Average training accuracy over all the data sets. 
Pareto
EC
ECW
Pareto*
EC*
ECW*
0.00 
0.01 
0.05 
0.10 
76
79
82
85
A
cc
ur
ac
y 
[%
]
?
 
Fig. 6.  Average test accuracy over all the data sets. 
 
 
 
 
Figs. 7 and 8 show the average rank for the training data 
accuracy and the test data accuracy. We can observe almost 
all of the same effects of candidate rule addition and lateral 
tuning as in the case of ? = 0.0. 
 
Pareto
EC
ECW
Pareto*
EC*
ECW*
0.00 
0.01 
0.05 
0.10 
0
2
4
6
A
ve
ra
ge
 ra
nk
?
 
Fig. 7.  Average rank for the training data accuracy over all the data sets.  
A smaller rank is better. 
Pareto
EC
ECW
Pareto*
EC*
ECW*
0.00 
0.01 
0.05 
0.10 
0
2
4
6
A
ve
ra
ge
 ra
nk
?
 
Fig. 8.  Average rank for the test data accuracy over all the data sets. 
A smaller rank is better. 
 
C. Comparison between Low and High Imbalanced Data 
We divided the data sets used in our experiments into two 
subsets: Low imbalance data sets (IR < 3.0) and high 
imbalanced data sets (IR > 3.0). Figs. 9 and 10 show the 
average rank for the test data accuracy over the low 
imbalanced data sets and the high imbalance data sets, 
respectively. We can see that the positive effect of genetic 
lateral tuning became weaker as ? became larger for the low 
imbalance data sets. On the other hand, the approaches with 
candidate rule addition and genetic lateral tuning (i.e., EC* 
and ECW*) kept good ranking in almost all cases. This 
observation may indicate that the proposed extensions are 
effective especially for the high imbalanced data sets. 
V.  CONCLUSION 
In this paper, we proposed two extensions of our genetic 
fuzzy rule selection for designing more accurate classifiers. 
One extension is to add compatible rules with misclassified 
patterns into candidate rules for genetic fuzzy rule selection. 
The other extension is to tune membership functions by 
genetic lateral tuning after genetic fuzzy rule selection. 
Experimental results showed that the candidate rule addition 
can improve the training data accuracy. This is because the 
possibility that the misclassified training patterns are 
classified by additional rules becomes high. Experimental 
results also showed that the genetic lateral tuning can 
improve the test data accuracy as well as the training data 
accuracy, since fuzzy membership functions are properly 
adjusted according to the pattern distributions. The 
combination of the proposed two extensions would be the 
best choice. 
As a future study, we will examine the effects of the 
proposed extensions using a large number of data sets 
TABLE VI 
ADJUSTED P-VALUES OBTAINED BY NEMENYI’S TEST, HOLM’S TEST, SHAFFER’S TEST, AND BERGMANN-HOMMEL PROCEDURE FOR THE TEST DATA 
ACCURACY OBTAINED IN OUR COMPUTATIONAL EXPERIMENTS 
i Hypothesis Unadjusted p pNeme pHolm pShaf pBerg 
1 Pareto vs. ECW* 3.1 x10-10 4.8 x10-9 4.8 x10-9 4.8 x10-9 4.9 x10-9 
2 Pareto vs. EC* 1.6 x10-7 2.4 x10-6 2.2 x10-6 1.6 x10-6 1.6 x10-6 
3 EC vs. ECW* 1.6 x10-4 0.0024 0.0021 0.0016 0.0016 
4 Pareto vs. ECW 8.0 x10-4 0.0119 0.0095 0.0080 0.0056 
5 Pareto* vs. ECW* 0.0012 0.0173 0.0127 0.0116 0.0081 
6 Pareto vs. Pareto* 0.0024 0.0355 0.0237 0.0237 0.0142 
7 ECW vs. ECW* 0.0033 0.0500 0.0300 0.0237 0.0142 
8 EC vs. EC* 0.0064 0.0963 0.0514 0.0449 0.0385 
9 Pareto vs. EC 0.0119 0.1781 0.0831 0.0831 0.0475 
10 Pareto* vs. EC* 0.0277 0.4156 0.1662 0.1662 0.0831 
11 ECW vs. EC* 0.0592 0.8876 0.2959 0.2367 0.1183 
12 EC* vs. ECW* 0.2945 1.0000 1.0000 1.0000 1.0000 
13 EC vs. ECW 0.4017 1.0000 1.0000 1.0000 1.0000 
14 EC vs. Pareto* 0.6002 1.0000 1.0000 1.0000 1.0000 
15 ECW vs. Pareto* 0.7532 1.0000 1.0000 1.0000 1.0000 
 
 
 
including data sets with more than two classes. We also have 
to compare the proposed method with other learning 
algorithms. There are still a lot of things we have to improve 
in the proposed extensions, especially the search space and 
genetic operations in the lateral tuning. The discussion on the 
tradeoff relation among accuracy, complexity, and 
interpretability is also another important future research 
issue.  
 
Pareto
EC
ECW
Pareto*
EC*
ECW*
0.00 
0.01 
0.05 
0.10 
0
2
4
6
A
ve
ra
ge
 ra
nk
?
 
Fig. 9.  Average rank for the test data accuracy over low imbalanced data sets. 
A smaller rank is better. 
Pareto
EC
ECW
Pareto*
EC*
ECW*
0.00 
0.01 
0.05 
0.10 
0
2
4
6
A
ve
ra
ge
 ra
nk
?
 
Fig. 10.  Average rank for the test data accuracy over high imbalanced data 
sets. A smaller rank is better. 
REFERENCES 
[1] R. J. Bayardo Jr. and R. Agrawal, “Mining the most interesting rules,” 
Proc. of the 5th ACM SIGKDD International Conference on 
Knowledge Discovery and Data Mining, ACM Press, New York, NY, 
USA, pp. 145-154, 1999. 
[2] B. Liu, W. Hsu, and Y. Ma, “Integrating classification and association 
rule mining,” Proc. of 4th International Conference on Knowledge 
Discovery and Data Mining, New York, AAAI Press, August 27-31, 
1998, pp. 80-86. 
[3] X. Yin and J. Han, “CPAR: Classification based on predictive 
association rules,” Proc. of SIAM International Conference on Data 
Mining, San Francisco, CA, May 2003, pp. 331-335  
[4] H. Ishibuchi, K. Nozaki, N. Yamamoto, and H. Tanaka, “Selecting 
fuzzy if-then rules for classification problems using genetic 
algorithms,” IEEE Trans. on Fuzzy Systems, vol. 3, no. 3, pp. 260-270, 
1995. 
[5] H. Ishibuchi, T. Murata, and I. B. Turksen, “Single-objective and 
two-objective genetic algorithms for selecting linguistic rules for 
pattern classification problems,” Fuzzy Sets and Systems, vol. 89, no. 2, 
pp. 135-150, 1997. 
[6] H. Ishibuchi, T. Nakashima, and T. Murata, “Three-objective genetics- 
based machine learning for linguistic rule extraction,” Information 
Sciences, vol. 136, no. 1-4, pp. 109-133, 2001. 
[7] H. Ishibuchi and T. Yamamoto, “Fuzzy rule selection by multi- 
objective genetic local search algorithms and rule evaluation measures 
in data mining,” Fuzzy Sets and Systems, vol. 141, no. 1, pp. 59-88, 
2004. 
[8] H. Ishibuchi, I. Kuwajima, and Y. Nojima, “Prescreening of candidate 
rules using association rule mining and Pareto-optimality in genetic rule 
selection,” Proc. of 11th International Conference on Knowledge- 
Based and Intelligent Information and Engineering Systems, pp. 
509-516, 2007. 
[9] I. Kuwajima, Y. Nojima, and H. Ishibuchi, “Obtaining accurate 
classifiers with Pareto-optimal and near Pareto-optimal rules,” Proc. of 
11th International Symposium on Artificial Life and Robotics, pp. 
195-198, Beppu, Japan, January 31-February 2, 2008. 
[10] H. Ishibuchi and T. Nakashima, “Effect of rule weights in fuzzy 
rule-based classification systems,” IEEE Trans. Fuzzy Systems, vol. 9, 
no. 4, pp. 506-515, August 2001. 
[11] H. Ishibuchi and T. Yamamoto, “Rule weight specification in fuzzy 
rule-based classification systems,” IEEE Trans. on Fuzzy Systems, vol. 
13, no. 4, pp. 428-435, August 2005. 
[12] J. M. Alonso and L. Magdalena, “An interpretability-guided modeling 
process for learning comprehensible fuzzy rule-based classifiers,” Proc. 
of 9th International Conference on Intelligent Systems Design and 
Applications, pp. 432-437, 2009. 
[13] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, “A fast and elitist 
multiobjective genetic algorithm: NSGA-II,” IEEE Trans. on 
Evolutionary Computation, vol. 6, no. 2, pp. 182-197, April 2002. 
[14] R. Alcalá, J. Alcalá-Fdez, and F. Herrera, “A proposal for the genetic 
lateral tuning of linguistic fuzzy systems and its interaction with rule 
selection,” IEEE Trans. on Fuzzy Systems, vol. 15, no. 4, pp. 616-635, 
2007. 
[15] J. Alcalá-Fdez, R. Alcalá, M. J. Gacto, and F. Herrera, “Learning the 
membership function contexts for mining fuzzy association rules by 
using genetic algorithms,” Fuzzy Sets and Systems, vol. 160, pp. 
905-921, 2009. 
[16] M. Kaya and R. Alhaji, “Utilizing genetic algorithms to optimize 
membership functions for fuzzy weighted association rules mining,” 
Applied Intelligence, vol. 24, no. 1, pp. 7-15, February 2006. 
[17] W. Wang and S. M. Bridges, “Genetic algorithm optimization of 
membership functions for mining fuzzy association rules,” Proc. of the 
7th International Conference on Fuzzy Theory & Technology, 
pp.131-134, Atlantic City, NJ, February 27-March 3, 2000. 
[18] J. Demšar, “Statistical comparisons of classifiers over multiple data 
sets,” Journal of Machine Learning Research, vol. 7, pp. 1-30, 2006. 
[19] M. Friedman, “The use of ranks to avoid the assumption of normality 
implicit in the analysis of variance,” Journal of the American Statistical 
Association, vol. 32, pp. 675-701, 1937. 
[20] P. B. Nemenyi, Distribution-free Multiple Comparisons, PhD thesis, 
Princeton University, 1963. 
[21] S. Holm, “A simple sequentially rejective multiple test procedure,” 
Scandinavian Journal of Statistics, vol. 6, pp. 65-70, 1979. 
[22] J. P. Shaffer, “Modified sequentially rejective multiple test 
procedures,” Journal of the American Statistical Association, vol. 81, 
pp. 826-831, 1986. 
[23] G. Bergmann and G. Hommel, “Improvements of general multiple test 
procedures for redundant systems of hypotheses,” In Bauer, Hommel, 
and Sonnemann, eds, Multiple Hypotheses Testing, Springer, Berlin, pp. 
100-115, 1988. 
[24] S. García and F. Herrera, “An extension on ‘Statistical comparisons of 
classifiers over multiple data sets’ for all pairwise comparisons,” 
Journal of Machine Learning Research, vol. 9, pp. 2677-2694, 
December 2008. 
The source code is available at http://sci2s.ugr.es/keel/multipleTest.zip 
 
 
