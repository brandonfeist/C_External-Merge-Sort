 
 
 
  
Abstract— Reliability of the Fuzzy Association Rules (FARs) 
extraction is a challenging research in knowledge discovery and 
data mining. Reliability refers to the trade-off between the 
prediction accuracy and the rules diversity. In this paper, an 
approach called Diverse Fuzzy Rule Base (DFRB) is proposed 
to extract the FARs which are used later to predict the future 
values. This approach also aims to ensure high quality and 
diversity of the FARs. This is achieved through four phases: 
firstly, the integration of Fuzzy C-Means (FCM) and Multiple 
Support Apriori (MSapriori) algorithms are applied to extract 
the FARs. The second phase calculates the correlation values 
for these FARs, and performs an efficient orientation for 
filtering FARs as a post-processing method. In the third phase, 
the FARs diversity is maintained through the clustering of 
FARs, based on the concept of the sharing function technique 
used in multi-objectives optimization. After that, the best and 
the most diverse FARs are evaluated and then stored in the 
Knowledge Base (KB). Finally, these FARs, stored in the KB, 
are utilized within the Fuzzy Inference System (FIS) for 
prediction. Experimental results for two case studies have 
shown that the proposed DFRB approach predicted the future 
values effectively, thus, outperforming the existing work. 
I. INTRODUCTION 
ssociation mining remains one of the most important 
techniques in Knowledge Discovery in Databases 
(KDD), increasingly attracting the attention of researchers. 
Mining of the association rules can be applied to predict the 
future value in a particular domain. Association rules can be 
constructed as: X ? Y where X is the antecedent (left hand 
side) and Y is the consequent (right hand side). The 
association rules are extracted from a database which relies 
on two metrics (interestingness measures): Minimum 
Support threshold (minsupp) and Minimum Confidence 
threshold (minconf). Since minsupp is the time frequency for 
particular item(s) that are divided by the number of 
transactions, and minconf is the percentage value of the 
support value for the antecedent and consequent together, 
divided by the support value of the antecedent part. 
Association rules mining can be divided into two main parts 
[1]: 
• Frequent item sets are found if the support value of the 
itemset is greater than or equal to minsupp. 
• Association rules are extracted if the confidence value of 
the frequent itemset is greater than or equal to minconf. 
The definition of the association rules is as follows: let 
 I ? ?i?, i?, . . , i?? be a set of distinct items (attributes), and 
 
B. I. Sowan, Student Member, IEEE, K. P. Dahal, Member, IEEE,  A. M. 
Hossain, Member, IEEE, M. S. Alam are with the School of Computing, 
Informatics and Media, University of Bradford, Bradford, BD7 1DP, UK 
(e-mails: {b.sowan; k.p.dahal; m.a.hossain; m.alam1}@Bradford.ac.uk).  
any set of items is called an itemset. Let D ? ?t?, t?, . . , t?? 
be a set of transactions database TID. Each transaction 
TID in D  consists in a set of items I,  strong association rules 
are defined in accordance to the form  X ? Y where, 
X, Y ? I and X?Y=? approve minsupp and minconf. 
Most of the common association rules algorithms are based 
on level-wises, such as Apriori [2], and others use the tree 
structure namely Frequent Pattern Growth (FP-Growth) [3]. 
As a concept derived from the association rules, Fuzzy 
Association Rule (FAR) applies a fuzzy approach to deal 
with quantitative attributes (quantitative data or crisp one) 
and to represent them in a natural and understandable 
manner. 
Fuzzy approach is widely exploited among the intelligent 
systems, since it is very simple and similar to the human 
way of thinking [4]. Furthermore, it helps to extract abstract 
patterns at a higher level than just on the data one (crisp data 
set). These are then used to transform quantitative data into 
fuzzy data through the identification of membership 
functions. The membership functions are defined using 
different methods, basically, based on human 
experience/know-how [5], [6]. However, in many occasions, 
it is too difficult to obtain the information required and the 
human experts. The Fuzzy C-Means (FCM) is a clustering 
technique commonly used to provide reliable membership 
values for constructing fuzzy sets [5]-[7] if data sets are 
available. 
The use of single minsupp for a whole database considers 
and assumes that all items in the database have the same 
frequency. However, in real applications, the database 
contains some items of a high frequency, while others are of 
a low frequency. The human expert, based on domain 
knowledge, can set minsupp for a specific value in order to 
find the frequent items. In that case, if minsupp is set too 
high it will extract a low number of frequent items. On one 
hand, the rare items will appear and cause a dilemma (called 
rare item problem). On the other hand, if minsupp is set too 
low, it will extract a high number of frequent items, which 
causes combinatorial explosions. In other words, all the 
possible associations will be found; thus, some of the items 
are uninteresting/insignificant [8]. In the literature, the rare 
item problem can be solved through the adoption of two 
methods. Firstly, the data set is divided into blocks 
according to their occurring item frequency, and then the 
association rules are extracted in each block with different 
minsupp. Secondly, the related rare items are grouped into 
one abstract item; therefore, this abstract item becomes a 
frequent one. It would not be possible for the first method to 
extract the association rules among these blocks, and the 
second method is suffering from extracting rules that involve 
Diversification of Fuzzy Association Rules to Improve Prediction 
Accuracy 
Bilal I. Sowan, Keshav P. Dahal, Alamgir M. Hossain, and Mohammad S. Alam 
A
978-1-4244-8126-2/10/$26.00 ©2010 IEEE
 
 
 
individual rare items and frequent items. To overcome the 
dilemma of rare item problem, Liu et al. [8] proposed an 
algorithm called MSapriroi using Multiple Item Support 
(MIS). However, the number of generated rules depends on 
the control parameters used. For instance, if the parameter 
values are set low, then they tend to extract a large number 
of rules, most of which are not useful. Otherwise, a small 
number of rules are generated that do not adequately cover 
the data.  
It is believed that such an approach is applied for 
extracting the FARs in order to store it in the knowledge 
Base (KB) and use it in the prediction of future values. This 
can be accomplished and achieved through FARs 
assessments, while considering the diversity within the 
FARs. The prediction system can therefore accept any input 
data to predict the output of future values. The best FARs, in 
some cases, do not always lead to good results; therefore, the 
diversified FARs can offer better results. 
In this paper, an approach called Diverse Fuzzy Rule Base 
(DFRB) is proposed which aims to extract a robust and 
diverse fuzzy rule base that enables the prediction of future 
values effectively. These fuzzy rules base are generated from 
FARs, and should be sustained and proved. The proposed 
approach facilitates the trade-off between both the prediction 
accuracy and the diversity within FARs.  
This paper is organized as follows. Section II presents the 
related works. Section III describes the proposed approach. 
Section IV reports the experimental results and evaluates the 
performance study. Finally, section V draws the conclusions. 
II. RELATED WORKS 
Mining association rules is a vital task in data mining 
research. Several algorithms and approaches are proposed 
for generating association rules which have support and 
confidence values higher than user-specified thresholds      
[9]. Similarly, there are several techniques that can be 
conducted to prune the huge number of such association 
rules and transform them into more representative ones [9]-
[11]. Marzena [9] introduced an approach to obtain 
representative rules from a large set of association rules 
using cover operator; these rules are based on satisfying the 
minsupp and minconf measures. The use of such measures to 
generate these rules could be affected at the representative 
rules level. The representative rules implicates small 
numbers of rules, which decrease the accuracy when they 
are evaluated and validated. Many techniques were offered 
by scholars suggesting objective measures to evaluat the 
association rules [12], [13]. Lenca et al. [14] proposed an 
approach for selecting the most interesting rules based on 
improvement of the objective measurements. Their approach 
used a Multi-Criteria Decision Aid (MCDA) method to 
sustain these rules for a non-expert user in a specific domain.  
A clustering technique, for association rules, was 
developed by Dechang and Xiaolin [15] based on the 
similarity of the antecedent part of the rules. The rules and 
its similarity coefficient are stored in the fuzzy simulation 
matrix to be understood by the user and then evaluated. 
However, the use of the Apriori algorithm for extracting 
these rules and the similarity of the antecedent parts only 
affects the result performance. 
Various approaches have been developed in order to extract 
FARs from quantitative data sets. These rules are presented 
in the form of “IF-Then” statements using statistical 
significant methods as minsupp and minconf. Huang et al. 
[6] proposed a fuzzy data mining approach to discover rules 
by applying the Apriori algorithm while adapting the 
discovered rules for the training Adaptive Network based on 
Fuzzy Inference System (ANFIS). The approach is applied 
in the human resources department for predicting future 
employee performance, in either suitable projects or 
positions. This approach [6] was tested for a small data set 
with some noise. It uses human expertise/experience (know-
how) to define the membership functions. It could be 
adapted for a small data set, but it is not feasible for large 
data sets. An approach was implemented by Lu et al. [5] 
which compared two methods for the prediction of one 
output value, this was applied to Abalone data set taken from 
the University of California, Irvine (UCI) of Machine 
Learning Repository. In the first method, FCM and Apriori 
algorithms were used to extract FARs and then a Genetic 
Algorithm (GA) was applied for tuning the fuzzy sets. The 
second method proceeded as the first, but it used variable 
thresholds in the prediction. The prediction accuracy in the 
first approach was 72.16% for training and 70.56% for 
testing data; while the second approach obtained 72.55% for 
training and 71.06% for testing data.  
Associative classification concept has also been widely 
investigated. Pach et al. [16] proposed a fuzzy associative 
classification technique. This technique considers both rules: 
the interpretability and classification accuracy, but it used 
the Apriori approach for extracting frequent items.  
Most of the above mentioned approaches suffer from one 
or more of the following problems: 
• The single minsupp approach is not fair when using a 
single minsupp for the whole data. Single minsupp 
assumes the same frequency for all items in the data. In 
this manner, the real application data possesses some items 
with a high frequency; while others possess a low 
frequency. Therefore, by using a single minsupp some of 
the significant association rules could be missed.    
• The use of such an objective measure to only assess the 
rules is not effective. It depends on selecting and tuning a 
parameter threshold to extract the best rules. 
• Association rule mining techniques produce many 
association rules that will affect the prediction results. 
• Extraction of representative rules may assist in 
understanding the perspective points of the user. Yet, it is 
not dependable and coverable in case of prediction 
accuracy.  
III. THE PROPOSED DIVERSE FUZZY RULE BASE APPROACH 
The proposed Diverse Fuzzy Rule Base (DFRB) approach 
considers both the trade-off between the prediction accuracy 
and the diversity of FARs to provide robustness in the fuzzy 
rules base. This approach is based on selecting the strong 
 
 
 
FARs in order to increase prediction accuracy and the FARs 
diversity to maintain more representative rules. As described 
in Fig. 1, the proposed approach consists of four phases; 
each phase is detailed as follows: 
 
 
 
 
 
 
 
 
   
 
 
 
  
 
 
 
 
 
 
 
  Fig. 1. The proposed DFRB approach phases. 
 
First phase: Generating the FARs based on FCM and 
MSapriori algorithms. FCM is employed as an automatic 
system which transforms the quantitative data set into fuzzy 
sets (terms). The MSapriori algorithm is applied to extract 
the FARs by setting the control parameters, used in 
MSapriori, at low values. Thus, the number of generated 
FARs increases. 
 
Second phase: Calculating the correlation coefficient value 
for each FAR. Correlation values are calculated for each of 
the FARs using equations (1) and (2). One of the correlation 
measures is used to evaluate the importance and strength of 
the association rule [16]-[18] in order to filter a large 
number of association rules over different objective 
measures.  
 
corr?X. FS ? Y. FS? 
 
? supp?X. FS ? Y. FS? ? supp?X. FS?. Supp?Y. FS?
?supp?X. FS?. ?1 ? supp?X. FS??. supp?Y. FS?. ?1 ? supp?Y. FS??
 
                                                                                          (1) 
 
where, corr?X. FS ? Y. FS?: correlation value of the FAR 
?X. FS ? Y. FS?, the interval of its range is                            
[-1, 1]. supp?X. FS ? Y. FS?: support value of the FAR, 
whereas the FARs are formed from the frequent 
itemset ?X. FS, Y. FS?. supp?X. FS?: support value of the “IF” 
as part of the FAR. supp?Y. FS?: support value of the “Then” 
part of the FAR. 
 
 ??????. ??? ? ?    ?   X.FS?N??? N                                                              (2) 
                                                        
where, supp?X. FS?:support value of a frequent item ?X. FS?. 
The following example explains the calculation of the 
correlation value. Let  r1: X. Low ? Y. Medium be a FAR 
and its data set shown in Table I. 
 
TABLE I 
FUZZY DATA SET 
X. Low Y. Medium 
0.3 0.7 
0.9 0.5 
0.8 0.2 
0.7 0.9 
 
corr?X. Low ? Y. Medium? 
 
? 0.3625 – ?0.5075?. ?0.3975???0.5075?. ?0.4925?. ?0.3975?. ?0.6025? ? 0.6571 
 
Supp??. ??? 
 
? ?0.3?. ?0.7? ? ?0.9?. ?0.5? ? ?0.8?. ?0.2? ? ?0.7?. ?0.9?4 ? 0.3625 
 
The FARs with positive correlation values are subsequently 
considered, they are grouped according to their length 
size K?. The FAR length is determined based on the number 
of attributes included. For example,  
 
group1 ?1: ?. ??? ? ?. ??? 
 ?2: ?. ??? ? ?. ?????? 
group2 ?1: ?. ??? ??? ?. ?????? ? ?. ??????        
            ?2: ?. ?????? ??? ?. ?????? ? ?. ???? 
 
The correlation value is normalized for each FAR within the 
group as follows: 
1. Determine the maximum correlation value MaxCorrK 
2. Divide each FAR correlation value by MaxCorrK 
For example, MaxCorrK ? 0.3 and two FARs in the group                  
                         
                         ???????????? ? 0.3=1 
 ???????????? ? 0.2=0.66 
 
This normalization is applied to rescale the correlation value 
for each FAR in each group. The reason behind the length 
size is that the longer the FAR size increases the smaller the 
correlation value is. As a result, this assists in selecting the 
best FAR from each group that satisfies the minimum 
correlation threshold minCorr. 
The motivations behind using the correlation measure are: 
• The tuning and setting the minsupp and minconf  have 
some difficulties [16], [19]. 
Third Phase 
Group Rules 1 
Diversity Rule 1 Diversity Rule n 
Best Rules 1 Best Rules n 
Prediction 
Diversed Rules 
Fuzzy Inference System 
Knowledge Base 
Group Rules n 
First Phase 
Second Phase 
Calculate Correlation Value 
Fourth Phase 
Fuzzy Association Rules 
 
 
 
• The correlation measure is used as a filtration for the 
generated FARs after using MIS as minsupp and minconf. 
• The correlation measure is robust compared with the 
confidence measure of equation (3) (as mentioned in [20]).  
 
   Conf?X. FS, Y. FS? ? S????X.FS,Y.FS?S????X.FS?                                       (3) 
Third phase: Finding the diversity FARs by calculating the 
distance between the FARs. A diversity of FARs is 
calculated for each of the FAR groups, it can be found 
through clustering FARs within each group as follows: 
1. The FARs are clustered based on their distance using 
equations (6) and (7). 
2. Clustering the FARs based on their distance, hence 
the number of FARs and their similarities can be 
identified within a cluster and other clusters using 
equations (4) and (5); these equations were applied 
[21] to maintain diversity within the sharing function 
technique in multi-objective optimization. 
 
Range? ? ? Accum?Distance???N???                                              (4) 
where, Range?: the value that can find out whether the 
cluster contains only one FAR (Range? enumerates the 
number of rules similar to a rules i); if the Range? value 
equal to 1 or the cluster contains more than one FAR 
(crowded cluster) if the  Range? value greater than 1. 
 Accum?Distance???: the accumulative distance between 
i  and all other FAR in the same group, whereas i ? FARs. 
 
 
Accum?Distance??? 
? ?1 ? ?
D???????
? ? , if     Distance ? ?;
0         , otherwise.
                             (5) 
where, ?: the threshold value that represents the cluster size 
(cluster radius), its range is in the interval [0.1, 1]. 
Distance??: the distance between two individual FARs i 
and j, whereas i, j ? FARs. Measuring the distance between 
two FARs is the main part at this phase using equations (6) 
and (7); these FARs can be clustered based on their 
similarities. Actually, the similarity between two FARs can 
be found as follows: 
 
S?? ? ?RAFS??RAFS??  ?RAFS??RAFS??                                                  (6) 
where, S??: the similarity between two FARs(i and j), the 
interval of its range is [0, 1]. RAFS? (Rule Attribute Fuzzy 
Set): the fuzzy set concerning an attribute within the FAR?. 
RAFS?: the fuzzy set concerning an attribute within the FAR?. 
Consequently, the distance can be calculated using equation 
(7).  
 
Distance?? ? 1 ? S??                                                            (7) 
The following example illustrates the calculation of the 
distance. Assuming the two rules FAR?  and  FAR? then: 
 
             FARi: ?. ??? ??? ?. ?????? ? ?. ???  
     FARj: ?. ?????? ??? ?. ?????? ? ?. ???. 
 
The similarity between FAR?  and  FAR? can be calculated by 
using equation (6): 
 
S?? ?
 |2|
 |4| ? 0.5 
       
The numerator 2 comes from FAR?. ?Z. Medium? similar to 
FAR?. ?Z. Medium?  and  FAR?. ?Y. Low? similar 
to FAR?. ?Y. Low?, whereas denominator 4 comes from all 
attributes fuzzy sets  
FAR?,?. ?X. Low, X. Medium, Z. Medium, Y. Low? 
Once the similarity between FAR?  and  FAR? is calculated, 
then the distance can be found by using equation (7), below: 
 
Distance?? ? 1 ? 0.5 ? 0.5 
 
Fourth phase: Selecting the best FARs of the highest 
correlation values and the diverse FARs; then, store these 
FARs in the Knowledge Base (KB) to be used by the Fuzzy 
Inference System (FIS) for a prediction. 
The approach for extracting robust and diverse fuzzy rule 
base is summarized in Fig. 2: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
     Fig.2. Extraction of robust and diverse fuzzy rule base algorithm. 
 
Input: Fuzzy Association Rule (FAR), Minimum Correlation 
threshold value minCorr, ? value, Number of the Diversed 
Rules (DR). 
 
Output: Robust and Diverse Fuzzy Rule Base. 
 
Method:  
1. Calculate the correlation value corr for each FAR? 
2. Divide FAR into a group based on their length size K? 
3. Sort (rank) FAR automatically in each group K? based 
on their highest correlation value. 
4. Select the best FAR from each group K? 
For each K? 
      IF corr? ????? ? ??????? 
           ???????? ?  ???? 
      EndIF 
EndFor 
5. Identify the diversed FARs for each group ?? 
                N_??????_1=counting the number of ???? of  
                                        ??????(?????? ????? 1). 
                ?? ? ?_??????_1. 
 For each K?   
        IF ?????????Range???????? ? 1? 
             IF ?corr? ????? ? ???????? 
                  While (?????????????? ? ??) 
                            IF ?Range??????? ?? 1? 
                                 ???????????? ?  ????   
                            EndIF         
                  EndWhile 
             EndIF 
        EndIF 
 EndFor 
 
 
 
Fig. 3 shows an example of the selection of the fuzzy rule 
base with robustness and diversity. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  Fig.3. Selection of the fuzzy rule base with robustness and diversity. 
IV. EXPERIMENTAL RESULTS AND PERFORMANCE STUDY 
The proposed DFRB approach has been applied in two case 
studies in order to evaluate its effectiveness. The first case 
study is a quantitative road traffic data set, which was 
considered in our previous work [22]. The second case is a 
quantitative data set called Abalone. The road traffic data 
has been generated using a traffic simulation model (the 
METANET macroscopic flow model) [23]. Each record in 
the data set, as shown in Table II, consists of: 
• Traffic state, represented by: traffic demands of road 1 (the 
number of vehicles that use road 1), traffic demands of 
road 2 (the number of vehicles that use road 2), traffic 
density of road 1 (the number of vehicles using road 1 per 
km), and traffic density of road 2 (the number of vehicles 
using road 2 per km).  
• The Predicted Average Total Time (ATT) required for a 
vehicle to cross the traffic network. 
 
Fig. 4 shows information about the input of the road traffic 
data set, whereas the statistical information regarding this 
data set is shown in Table III. While Figs. 5 and 6 show the 
analyses of the data set, which clarify the distribution and 
consistency. 
 
 
      
         Fig. 4. Information related to the input road traffic data set. 
 
 
TABLE II 
PART OF THE ROAD TRAFFIC DATA SET 
Case  
No. 
Demand    
1 
Demand 
2 
Density  
1 
Density  
2 
ATT 
1 6030 316 5 87 629.7 
2 1147 1638 62 50 414.4 
3 1277 797 10 14 233.5 
4 4061 1198 38 75 581.2 
: : : : : : 
      
 
TABLE III 
STATISTICAL INFORMATION OF THE ROAD TRAFFIC DATA SET 
 Demand 
1 
Demand 
2 
Density  
1 
Density  
2 
ATT 
Min 185 123 1 1 222.8 
Max 6986 3498 99 99 729.8 
Mean 3670.110 1640.45 48.85 50.32 515.7 
SD 2060.326 919.69 28.919 27.376 109.9 
Correl 0.438 0.257 0.398 0.527 1 
 
 
 
       Fig. 5. Road traffic data set analysis for Demand 1 and 2. 
 
Fig. 5 shows the analysis of the road traffic data set. A 
boxplot (also known as a box-and-whisker diagram) is a 
suitable method which graphically describes groups of 
numerical data, such as the: minimum value, lower quartile 
(Q1), median (Q2), upper quartile (Q3), and the maximum 
value. Therefore, a boxplot is used for detecting outlier 
(noisy) data. The data set is found to be consistent and 
without any outlier data. Also all fields (attributes) were 
distributed in different ranges of value; however, our aim is 
to find out if there were any outlier cases for each separate 
field.  
 
Demand 1 Demand 2
0
1000
2000
3000
4000
5000
6000
7000
Va
lu
es
Density 1 
Density 2 
Road 1 
Road 2 
Group1 of FARs, length size  K? ? 2 ???? value Range?
?. ?????? ? ?. ???? 1 1 
?. ??? ? ?. ??? 0.9 1 
?. ???? ? ?. ???? 0.8 1 
?. ??? ? ?. ?????? 0.7 1 
?. ?????? ? ?. ??? 0.5 1 
?. ???? ? ?. ??? 0.4 1 
 
Group 2 of FARs, length size  K? ? 3 ???? value Range?
?. ???? ???  ?. ?????? ? ?. ???? 1 1 
?. ??? ??? ?. ?????? ? ?. ??? 0.8 1.7 
?. ?????? ???  ?. ??? ? ?. ??? 0.6 2 
?. ??? ??? ?. ??? ? ?. ?????? 0.5 1 
?. ???? ???  ?. ???? ? ?. ?????? 0.4 1.8 
?. ??? ???  ?. ???? ? ?. ?????? 0.4 1 
 
 
Assuming that minCorr=0.7, and DR=1 
 
 
 
 
 
 
 
 
 
 
?. ?????? ? ?. ???? 
?. ??? ? ?. ??? 
?. ???? ? ?. ???? 
?. ??? ? ?. ?????? 
?. ???? ???  ?. ?????? ? ?. ???? 
?. ??? ??? ?. ?????? ? ?. ??? 
?. ??? ??? ?. ??? ? ?. ?????? 
 
 
 
We have divided the road traffic data into 75 records for 
training and 25 records for testing. 
The Abalone data is taken from the University of 
California, Irvine (UCI) of Machine Learning Repository 
[24]. We have divided the Abalone data into 3133 records 
for training and 1044 records for testing. 
The Proposed approach has been applied to predict the 
ATT in road traffic data and the Abalone ring that represents 
the Abalone age in Abalone data.  
For the purpose of evaluation and validation, prediction 
quality is assessed using one of the statistical measures 
called Mean Absolute Percentage Error (MAPE), 
highlighted in equation (8). It is defined as follows: 
 
 
MAPE ? ?? ?  ??
???????
???
? ? 100???                                      (8)    
                                 
 
where, PV: the predicted output value, RV: the real output 
value, N: Total number of the comparison record. 
 
Table IV shows the sensitivity of MAPE adapting 
minCorr over different numbers of FARs. On the other hand, 
Table V shows the sensitivity of MAPE adapting minCorr 
over different numbers of FARs and the diverse FARs, 
where ? ? 0.3 in both tables. The results shown in Tables 
IV and V clearly demonstrate that MAPE is not affected 
when the diverse FARs are added. This is explained through 
the usage of an efficient and effective technique to select the 
diverse FARs. 
 
TABLE IV 
THE SENSITIVITY OF MAPE ADAPTING MINCORR 
MAPE Number of FARs minCorr 
22.2% 152 0.4 
9.3% 88 0.5 
8.1% 53 0.6 
10.6% 29 0.7 
14.2% 16 0.8 
23.6% 8 0.9 
 
TABLE V 
THE SENSITIVITY OF MAPE ADAPTING  
MINCORR AND DIVERSED FARS 
MAPE Number of FARs minCorr 
22.2% 152 0.4 
9.3% 89 0.5 
8.1% 54 0.6 
10.6% 31 0.7 
14.2% 18 0.8 
23.6% 10 0.9 
 
Table VI represents the sensitivity of MAPE adapting ? 
value (cluster size) over different numbers of diverse FARs 
when considering 53 FARs. It can be easily noted that when 
the value of ? is less than 0.3 or greater than 0.6, it does not 
affect MAPE, however, when it is between 0.3 and 0.6, 
MAPE changes slightly. In addition, when the value of ? is 
between 0.3 and 0.6 then several numbers of diverse FARs 
are generated which slightly affect the MAPE. However, 
when the selection of ? is less than 0.3, each cluster may 
include one FAR; and when the value of ? is greater than 
0.6, the cluster may include all FARs. 
 
TABLE VI 
THE SENSITIVITY OF MAPE AND ? VALUE  
OF MINCORR= 0.6 WITH DIVERSED FARS 
MAPE Number of diversed FARs ? vlaue 
8.1% - 0.1 
8.1% - 0.2 
8.1% 1 0.3 
8.1% 3 0.4 
9.9% 4 0.5 
9.9% 2 0.6 
8.1% - 0.7 
8.1% - 0.8 
8.1% - 0.9 
8.1% - 1 
 
Fig. 6 shows the sensitivity of the MAPE and minCorr for 
the brute-force approach (the diversity is employed in all 
FARs together of different K? (length size of FAR)). The 
graph shows that when minCorr is 0.49, the minimum 
MAPE is 11.2%, and it contains rules that cover most cases. 
It is noted that as minCorr decreases from 0.49, the MAPE 
increases. This is explained by producing a large number of 
rules (decrease in minCorr is accompanied by an increase in 
the uninteresting FARs to cause noise for the FIS). 
Moreover, it is observed that when the correlation value 
increases beyond 0.49, the MAPE also increases. Again this 
is explained by producing a small number of FARs, which 
do not give robust results for the FIS (the increase in 
minCorr implies a decrease in the number of relevant rules). 
 
 
 
      Fig 6. The sensitivity of MAPE and minCorr. 
 
Table VII depicts the sensitivity of MAPE over different 
numbers of FARs and diverse FARs, where ? ? 0.3 and 
minCorr = 0.49, which illustrates the brute-force approach. 
This approach produces a good result; its MAPE is 
acceptable as compared with the employed diversity in 
FARs with different individual K? (length size of FAR), as 
shown in Table V.  The diversity is applied in FARs with 
different K?; they produce 8.1% MAPE and generate a 
slightly high number of FARs when compared with the 
brute-force approach, which produces 11.2% MAPE and less 
numbers of FARs. 
 
0
2
4
6
8
10
12
14
16
18
20
0.45 0.46 0.47 0.48 0.49 0.5 0.51 0.52 0.53 0.54 0.55
M
A
P
E
minCorr
 
 
 
TABLE VII 
THE SENSITIVITY OF MAPE OVER DIFFERENT  
NUMBERS OF FARS AND DIVERSED FARS 
MAPE Number of diversed FAR Number of FARs 
11.2% 0 11 
11.2% 1 11 
11.2% 2 11 
18.3% 3 11 
 
Other criteria measures are applied in this study to 
evaluate the predicted accuracy, are as follows [25], [26]: 
 
•  Mean Absolute Error (MAE) 
 
  
        ??? ? ?? ? |? ?? ? ? ??|??                                  (9) 
 
• Normalized Mean Absolute Error (????)            
                  
         
            ???? ? ? |???????|????? ??????? ? 100%                 (10) 
 
• Normalized Root Mean Square Error (?????)     
  
 
           ????? ? ?
?
? ? ??????????????
?
? ? ???????
? 100%        (11) 
 
 
• Pearson Product-Moment Correlation Coefficient ? 
(Pearson ?) 
 
        ? ? ? ????????????????????????????
?? ????????????????? ? ?????????????????
               (12) 
 
where 
??: The predicted output value. 
??: The real output value. 
?: Total number of the comparison record. 
??????: The mean of real output. 
??????: The mean of predicted output. 
?????:  Uncorrelated ? 1 ? ?. 
 
These essential measures are concerned with the prediction 
model. ????, ????, ?????, ????? and Pearson 
correlation coefficient (Pearson ?) are the most widely used 
and important measures to evaluate the prediction method 
[25], [26]. The Pearson r is used to measure the relationship 
between two variables (the predicted and the real output 
value). The range of Pearson r  correlation varies from -1 to 
+1. When r equals 0, the predicted and real output values 
are uncorrelated. When r equals 1, the predicted and real 
output values are approximately the same. And when r
equals -1, the predicted and real output values are 
approximately the same with opposite directions.  The 
values of such criteria are show in Table VIII. 
TABLE VIII 
CALCULATION OF THE EVALUATION CRITERIA 
Abalone data Road traffic data Measure Criteria 
25.5% 8% ????
2.78%          32.4% ??? 
27.8% 6.7%, ????
37.2 9.5%, ?????
0.51 0.05 ?????
 
Table VIII shows the impact of using different criteria 
measurements. It is noted that different criteria yield 
different values. This is attributed to the different ranges of 
values in each data set. 
The results are compared to those of the integrated Fuzzy 
C-Means (FCM) and Apriori approach. Prediction quality is 
assessed using the MAPE in equation (8). The experimental 
results on the Abalone and road traffic data are summarized 
in Table IX. 
 
TABLE IX 
CALCULATION OF MAPE 
FCM and DFRB FCM and Apriori  Data set 
25.5% 29.4% [5] Abalone  
8.1% 9.1% [23] Road traffic  
 
Table IX presents the results from using two different 
methodologies: first, it concerns the integrated FCM and 
Apriori; while, the second deals with FCM and DFRB. In 
each methodology, the MAPE is calculated, which is the 
result of the sensitivity improvement of future value 
predictions by minimizing the MAPE using the proposed 
DFRB approach. The result was compared with reported 
work, and it achieved a better result for the DFRB than the 
results in [5], [22]. It is noted that the result in [5] was 
generated by two approaches. The first approach applied 
FCM and Apriori algorithms, its MAPE was equal to 29.4% 
(its equivalent MAE was 3.77). While the value of MAPE 
using the proposed DFRB is equal to 25.5% (its equivalent 
MAE was 2.78). The second approach applied FCM and 
Apriori algorithms, and then a Genetic Algorithm (GA) was 
employed in order to optimize and minimize the MAE. The 
MAE, based on this approach, is equal to 1.77 (it was not 
mentioned how many runs were experimented for the GA to 
optimize the MAE in [5]).  
The proposed DFRB produces a good result and can be used 
with a wider data set (even when the data set contains noisy 
data). This provides more generalized prediction method. 
The large differences in MAPE, between the two data sets 
used in the experiment, refer to the high number of noisy 
data and high number of attributes existing in the Abalone 
data set. However, the results are still better than the 
previous work, shown in Table IX. 
V. CONCLUSION 
This paper proposed the Diverse Fuzzy Rule Base 
approach which focused on the Fuzzy Association Rules 
extraction and effective selection to predict the future values. 
The approach concerns both the best and diverse FARs 
through its capability in filtering them in order to extract the 
best FARs, thus reflecting an increase in the prediction 
 
 
 
accuracy. It generates the FARs, and then calculates the 
correlation coefficient value for each FAR. After that, it 
clusters the FARs to determine its diversity while selecting 
the best FARs (with a higher correlation value) and diverse 
FARs for prediction using FIS. The proposed approach 
expresses and maintains the trade-off between both the 
prediction accuracy and the FARs diversity. The approach 
was employed for two case studies: real data set concerning 
the road traffic domain, and the Abalone data set. It is noted 
that the proposed DFRB approach offers higher prediction 
accuracy as compared to other approaches reported in the 
literature. In the future, the associative classification 
techniques will be investigated to explore further levels of 
accuracy. 
   REFERENCES 
[1] R. Agrawal, T. Imielinski, and A. Swami, "Mining association rules 
between sets of items in large databases," In Proceeding of the 1993 
ACM SIGMOD International Conference on Management of Data, 
Washington, DC, 1993, pp. 207-216. 
[2] R. Agrawal and R. Srikant, "Fast algorithms for mining association 
rules," In Proceeding of the 20th International Conference on Very 
Large Data Bases, 1994. pp. 487-499. 
[3] H. Jiawei, P. Jian, and  Y. Yiwen, "Mining Frequent Patterns Without 
Candidate Generation," In Proceeding of  the ACM SIGMOD 
International Conference on Management of Data, Dallas, USA, 2000, 
pp. 1-12. 
[4] M. Zhang and C. He, "Survey on Association Rules Mining 
Algorithms," Advancing Computing, Communication, Control and 
Management, Lecture Notes in Electrical Engineering (LNEE), 
Springer-Verlag, vol. 56, pp. 111-118, 2010. 
[5] J. Lu, B. Xu, and J. Jiang, "A prediction method of fuzzy association 
rules," In Proceeding of  IEEE International Conference on 
Information Reuse and Integration IRI, 2003, pp. 98-103. 
[6] M. J. Huang, Y. L. Tsou, and S.C. Lee, "Integrating fuzzy data mining 
and fuzzy artificial neural networks for discovering implicit 
knowledge," Knowledge-Based Systems, vol. 19, no. 6, pp. 396-403, 
2006. 
[7] J. C. Bezdek, Pattern Recognition with Fuzzy Objective Function 
Algorithms. New York, NY: Plenum Press, 1981. 
[8] B. Liu, W. Hsu, and Y. Ma, "Mining association rules with multiple 
minimum supports," In Proceeding of the fifth ACM SIGKDD 
international conference on Knowledge discovery and data mining, 
1394 New York, NY, USA, 1999, pp. 337-341. 
[9] K. Marzena, "Representative Association Rules," In Proceedings of 
the Second Pacific-Asia Conference on Research and Development in 
Knowledge Discovery and Data Mining PAKDD-98, Lecture Notes in 
Computer Science (LNCS), vol. 1394, Springer-Verlag, pp. 198-209, 
April 1998. 
[10] M. Kryszkiewicz, "Closures of Downward Closed Representations of 
Frequent Patterns," in Proceedings of the 4th International Conference 
on Hybrid Artificial Intelligence Systems HAIS 2009, Lecture Notes 
in Artificial Intelligence (LNAI), vol. 5572, Springer-Verlag, pp. 104-
112, June 2009.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[11] M. Kryszkiewicz and H. Rybinski, "Incomplete database issues for 
representative association rules," Lecture Notes in Computer science 
(LNCS), vol. 1609, Springer-Verlag, pp. 583-591, June 1999 
[12] T. T. Nguyen Le, H. X. Huynh, and F. Guillet, "Finding the Most 
Interesting Association Rules by Aggregating Objective 
Interestingness Measures," Lecture Notes in Artificial Intelligence 
(LNAI), vol. 5465, Springer-Verlag, pp. 40-49, 2009. 
[13] E. Suzuki, "Compression-Based Measures for Mining Interesting 
Rules," Lecture Notes in Artificial Intelligence (LNAI), vol. 5579, 
Springer-Verlag, pp. 741-746, 2009. 
[14] P. Lenca, P.  Meyer, B. Vaillant, S. Lallich, "On selecting 
interestingness measures for association rules: User oriented 
description and multiple criteria decision aid," European Journal of 
Operational Research, vol. 184, no. 2, pp. 610-626, 2008. 
[15] P. Dechan and Q. Xiaolin, "A New Fuzzy Clustering Algorithm on 
Association Rules for Knowledge Management," Information 
Technology Journal, vol. 7, no. 1, pp. 119-124, 2008. 
[16] F. P. Pach, A. Gyenesei, and J. Abonyi, "Compact fuzzy association 
rule-based classifier," Expert Systems with Applications, vol. 34, no. 
4, pp. 2406-2416, 2008. 
[17] M. Steinbach, P. N. Tan, H. Xiong, and and V. Kumar, "Objective 
measures for association pattern analysis," In Prediction and 
discovery: AMS-IMS-SIAM Joint Summer Research Conference, 
Machine and Statistical Learning, Snowbird, Utah: American 
Mathematical Society, vol. 443, p. 205, 2007. 
[18] P. N. Tan, V. Kumar, and J. Srivastava, "Selecting the right objective 
measure for association analysis," Information Systems, vol. 29, no. 4, 
pp. 293-313, 2004. 
[19] O. R. Zaiane and M.-L. Antonie, "On pruning and tuning rules for 
associative classifiers," Lecture Notes in Artificial Intelligence 
(LNAI), vol. 3683, Springer-Verlag, pp. 966-973, 2005. 
[20] M. Khan, M. Muyeba, and F. Coenen, "Mining Fuzzy Association 
Rules from Composite Items,"  Artificial Intelligence in Theory and 
Practice II, vol. 276, Springer-Verlag, pp. 67-76, 2008. 
[21] K. Deb, Multi-objective optimization using evolutionary algorithms. 
Chichester, UK: Wiley, 2001. 
[22] B. Sowan B., K. P. Dahal, A. M. Hossain, and K. Almejalli, 
"Knowledge Discovery based on Integrated Fuzzy and Apriori 
Approach for Prediction,". In Proceeding of the International 
Conference on Software, Knowledge, Information Management and 
Applications (SKIMA’2009), Fes, Morocco, 2009, pp. 70-77. 
[23] A. Messmer and M. Papageorgiou, "METANET: A macroscopic 
simulation program for motorway networks," Traffic Engineering and 
Control, vol 31, no (8/9), pp. 466–-470, 1990. 
[24] C. L. Blake and C. J. Merz, UCI Repository of Machine Learning 
Databases [Online]. Irvine, CA: University of California, Department 
of Information and Computer Science, 1998. 
 Available: http://www.ics.uci.edu/~mlearn/MLRepository.html 
Accessed: August  2009. 
[25] S. Han, S. M. Schneider, and R.G. Evans, "Evaluating Cokriging for 
Improving Soil Nutrient Sampling Efficiency," Transaction-American 
Society of Agricultural Engineers (ASAE), vol. 46, no. 3, pp. 845-
849, 2003. 
[26] Quek, C., M. Pasquier, and B. B. S. Lim, "POP-TRAFFIC: a novel 
fuzzy neural approach to road traffic analysis and prediction," IEEE 
Transactions on Intelligent Transportation Systems, vol. 7, no. 2, pp. 
133-146, 2006. 
 
 
 
 
