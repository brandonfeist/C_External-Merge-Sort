Hiding Sensitive XML Association Rules via Bayesian Network 
  
 
Khalid Iqbal 
Department of Computer Science 
Shaheed Zulfikar Ali Bhutto Institute 
of Science and Technology 
(SZABIST) 
Islamabad, Pakistan 
mykhalidiqbal@yahoo.com 
Dr. Sohail Asghar 
Center of Research in Data Engineering 
(CORDE) 
Mohammad Ali Jinnah University 
Islamabad, Pakistan 
sohail.asghar@Jinnah.edu.pk 
Simon Fong 
Department of Computer and 
Information Science 
Faculty of Science and Technology 
University of Macau 
Macau SAR 
ccfong@umac.mo 
 
 
Abstract— Privacy Preserving Data Mining (PPDM) is 
receiving a lot of attention recently by researchers from 
multiple domains, especially in Association Rule Mining. The 
outputs of Association Rule Mining often involve values of 
attributes that can be used to characterize the identities of the 
users. The relations between antecedents and consequents are 
also explicitly displayed. The purpose of preserving association 
rules is to minimize the risk of disclosing sensitive information 
to external parties. In this paper, we proposed a PPDM model 
for XML Association Rules (XARs). The proposed model 
identifies the most probable items called ‘sensitive items’, and 
to modify their original data sources, so that the resultant 
XARs can have higher accuracy and stronger reliability. Such 
reliability is not addressed before in the literature in any kind 
of methodology used in PPDM domain and especially in XML 
association rules mining. Thus, the significance of the 
suggested model sets to open a new research dimension to the 
academia in order to control the sensitive information in a 
more unyielding line of attack. 
Keywords-component; formatting; style; styling; insert (key 
words) 
I.  INTRODUCTION 
In data mining, trends and patterns are identified on a 
huge set of data to discover knowledge. In such analysis, 
varieties of algorithms exist for extracting knowledge such as 
clustering, classification and association rule mining. Thus, 
association rules mining is one domain for delivering 
knowledge on complex data. Moreover, the basis of the 
discovered association rules is usually determined by the 
minimum support s% and minimum confidence c% to 
represent the transactional items in database D. Thus, it has 
the implication of the form AB, where A is the antecedent 
and B is the consequent. The problem with such display of 
rules is the disclosure of sensitive information to the external 
part when data is shared. Hence Privacy Preserving in Data 
Mining (PPDM) related to Association Rules emerges. 
In PPDM, Sensitive information is controlled with the 
help of identification of sensitive item(s) or sensitive rules. 
The question is how to select or identify the sensitive 
item(s)? In literature, various methodologies, such as in [2, 3, 
4, 5, 6], are proposed by the researchers. The problem with 
these techniques is generation of sensitive rules with the use 
of antecedent and consequent while a number of techniques 
use the assumption based on sensitive item(s) identification 
after transformation of database. Furthermore, this act raises 
another question that whether the assumed or the identified 
item is estimated with reliability to modify the original data 
source? Thus, all these questions need to be answered for the 
more accurate results for such NP-hard problem [7]. 
In order to tackle these research questions, Bayesian 
network [8, 10] is adopted here in our method, because of its 
reliability. The problem again stood up because in most 
areas, a lot of works have been proposed especially in rule 
mining. This question has been solved through XML which 
is used for interchange of information over the web and may 
have information disclosure in the form of association rules. 
In such a case, XML association rules can be found in 
literature as in [1] but the security issue of XML Association 
Rules (XARs) has not been studied. Thus we focus to 
generate controlled XARs with high accuracy and reliability. 
In this scenario, we use K2 algorithm [8] to generate 
Bayesian Network (BN) based on XML document with 
reliability and accuracy. From the same XML documents, 
XARs are generated using the apriori algorithm [9] based on 
the original and modified XML transactional itemset. As K2 
algorithm [8] generates BN probabilistically using Bayesian 
approach, so we prepare a Conditional Probability Table 
(CPT) for the occurrence of each item. This table is later 
used for the identification of sensitive item that has the 
maximum conditional probability which shows its highest 
occurrence among relation measurement of transaction 
items. Thus this item is used to modify only the more than 
one largest item based transactions which is not dominant to 
the others. Such modified database is D’, from which XARs 
are generated. 
The remainder of the paper is structured as follows. 
Section II provides a literature review on PPDM, XARs and 
BN. Section III presents the proposed PPDM model while 
Experimental Results are shown in section IV. Finally, 
section V concludes and mentions about the future work 
 
 
 
 
- 466 -
II. LITERATURE REVIEW 
With the widespread and escalating increases in the 
digital data globally, privacy issues got the attention of the 
researchers in different domains. Therefore, we focus the 
privacy issues of association rule mining when sharing 
information between parties. The objective of privacy 
preservation of association rules is to discover valuable, non-
obvious information from the large databases efficiently. As 
a result, the literature review is given on privacy risks 
minimization in association rules in a reliable way. 
The reality of information sharing involves disclosing 
risks; thus, Dasseni et al. [2] investigated confidentiality 
issues regarding association rules. The reason to investigate 
this issue is the disclosure risk involved in some of the 
association rules which are above the privacy threshold. This 
disclosure risk needs to be resolved and needs to be hidden 
the sensitive information revealed through association rules. 
Therefore, a problem is formulated using association rules to 
address and hide the disclosed information. Such formulation 
considers a database D from which the relevant rules are 
mined and Ri is the subset of R; where Ri represent the 
sensitive information. In such a case, database D needs to be 
transformed into modified database called D’. This 
transformed database is used to generate R with an exception 
of Ri. 
To provide a solution, two approaches are presented to 
hide Ri such as hiding frequent sets at source to prevent the 
generation of Ri and bring down the threshold values such as 
support and confidence. 
As an association rule AB has a set of antecedent and 
consequent represented by A and B respectively. Moreover, 
the confidence of AB can be termed as 
Conf(AB)=Supp(AUB)/Supp(A). This relation shows the 
dependency of confidence on Support. Therefore, three 
strategies with five assumptions are proposed in [2]. 
• Decrease the support of the rule based on 
antecedent or consequent.  
• This strategy has two cases. 
o Partially supported transactions which 
cause to increase the support using the 
antecedent.  
o Fully supported transactions that maintain 
both the antecedent and consequent causes 
to decrease the support of rule using the 
consequent.  
Hence, the purpose of all these strategies is to preserve 
the sensitive information from being disclosed by modifying 
database based on single element modification of either an 
antecedent or consequent. The proposed work is simple and 
can be generalized with an importance of reducing the 
disclosed information with the help of support and 
confidence. Also, this approach does not control the side 
effects after the modification of database. Moreover, it does 
not provide a criterion for the identification of sensitive 
item(s) in the antecedent or consequent existing in a rule. 
Furthermore, Guo proposed a framework by 
reconstructing the data for hiding the sensitive rules [3]. 
They formulated a problem based on transactional database 
D from R rules are generated with MST (Minimum Support 
Threshold) and MCT (Minimum Confidence Threshold). In 
R, Rh sensitive rules exists such that Rh ? R. Therefore, Rh 
represents the sensitive association rules disclosing private 
information to public and need to be secured. In such 
situation, the original databaseD is changed to the released 
database D’. 
From D’, R?Rh rules are mined under the same MST and 
MCT. Therefore to stop exposing the sensitive information 
through rules, the framework is divided into three phases as 
Frequent Set Mining (FS), Perform Sanitation Algorithm and 
FP-tree based inverse frequent set mining [3]. 
Hence, the proposed framework considers the frequent 
itemset (FS) generated from the original database with the 
MST and MCT. With the use of sanitation algorithm, non-
sensitive rules (FS’) are extracted and converted back into 
the FP-tree. From FP-tree, the released database is obtained 
including the infrequent items. The main strength of the 
framework is hiding the sensitive association rules inversely 
without reducing the MST and MCT. Besides, the selection 
of FP-tree in forming a release database creates complexity 
especially if the multiple transactions may have a same 
itemset and with the huge depth in the tree. Thus, the 
framework cannot control the generation of ghost rules, 
unable to hide the entire sensitive rules and loses the rules 
after modification in the original database due to the 
unavailability of unyielding basis to identify and select 
sensitive item(s). 
In addition to minimal effect in the transformed database, 
Rajalaxmi et al. [4] proposed data sanitization algorithm 
based on hybrid conflict ratio approach in order to reduce the 
side effects caused in the original database. This approach 
picked the victimized transactions and items in the 
sanitization process and minimizes the legitimate loss. In this 
process, the original database is modified based on the 
assumption of sensitive itemsets listed already known as an 
input. The purpose of this modification is to keep minimum, 
the effect to the non-sensitive itemsets. For this purpose, 
partial list of transactions is selected for the database 
modification in the sanitization process and victim items are 
deleted from the transactions and as a result victimized 
transactions are as side effects. Thus, to measure the conflict 
ratio in transactions and ith item conflict ratio in a 
transaction, n(P) and n(P’), and n(PSi) and n(P’Si) are used as 
given in the following equations (1) and (2) [4]. 
'
'
( ) ( ) / ( ) (1)
( ) ( ) / ( ) (2)
i i
s s
i s s
TCR t n P n P
ICR t n P n P
= ?
= ?
 
As informative rules can be a subset of generated rules, 
so Wang et al. [5] focused on rule body and rule head to 
present their algorithms with the predicted itemset. For this 
purpose, ISL (Increased Support on LHS) and DSR 
(Decrease Support on RHS) algorithm are suggested. In such 
case, let R be the rule set such as CA (66%, 100%) and 
CB (50%, 75%) with their support and confidence. So the 
predicted itemset P={C} is assumed based on the given 
association rule body (LHS). The other predicted itemset Q= 
{A, B} can be generated on the given association rules head 
- 467 -
(RHS). The sequence of Q can be generated from the sorted 
rules on confidence in descending order. This generated 
sequence of Q is matched with P and added to the Q (if 
matched). Finally, association rule head is matched with the 
Q and removed those rules from rule set R. Thus, the 
database D is modified using P in order to increase the 
support of item in the non-existing transactions. 
Furthermore, the database D is also modified based on Q 
with the decrease of the support of item existence in the 
transactions. The suggested approach is based on the 
assumption of already known predicted itemset which leads 
to manual data mining. Hence the proposed method cannot 
become practical in case of the best case or the worst case. 
With the new metric introduction for not to disclose 
sensitive information, Saygin et al. [6] presented algorithms 
for privacy preserving by demonstration of security issues 
related to association rules. They extended their approach by 
making some modifications in the original dataset. This 
modification is carried out with an introduction of new 
symbol “?” mark. The question mark in the transactions 
neither represents the presence nor the absence of an item. 
With this modification in the original dataset, support and 
confidence are also affected and modified definitions are 
presented. For this purpose, the support for an itemset is 
taken in interval form such as [minSupport(A), 
maxSupport(A)] [6]. Moreover, the confidence interval is 
presented as [minConfidence(antecedent consequent), 
maxConfidence(antecedent consequent)]. The following 
equations (6) and (7) represents the 
minConfidence(antecedentconsequent), 
maxConfidence(antecedentconsequent). 
The reliability estimation is carried by Doguc et al. [10] 
who came up in literature with a generic approach to 
estimate the trustworthiness of a system. Such estimation of 
an approach in terms of reliability is presented by BN 
(Bayesian Network) Model. In such estimation, historical 
dataset is used based on the edges and nodes. Edges 
represent the relationship among nodes which is uncertain. 
For this purpose, Bayesian theorem is used through which an 
ith node occurrence can be measured with a priori 
occurrences of jth nodes. Thus K2 algorithm [10, 8] can be 
used to measure the reliability of occurrences of nodes at any 
position in an incremental fashion. Moreover, K2 algorithm 
[8] quantify associations and rank the parent set with a 
reduction of search space heuristically with the use of 
scoring function. Additionally, the limitation of K2 
algorithm [8] is the fixed order including the first node in 
order as parent which can benefit in mining process of 
preserving association rule privacy. This may reduce the n 
attributes set to (n-1)th attributes set. 
To sum up the discussion on PPDM in the light of the 
reviewed literature, we come to know that no single 
technique is perfect because of the NP-hardness of the 
problem [7]. Also each methodology suggests its own 
parameters. These parameters may be common in one aspect 
and different in other aspect while preserving the sensitive 
rules in data mining. In such case, sensitive item selection 
and sensitive rules are assumed to delete from database or 
hide rules respectively. Therefore, the problem of 
modification in database using the sensitive item is based on 
the assumption in association rule mining domain. Thus the 
question rises that “which domain has yet got so much 
attention in disclosing the information through association 
rules?” To the bottom of the answer, supplementary 
literature is reviewed on XML association rules which focus 
only on the generation of XML Association Rules rather than 
their sensitivity. 
III. PROPOSED PPDM MODEL 
As XML is emerged as a standard data source to 
interchange information over web due to its flexible 
structure, the problem with such exchange is the outflow of 
secrecy of information while sharing data publically. 
Therefore, we consider a XML document that contains the 
transactional information of items according to their 
transaction IDs. To focus on the XML domain and address 
security issues in the context of XML association rules, we 
proposed a PPDM model as shown in Figure 1. 
 
 
Figure 1.  Proposed Model for Privacy Preservation of XARs. 
This model reads XML document automatically and 
converts it into transactional itemset for apriori [9] and 
binary table for K2 algorithm [8]. Apriori generates XARs 
and K2 generates BN with CPT. Thus, a sensitive item is 
identified based on the maximum probability in CPT and 
deleted from the original data source for the not dominant 
largest transaction as considered an assumption with constant 
support. As a result, the experimental results are presented in 
the next section which is evident to minimize the disclosure 
risk of information while shared. Thus, to avoid such 
disclosure, the main steps involved in the process of hiding 
sensitive XML association rules using the proposed model as 


	








!

	"#



$!
%
&	
%%



'()	

	*
+,
-
	

()	


	







%
&	

 
- 468 -
in Figure 2. This algorithm detects the sensitive item(s) 
identified from XML document in order to delete it from the 
transaction which has the maximum conditional probability. 
Such deletion of item is helpful in hiding sensitive XARs. 
 
 
Figure 2.  Proposed Algorithm for hiding Sensitive XARs. 
IV. EXPERIMENTAL RESULTS 
The algorithm suggested, as in section 3, is implemented 
in Matlab 7.6 because of the complexity of reduction in 
development including the built-in functions. Before 
showing experimental results on a dataset, we selected XARs 
based on the maximum conditional probabilistic item as 
sensitive. Based on this sensitive item, 131 XARs can be 
declared as sensitive from 254 XARs with support of 4%. 
Thus, the following XML association rules are sensitive as 
shown in Figure 3. 
 
 
Figure 3.  Sample of Sensitive XML Association Rules 
Moreover, the sensitive item is identified based on the 
maximum conditional probability of item dislocation_of' 
symbolized as E in Bayesian Network which is shown as in 
Table 1. 
TABLE I.  ITEMS CONDITIONAL PROBABILITY IN BN 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
We used XML document containing transactional items 
which are symbolized as shown in Table 2. 
TABLE II.  SYMBOLIZED ITEMS ALPHABETICALLY 
 
 
 
 
 
 
 
 
 
 
 
 
 
Moreover, the BN is generated using K2 algorithm [8] as 
shown in Figure 4.1 based on the same transactional items in 
alphabetical order as shown in Figure 4. 
 
Figure 4.  Bayesian Network using K2 Algorithm [8]. 
Input: XML document 
Output: Hidden XML SARs 
1.  max   
2. Repeat steps 3-8 two times
3. max { };  1 / / arg  
4.    
5.        { } max  
6.                      
7.   
i i
i
i i
Identify imum probability item
L T i L est Transaction
each T do
IF L T THEN
Delete Item from Transaction
=
?
=

    
8. 
9.    '  
END IF
Next
Generate XARs on D
 
AÏE, BÏE, CÏE, DÏE, EÏF, EÏG, EÏH, EÏI, A,BÏE, A,CÏE
,A,DÏE, A,EÏF ,A,EÏG, A,EÏH, A,EÏI, B,CÏE, B,DÏE, B,EÏG,
B,EÏH, C,DÏE, C,EÏF, C,EÏG, C,EÏH, C,EÏI,D,EÏF,D,EÏG,
D,EÏH, D,EÏI, E,FÏG, E,FÏH, E,FÏI, E,GÏH, E,GÏI, E,HÏI,
A,B,CÏE, A,B,DÏE, A,B,EÏG, A,B,EÏH, A,C,DÏE, A,C,EÏF,
A,C,EÏG, A,C,EÏH, A,C,EÏI, A,D,EÏF, A,D,EÏG, A,D,EÏH,
A,D,EÏI, A,E,FÏG, A,E,FÏH, A,E,GÏH, A,E,GÏI, A,E,HÏI,
B,C,DÏE, B,C,EÏG, B,C,EÏH, B,D,EÏG, B,D,EÏH, B,E,GÏH,
C,D,EÏF, C,D,EÏG, C,D,EÏH, C,D,EÏI, C,E,FÏG, C,E,FÏH,
C,E,GÏH, C,E,GÏI, C,E,HÏI, D,E,FÏG, D,E,FÏH, D,E,FÏI,
D,E,GÏH, D,E,GÏI, D,E,HÏI, E,F,GÏH, E,F,GÏI, E,G,HÏI,
A,B,C,DÏE, A,B,C,EÏG, A,B,C,EÏH, A,B,D,EÏG, A,B,D,EÏH,
A,B,E,GÏH, A,C,D,EÏF, A,C,D,EÏG, A,C,D,EÏH, A,C,D,EÏI,
A,C,E,FÏG, A,C,E,FÏH, A,C,E,GÏH, A,C,E,GÏI, A,C,E,HÏI,
A,D,E,FÏG, A,D,E,FÏH, A,D,E,GÏH, A,D,E,GÏI, A,D,E,HÏI,
A,E,F,GÏH, A,E,G,HÏI, B,C,D,EÏG, B,C,D,EÏH, B,C,E,GÏH,
B,D,E,GÏH, C,D,E,FÏG, C,D,E,FÏH, C,D,E,GÏH, C,D,E,GÏI,
C,D,E,HÏI, C,E,F,GÏH, C,E,G,HÏI, D,E,F,GÏH, D,E,F,GÏI,
D,E,G,HÏI, A,B,C,D,EÏG, A,B,C,D,EÏH, A,B,C,E,GÏH,
A,B,D,E,GÏH, A,C,D,E,FÏG, A,C,D,E,FÏH, A,C,D,E,GÏH,
A,C,D,E,GÏI, A,C,D,E,HÏI, A,C,E,F,GÏH, A,C,E,G,HÏI,
A,D,E,F,GÏH, A,D,E,G,HÏI, B,C,D,E,GÏH, C,D,E,F,GÏH,
C,D,E,G,HÏI, A,B,C,D,E,GÏH, A,C,D,E,F,GÏH, A,C,D,E,G,HÏI 
Item Order Item Symbol BN Probability 
2 B 0.210 
3 C 0.874 
4 D 0.640 
4 D 0.636 
5 E 0.936 
6 F 0.872 
7 G 0.689 
8 H 0.890 
8 I 0.875 
9 J 0.306 
9 K 0.294 
Lymph dataset Items Item Symbol 
'bl_of_transaction_c' A 
'bl_of_transaction_s' B 
'block_of_affere' C 
'by_pass' D 
'dislocation_of' E 
'early_uptake_in' F 
'exclusion_of_' G 
'extravasates' H 
'regeneration_of' I 
- 469 -
 Figure 5.  Dependency of Items via Bayesian Network 
Additionally, K2 algorithm [8] is used this alphabetical 
order to calculate the conditional probabilities of the 
occurrence of the items. This occurrence of an item is in 
terms of their maximum probability which is recorded in 
MS-Excel File as shown in Figure 5. Furthermore in parallel 
to BN, we generated association rules using the same 
transactional items with the help of apriori algorithm [9]. 
These association rules are generated on the original data 
source as shown in Table 3. 
TABLE III.  XML ASSOCIATION RULES FROM D 
 
Now the transactional items used in this overall privacy 
preservation of association rule mining is based on lymph 
dataset available at [11]. In this dataset, there are 9 attributes 
out of 18 which represent the presence or absence of an item 
in a transaction. Thus, we used only 9 attributes as shown in 
Table 2 with 151 transactions. With the use of this dataset, a 
sensitive item ‘E’ is selected based on the maximum 
probability. The reason for choosing the maximum 
probability item is the frequent occurrence of this item 
among different transactions. Therefore, this item is used to 
modify the original data source having maximum length 
transactions. This restriction limits to affect the original data 
source minimally for the maximum useful output without 
disclosing the sensitive information to external parties. After 
modification of the data source, the apriori algorithm [9] is 
again used to generate the XML association rules which hide 
the sensitive XML association rules as shown in Table 4. 
TABLE IV.  ASSOCIATION RULES BASED ON D’ 
 
 
The overall summary of the hiding process of XML 
association rules is shown in Table 5 which shows the 
effectiveness of the proposed technique 
TABLE V.  SUMMARY OF XML ASSOCIATION RULES ON D’ 
 
 
In Table 5, the results from the proposed model as in 
Figure 1 are summarized for a  compact view. From this 
table, SARs, hidden Sensitive XARs and Side effects of the 
model can be examined for future proposed techniques. 
Rule # Association Rules Support Confidence Lift Ratio 
1 A==>B 4.7 26.9 3.8 
2 A==>C 17.6 100.0 1.2 
3 A==>D 13.5 76.9 2.1 
4 A==>E 13.5 76.9 0.8 
5 A==>F 12.8 73.1 0.7 
6 A==>G 16.2 92.3 0.8 
7 A==>H 15.5 88.5 1.2 
8 A==>I 4.1 23.1 2.3 
9 B==>C 4.7 100.0 1.2 
10 B==>D 4.7 100.0 2.8 
11 B==>E 4.7 100.0 1.0 
12 B==>G 4.7 100.0 0.9 
13 B==>H 4.7 100.0 1.3 
14 C==>D 20.9 37.8 1.1 
15 C==>E 35.8 64.6 0.7 
 !!"# $%& '?&' ?&'
' !!"@ KK& X?&Y ?&'
X !!"Z $&Y Y&% ?&%
% !!"[ K& '&$ ?&'
? !!" %& X?& ?&X
 !!"# '& '& ?&'
 !!"@ & XX&% ?&X
$ !!"Z & XX&% &
K !!"[ & Y&? &Y
Y !!"# Y&? 'X& ?&X
 !!"@ Y%&Y X%&X ?&X
' !!"Z $Y&X YK& ?&'
X !!"[ K&' '& ?&'
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\\
248 A,D,E,G,H==>I 4.1 37.5 3.8 
249 B,C,D,E,G==>H 4.7 100 1.3 
250 C,D,E,F,G==>H 12.8 95 1.3 
251 C,D,E,G,H==>I 4.1 24 2.4 
252 A,B,C,D,E,G==>H 4.7 100 1.3 
253 A,C,D,E,F,G==>H 8.8 100 1.3 
254 A,C,D,E,G,H==>I 4.1 37.5 3.8 
Rule # Association Rules Support Confidence Lift Ratio 
 !!" K&' &% $&X
 !!" '& ??&? &
$ !!" $&Y '&% &
K !!" &Y Y&K ?&'
Y !!"# &X '$& ?&'
 !!"@ & %&$ ?&X
' !!"Z Y&Y XX&Y &
X !!"[ K& $& &$
% !!" K&' ??&? &
? !!" K&' ??&? &X
 !!"@ K&' ??&? ?&%
 !!"Z K&' ??&? &$
$ !!" ?&% $'&X &
K !!" $$&X &? ?&
Y !!"# $%& '?&' ?&'
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
'' @!!"Z K&' ??&? &$
'X #!!"@ &X '&K ?&
'% #!!"Z '&K 'X& &?
X? @!!"Z X&X X&$ &
X #@!!"Z %&Y %$&$ &
X @Z!!"[ K& $$&$ $&$
X$ #@!!"Z '&K X&X ?&%
XK #@!!"Z &X '&% &?
XY #@!!"Z ?&X X?&? &
X #@!!"Z &X '&% &?

%&
%& $
%&

.
// // #

YK $ X $ Y % $
- 470 -
V. CONCLUSION 
In this work, XML document is read automatically with 
the conversion of transactional itemset and binary table. 
Such forms of data are used in order to generate XARs and 
BN with the help of apriori and K2 algorithm. Moreover, our 
contribution in this regard is to analyze and use the CPT to 
identify sensitive XML transactional item in order to modify 
the itemset. This leads us to hide the XARs. In such process 
of hiding, reliability and accuracy issue were the main 
concern which was validated through K2 [8] for the accurate 
computation of sensitive item. Moreover, the proposed 
PPDM model is more effective when there is at least one 
transaction equal in length as an assumption of the model. 
Further, the assumption of largest transaction will be 
analyzed in optimal way. 
ACKNOWLEDGMENT 
The authors would like to acknowledge the kind efforts 
by Lowel Guandi for implementing K2 algorithm and Sadik 
Hava for apriori implementation in Matlab. 
 
REFERENCES 
[1] Wang, X. and Cao C., “Mining Association Rules from Complex and 
Irregular XML Documents using XSLT and Xquery” International 
Conference on Advanced Language Processing and Web Information 
Technology , 978-0-7695-3273-8/08, 2008  
[2] [2]. Dasseni, E. Vassilios S. Verykios, Ahmed K. Elmagarmid, Elisa 
Bertino, “Hiding Association Rules By using Confidence and 
Support“ , CSD TR#00-010, June 2000 
[3] Guo Y.,”Reconstruction-Based Association Rule Hiding” 
Proceedings of SIGMOD2007 Ph.D. Workshop on Innovative 
DatabaseResearch 2007(IDAR2007), June 10, 2007, Beijing, China 
[4] R.R.Rajalaxmi, A.M.Natarajan, “Hybrid Conflict Ratio for Hiding 
Sensitive Patterns with Minimum Information Loss” International 
Journal of Computer Theory and Engineering, Vol. 1, No. 4, October 
2009 
[5] Wang S., Parikh B., Jafari A.,” Hiding informative association rule 
sets”, Expert Systems with Applications 33 (2007) 316–323 
[6] Yucel Sayg?n, Vassilios S. Verykios, Ahmed K. Elmagarmid, 
“Privacy Preserving Association Rule Mining”, Page: 151-158, Year 
of Publication: 2002, ISSN:1066-1395, IEEE Computer Society 
Washington, DC, USA 
[7] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim, V. Verykios, 
“Disclosure Limitation of Sensitive Rules”, Page:45-52,Year of 
Publication: 1999, ISBN:0-7695-0453-1,IEEE Computer Society , 
Washington, DC, USA 
[8] Gregory F. Cooper and Edward Herskovits. A Bayesian method for 
the induction of probabilistic networks from data. Mach. Learn., 
9(4):309{347, 1992 
[9] R. Agralwal, T.Imielinski, and A.Swami. Mining associations 
between sets of items in large databases. In P.Buneman and S. 
Jajodia, editors, SIGMOD93, pages 207-216, Washington, D.C, USA, 
May 1993 
[10] O. Doguc, and J.E. Ramirez-Marquez “A generic method for 
estimating system reliability using Bayesian Networks”, in proc. 
Reliability Engineering and System Safety, ( 2008) 
[11] [11]. http://tunedit.org/repo/UCI/lymph.arff,DatasetAccessDate:31-
03-2010 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
- 471 -
