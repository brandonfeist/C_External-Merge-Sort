2010 International Conference on Networking and Digital Society 
Incremental Maintenance of Association Rules Over Data Streams 
lun Tan1,2 
I College of Computer and Information Engineering 
Central South University of Forestry & Technology 
Changsha, Hunan Province, China 
e-mail: tanjun007@vip.sina.com 
Abstract-There exist emerging applications of data streams 
that require association rules mining, such as web click stream 
mining, sensor networks, and network traffic analysis. In order 
to efficiently trace the changes of association rules over data 
streams which are continuous, unbounded, usually come with 
high speed, in this paper we propose Fd-tree method which 
requires no scanning of the whole data stream and to only scan 
the updated transactions once without involving candidate sets 
generation. The experiment results on synthetic datasets and 
real datasets show that the new algorithm outperform other 
algorithm in not only the speed of algorithms, but also their 
memory consumption and their scalability. 
Keywords- Association rules; Data streams; Incremental 
maintenance; Fd-tree 
I. PREFACE 
The increasing prominence of data streams arising in a 
wide range of advanced application such as web click stream 
mining, network traffic analysis, sensor networks has led 
to the study of online mining of association rules. A data 
stream is an ordered sequence of items that arrives in timely 
order. Different from data in traditional static databases, data 
streams have the following characteristics [1] [2]. First, they 
are continuous, unbounded, and usually come with high 
speed. Second, the volume of data streams is large and 
usually with an open end. Third, the data distribution in 
streams usually changes with time. 
Traditional association rules mining algorithms are 
developed to work on static data, therefore, can not be 
applied directly in data streams. In the past, many 
algorithms were proposed, most of which were based on the 
Apriori algorithm [3], which generated and tested candidate 
itemsets level-by-Ievel. This may cause iterative database 
scans and high computational costs. Han, Pei thus proposed 
the FP-growth algorithm[4][5] which use a frequent pattern 
tree(FP-tree) data structure and allows mining of frequent 
itemsets without generating candidate itemsets. Compared 
with Apriori and its variants, it achieves higher performance. 
Both the Apriori and the FP-tree mining approaches 
belong to batch mining. That is, they must process all the 
transactions in a batch way. In data stream, new transaction 
insertions and old transaction deletions may lead to 
previously discovered association rules no longer being 
interesting, and new interesting association rules may also 
appear. Designing an efficient algorithm that can maintain 
978-1-4244-5161-6110/$26.00 ©2010 IEEE 
444 
Yingyong Bu2 and Haiming Zhao2 
2 College of Mechanical and Electrical Engineering 
Central South University 
Changsha, Hunan Province, China 
e-mail: buyingyong@126.com 
association rules as a data stream grows is thus critically 
important. 
One noticeable incremental mining algorithm was the 
FUP algorithm [6]. The FUP algorithm modified the Apriori 
mining algorithm and adopted the pruning techniques used in 
the DHP algorithm [7]. Although the FUP algorithm could 
indeed improve mining performance for incrementally, 
changing data streams still needed to be scanned when 
necessary. Hong, lin [8] modified the FP-tree structure and 
designed FUFP-tree structure to efficiently handle newly 
inserted transactions based on the FUP concept. The FUFP­
tree structure was similar to the FP-tree structure except that 
the links between parent nodes and their child nodes were bi­
directional. Besides, the counts of the sorted frequent items 
were also kept in the header-table-of the FP-tree algorithm. 
In this paper, we propose a new method that uses a Fd­
tree structure to store all the information and requires (1) no 
scanning of the original database, (2) to only scan the 
updated transactions once without involving candidate sets 
generation. A thorough performance study on synthetic 
datasets and real datasets has shown that our proposed 
algorithm is both time and space efficient and adapts very 
rapidly to the change in data streams. 
II. PRELIMINARIES 
Association rules provide information about whether or 
not different sets of values relate to on another within a data 
stream. The following is a formal definition of association 
rules based on the descriptions presented in [5]. 
Let 1= (ii, i2 ... iJ be a set of literals, referred to as items. 
Each transaction T contains a set of items (i], i2 ... ik) cI. We 
will refer to a set of items as an itemset. The number of 
items in the itemset is the length of the itemset. Therefore, an 
itemset of length k is a k-itemset. 
A transaction data stream is a sequence of incoming 
transactions. For example, FigJ shows a data stream D 
which adopts sliding window mechanism. Each window is 
decomposed into a number of equal sizes non-overlapping 
batches of transaction, called pane. Let the window slides 
pane-by-pane. 
An association rule is an implication of the form X?Y, 
where X, YcD, XnY=0. X is called the antecedent of the 
rule and Y is the resultant or consequent of the rule. Each 
rule has two associated measures, support and confidence. 
The support of itemset XY is the percentage of records that 
contain both X and Y in data stream., and the confidence is 
the percentage of records containing X that also contain Y. 
Association rule mining is to find all association rules the 
support and confidence of which are above or equal to a 
user-specified minimum support and confidence, 
respectively. 
TID 
1 
2 
3 
4 
5 
6 
Trans 
a, b, d, e 
a) b, c) e 
b, c, e 
c, e 
a, C, d 
b, C, e, d 
PII1'J': Siz?2 
WiJldow Slze-2 
Strl;'nm Data 
Figure I. Data stream D 
III. FD-TREE BASED INCREMENTAL UPDATING 
When the data stream is updated, because of transaction 
deletions and insertions, the frequent itemsets may change. 
Some frequent itemsets at a given time point may become 
infrequent after some further insertions. Then, discarding 
infrequent itemsets will prevent the discovery of the 
respective new frequent itemsets which may well be frequent. 
For instance, assurme current data stream D include the first 
window transactions (TID 1 ,2,3,4) and assume new 
transactions TID 5-6 are added to D, the minimum support 
threshold is equal to 50%. Frequent Abe become now an 
infrequent itemset (33%) while frequent itemset d is frequent 
(50%).If itemset abed is initially discarded as infrequent 
itemset in FP-tree (25%),then the new frequent itemset d 
would have been missed. 
It is not practical to reconstruct FP-tree each time when 
the data stream is updated. If the minimum support of a data 
stream is 1, its FP-tree is just a compact version of the 
current data stream. To distinguish it from the FP-tree of 
higher support, we call the tree based on minimum support 1 
the Fd-tree. This Fd-tree stores all the itemsets of the data 
stream. When the transactions are deleted or inserted, the 
changed transaction instead of the whole data stream is 
scanned. This Fd-tree includes the FP-tree inside it. So, if we 
can project the FP-tree from this Fd-tree, we can mine the 
frequent itemsets based on the FP-tree from this Fd-tree. The 
Fd-tree is just used for maintaining the frequent itemsets 
when there is an update to the data stream since it keeps 
information regarding not only previously frequent itemsets, 
but also previously infrequent itemsets. Thus, it eliminates 
the need to scan the whole data stream when certain types of 
updates occur. 
To illustrate the construction of Fd-tree. First, scan D to 
get all the occurrences of all the items. Sort them in 
descending order of support. Next, use these occurrences to 
construct the Fd-tree. The Fd-tree is shown in Figure 2. 
445 
I-list 
e 4 
b 3 
c 3 
a 2 
d I 
Figure 2. Construction of F d-tree 
Now, we introduce how to mine the incremental rules 
with Fd-tree when old transactions are deleted from data 
stream and new transactions are inserted into data stream. 
First, suppose the old pane including TID 1-2 is deleted. 
The deletion procedure never would introduce new branches 
to the Fd-tree. It only follows the branch and decreases the 
count of the nodes. By only scanning the deletion part once, 
the occurrences of the items are obtained. The Fd-tree after 
the old pane is deleted is shown in Figure 3. 
I-Ii st 
c 2 
c 2 
b 1 
Figure 3. the Fd-tree after the old pane is deleted 
Next, suppose the new pane including TID 5-6 is inserted. 
The Fd-tree just scans the additional transactions only once 
to update the Fd-tree. When the new transactions share the 
same branch with the ones in the original data stream, it just 
increases the count of each item. Otherwise it adds the new 
branch into the Fd-tree. At the same time the occurrence of 
each item in the new transactions are also obtained. The Fd­
tree after the new pane is inserted is shown in Figure 4. 
I-Ii 1: 
C 4 
e 3 
b 2 
d 2 
a 1 
Figure 4. the F d-tree after the new pane is inserted 
When mmmg the updated association rules in the 
updated data stream, we need to project the FP-tree out from 
the updated Fd-tree. Suppose the minimum support threshold 
is 50%. We note that the frequent item order changed and 
item a is no longer frequent any more in updated data stream. 
Do we need to rearrange the FP-tree? In another words, do 
we need to delete the node a from the FP-tree and 
restrictedly arrange the FP-tree structure according to their 
descending order? We notice that the updated part is usually 
dramatically smaller than the original data stream. The FP­
tree is based on the original data stream therefore most 
amounts of frequent itemsets are already stored in the FP­
tree when data stream is updated. The changed part would 
have comparatively fewer amounts of frequent itemsets. 
Even the changed transactions affect the item' order, since 
most of the frequent itemsets in the data stream are based on 
the old order, only small amounts of itemsets follow the new 
order, it is not necessary to change the order strictly each 
time the order is changed. Otherwise the order change would 
cause a lot of overhead before mining. We don't care about 
the order change among the frequent items and among the 
small items For example, the occurrences of item c becomes 
4 and e becomes 3,but they are still frequent items and all 
their itemsets are already in FP-tree, so there is no need to 
rearrange their orders. Only when infrequent items become 
frequent or frequent items become infrequent, it is necessary 
to rearrange the order. That means that if there is an 
infrequent item that becomes frequent, it needs to be placed 
in the FP-tree part of the Fd-tree; if there is a frequent item is 
now small, it needs to be lowered down out of the FP-tree 
part in the Fd-tree. For example, the previous frequent item a 
becomes infrequent and meanwhile the previous infrequent 
item d becomes large, so their order changed. 
To project FP-tree from Fd-tree, start from the root, 
following each branch if its next node is frequent till there 
are no frequent items in a branch. The process is repeated 
after all branches from root are traversed. The cost of 
projecting an FP-tree is equal to cost traversing FP-tree once. 
At last, mining the updated association rules depends on the 
FP-tree. 
Using the Fd-tree to mine the incremental association 
rules has the following advantages: (1) no scanning of the 
original database is needed even when the small itemsets 
become frequent after updating the database, yet the original 
FP-growth has to scan the original database to reconstruct 
the FP-tree in this situation, (2) the mining process is based 
on the FP-tree, the compact structure instead of generating 
many candidates, (3) it only scans the updated transactions 
once,. yet the FUP need to scan on each level. 
The incremental association rules mining with Fd-tree 
follows the following steps: 
(1) Construct the Fd-tree using all items in the data stream 
at the beginning. 
(2) After the Fd-tree is constructed, during the later data 
stream update just scan the updated part once to update 
the Fd-tree. 
(3) Project the FP-tree from the Fd-tree according to the 
frequent items. 
446 
(4) Using the FP-growth procedure in the original FP-tree 
algorithm to mine the frequent patterns in the FP-tree. 
IV. EXPERIMENT ANALYSIS 
We compare the performance of Fd-tree, FUFP and FUP. 
All the programs are written in Microsoft Visual C++ 6.0 
and run with Windows XP on a 2.660Hz CPU and lOB 
memory. The experiments were performed on a synthetic 
datasets developed by IBM Almaden Quest research group 
[9] and a real datasets from the UCI Machine Learning 
Repository [10] [11]. The synthetic dataset is called 
TlOI4DlOOK whose average transaction length is 10, 
average length of the maximal frequent itemset is 4, and 
total number of transaction is lOOk. The real dataset is chess 
whose average transaction length is 37, total number of 
transactions is 3196. The chess dataset is a dense dataset but 
the TlOI4DlOOK dataset is a sparse dataset. To simulate data 
streams, the transactions in both synthetic data and real 
datasets are looked up one by one in sequence and feed them 
in the buffer. 
In the experiment, we compare the performance of the 
Fd-tree, FUFP and FUP by updating trees constructed using 
sparse and dense datasets separately. The results of the 
experiments are shown in Figure 5 and Figure 6. In 
TlOI4DlOOK dataset, the size of sliding window is changed 
from 20K transactions to lOOK transactions. In chess dataset, 
the size of sliding window is changed from 1000 transactions 
to 3000 transactions. The result clearly reflects that the larger 
the datasets, the better the Fd-tree performs compared with 
the FUFP and FUP for both dense and sparse datasets. 
V. CONCLUSIONS 
In this paper, we propose a novel method for incremental 
association rules mining over data streams. This method is 
based on Fd-tree structure which requires no scanning of 
the original database and to only scan the updated 
transactions once without involving candidate sets generation. 
Experiment result indicates that the algorithm has more 
excellent performance than the FUP and FUFP methods. 
TIOl4DIOOK 
I-+- DB-tree - FUFP FUP I 
20k 40k 60k 80k lOOk 
No of transactions 
Figure 5. Processing time in TlOI4DlOOK 
chess 
I---+-- DB-tree - FUFP 
1000 2000 3000 
No.of transactions 
Figure 6. Processing time of in chess 
ACKNOWLEDGMENT 
Financial supports from Youth Scientific Research 
Foundation of Central South University of Forestry & 
Technology (Grant NO.2009046B) are highly appreciated. 
REFERENCES 
[I] Babcock,B., B.Babu,S., Datar,M, Models and issues in data stream 
systems. In Proceedings of the PODS(pp.I-16) 
[2] Jiang,N., Gruenwald,L., Research issues in data stream association 
rule mining.SIGMOD Record,35(l). 
[3] RAgrawal, RSrikant, Fast algorithm for mining association rules. 
In Proc 1994 Int.Conf. Very Large Data Bases (VLDB'94), pp. 487-
499, Sept 1994 
[4] J.Han, J.Pei, and Y.Yin, "Mining frequent patterns without candidate 
generation". In Proc. 2000 ACM- SIGMOD In!. Conf. Management 
of Data (SIGMOD'OO), pp. 1-12, May 2000 
[5] Jiawei Han, Micheline Kamber, Data Mining Concepts and 
Techniques, mechanism industry publishing, Bei Jing, 2002, pp.156-
160 
[6] Cheung,D.W.,Lee,S.D.,&Kao,B. A general incremental technique for 
maintaining discovered association rules.In Proceedings of database 
systems for advanced applicaiotns,pp.185-194,1997. 
[7] Park,J.S.,Chen,M.S.,&Yu,P.S.,Using a hash-based method with 
transaciton trimming for mining association rules. IEEE Transactions 
on Knowledge and Data Engineering"pp.812-825,1997. 
[8] Hong,T.P.,Lin,J.W.,&Wu,Y.L.. A fast updated frequent pattern 
tree.In The IEEE International conference on systems,man,and 
cybernetics,pp.2167-2172,2006. 
[9] IBM,QUEST Data Mining Project, 
http://www.almaden.ibm.com/cs/q uest 
[10] C.L.Blake, C.J.Merz, UCI Repository of Machine Learning Database, 
University of California-Irvine, Irvine,CA.1998. 
[II] T.Brijs, G.Swinnen,K.Vanhoof, G.Wets, Using association rules for 
product assortment decision:a case study,in:Proceedings of the Fifth 
International Conference on Knowledge Discovery and Data 
Mining,San Diego(USA), 1999 ,pp.254-260 
447 
