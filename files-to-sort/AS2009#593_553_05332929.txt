- 3863 -
Fuzzy Association Rule Mining and Classi?er with Chi-squared Correlation
Measure using Genetic Network Programming
Karla Taboada1, Shingo Mabu1, Eloy Gonzales1, Kaoru Shimada1, and Kotaro Hirasawa1
1Graduate School of Information, Production and Systems, Waseda University, Japan
2-7 Hibikino, Wakamatsu-ku, Kitakyushu-shi, Fukuoka 808-0135 Japan
(Tel : +81-93-692-5261; E-mail: {karla taboada, egonzale}@asagi.waseda.jp, {mabu, k.shimada}@aoni.waseda.jp,
hirasawa@waseda.jp
Abstract: One of the most important issues in any association rule mining is the interpretation and evaluation of discov-
ered rules. Thus, most algorithms employ the support-con?dence framework for evaluating association and classi?cation
rules. Unfortunately, recent studies show that the support and con?dence measures are insuf?cient for ?ltering out unin-
teresting association rules, for instance, even strong association rules can be uninteresting and misleading. To deal with
this limitation, the support-con?dence framework can be suplemented with additional interestingness measures based on
statistical signi?cance and correlation analysis. In this paper, a novel fuzzy association rule-based classi?cation approach
is proposed, where ?2 is applied as a correlation measure. The algorithm is based on Genetic Network Programming
(GNP) and discover comprehensible fuzzy association rules potentially useful for classi?cation. GNP is an evolutionary
optimization algorithm that uses directed graph structures as genes instead of strings and trees of Genetic Algorithms
(GA) and Genetic Programming (GP), respectively. This feature contributes to creating quite compact programs and im-
plicitly memorizing past action sequences. The proposed model consists of two major phases: 1) generating fuzzy class
association rules by using GNP, 2) building a classi?er based on the extracted fuzzy rules. In the ?rst phase, ?2 is used
for computing the correlation of the rules to be integrated into the classi?er. In the second phase, the ?2 value is used as
a weight of the rule when calculating the matching degree of the rule with new data. The performance of the proposed
algorithm has been compared with other relevant algorithms and the experimental results have shown the advantages and
effectiveness of the proposed model.
Keywords: association rule mining, classi?cation, fuzzy association rules, fuzzy membership functions, genetic network
programming.
1. INTRODUCTION
Classi?cation is one of the several tasks of data mining
and it is a very important area of learning in the database
?eld of the real world. One of the comprehensible mod-
els is the association rule-based classi?cation that com-
bines the advantages of traditional classi?cation and as-
sociation rule discovery. A class association rule is gen-
erally expressed as IF-THEN rule, i.e., IF [term1 AND
term2 AND ... ] THEN [class]. Each term of the an-
tecedent is a pair of [attribute, value]. The consequent
is the result of classi?cation, that is, the class value of
the attributes. Recently, extensive research has been car-
ried out to develop enhanced methods for classi?cation
and higher classi?cation accuracy is obtained than tra-
ditional classi?ers. However, recent studies show that
the associative classi?ers suffer from some problems in-
herited from association rule mining such as the limited
support-con?dence framework. To address this weak-
ness, several measures have been proposed to evaluate
the signi?cance of the rules and to focus only on those
that are signi?cant accurately and statistically. On the
other hand, a correlation measure can be used to enhance
the support-con?dence framework for association rules,
that is, A? B[support,con f idence,correlation] is used,
where the rule is measured not only by its support and
con?dence but also by the correlation between A and B.
Among many different correlation measures, the ?2 test
is one of the most important because of its solid statistical
basis. Many successful techniques utilize the ?2 test for
independence which is based on the diferences between
the expected number of occurrences of a pair of itemsets
and its observed number [1]. The primary assumption is
that these diferences will be small for independent item-
sets. A small ?2 value leads to the rejection of the hy-
pothesis that the itemsets are correlated.
In this paper, a novel fuzzy association rule-based clas-
si?cation approach is proposed, where ?2 is used as a
correlation measure. The algorithm is based on Genetic
Network Programming (GNP) and discover comprehen-
sible fuzzy association rules which are potentially useful
for classi?cation. The fuzzy discretization technique is
proposed for dealing with databases with continuous at-
tributes. Fuzzy sets help to overcome the so-called sharp
boundary problem by giving different membership val-
ues, not only 1 and 0 given by traditional discretization
methods. Moreover, fuzzy sets can make the discovered
rules more understandable for the users. On the other
hand, GNP is one of the evolutionary algorithms inspired
by biological evolution [2], [3], [4], which is an extension
of Genetic Algorithms (GA) and Genetic Programming
(GP). The main difference among them is the representa-
tion of the solutions. GA evolves strings as solutions and
it is mainly applied to optimization problems. GP was
formulated later in order to expand the expression ability
of GA by using tree structures. GNP uses directed graph
structures as solutions instead of strings or trees, there-
ICROS-SICE International Joint Conference 2009
August 18-21, 2009, Fukuoka International Congress Center, Japan
PR0002/09/0000-3863 ¥400 © 2009 SICE
- 3864 -
fore GNP can deal with complex problems more effec-
tively and ef?ciently than GA and GP [5]. GNP produced
many novel and outstanding results in the areas such as
Data Mining [6], [7], Intelligent Mobile Robot [2], Multi
Agent System [3], Elevator Group Supervisory Control
System [8], Stock Market Prediction [9], Automatic Pro-
gram Generation [10], and so on.
2. ?2 TEST FOR INDEPENDENCE AND
CORRELATION
In statistics, ?2 test is a widely used method for test-
ing the independence or correlation among variables. Ba-
sically, ?2 test is based on the comparison of observed
frequencies with the corresponding expected frequencies.
The closer the observed frequencies are to the expected
frequencies, the larger the weight of evidence in favor
of independence is. If all the variables are in fact inde-
pendent, the ?2 value would be 0. If it is higher than
a cutoff value (6.63 at the 99% signi?cance level), the
independence assumption is rejected. Notice that the cut-
off value for any given signi?cance level can be obtained
from widely available tables for the ?2 distribution. For-
merly, many other successful techniques utilized the ?2
test for independence or correlation [1], [11], [12], [13].
In the proposed algorithm, ?2 test is used for generating
correlated fuzzy class association rules as well as weights
of the fuzzy rules for building the classi?er. By adding
a correlation measure to the support-con?dence frame-
work, the discovery of more meaningful correlated rules
becomes possible.
The ?2 statistic is de?ned as follows:
?2 = ?
AllCells
(O?E)2
E . (1)
Where, E denotes the value of the expectation under
the assumption of independence and O the value of the
observation. Then, let support(X) = x, support(Y ) =
y, support(X ?Y ) = z and the number of database tu-
ples equal N. If events X and Y are independent, then
support(X ?Y ) = xy. Table 1 is the contingency of X
and Y : the upper parts are the expectation values under
the assumption of their independence, and the lower parts
are observational.
Table 1 The contingency table of attributes X and Y .
Y ¬Y ?row
X Nxy N(x? xy)
Nz N(x? z) Nx
¬X N(y? xy) N(1? x? y+ xy)
N(y? z) N(1? x? y+ z) N(1? x)
?col Ny N(1? y) N
We can calculate ?2 using x, y, z and N from Table 1
as follows:
?2 = N(z? xy)
2
xy(1? x)(1? y) . (2)
?2 test could be used in multi-dimensional vari-
ables. However, in association rule mining only
two-dimensional variables are needed, i.e., for two-
dimensional contingency table its degree of freedom is
1. ?2 test is a very effective method, however it has also
some limitations [1]. The ?2 test rests on the normal ap-
proximation to the binomial distribution. This approxi-
mation breaks down when the expected values are small.
Therefore, statistics texts recommend the use of ?2 test
only if (1) all cells in the contingency table have expected
value greater than 1; and (2) at least 80% of the cells
in the contingency table have the expected value greater
than 5.
3. FUZZY ASSOCIATION RULE MINING
AND CLASSIFIER
The proposed fuzzy association rule mining and clas-
si?cation model consists of two major phases: 1) generat-
ing fuzzy class association rules by using GNP, 2) build-
ing a classi?er based on the extracted fuzzy rules. In the
?rst phase, taking the GNP’s structure into account, the
extraction of fuzzy association rules is done without iden-
tifying frequent itemsets. The frequent item set search-
ing would be the bottleneck of all the association rule
mining algorithms due to its long searching time. More-
over, fuzzy rules are updated by evolving the member-
ship functions through generations in order to obtain the
best quali?ed rules for building the classi?er. The sup-
port, con?dence and ?2 measures are easily calculated
taking the GNP’s structure into account [6]. In the sec-
ond phase, all of the generated fuzzy rules are used to
predict the class of the test data. For each test data, the
classi?er computes the average matching degree between
the data and the rules in each class. The ?2 value is used
as a strength of the rule when calculating the matching
degree of the rules and the test data. Finally, the class
with the largest matching degree is assigned to the test
data. The accuracy on the test data set is calculated as
the number of correctly classi?ed test data divided by the
total number of test data.
3.1 Fuzzy Class Association Rule Mining
Since the accuracy of a classi?cation model can be
largely affected by the partitioning of continuous at-
tributes, a fuzzy discretization technique is reviewed for
dealing with databases with continuous data [14]. Firstly,
the values of all continuous attributes of the database are
fuzzi?ed into three linguistic terms (e.g. low, middle and
high). These linguistic terms are de?ned by the combina-
tion of trapezoidal and triangular membership functions
symmetrically spaced [See Fig. 1]. Each continuous at-
tribute is associated with its own membership functions.
TID in Fig. 1 shows the transaction number. In addition,
the parameters of the membership functions are evolved
- 3865 -
generation by generation in order to discover more in-
teresting rules. Uniform and non-uniform mutation [15]
were used for the evolution of the parameters of the mem-
bership functions.
(a) Fuzzy attributes obtained from databases with continuous values.
(b) De?nition of the membership functions.
Fig. 1 The proposed fuzzy discretization technique.
The main task in this phase is to extract the fuzzy class
association rules from the fuzzi?ed training set. The rules
have the following form:
If (Ai isQi)?·· ·? (Aj isQj)? (C = k),
where, Qi, ...,Qj are the linguistic terms of the fuzzy
attributes Ai, ...,Aj and k denotes the class label of the
class attributeC (k = 0,1,2, ...K).
The basic structure of GNP for the extraction of fuzzy
class association rules is shown in Fig. 2. The fuzzy rules
are represented as the connections of judgment nodes in
GNP [6], [7]. Each judgment node examines the fuzzy
attribute values. P1 is a processing node and is a start-
ing point of extracting association rules. Each processing
node has an inherent numeric order (P1, P2,. . . , Ps) and is
connected to a judgment node. Yes-side of the judgment
node is connected to another judgment node. No-side of
the judgment node is connected to the next numbered pro-
cessing node. The calculation of the measurements such
us support, con?dence and ?2 is made using processing
nodes [6], [7]. Judgment nodes can be reused and shared
with some other association rules because of GNP’s fea-
tures. All GNP individuals are searched in parallel at the
same time.
Fig. 2 Basic GNP structure for fuzzy association rule
mining.
Once a GNP individual starts the searching for associ-
ation rules, the transition from one judgment node to an-
other is determined probabilistically by using the fuzzy
values. That is, the fuzzy value is used for moving to
the Yes-side or No-side of the judgment node as Fig. 3
and Fig. 4 show. In Fig. 3, r is a random variable in
(0,1), ai is the value of fuzzy attribute Ai and ?Qi(ai) is
the value of the membership function ?Qi(Ai) when the
value of fuzzy attribute Ai is ai. A random number is
generated and compared to the membership value of the
fuzzy attribute. If the random number is smaller than or
equal to the membership value, then go to the Yes-side
of the judgment node, otherwise, go to the No-side of the
jugdment node.
Fig. 3 Probabilistic transition from one judgment node
to another.
In order to calculate the support, con?dence and ?2
of the fuzzy rules, the total number of tuples moving to
Yes-side at each judgment node is calculated for every
processing node [6], [7]. In Fig. 2, N is the total number
of tuples, a, b, c and d are the number of tuples moving
to Yes-side at each judgment node and a(k), b(k), c(k)
and d(k) are the number of tuples moving to Yes-side at
each judgment node that satisfy the class k. These counts
- 3866 -
Fig. 4 Transition from one judgment node to another
using probability Pt determined by fuzzy values.
are used for the calculation of the measurements. Table 2
shows how to calculate the support and con?dence of the
fuzzy rules extracted from the GNP individual in Fig. 2.
Table 2 Support and con?dence of fuzzy association
rules.
association rules supp. conf.
A1 High? A2 Low b/N b/a
A1 High? A2 Low?A3 Mid c/N c/a
A1 High? A2 Low?A3 Mid?A4 Low d/N d/a
A1 High?A2 Low? A3 Mid c/N c/b
A1 High?A2 Low? A3 Mid?A4 Low d/N d/b
A1 High?A2 Low?A3 Mid ? A4 Low d/N d/c
The mined fuzzy class association rules that satisfy
the minimum support, con?dence and ?2 thresholds are
stored with its signi?cance measures and fuzzy parame-
ters in a pool through generations. Ocassionally, a fuzzy
rule already stored in the pool can be once again ex-
tracted, in that situation, the membership functions and
?2 values might be changed, where only the fuzzy rule
with higher ?2 value could replace the same old fuzzy
rule in the pool along with its fuzzy parameters. There-
fore, the pool is updated in every generation and only
important fuzzy rules with higher ?2 values and better
adapted fuzzy parameters are stored.
3.1.1 Fitness function of GNP
The ?tness of GNP for classi?cation is de?ned as fol-
lows:
F = ?
r?R
{?2(r)+10(n(r)?1)+?new(r)}. (3)
Where,
R: set of suf?xes of extracted important association rules
satisfying the minimum measurements thresholds in a
GNP individual.
?2(r): ?2 value of rule r.
n(r): the number of attributes in the antecedent of rule r.
?new(r): additional constant de?ned by
?new(r) =
?
?new (rule r is new)
0 (rule r has been already extracted)
(4)
Notice that in Eq.(3) we do not take into account the
consequent term because GNP individuals are used to ex-
tract fuzzy classi?cation rules, where the consequent is
?xed.
3.1.2 Genetic operators of GNP
Elite selection method is used. Thus, once all
crossovers and mutations have been performed, all the
produced GNP offspring are sorted by their ?tness val-
ues and only 1/3 best individuals are selected for repro-
duction. The following genetic operators are executed to
GNP individuals:
• Crossover: Operator producing two offspring from
parents. Uniform crossover is used. Judgment nodes
are selected as crossover nodes with the probability
of Pc.
• Mutation-1: The connection of the judgment nodes
is changed by mutation rate of Pm1.
• Mutation-2: The function of the judgment nodes is
changed by mutation rate Pm2.
All the connections of the processing nodes are
changed randomly in order to extract rules ef?ciently.
The ?owchart of the proposed fuzzy class association
rule mining method is described in Fig. 5.
Fig. 5 Flowchart of the proposed fuzzy class association
mining method.
- 3867 -
3.2 Building a Classi?er Model
In this section, the proposed algorithm is described for
the classi?cation after fuzzy association rule mining. An
associative classi?cation model is based on the discov-
ered rules. Therefore, the set of rules is used to deter-
mine an unknown class label. In the proposed method,
the GNP-based data mining algorithm generates a pool
of fuzzy association rules for each class in the dataset.
Then, the rules in each pool are used to predict the class
of the test data d. Recall that each fuzzy rule was stored
in the pool with its own fuzzy parameters. Then, for the
test data d, the classi?er computes the average matching
degree between data d and the rules in class k. Now, the
?2 value is used as a weight of fuzzy rule r when calcu-
lating the average matching degree of the rules and test
data d. Finally, the class with the highest average match-
ing degree is assigned to the test data. The accuracy on
the test data is calculated as the number of correctly clas-
si?ed test data divided by the total number of test data.
The classi?cation of test data d is determined as follows:
1) Rk: Provide the set of suf?xes of rules in class k,
(k = 1,2 . . .K).
2) mk(d): Compute the average matching degree
between data d and the rules in class k.
mk(d) = 1|Rk| ?r?Rk Dk(d,r), (5)
Dk(d,r) = Sk(d,r)Sk(r) ??
2(r), (6)
where,
Dk(d,r) : matching degree between data d and rule r
in class k.
Sk(d,r) : the sum of the fuzzy membership values of
the fuzzy attributes in the antecedent of fuzzy
rule r in class k, which are calculated by data d.
Sk(r): the number of attributes in the antecedent of
fuzzy rule r in class k.
?2(r): ?2 value of fuzzy rule r.
3) Predict in such way that data d belongs to the class
having the highest mk(d).
4. SIMULATION RESULTS
To evaluate the performance of the proposed GNP-
based association rule mining and classi?er, Iris dataset
from UCI (University of California at Irvine) reposi-
tory has been used [16]. In terms of the classi?cation
accuracy, the proposed model has been compared with
three other evolutionary systems: CEFR [17], ESIA [18],
BGP[19] and three Apriori-like mining methods: CMAR,
C4.5 and CBA that are described in [20]. These methods
were selected because they have obtained good results in
comparison with other data mining classi?cation systems
and because they have been applied to some of other data
sets used in our experiments. The comparison was per-
formed under the same conditions in terms that: all of
them deal with continuous values, they deal with clas-
si?cation problems, uses the support/con?dence frame-
work and evaluate their models trough the classi?cation
accuracy. The comparison was also performed under the
same conditions with CEFR method due to the follow-
ing reasons: CEFR is an evolutionary computation based
method (Genetic Programming) that deals with continu-
ous attributes using fuzzy discretization, discovers fuzzy
classi?cation rules based on a fuzzi?ed database, uses
three fuzzy membership functions and evolves the param-
eters of the fuzzy membership functions. The Iris dataset
is one of the most well-known datasets in machine learn-
ing literature. The dataset contains three classes of Iris
plant: Setosa, Versicolor and Virginica. The algorithm
classi?es the examples based on four attributes: sepal
length, sepal width, petal length and petal width. There
are 50 instances of each class in the dataset. The parame-
ters used for the extraction of fuzzy class association rules
by GNP are summarized in Table 3. All algorithms have
been developed in a Java-based software development en-
vironment. Experiments were performed on a 1.50GHz
Pentium M with 504MB RAM.
Table 3 Parameters for fuzzy classi?cation rule mining.
Parameter Value
Population size 120
Maximum generations 500
Number of processing nodes 20
Number of jugment nodes 200
Crossover rate 1/5
Mutation of the conecction rate 1/3
Mutation of the function rate 1/5
Mininum support 0.01
Minimum con?dence 0.5
Minimum ?2 6.63
?new 150
In order to obtain the best performance of the proposed
algorithm, the following methods were studied:
• Evolution of the fuzzy membership functions using
uniform and non-uniform mutation.
• Estimation of the matching degree with and without
using the ?2 value as a weight of the fuzzy rule.
The number of extracted fuzzy rules per each class
in the dataset using the uniform and non-uni?rm muta-
tion is shown in Fig.6, while Fig.7 shows the classi?ca-
tion accuracy of the different proposed methods. It can
be seen from Fig.6 that the GNP-based association rule
mining using non-uniform mutation extracts more rules
than GNP with uniform mutation. This is because, non-
uniform mutation reduces the disadvantages of random
mutation by searching the space uniformly at early gen-
erations and very locally at later generations. In other
words, the non-uniform mutation has the advantage of
higher probability for random search at early stages and
- 3868 -
much better local ?ne-tuning ability at later stages.
Fig. 6 Number of extracted fuzzy rules by GNP with
uniform and non-uniform mutation.
Fig. 7 Classi?cation accuracy of the proposed methods.
It can be seen from Fig. 7 that the evolution of the
fuzzy membership functions using non-uniform muta-
tion and taking the ?2 value into account as a weight of
the rule can obtain higher classi?cation accuracies. Ev-
idently, assigning appropriate weights to the rules ob-
tained by GNP will achieve higher classi?cation accu-
racies. A sample of the extracted fuzzy rules is shown
in Fig. 8. Table 4 shows the classi?cation accuracies
of seven methods including the proposed one on the Iris
dataset. It can be seen from Table 4 that the proposed
GNP-Fuzzy method outperforms all the other methods.
From Fig. 6, Fig. 7 and Table 4, we can draw the follow-
ing conclusions: (1) The proposed method can extract
correlated fuzzy rules in the selected database by tak-
ing the GNP’s structure into account. (2) The fuzzy dis-
cretization technique developed for dealing with contin-
uous data shows the signi?cance in the rule’s extraction
process since fuzzy class association rules in the pool are
used directly for the ?nal classi?er. (3) It is easy to calcu-
late the membership values, however the critical task is to
?nd appropiate membership functions. This is achieved
by evolving the fuzzy parameters using non-uniform mu-
tation, which shows its effectiveness for discovering new
fuzzy rules generation by generation. (4) The proposed
method builds a classi?er based on the average degree of
matching of the rules in each class with test data. (5)
We use support, con?dence and also the correlation mea-
sure ?2 value for calculating the signi?cance of the rules,
therefore, more effective rules are involved in the classi-
?er model. Using the ?2 values as the correlation mea-
sure for extracting fuzzy rules and also using them as
weights of the fuzzy rules leads to the improvement of the
classi?cation accuracy. (6) Finally, the proposed method
extracts fuzzy classi?cation rules which are more com-
prehensible for the users.
Fig. 8 Sample of the extracted fuzzy classi?cation rules.
Table 4 Comparison of the classi?cation accuracy (%).
Classi?cation approach Method Accuracy
GNP-Fuzzy GNP 97.5
CEFR-Miner GP 95.3
ESIA GA 95.3
BGP GP 94.1
CBA Apriori 94.0
C4.5 Apriori 95.3
CMAR Apriori 94.7
5. CONCLUSION
In this paper, a fuzzy association rule mining and clas-
si?cation method based on GNP have been proposed. We
have shown that the features of GNP make the proposed
model easy to formulate and use. Taking the structure
of GNP into account, the extraction of fuzzy association
rules is done without identifying frequent itemsets used
in most Apriori-based data mining algorithms. The fuzzy
membership functions are used for fuzzy rules extraction,
where their parameters are evolved in order to perform
the global search in the space of candidate membership
functions. The method of how to apply ?2 values to min-
ing association rules is also discussed. The experiments
of the proposed method and its comparisons with other
methods demonstrate that the algorithm is very effective.
REFERENCES
[1] S. Brin, R. Motwani and C. Silverstein, “Beyond
market baskets: generalizing association rules to
correlations”, In Proc. of the 1997 ACM SIGMOD
Conf., pp.265-276, 1997.
- 3869 -
[2] S. Mabu, K. Hirasawa and J. Hu, “A Graph-Based
Evolutionary Algorithm: Genetic Network Pro-
gramming and Its Extension Using Reinforcement
Learning”, Evolutionary Computation, MIT press,
Vol. 15, No.3, 2007.
[3] T. Eguchi, K. Hirasawa, J. Hu and N. Ota, “A study
of evolutionary multiagent models based on sym-
biosis”, IEEE Trans. on Systems, Man and Cyber-
netics, Part B, 36(1): pp. 179-193, 2006.
[4] K. Hirasawa, T. Eguchi, J. Zhou, L. Yu, J. Hu and
S. Markon, “A Double-deck Elevator Group Super-
visory Control System using Genetic Network Pro-
gramming”, IEEE Trans. on System, Man and Cy-
bernetics, Part C, Vol. 38, No. 4, pp. 535-550, 2008.
[5] K. Hirasawa, M. Okubo, H. Katagiri, J. Hu and
J. Murata, “Comparison between Genetic Network
Programming and Genetic Programming”, In Proc.
of the Congress of Evolutionary Computation, pp.
1276-1282, 2001.
[6] K. Shimada, K. Hirasawa and J. Hu, “Genetic Net-
work Programming with Acquisition Mechanisms
of Association Rules”, Journal of Advanced Com-
putational Intelligence and Intelligent Informatics,
Vol. 10, No. 1, pp. 102-111, 2006.
[7] K. Shimada, K. Hirasawa and J. Hu, “Class Associ-
ation Rule Mining with Chi-Squared Test Using Ge-
netic Network Programming”, In Proc. of the IEEE
SMC, pp. 5338-5344, 2006.
[8] L. Yu, J. Zhou, S. Mabu, K. Hirasawa, J. Hu
and S. Markon, “Double-Deck Elevator Group Su-
pervisory Control System Using Genetic Network
Programming with Ant Colony Optimization with
Evaporation”, J. of Advanced Computational Intel-
ligence and Intelligent Informatics, Vol. 11, No. 9,
pp. 1149-1158, 2007.
[9] Y. Chen, S. Mabu, K. Shimada and K. Hirasawa,
“Real Time Updating Genetic Network Program-
ming for Adapting to the Change of Stock Prices”,
IEEJ Trans. EIS, Vol. 129, No. 2, pp. 344-354,
2009.
[10] S. Mabu, K. Hirasawa, Y. Matsuya and J. Hu, “Ge-
netic Network Programming for Automatic Pro-
gram Generation”, J. of Advanced Computational
Intelligence and Intelligent Informatics, Vol. 9, No.
4, pp. 430-435, 2005.
[11] C. Silverstein, S. Brin and R. Motwani, “Beyond
market baskets: generalizing association rules to de-
pendence rules”, Data Mining and Knowledge Dis-
covery, pp. 39-68, 1998.
[12] R. Hilderman and H. Hamilton, “Applying Objec-
tive Interestingness Measures in Data Mining Sys-
tems”, In Proc. of the 4th European Symposium on
Principles of Data Mining and Knowledge Discov-
ery (PKDD’00), Lecture Notes in Computer Sci-
ence, Springer-Verlag, Lyon, France, pp. 432-439,
2000.
[13] S. Alvarez, “Chi-squared computation for associ-
ation rules: preliminary results”, Technical Re-
port BC-CS-2003-01 July 2003, Computer Science
Dept. Boston College Chestnut Hill, MA 02467
USA, 2003.
[14] K. Taboada, S. Mabu, E. Gonzales, K. Shimada and
K. Hirasawa, “Mining Fuzzy Association Rules:
A General Model Based on Genetic Network Pro-
gramming and its Applications”, IEEJ Trans., Vol.
5, No. 2, To appear, 2009.
[15] Z. Michalewicz, ”Genetic Algorithms + Data
Structures = Evolution Programs”, (3rd Edition),
Springer, 1996.
[16] C. J. Merz and P. Murphy, UCI repos-
itory of machine learning database,
http://www.cs.uci.edu/mlearn/MLRepository.html,
1996.
[17] R. Mendez, F. Voznika, A. Freitas and J. Nievola,
”Discovering Fuzzy Classi?cation Rules with Ge-
netic Programming and Co-Evolution”, In Proc. of
the 5th European Conference on Principles of Data
Mining and Knowledge Discovery (PKDD 2001), L
N A I 2168, pp. 314-325, Springer Berlin, 2001.
[18] J. J. Liu and J. T. Kwok, “An Extended Genetic Rule
Induction Algorithm”, In Proc. of the Congress
on Evolutionary Computation, La Jolla, CA, USA,
2000.
[19] S. E. Rouwhorst and A. P. Engelbrecht, “Searching
the Forest: Using Decision Tree as Building Blocks
for Evolutionary Search in Classi?cation”, In Proc.
of the Congress on Evolutionary Computation, La
Jolla, CA, USA, pp. 633-638, 2000.
[20] X. Yin and J. Han, “CPAR: Classi?cation based on
Predictive Association Rules”, In Proc. of the SIAM
International Conference on Data Mining, 2003.
