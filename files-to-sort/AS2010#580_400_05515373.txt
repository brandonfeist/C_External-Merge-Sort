                                                                                   
GLFMiner: Global and Local Frequent Pattern 
Mining with Temporal Intervals 
Kuo-Cheng Yin 
Department of Information Engineering and Computer 
Science, Feng Chia University, Taichung, 407 Taiwan 
Department of Information Management, Jen-Teh Junior 
College, Taiwan 
E-mail: inn0206@gmail.com 
Yuh-Long Hsieh, Don-Lin Yang  
Department of Information Engineering and Computer 
Science 
Feng Chia University 
Taichung, 407 Taiwan  
E-mail: yuhlong.hsieh@gmail.com, dlyang@fcu.edu.tw
Abstract—In this paper, we propose a new approach of mining 
temporal association rules. In conventional association rule 
mining algorithms, if the value of minimum support is set too 
high, we may lose lots of valuable rules. But if it is set too low, 
many trivial rules will be mined, and it is hard to distinguish 
which ones are valuable. When taking temporal factors into 
consideration, an itemset may not be frequent over the entire 
database but may be frequent in some specific intervals. Here, we 
propose a temporal association rule mining algorithm for interval 
frequent patterns, called GLFMiner, which can automatically 
generate all of the intervals without using any domain knowledge. 
In our algorithm, we consider not only global frequent patterns 
but also local frequent patterns. Then, with the same value of 
minimum support, we can find plenty of valuable temporal rules 
and don’t lose any rule that conventional association rule mining 
algorithm can find. The experimental results show that our 
algorithm can mine more temporal frequent patterns than the 
conventional association rule mining algorithm.
Keywords- association rule; local frequent pattern; global 
frequent pattern; temporal frequent pattern 
I. INTRODUCTION
The problem of mining association rule is to discover all 
rules that have support and confidence greater than or equal to 
the user-defined minimum support and minimum confidence 
thresholds. For example, examining the dataset of a 
supermarket, we may get an association rule like  
Turkey?Pumpkin pie (support=0.01%, confidence=5%) 
which means that 0.01% of all transactions contain both turkey 
and pumpkin pie, and 5% of all transactions which contain 
turkey also contain pumpkin pie. 
In fact, we can not regard the above rule as a prominent 
association rule due to the following two reasons. First, the 
support of that rule is low. It means that the turkey and 
pumpkin pie seldom coexist in the entire dataset. Second, the 
confidence of that rule is low too. It means that a large number 
of transactions which contain turkey do not contain pumpkin 
pies. However, if we only look at the transactions in a specific 
time interval, for example the week before Thanksgiving, it 
can be found that most of the transactions contain both turkey 
and pumpkin pie. It means that the rule, turkey?pumpkin pie, 
has a high support and a high confidence in the specific 
interval, the week before Thanksgiving.  
From the above example, an itemset may not be frequent 
for the entire database but may be frequent in some specific 
intervals. We can realize there are lots of meaningful frequent 
patterns which can be found in some specific intervals. 
Therefore, it is important on how we can find these intervals 
of frequent patterns in an effective manner. In [4], Yingjiu 
proposed the calendar based script to find the time interval, 
but it has to devise the calendar based script by using domain 
knowledge. Here, we expect to automatically generate the 
intervals without any domain knowledge. Our proposed 
GLFMiner algorithm first transforms the database into a bit-
map representation, and then recursively joins (k-1) itemsets 
to generate k itemsets in depth-first order. After joining the 
itemsets, GLFMiner will generate the intervals of frequent 
itemsets.  
The frequent patterns mined from the conventional 
association rule mining algorithms are called global frequent 
patterns. There is a problem which may lead the user to make 
a wrong decision according to these association rules. For 
example, a shopkeeper mines an association rule, 
diaper?beer, and then he/she may promote a sale package, 
10% discount for buying beer and diaper together, in the 
winter. The promotion is doomed to failure. The main reason 
is that one does not know when is the right time to apply the 
rule ‘diaper?beer’. Most people like to drink beer in the 
summer, so ‘diaper?beer’ may be suitable for the summer not 
winter. From the above example, it is important to generate the 
association rule which contains specific interval to be applied 
for the best result. Using GLFMiner algorithm we can not only 
get the frequent patterns of specific intervals, but also generate 
all the specific intervals for these local frequent patterns. 
The rest of paper is organized as follows. In Section II, we 
will describe the temporal association rule mining problem 
and introduce the related work of temporal association rule 
mining. In Section III, the proposed GLFMiner algorithm is 
described in three folds: (1). read the database and transform 
transactions into the bit-map representation, (2). localize the 
bit-map representations of all items to form intervals, (3). 
recursively join (k-1) itemsets to generate k itemsets and find 
local and global frequent itemsets. In Section IV, experimental 
results of synthetic datasets are given. Finally, we make a 
conclusion in Section V. 
This research was supported by the National Science Council, Taiwan, under
grants NSC 98-2221-E-035-059-MY2 and NSC 98-2218-E-007-005. 
2248978-1-4244-5046-6/10/$26.00 c©2010 IEEE
II. BACKGROUND AND RELATED WORK
In past decades, various algorithms have been proposed to 
efficiently discover the frequent itemsets in different 
applications. These methods include level-wise algorithms 
[1,2,3] and pattern-growth methods [4,5].  
Temporal association rule mining is an extension of 
association rule generation. There are many temporal 
association rule mining algorithms being proposed recently. 
They can mine more meaningful frequent patterns, temporal 
association rules of intervals and up-to-date association rules, 
than conventional association rule mining algorithm. We will 
introduce the related studies in the following. 
Hong [6] addressed the up-to-date association rule. The 
main idea comes from that an itemset may not be frequent for 
an entire database but may be large up-to-date since the items 
seldom occurring early may often occur later. An up-to-date 
pattern is composed of an itemset and its up-to-date lifetime, 
in which the user-defined minimum support threshold must be 
satisfied. 
It is possible to find interesting associations with a high 
confidence level but with small support. Ale [7] limited the 
total transactions to the ones belonging to the items' lifetime, 
those associations would be now discovered, as they would 
count on enough support. He expanded the notion of 
association rules incorporating time to the frequent itemsets. 
Every item has a period of lifetime or lifespan in the database, 
which explicitly represents the temporal duration of the item 
information, i.e. the time in which the item is relevant to the 
user. 
Lee [8] explored a new problem of mining general 
temporal association rules in publication databases. A 
publication database is a set of transactions where each 
transaction is a set of items of which each item contains an 
individual exhibition period. The author claimed that the 
current model of association rule mining is not able to handle 
the publication database due to the following fundamental 
problems, i.e., (1) lack of consideration of the exhibition 
period of each individual item; (2) lack of an equitable support 
counting basis for each item. He proposed a PPM algorithm. 
The basic idea of PPM is to first partition the publication 
database in light of exhibition periods of items and then 
progressively accumulate the occurrence count of each 
candidate 2-itemset based on the intrinsic partitioning 
characteristics. 
Tsai [9] proposed a new framework for data stream mining, 
called the weighted sliding window model. The proposed 
model allows the user to specify the number of windows for 
mining, the size of a window, and the weight for each window. 
It emphasized the temporal factor and gave higher weight to 
recently happened events. 
Li [10] studied the problem of mining association rules and 
related time intervals, where an association rule holds either in 
all or some of the intervals. To restrict to meaningful time 
intervals, he uses calendar schemas and their calendar-based 
patterns. A calendar schema example is (year, month, day) and 
a calendar-based pattern within the schema is (*, 3, 15), which 
represents the set of time intervals each corresponding to the 
15th day in March. 
[10,11] assume that the transactions are time-stamped, so 
one can decide if a transaction occurs during a specific time 
interval. The others [6,7,8,9] don’t make this assumption.  
In GLFMiner, we don’t assume the transaction is time 
stamped and use the transaction sequence as the temporal 
factor to generate all the intervals of itemsets. Our main 
contribution is that it can not only find out global frequent 
patterns in the whole database, but also discover local frequent 
patterns within the specific intervals.  
III. ALGORITHM DESCRIPTION 
A. Notation and definitions 
DB The database DB 
|DB| The number of transactions in the database DB 
|DBi| The total number of transactions in the interval i of DB
T(?) The transactions containing ? in the database DB 
Ti (?) The transactions containing ? in the specific interval i of DB 
MinSup The minimum support threshold 
MinLen The minimum length of an interval threshold
A frequent pattern is an itemset whose frequency in DB is 
larger than or equal to MinSup. Here, we propose the concept of 
local and global frequent patterns. GLFMiner performs a search 
for frequent pattern sets over a novel Interval-tree search space 
which is shown in Fig. 8. Each node in the Interval-tree, 
represented by an itemset-interval-tidset-count data structure, is in 
fact a prefix-based class. All the children with length k of a given 
node ? belong to its class since they all share the same prefix ?.
So, all the children in the same class can be joined to form (k+1) 
frequent patterns. Now, we show some definitions that will be 
used in the proposed algorithm later. 
Table 1 An example dataset 
Tid Transaction Time Items 
1 2009/7/1  a,b,d,f 
2 2009/7/16 a,b,d,f 
3 2009/8/3 d,f 
4 2009/8/9 c,f 
5 2009/9/10 a,f 
6 2009/9/30 f 
7 2009/10/3 c,e 
8 2009/10/18 a,b,c 
9 2009/11/8 a,b,c,d,e 
10 2009/11/27 a,f 
Definition 1: Interval-tree={Node1, Node2, …, Noden}. 
Interval-tree is a prefix based tree. The root node 
of Interval-tree is null. If Noden is the parent of 
Nodem, |Nodem|=|Noden|+1 and Noden is the 
prefix of Nodem.
Definition 2: The structure of a node for itemset ? in the 
Interval-tree is defined as follows:  
Struct 
{
2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2249
Itemset 
TidSegmentSet 
}
where Itemset records frequent pattern ? and each TidSegment
records information of intervals. TidSegmentSet is the set of all 
TidSegments.
Interval information contains ?[begin,end](bitmap):count, 
where [begin,end] represents an intervaO ?.begin is the first 
transaction id in this interval, ?.end is the last transaction id in 
this interval; ?.bitmap is a consecutive number of 1 and 0 
where 1 represents the corresponding transaction contains ?
and 0 represents the corresponding transaction does not 
contain ?; and ?.count is the number of the transactions which 
contain ?. For example, in Table 1, a[1,10](1100100111):6 
represents that itemset ‘a’ appears in the interval [1,10], the 
corresponding bitmap is (1100100111) and the frequency of 
occurrence is 6. ab[1,2](11):2,[8,9](11):2 represents that 
itemset ‘ab’ appears in two intervals: [1,2] and [8,9]. 
Definition 3: An itemset ? is called a global frequent pattern 
in a database DB if: 
(1) Support (?) = |T(?)|/|DB|  
(2) Support (?) MinSup 
The definition of global frequent patterns is the same as 
the definition of frequent patterns of conventional association 
rule mining algorithm. For example, based on the 
MinSup=0.5, item ‘a’[1,10] in Table 1 is a 1-global frequent 
itemset for the entire database, where the first transaction 
containing ‘a’ is 1 and the last transaction containing ‘a’ is 10.  
Definition 4: An itemset ? is called a local frequent pattern in 
a database DB if: 
(1) Support (?) = |Ti(?)|/|DBi|
(2) Support (?) MinSup 
Giving a MinSup, local frequent patterns represent the patterns 
whose counts are larger than MinSup just for the specific 
intervals. For example, if MinSup=0.5, itemset ‘e’ is a 1-local 
frequent itemset in the interval i=[7,9], because |Ti(e)|=2, 
|DBi|=3 and |Ti(e)|/|DBi|=0.67. However, it is not a global 
frequent itemset for MinSup=0.5. 
Definition 5: Two consecutive intervals are called mergeable 
if and only if the following condition is met:  
MinSupbeginend
countcount
nn
nn ?+?
+
?
?
1..
..
1
1
??
??
where ?n-1[begin,end]:count and ?n[begin,end]:count are two 
consecutive intervals of ?.
For example, c[4,4](1):1, c[7,9](111):3, 
MinSupbeginend
countcount ?== +?
+
+?
+ 67.0149
13
1..
..
12
12
??
??  , they are called 
mergeable. 
Definition 6: The merge of consecutive intervals is defined as 
follows: 
Merge(?n-1, ?n)= ?n-1 [begin,end](bitmap):count, where 
?n-1[begin,end](bitmap):count and ?n[begin,end](bitmap): 
count are two consecutive intervals of ? to be merged, then 
?n-1.begin=?n-1.begin, ?n-1.end=?n.end, ?n-1.count=(?n-1. count 
+?n.count), and bitmap is adjusted accordingly.  
For example, two intervals: cn-1[4,4](1):1, cn[7,9](111):3, 
Merge(cn-1,cn)=cn-1[4,9](100111):4, where cn-1.begin=cn-1.begin 
=4, cn-1.end= cn.end=9, cn-1.count=( cn-1.count+ 
cn.count)=(3+1) =4. 
Definition 7: The minimum length of an interval is denoted as 
MinLen. 
If the length of an interval is less than MinLen, it means 
this interval is not prominent enough. Then it will be deleted. 
For example, the length of an interval is 1, the support of this 
interval is 100% and the confidence is 100% too. Since it is 
meaningless at all, we can regard it as a noise and delete it. 
Definition 8: The nodes of itemset ? and itemset ? are called 
joinable, if and only if both the nodes ? and£
have the same parent node in the Interval-tree. 
Definition 9: The join of the nodes of itemset ? and itemset ?
is defined as follows?
?[begin,end](bitmap)?join(?[begin,end](bitmap), 
?[begin,end](bitmap)) 
where 
????? as in the traditional definition of join.  
?.begin=Max(?.begin, ?.begin) 
?.end=Min(?.end, ?.end) 
?.bitmap=AND( ?[?.begin, ?.end].bitmap, ?[?.begin, 
?.end].bitmap ) 
If (?.begin>=?.end), it means that the intervals of itemsets ?
and ? are disjoined. Then, the node of itemset ? will be 
discarded. 
For example, ?[begin,end](bitmap)=join( ab[1,2](11), 
af[1,5](11001)=abf[1,2](11) 
?= {a,b}?{a,f}={a,b,f} 
?.begin=Max(1,1)=1 
?.end=Min(2,5)=2 
?.bitmap=AND ( ab[1,2].(11), af[1,2].(11) )=AND(11,11)=11. 
B. Main Algorithm 
The proposed algorithm is composed of two main steps. 
First, it scans the database to find out the global frequency of 
each item and transforms all items into bit-map representation 
to speed up the following processing. Then, it localizes each 
item that is not global frequent and adds them to the Interval-
tree.
Second, it recursively joins each item in depth-first order 
on the Interval-tree. After that, it localizes the joined itemset to 
find out the frequent intervals and add them to the Interval-
tree. Those frequent intervals are output as temporal frequent 
itemsets. The pseudo code of GLFMiner algorithm is 
described in Fig. 1. In the following section, we will illustrate 
the detail steps of GLFMiner. 
2250 2010 5th IEEE Conference on Industrial Electronics and Applicationsis
                        
Main_Algorithm 
Input: (1) DB_File (2) MinSup (3) MinLen 
Output:(1) Global and Local Frequent ItemSet 
Begin 
1)  RootNode=ScanDataBase(DB_File, MinSup, MinLen); 
2)  FreqSet = RecursiveJoin(RootNode); 
End 
Fig. 1 The main algorithm of GLFMiner 
Function ScanDatabase 
Input:  (1) DB_File (2) MinSup (3) MinLen 
Output: (1) m_RootNode 
Begin 
1)   m_RootNode Í Create Root Node 
2)   Candidate_Items Í getItemFrequency (DB_File) 
3)   for (each item in Candidate_Items) 
4)     Begin 
5)        If not global frequent 
6)          Localize (Candidate_Items) 
7)        If IsFrequent (Candidate_Items, MinSup, MinLen) 
8)          m_RootNode.addChild (Candidate_Items); 
9)     End 
10)  Return m_RootNode 
End 
Fig. 2 The pseudo code of ScanDatabase 
Step 1: At first, GLFMiner scans the database, transformsds 
all items into bit-map representation and gets the frequency 
of each item to check whether it is global frequent. If it is not 
global frequent, Localize function is used to get local 
frequent intervals. The pseudo code of ScanDatabase is listed 
in Fig. 2. By using the dataset of Table 1 with MinSup=0.5, 
the bitmap representation of item ‘a’ is (1100100111) as 
shown in Fig. 3.  Because the count of item ‘a’ is 6 and is 
larger than MinSuph |DB|=0.5h 10=5, ‘a’ is a global 
frequent itemset. The bitmap representation of item ‘b’ is 
(1100000110). Since the count of item ‘b’ is 4 and is less 
than the MinSup threshold, ‘b’ is not a global frequent 
itemset and has to be localized. 
a(1100100111), b(1100000110), c(0001001110), d(1110000010), 
e(0000001010), f(1111110001)
Fig. 3 The bitmap representation of items 
Function Localize 
Input: (1) Node 
Begin 
1) TIDSegmentSet = Partition (TIDSet(Node), MinSup) 
2) TIDSegmentSet = MergeSegmentSet (TIDSegmentSet, MinSup) 
3) TIDSegmentSet = PruneSmallThanMinLen (TIDSegmentSet) 
End 
Fig. 4 The pseudo code of Localize 
Step 2: Localize those intervals of items which are not global 
frequent. Localization contains three steps as shown in Fig. 4. 
First, it partitions the bitmap representation of an itemset to 
find out the frequent intervals of that itemset. Then, it checks 
whether the two consecutive intervals can be merged in order 
to form a larger frequent interval. At last, it prunes the 
intervals whose lengths are less than MinLen.  
Function Partition 
Begin 
1)For each bitmap of Itemset ti
2)  k=1; Interval[1].begin==0 
3)  For j=1 to n //n=the length of the interval { 
4)    if (bitmap[j]=1) { 
5)      if (Interval[k].count==0 ) { 
6)          Interval[k].begin=j; 
7)          Interval[k].count=1; } 
8)      else {  
9)          Interval[k].count++; 
10)          Interval[k].end=j;  } }} 
11)   else { 
12)     if (Interval[k].count/(i-Interval[k].begin)<MinSup) and  
(Interval[k].count ? 0) { 
13)           Add_A_New_Interval_for_ti
14)           k++ 
15)           Interval[k].count= 0 }}} 
End 
Fig. 5 The pseudo code of Partition 
Step 2-1: Partition the bitmap representation of an itemset. The 
related pseudo code is described in Fig. 5. For example, 
itemset ‘d’ is not a global frequent itemset, and the bitmap 
representation of itemset ‘d’ is (1110000010). The procedure 
of partitioning itemset ‘d’ is shown in Table 2. 
Table 2 Partitioning the intervals of Itemset ‘d’ 
n Bit Interval  Action 
1 1 d[1,1]:1 1/0.5=2 ? (1-1+1) 
2 1 d[1,2]:2 2/0.5=4 ? (2-1+1) 
3 1 d[1,3]:3 3/0.5=6 ? (3-1+1) 
4 0 d[1,3]:3 3/0.5=6 ? (4-1+1) 
5 0 d[1,3]:3 3/0.5=6 ? (5-1+1) 
6 0 d[1,3]:3 3/0.5=6 ? (6-1+1) 
7 0 d[1,3]:3 3/0.5=6 < (7-1+1) Add A New Interval
8 0   Skip 
9 1 d[9,9]:1 1/0.5=2 ? (9-9+1) 
10 0 d[9,9]:1 1/0.5=2 ? (10-9+1) Add A New Interval
Step 2-2: Merge the two consecutive intervals into a larger 
interval from the back to the front. The pseudo code is 
described in Fig. 6. Taking c1[4,4](1):1 and c2[7,9](111):3 for 
example (cn-1=c1 and cn=c2), because (c1.count+c2.count)/ 
(c2.end-c1.begin+1)=(1+3)/(9-4+1)=4/6>MinSup, c1[4,4](1):1 
and c2[7,9](111):3 are merged into c1[4,9](100111):4.  
Function MergeSegmentSet (TIDSegmentSet, MinSup) 
Input: (1) SegmentList,(2) MinSup 
Output: TIDSegmentlSet 
Begin 
1)   n =|SegmentList | -2 
2)   While(n>=0) 
3)        if mergeable (Segmentn,Segmentn+1)
4)            SegmentList.remove (Segmentn+1)
5)            Segmentn= merge (Segmentn,Segmentn+1)
6)            if n == |SegmentList|-1 
7)                n--; 
8)       else 
9)            n--; 
End 
Fig. 6 The pseudo code of MergeSegmentSet 
Step 2-3: Prune the intervals whose length are less than 
MinLen in order to remove trivial intervals. For example, if 
MinLen=0.2 and the length of d2[9,9]:1 is 1 which is less 
than 0.2?10=2, d2[9,9]:1 will be removed. 
2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2251
Step 3: Recursively join the itemsets in depth-first (DF) order 
from the root. The pseudo code is described in Fig. 7. The 
node of length (k-1) joins all the right siblings to generate the 
combined itemset of length k. Every joining procedure 
contains the following steps.  
Step 3-1: Node 1 joins Node 2 (right sibling). For example,  
SonNode =a[1,10](1100100111):6 joins b[1,2](11):2 ?
ab[1,2](11):2 
SonNode =a[1,10](1100100111):6 joins b[8,9](11):2 ?
ab[8,9](11):2 
Step 3-2: Localize SonNode. 
Step 3-3: If SonNode is frequent, add it as a child of Node 1.  
Step 3-4: Add Node 1 to Frequent set FreqSet.  
Function RecursiveJoin 
Input:  (1) ParentNode 
Output: (1) FreqSet 
Begin 
1)for (each node1ParentNode ) 
2)  Begin 
3)     for (each node2  Right Siblings of node1 ) 
4)        Begin 
5)           SonNode = node1.Join(node2) 
6)           If not global frequent 
7)               Localize (Candidate_Items) 
8)           If isFrequent (SonNode) Then 
9)               node1.addChild (SonNode) 
10)      End 
11)   FreqSet=FreqSet?node1 
12)   FreqSet=FreqSet?RecursiveJoin (node1) 
13)   ParentNode.RemoveChild (node1) 
14) End 
End 
Fig. 7 The pseudo code of RecursiveJoin 
C. A Complete Example 
Step 1: GLFMiner transforms each item in DB into bitmap 
representation. 
Step 2: Perform localization 
Repeat 
Step 3-1: Node 1 joins Node 2 
Step 3-2: Localize SonNode 
Step 3-3: If SonNode is frequent, add it as a child of Node 1 
Step 3-4: Add Node 1 to Frequent set FreqSet. 
Table 3 shows the part of procedure when deploying 
GLFMiner to mine the dataset of Table 1. Here, it just lists the 
construction procedure of the leftmost branch of the Interval-
Tree. The complete Interval-tree is shown in Fig. 8. 
Table 3 The part of procedures of deploying GLFMiner 
Step 
1
Bitmap representations of every item 
a(1100100111):6, b(1100000110):4, c(0001001110):3, 
d(1110000010):4, e(0000001010):2, f(1111110001):8
Step 2-1 Partition 
a[1,10](1100100111):6, b[1,2](11):2, 
b[8,9](11):2,c[4,4](1):1, c[7,9](111):3, d[1,3](111):3, 
d[9,9](1):1, e[7,9](101):2, f[1,10](1110110101):7
Step 2-2 Merge 
a[1,10](1100100111):6, b[1,2](11):2, b[8,9](11):2, 
c[4,9](100111):4, d[1,3](111):3, d[9,9](1):1, 
e[7,9](101):2, f[1,10](1111110001):7 
Step 2-3 Prune 
a[1,10](1100100111):6, b[1,2](11):2, b[8,9](11):2, 
c[4,9](100111):4, d[1,3](111):3, e[7,9](101):2, 
f[1,10](1111110001):7 
Step 3-1 Join(a,*) ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,10](1100100001):5
Step 3-2 Localize ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,5](11001):3 
Step 3-3 Add node ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,5](11001):3 
Step 3-4 Add to Frequent set ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,5](11001):3 
Step 3-1 Join(ab[1,2],*) abd[1,2](11):2, abd[8,8](1):1, abf[1,2](11):2, abf[8,8](1):1
Step 3-2 Localize abd[1,2](11):2, abf[1,2](11):2 
Step 3-3 Add node abd[1,2](11):2, abf[1,2](11):2 
Step 3-4 Add to Frequent set abd[1,2](11):2, abf[1,2](11):2 
Step 3-1 Join(abd[1,2],*) abdf[1,2](11):2
Step 3-2 Localize abdf[1,2](11):2 
Step 3-3 Add node abdf[1,2](11):2 
Step 3-4 Add to Frequent set abdf[1,2](11):2 
Step 3-1 Join(abdf[1,2],*) 
Step 3-1 Join(abf[1,2],*) 
Step 3-1 Join(ab[8,9],*) abc[8,9](11):2
Step 3-2 Localize abc[8,9](11):2 
Step 3-3 Add node abc[8,9](11):2 
Step 3-4 Add to Frequent set abc[8,9](11):2 
Fig.8 The complete Interval-tree of Table 1 
2252 2010 5th IEEE Conference on Industrial Electronics and Applicationsis
IV. EXPERIMENTAL RESULTS
We implemented our algorithm in JAVA on an Intel Core 
Duo Processor personal computer with 1.99 GHz and 4 GB 
RAM. The synthetic database of IBM dataset generator, 
T10I4D100K was used. In T10I4D100K, the size of a 
transaction is 10, the size of potential maximal frequent 
itemsets is 4, and the number of transactions is 100,000
GLFMiner algorithm was compared to the 
conventional association rule mining algorithm of Apriori 
without considering temporal intervals. In the first 
experiment, the relationship between the numbers of frequent 
patterns for different minimum support thresholds is shown in 
Fig. 9. Fig. 9 shows the results of T10I4D100K with 
MinLen=0.01 and MinSup=0.9 to 0.1. It is clear that the 
number of frequent patterns discovered by GLFMiner was 
larger than those mined by the conventional method.
0
2,000
4,000
6,000
8,000
10,000
12,000
14,000
16,000
0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
MinSupport Threshold
??
?
??
???
???
??
??
??
???
??
??
??
?
???????
????????

Fig. 9 The relationship between the numbers of frequent patterns for 
different MinSup thresholds of T10I4D100K 
The variation between the numbers of local frequent 
patterns and different MinSup thresholds for T10I4D100K is 
shown in Fig. 10. We can observe that the smaller the MinSup 
is, the larger the count of local frequent patterns is.  
0
100
200
300
400
500
600
700
800
0.09 0.08 0.07 0.06 0.05 0.04 0.03 0.02
MinSupport Threshold
??
?
??
???
???
??
??
??
??
??
??
??
?
??
???
??
?
Fig. 10 The relationship between the numbers of local frequent patterns for 
different MinSup thresholds of T10I4D100K 
The variation between the number of frequent patterns and 
different MinSup thresholds for T10I4D100K with 
MinSup=0.4 and MinLen=0.009 to 0.001 is shown in Fig. 11. 
We can observe that the smaller the MinLen is, the larger the 
count of frequent patterns is. When deploying GLFMiner 
algorithm, we can set a higher MinSup to cooperate with 
appropriate MinLen to mine the valuable frequent patterns.  
0
20
40
60
80
100
120
0.009 0.008 0.007 0.006 0.005 0.004 0.003 0.002 0.001
??????????? ?????
?
??
??
???
???
??
??
??
???
??
??
??
?
???????
????????
Fig. 11 The variation between the numbers of frequent patterns and 
different minimum support of MinLen thresholds 
V. CONCLUSIONS AND FUTURE WORK
In this work, we have described the concept of global and 
local frequent patterns and propose an approach, GLFMiner, 
to discover such patterns from a temporal dataset. We have 
achieved the following advantages: 
?Discover association rules which are frequent in some 
specific time intervals. 
?The mined association rules contain time attributes that 
make them more useful for users. 
?Valuable rules can still be mined using larger thresholds. 
?Automatically generate the intervals of frequent patterns. 
REFERENCES 
 [1] Ming-Chuan Hung, Shi-Qin Weng, Jungpin Wu and Don-Lin Yang, 
“Efficient Mining of Association Rules Using Merged Transactions 
Approach,” WSEAS Transactions on Computers, Iss. 5, Vol. 5, May 
2006, pp. 916-923. 
[2] R. Agrawal and R. Srikant, “Fast Algorithms for Mining Association 
Rules,” Proceedings of the 20th International Conference on Very Large 
Data Bases, 1994, pp. 487-499. 
[3] Wei Song, Bingru Yang and Zhangyan Xu, ? Index-BitTableFi: An 
improved algorithm for mining frequent itemsets,” Knowledge-Based 
Systems, Volume 21, Issue 6, Aug. 2008, pp. 507-513. 
[4] J. Han, J. Pei, and Y. Yin, “Mining Frequent Patterns without Candidate 
Generation,” Proceedings of the 2000 ACM SIGMOD International 
Conference on Management of Data, 2000, pp. 1-12. 
[5] M. Song and S. Rajasekaran, “A Transaction Mapping Algorithm for 
Frequent Itemsets Mining,” IEEE Transaction on Knowledge and Data 
Engineering, Vol. 18, No. 4, 2006, pp. 472-481. 
 [6] Tzung-Pei Hong, Yi-Ying Wu, Shyue-Liang Wang, “An effective mining 
approach for up-to-date patterns”, Expert systems with applications, 36, 
2009, pp. 9747?9752. 
 [7] J. M. Ale and G. H. Rossi, “An approach to discovering temporal 
association rules”, Proceedings of the 2000 ACM Symposium on 
Applied computing - Volume 1, pp. 294 - 300. 
 [8] C. H. Lee, C. R. Lin and M. S. Chen, “On mining general temporal 
association rules in a publication database,” Proceedings of the 2001 
IEEE International Conference on Data Mining, pp. 337-344. 
[9] Pauray S. M. Tsai, “Mining frequent itemsets in data streams using the 
weighted sliding window model,” Expert Systems with Applications, 
Volume 36, Issue 9, November 2009, pp. 11617-1162. 
[10]  Yingjiu Li, Peng Ning, X. Sean Wang and Sushil Jajodia, “Discovering 
calendar-based temporal association rules,” Data and Knowledge 
Engineering, Volume 44, Issue 2, Feb. 2003, pp. 193-218.  
[11]  K. Verma, O. P. Vyas, and R. Vyas, “ Temporal approach to association 
rule mining using T-tree and P-tree” , Lecture Notes in Computer 
Science, 3587, 2005, 651?659. 
2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2253
