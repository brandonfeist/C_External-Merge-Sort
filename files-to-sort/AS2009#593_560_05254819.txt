2009 International Conference on Electrical Engineering and Informatics 
5-7 August 2009, Selangor, Malaysia 
978-1-4244-4913-2/09/$25.00 ©2009 IEEE 
AI-08 
36 
 
Scalable and Efficient Method for Mining 
Association Rules 
Wael A. AlZoubi, Azuraliza Abu Bakar, Khairuddin Omar 
System Management and Science Department, National University of Malaysia 
Faculty of Information Science And Technology, Universiti Kebangsaan Malaysia, 43600 Bangi, Selangor. 
Malaysia 
alzoubi_wael@yahoo.com 
aab@ftsm.ukm.my 
ko@ftsm.ukm.my 
ABSTRACT 
Association rules mining (ARM) algorithms have been extensively 
researched in the last decade. Therefore, numerous algorithms 
were proposed to discover frequent itemsets and then mine 
association rules. This paper will present an efficient ARM 
algorithm by proposing a new technique to generate association 
rules from a huge set of items, which depends on the concepts of 
clustering and graph data structure, this new algorithm will be 
named clustering and graph-based rule mining (CGAR). The 
CGAR method is to create a cluster table by scanning the database 
only once, and then clustering the transactions into clusters 
according to their length. The frequent 1-itemsets will be extracted 
directly by scanning the cluster table. To obtain frequent k-
itemsets, where k ? 2, we build directed graphs for each cluster in 
the case of very huge amount of transactions. This approach 
reduces main memory requirement since it considers only a small 
cluster at a time and hence it is scalable for any large size of the 
database. Experiments show that our algorithm outperforms other 
rule mining algorithms. 
1. INTRODUCTION 
Data mining is a tool that supports research and allows new 
assertions to be made by disclosing previously undisclosed 
details in large amounts of data [11]. One of the most 
challenges in database mining is developing fast and efficient 
algorithms that can deal with large volume of data because 
most mining algorithms perform computation over the entire 
database and mostly the databases are very large. 
Association rules mining is one of the most well studied 
data mining tasks. It discovers relationships among attributes in 
different types of databases, producing if-then statements 
concerning attribute-values [2]. It was firstly introduced in [1] 
to discover association rules between items over basket data, an 
association rule describes the associations among items in 
which when some items are purchased in a transaction, the 
others are purchased, too. In order to find association rules, we 
need to discover all large or frequent itemsets from a large 
database of customer transactions. A large itemset is a set of 
items which appear often enough within the same transactions. 
In this paper, we introduce an algorithm called CGAR, 
which is fundamentally different from all the previous 
algorithms in the following points: 
i. It reads the database of transaction only once to 
generate frequent 1-itemsets. 
ii. It is scalable with all types of databases 
regardless to their size. 
iii. It is as efficient as it requires less memory and 
CPU time to generate strong rules from the 
transaction database. 
iv. It is easy to implement as it uses simple cluster 
table and a robust graph data structure. 
  
37 
 
The rest of the paper is organized as follows. In 
Section 2, we provide a general definition of the problem of 
rule mining, in section 3, a concise explanation of rule mining 
algorithms and the relative researches of association rules are 
given, and then, in Section 4, we offer our algorithm, which we 
have called CGAR, and give an example of CGAR in Section 
5. Section 6 contains the design of our experiments and the 
results returned; finally, in Section 7, we present our 
conclusions. 
2. Association Rule Problem 
Association rules, first introduced in 1993, are used to 
identify relationships among a set of items in a database, it was 
used in the sale transaction databases domain, and so there 
should be a set of [m] distinct items I = {I1, I2, … , Im}, and a 
database of  transactions D,  where each transaction T has a 
unique identifier TID, and contains a set of items such that T?I. 
An association rule is an implication of the form 
X?Y, where X and Y are subsets of I, and they are disjoint, 
that is, X?Y =?. X and Y are sets of items called itemsets. The 
rule X ?Y holds in the database D with confidence c, if c% of 
transactions in D that contain X also contain Y. The rule X ?Y 
has support s in the transaction set D, if s% of transactions in D 
contain X ?Y. Given the database D, the problem of mining 
association rules involves the generation of all association rules 
that have support and confidence greater than or equal to the 
user-specified minimum support and minimum confidence. 
3. Background 
Previous studies in data mining have presented 
efficient algorithms for discovering association rules. But the 
main problem in the first algorithms is the need to do multiple 
passes over the datasets to generate frequent itemsets. The 
Apriori association rule algorithm proposed by Agrawal and 
Srikant [2] can discover meaningful itemsets and build 
association rules within large databases, but a large number of 
the candidate itemsets are generated from single itemsets and 
this method also needs to perform contrasts against the whole 
database, level by level, in the process of creating association 
rules. Performance is severely affected, as the database is 
repeatedly scanned to contrast each candidate itemset with the 
database. After Agrawal et al. [1994] proposed the Apriori 
association rule, most association rules researchers have used 
Apriori-like candidate generated approaches, all of these 
methods focus on reducing the number of candidate itemsets, 
and therefore reducing the number of database scans. 
Different strategies were developed after that to 
improve the process of generation association rules, as in FP-
Growth [8], which outperforms all candidate-set-generation-
and- test algorithms as it mines frequent patterns without 
candidate generation, but it still have problems in the case of no 
common prefixes within the data items. Another technique is 
the sampling algorithm which reduces the number of database 
scans to a single scan, but still wastes considerable time on 
candidate itemsets [5].  A third algorithm is the dynamic 
itemset count (DIC) algorithm [6] for finding large itemsets, 
which uses fewer passes over the data than classic algorithms, 
and yet uses fewer candidate itemsets than methods based on 
sampling [5]. In addition, the column-wise apriori algorithm 
[10] and the tree-based association rule algorithm [4], 
transformed the storage structure of the data, to reduce the time 
needed for database scans, improving overall efficiency. 
Finally, the partition algorithm [7]  to further improve 
efficiency, it does so by effectively reducing the number of 
database scans, however, considerable time is still wasted 
  
38 
 
scanning infrequent candidate itemsets. Pork et al. proposed an 
effective algorithm DHP (direct hashing and pruning) [3] for 
the initial candidate set generation. This method efficiently 
controls the number of candidate 2-itemsets, pruning the size of 
database [8]. 
4. Clustering and Graph-based Association Rule (CGAR) 
Although, the Cluster-based Association Rule (CBAR) 
algorithm [1] outperforms Apriori algorithm as it scans the 
database only once, but the opportunity to enhance cluster-
based algorithms still available by providing an efficient graph 
data structure to simplify the process of generating frequent k-
itemsets, where k ? 2.   
In this paper, we present a new algorithm called 
clustering and graph-based association rule (CGAR), for 
efficient association rules mining, which overcome the 
drawbacks of the previous algorithms. 
The items should be given sequential numbers to 
simplify the process of building the graph; this must be taken in 
consideration as an important action before applying our 
proposed algorithm. CGAR scans the database of transactions 
only once to build the clustering table as a two-dimensional 
array where the columns represent items and the rows 
represent transactions’ IDs (TIDs). The contents of the table 
consist of 0 or 1 to indicate the absence or presence of an item 
in a transaction, respectively. After that, the bit vectors for 
each item will be ready and it is an easy process to determine 
the frequent 1-itemsets by counting the number of 1s in each 
transaction, if it isn’t less than the minimum support 
threshold, it is considered as a frequent itemset and then be 
used in building the graph, otherwise, it will be discarded 
from further discussion as it is infrequent item. The second 
phase starts by reordering frequent 1-itemsets by providing 
each one with a sequential number to facilitate the process of 
constructing the graph, which is constructed by doing logical 
and operation between each pair of consecutive frequent 1-
itemsets <itemi, itemj> | i < j, if the number of 1s in the result 
is greater than or equal to minimum support threshold, a 
directed edge is drawn from itemi to itemj, this operation is 
repeated for all frequent 1-itemsets. As the graph is completed, 
the set of frequent 2-itemsets are generated, and it will be direct 
from the graph traversing to generate frequent k-itemsets, such 
as k ? 3. CGAR will deal with only one type of ARs, that is, 
Boolean ARs. 
5. An Example of CGAR 
We provide an example to give an extra explanation to 
our proposed algorithm; the minimum support threshold is 
45%. There are 18 transactions and 5 different items in the 
database. We assume – as in most of sequential rule mining 
algorithms – that the items are in lexicographical order. A 
transaction database example is shown in Table 1; we represent 
the items by letters rather than numbers to deal some worst 
cases, where the numbering step is required 
TID Items  TID Items TID Items 
T1 A, B, C T7 C, E T13 A, B, C, E 
T2 B, C T8 B, C, E T14 C, D 
T3 A, E T9 A, B, C, D T15 B, C, D 
T4 A, C, D, E T10 A, D T16 A, D, E 
T5 A, C T11 A, B, D T17 B, D, E 
T6 A, C, E T12 C, E T18 A, C, D 
Table 1: an example of database of transactions 
  
39 
 
The first step, as we said, is scanning the database to  
determine the length of each transaction, the length means the 
number of items in a transaction, and at the same time, 
assigning numbers to the items, item A will be given the 
number 1, item B the number 2 and so on. This will help us in 
both constructing the cluster table and building the graph, after 
that we don’t need to rescan the database, as we will move to 
deal with the clustering table that can be easily resided in the 
main memory. 
 In our example, the maximum transaction length is 4, 
and so, there will be at most four clusters. Since there are no 
transactions of length 1, the total number of clusters is 3 as 
shown in Table 2, the table contents are 0s or 1s to denote 
absence or existence of an item in a transaction, after 
constructing the table, each column is the bit vector for the 
corresponding item, and so, no need to make further contrasts 
with the cluster table. These bit vectors are used in building the 
graph and determining the frequent 1-itemsets. 
The bit vectors for the items are: 
BV1 = 011010011010101111    
BV2 = 100000010111010011 
BV3 = 101101111101001111 
BV4 = 000010100011111110 
BV5 = 010101001100110101 
 
 
By counting the number of 1s in each bit vector, we 
determine the support for each candidate itemset of length 1, as 
the following: support ({1}) = 55%, support ({2}) = 40%, 
support ({3}) = 45%, support ({4}) = 65%, and support ({5}) = 
0.45.Thus the frequent 1-itemsets are: {{1}, {3}, {4}, {5}} as 
their supports are not less than 45%. 
  
40 
 
The second step is started by making logical and (?) 
between each pair of frequent 1-itemsets, as we mentioned 
earlier in this paper, and by assigning 30% as a new value to 
the minimum support threshold, we found that the frequent 2-
itemsets will be: {{1, 3}, {1, 4}, {3, 5}}, and the graph is 
constructed by drawing an edge between each pair of frequent 
items, as in Figure 1. 
 
 
Figure 1: a simple directed graph to display frequent k-itemsets, k ? 2 
To determine frequent 3-itemsets, we traverse the 
graph as if there is a path among three nodes {i , j} and {j, k} 
then the set {i, j, k} will be frequent 3-itemset. Here, in this 
example, {{1, 3, 5}} is the only frequent 3-itemsets. As there 
are no extra edges, the algorithm terminates. 
In the standard situation, as the database contains 
hundreds of thousands of transactions and different items, 
constructing only one graph is not practical, and so we 
suggested to construct different graphs for each cluster and find 
from this graph all frequent itemsets, then combine the subsets 
of frequent itemsets together to get the whole set of frequent 
itemsets, and this technique is scalable with all transactions 
databases of different sizes. 
6. Experimental Results 
To assess the efficiency of the proposed technique, we 
have implemented the CGAR, along with Apriori algorithm, 
using Java programming language on a Pentium IV 1700 MHz 
PC with 512MB of available physical memory. The test 
databases are the standard datasets available to evaluate rule 
mining algorithms, they are: T10I4D100K and T40I10D100K. 
We execute both algorithms, Apriori and CGAR, at 
various values of minimum support thresholds, as the number 
of frequent itemsets generated inversely proportional with the 
value of the minimum support. Figure 2 displays the average 
execution time in seconds to generate all frequent itemsets 
using CGAR and Apriori algorithm. 
 
 
 
 
 
 
 
Figure 2: a comparison between Apriori and CGAR 
The experimental results in Figure 2 show that the 
CGAR algorithm has better performance than Apriori in terms 
of the execution time. When there is an increase in the number 
and size of frequent itemsets discovered, i.e. reduction in the 
minimum support threshold, the performance gap between 
these algorithms is displayed in greater clearance. 
7. Conclusion 
In this paper we propose a new framework, which is 
scalable and efficient.  The entire database is divided into 
1 
3 
5 
4 
Time 
(Seconds) 
 
Minimum Support % 
  
41 
 
partitions of variable sizes, each partition will be called a 
cluster.  Each cluster is considered one at a time by loading the 
first cluster into memory and calculating large itemsets and the 
corresponding support counts. Then the second cluster is 
considered similarly and the cumulative support count is 
calculated for the cumulative large itemsets. This process is 
continued for the entire set of clusters and finally we have the 
whole large itemsets and the corresponding cumulative support 
counts.  This approach reduces main memory requirement since 
it considers only a small cluster at a time and hence it is 
scalable for any large size of the database. 
Experiments using two of the standard transaction 
databases available on the Internet, T10I4D100K and 
T40I10D100K, show that CGAR outperforms Apriori, a 
familiar and widely used association rule mining algorithm. 
When there is a reduction in the value of the minimum support 
threshold, the performance gap between the algorithms 
becomes more evident.  
References 
[1] Yuh-Jiuan Tsay,  Jiunn-Yann Chiang, CBAR: an efficient method for 
mining association rules, Knowledge-Based Systems 18 (2005) 99–105. 
[2] R. Agrawal, T. Imilienski, A. Swami, Mining association rules between sets 
of items in large databases, Proceedings of the ACM SIGMOD International 
Conference on Management of Data, Washington, DC, 1993 pp. 207–216. 
[3] S. Ayse Ozel and H. Altay Güvenir, An Algorithm for Mining Association 
Rules Using Perfect Hashing and Database Pruning, (2000). 
 
[4] R. Agrawal, R. Srikant, Mining sequential patterns, Proceedings of the 11th 
International Conference on Data Engineering (ICDE), 1995.  
[5] F. Berzal, J.C. Cubero, N. Marin, J.M. Serrano, TBAR: an efficient method 
for association rule mining in relational databases, Elserier Data and 
Knowledge, Engineering 37 (2001) 47–64. 
[6] S. Brin, R. Motwani, C. Silverstein, Beyond market baskets: generalizing 
association rules to correlations, ACM SIGMOD Conference on Management 
of Data, Tuscon, Arizona, 1997 pp. 265–276. 
[7] Ashok Savasere, Edward Omiecinski, and Shamkant Navathe. An Efficient 
Algorithm for Mining Association Rules in large databases. 1995 
[8] Han, J., Pei, J., Yin, Y: Mining frequent Patterns without Candidate 
Generation. In: ACM-SIGMOD, Dallas (2000) 
 [9] Show-Jane Yen and Arbee L.P. Chen, A Graph-Based Approach for 
Discovering Various Types of Association Rules, IEEE TRANSACTIONS ON 
KNOWLEDGE AND DATA ENGINEERING, VOL. 13, NO. 5, 
SEPTEMBER/OCTOBER 2001. 
[10] D.W. Cheung, J. Han, V.T. Ng, A.W. Fu, Y. Fu, A fast distributed 
algorithm for mining association rules, Proceedings of International Conference 
on PDIS’96, Miami Beach, Florida, USA, 1996. 
[11] Ben Franklin, Genealogical Data Mining, 2006. 
 
