 339
Potential use of Artificial  Neural Network in Data Mining 
 
Ms.Smita.Nirkhi 
Department of computer Science 
G.H.Raisoni College of Engineering 
Nagpur, India 
smita811@gmail.com 
 
 
Abstract— with the enormous amount of data stored in 
files, databases, and other repositories, it is increasingly 
important, to develop powerful means for analysis and 
perhaps interpretation of such data and for the 
extraction of interesting knowledge that could help in 
decision-making. Data Mining, also popularly known as 
Knowledge Discovery in Databases (KDD), refers to the 
nontrivial extraction of implicit, previously unknown 
and potentially useful information from data in 
databases. Thus data mining is the process of automated 
extraction of hidden, predictive information from large 
databases. Data mining includes: extract, transform, and 
load transaction data onto the data warehouse system.  
Neural networks have been successfully applied in a 
wide range of supervised and unsupervised learning 
applications. Neural-network methods are not 
commonly used for data-mining tasks, because they may 
have complex structure, long training time, and uneasily 
understandable representation of results & often 
produce incomprehensible models. However, neural 
networks have high acceptance ability for noisy data and 
high accuracy and are preferable in data mining. In this 
paper, investigation is made to explore application of 
Artificial Neural Network in Data mining techniques, 
the key technology and ways to achieve the data mining 
based on neural networks are also researched. Given the 
current state of the art, neural-network deserves a place 
in the tool boxes of data-mining specialists.  
 
Keywords-Data mining,KDD,SOM,Data mining process 
I.  INTRODUCTION  
Data mining, the extraction of hidden predictive 
information from large databases, is a powerful new 
technology with great potential to help companies focus on 
the most important information in their data warehouses. 
Data mining tools predict future trends and behaviors, 
allowing businesses to make proactive, knowledge-driven 
decisions. The automated, prospective analyses offered by 
data mining move beyond the analyses of past events 
provided by retrospective tools typical of decision support 
systems. Data mining tools can answer business questions 
that traditionally were too time consuming to resolve. They 
search databases for hidden patterns, finding predictive 
information that experts may miss because it lies outside 
their expectations. Different types of data mining tools are 
available in the marketplace, each with their own strengths 
and weaknesses. Internal auditors need to be aware of the 
different kinds of data mining tools available and 
recommend the purchase of a tool that matches the 
organization's current detective needs. This should be 
considered as early as possible in the project's lifecycle, 
perhaps even in the feasibility study. 
 
Data mining commonly involves four classes of tasks.[1] 
Classification - Arranges the data into predefined groups. 
For example an email program might attempt to classify an 
email as legitimate or spam. Common algorithms include 
Decision Tree Learning, Nearest neighbor, naive Bayesian 
classification and Neural network.  
Clustering - Is like classification but the groups are not 
predefined, so the algorithm will try to group similar items 
together.  
Regression - Attempts to find a function which models the 
data with the least error.  
Association rule learning - Searches for relationships 
between variables. For example a supermarket might gather 
data on customer purchasing habits. Using association rule 
learning, the supermarket can determine which products are 
frequently bought together and use this information for 
marketing purposes. This is sometimes referred to as "market 
basket analysis".  
Artificial Neural Network is a system loosely modeled 
based on the human brain. The field goes by many names, 
such as connectionism, parallel distributed processing, 
neuro-computing, natural intelligent systems, machine 
learning algorithms, and artificial neural networks. It has 
ability to account for any functional dependency. The 
network discovers (learns, models) the nature of the 
dependency without needing to be prompted. Initially the 
application of data mining is not being used because of 
Complex structure, long training time, and poor 
interoperability. But as neural networks is a powerful 
technique to solve many real world problems. They have the 
ability to learn from experience in order to improve their 
performance and to adapt themselves to changes in the 
environment. In addition to that they are able to deal with 
incomplete information or noisy data and can be very 
Volumn 2
 978-1-4244-5586-7/10/$26.00      2010 IEEEC
 340
effective especially in situations where it is not possible to 
define the rules or steps that lead to the solution of a problem.  
II. DATA MINING TECHNIQUES 
Data mining techniques can be implemented rapidly on 
existing software and hardware platforms to enhance the 
value of existing information resources, and can be 
integrated with new products and systems as they are 
brought on-line. When implemented on high performance 
client/server or parallel processing computers, data mining 
tools can analyze massive databases to deliver answers to 
questions such as, "Which clients are most likely to respond 
to my next promotional mailing, and why?" 
As shown in Fig1, Data mining process consist of three 
main phases:- 
1. Data preprocessing 
2. Applying data mining techniques 
3. Interpretation of Results  
 
Fig1: General Data mining Process 
This section provides an introduction to the basic 
techniques of data mining. The most commonly used 
techniques in data mining are:  
• Artificial neural networks: Non-linear predictive 
models that learn through training and resemble 
biological neural networks in structure.  
• Decision trees: Tree-shaped structures that 
represent sets of decisions. These decisions 
generate rules for the classification of a dataset. 
Specific decision tree methods include 
Classification and Regression Trees (CART) and 
Chi Square Automatic Interaction Detection 
(CHAID).  
• Genetic algorithms: Optimization techniques that 
use process such as genetic combination, mutation, 
and natural selection in a design based on the 
concepts of evolution.  
• Nearest neighbor method: A technique that 
classifies each record in a dataset based on a 
combination of the classes of the k record(s) most 
similar to it in a historical dataset . Sometimes 
called the k-nearest neighbor technique.  
• Rule induction: The extraction of useful if-then 
rules from data based on statistical significance.  
III. ANN APPLICATION IN DATA MINING 
As discussed in the previous section, we can use various 
techniques in data mining. This section will focus on how 
artificial neural networks are appropriate for data mining. 
There are two main types of neural network models: 
supervised neural networks such as the multi-layer 
perceptron or radial basis functions, and unsupervised neural 
networks such as Kohonen feature maps. A supervised 
neural network uses training and testing data to build a 
model. The data involves historical data sets containing input 
variables, or data fields, which correspond to an output. The 
training data is what the neural network uses to “learn” how 
to predict the known output, and the testing data is used for 
validation. The aim is for the neural networks to predict the 
output for any record given the input variables only.  
 
 
            Fig2: Example of a simple feed forward neural network  
 
One of the simplest feed forward neural networks 
(FFNN), such as the one in Fig2, consists of three layers: an 
input layer, hidden layer and output layer. In each layer there 
are one or more processing elements (PEs). PEs are meant to 
simulate the neurons in the brain and this is why they are 
often referred to as neurons or nodes. A PE receives inputs 
from either the outside world or the previous layer. There are 
connections between the PEs in each layer that have a weight 
(parameter) associated with them. This weight is adjusted 
during training. Information only travels in the forward 
direction through the network - there are no feedback loops.  
Volumn 2
 341
 
Why Neural Networks 
 
High Accuracy: Neural networks are able to approximate 
complex non-linear mappings.  
Noise Tolerance:  Neural networks are very flexible with 
respect to incomplete, missing and noisy data.  
Independence from prior assumptions: 
 Neural networks can be updated with fresh data, making 
them useful for dynamic environments. Hidden nodes, in 
supervised neural networks can be regarded as latent 
variables. Neural networks can be implemented in parallel 
hardware 
 
IV. TRADITIONAL APPROACHES TO INFORMATION 
PROCESSING VS. NEURAL NETWORKS 
In this section comparison is made between traditional 
methods & neural Network for information processing. 
A) Foundation: Logic vs. Brain 
Traditional Approach: - Simulate and formalize human 
reasoning and logic process. TA treats the brain as a black 
box. TA focuses on how the elements are related to each 
other and how to give the machine the same capabilities. 
Neural Networks:- Simulate the intelligence functions of 
the brain. NN focus on modeling the brain structure. NN 
attempts to create a system that functions like 
the brain because it has a structure similar to the structure of 
the brain 
B). Processing Techniques: Sequential vs. Parallel 
Traditional Approach: The processing method of TA is 
inherently sequential. 
Neural Networks: The processing method of NN is 
inherently parallel. Each neuron in a neural network system 
functions in parallel with others 
C ) Learning: Static and External vs. Dynamic and Internal 
Traditional Approach: Learning takes place outside of the 
system. The knowledge is obtained outside the system and 
then coded into the system. 
Neural Networks: Learning is an integral part of the system 
and its design. Knowledge is stored as the strength of the 
connections among the neurons and it is the job of NN to 
learn these weights from a data set presented to it. 
 
D) Reasoning Method: Deductive vs. Inductive 
Traditional Approach: Is deductive in nature. The use of 
the system involves a deductive reasoning process, applying 
the generalized knowledge to a given case. 
Neural Networks: Is inductive in nature. It constructs an 
internal knowledge base from the data presented to it. It 
generalizes from the data, such that when it is presented a 
new set of data, it can make a decision based on the 
generalized internal knowledge. 
 
E) Knowledge Representation: Explicit vs. Implicit 
Traditional Approach: It represents knowledge in an 
explicit form. Rules and relationships can be inspected and 
altered. 
Neural Networks: The knowledge is stored in the form of 
interconnections strengths among neurons. Nowhere in the 
system, can one pick up a piece of computer code or a 
numerical value as a discernible piece of knowledge. 
V. DATA MINING BASED ON NEURAL NETWORK 
A  Data mining based on Self-Organizing Maps (SOM)  
The self-organizing maps (SOM) introduced by Teuvo 
Kohonen [11]are deemed as being highly effective as a 
sophisticated visualization tool for visualizing high 
dimensional, complex data with inherent relationships 
between the various features comprising the data. The 
SOM’s output emphasizes the salient features of the data and 
subsequently leads to the automatic formation of clusters of 
similar data items. This particular characteristic of SOMs 
alone qualifies them as a potential candidate for data mining 
tasks that involve classification and clustering of data items. 
A ‘learnt’ SOM can be used as an important visualization aid 
as it gives a complete picture of the data; similar data items 
are automatically grouped together.  
The Self-Organizing Map (SOM) has proven to be one of 
the most powerful algorithms in data visualization and 
exploration. Application areas include various fields of 
science and technology, e.g., complex industrial processes, 
telecommunications systems, document and image databases, 
and even financial applications. The SOM maps the high-
dimensional input vectors onto a two-dimensional grid of 
prototype vectors and orders them. For a human interpreter, 
the ordered prototype vectors are easier to visualize and 
explore than the original data. The SOM has been widely 
implemented in various software tools and libraries. 
 
Fig3: Applying SOM in Data mining 
 
As shown in fig3, Post-processing the SOM extracts 
qualitative or quantitative information of the data. 
Visualization and clustering provide qualitative information, 
while modeling and monitoring give quantitative information 
resulting in deeper understanding of the system behavior 
B  Data mining based on Neuro-Fuzzy 
Volumn 2
 342
A neuro-fuzzy system is based on a fuzzy system which 
is trained by a learning algorithm derived from neural 
network theory. The learning procedure operates on local 
information, and causes only local modifications in the 
underlying fuzzy system.  
A neuro-fuzzy system can be viewed as a 3-layer feed 
forward neural network. The first layer represents input 
variables, the middle (hidden) layer represents fuzzy rules 
and the third layer represents output variables. Fuzzy sets are 
encoded as (fuzzy) connection weights. It is not necessary to 
represent a fuzzy system like this to apply a learning 
algorithm to it. However, it can be convenient, because it 
represents the data flow of input processing and learning 
within the model. Sometimes 5-layer architecture is used, 
where the fuzzy sets are represented in the units of the 
second and fourth layer. A neuro-fuzzy system can be 
always interpreted as a system of fuzzy rules. It is also 
possible to create the system out of training data from scratch, 
as it is possible to initialize it by prior knowledge in form of 
fuzzy rules. The learning procedure of a neuro-fuzzy system 
takes the semantically properties of the underlying fuzzy 
system into account. This results in constraints on the 
possible modifications applicable to the system parameters.  
Neural networks achieve high accuracy in classification, 
prediction and many others applications as suggested in the 
literature. But this system is unable to explain the knowledge 
embedded in trained neural networks is one of the major 
drawbacks of this technology. Much of attention has been 
paid to solve this problem by extracting rules from trained 
neural networks.Fig.4 shows data mining process based on 
neuro-fuzzy system. 
The first step is to build neural network forecasting 
model by the neural network construction system. The 
mechanism of the subsystem is like an Expert System Shell. 
The second step is to extract rules from trained the neural 
networks. Neural network architecture and weight space are 
used to mine the business rules that govern the forecasting by 
the rule extraction mechanism. 
In the third step hidden forecasting rules extracted in the 
previous step are incorporated to the network generated by 
neural network construction system to form a descriptive 
neural network, DNN. Most of researchers extract if-then 
type association rules, as they are more understandable for 
humans than other representations. 
 
Fig 4: Data mining process using Descriptive Neural Network 
C Data mining based on ART2 
Clustering analysis is an important research topic in data 
mining field, and it is one of main task of data mining. 
Adaptive Resonance Theory (ART) neural network is an 
effective method to realize clustering. But the classical 
ART2 network has some shortcoming and insufficiency in 
data clustering application. The classical ART2 network 
must designate p alert parameters before the network training; 
the configuration of this parameter has a direct impact on the 
network clustering result. The classical ART2 uses the 
"winner takes all" competition rule, in general only considers 
winning neuron information, but neglects other useful 
neuron information in the output layer. The classical ART2 
network output is essentially one-dimension structure is 
unable to manifest the whole relation to entire input mode 
space. By improving the structure of ART2, ample 
considering amplitude information of mining object, which 
can decrease the requirement of vigilance parameter and earn 
cluster result with administrative level structure .we can 
apply ART2 Neural network in data mining for browsing 
patterns in web log data.  
D Data mining based on Back propagation  
Some situations where a BP NN might be a good idea:  
1. A large amount of input/output data is available, but 
you're not sure how to relate it to the output. 
2. The problem appears to have overwhelming complexity, 
but there is clearly a solution. 
3. It is easy to create a number of examples of the correct 
behavior. Outputs can be "fuzzy", or non-numeric. 
Back propagation algorithm can be used for classification 
problems. 
VI. CONCLUSION & DISCUSSION 
In this paper, we have reviewed how to apply Artificial 
Neural Network in Data mining techniques. Neural network 
itself is very suitable for solving the problems of data mining 
because of its characteristics of good robustness, self-
organizing adaptive, parallel processing, distributed storage 
and high degree of fault tolerance. This overall benefit that 
ANN offer makes it a powerful & exciting tool to be applied 
in the field of Data mining to enhance capabilities of  Data 
mining process.The outcome from such a combined tool 
would provide valuable insights& intellegance for planning 
& decision making in all spheres. Further, Particle swarm 
optimization, Ant colony optimization can be integrated with 
artificial neural network to further enhance the performance 
of ANN in Data mining. 
REFERENCES 
[1] Data Mining: Concepts and Techniques  Jiawei Han and Micheline 
Kamber, Morgan Kaufmann, 2001. 
[2] Data Mining:Practical Machine Learning  Ian H. Witten, Eibe Frank, 
Morgan Kaufmann, 2000 
Volumn 2
 343
[3]  Fundamentals of Neural Networks,Laurene V. Fausett 
[4] Xianjun Ni,’Research of Data Mining Based on Neural Networks’ 
World Academy of Science, Engineering and Technology 39 2008 
[5] David Hand, Principles of Data Mining [M]. Massachusetts Institute 
of Technology,2001 
[6] Feng Jiansheng. KDD and its applications, BaoGang techniques. 
1999(3): 27-31. 
[7] Wooldrldge M J. Agent-Based software engineering. IEEE 
Transactions on Software Engineering [J]. 1999,144 (1): 26-27. 
[8] Lie Lu and Hong-Jiang Zhang, “Content analysis for audio 
classification and segmentation.”, IEEE Transactions on Speech and 
Audio Processing, 10:504–516, October 2002. 
[9] T. Tolonen and M. Karjalainen, “A computationally efficient 
multipitch 
[10] analysis model,” IEEE Transactions on Speech and Audio Processing, 
Vol. 8(No. 6):708–716, November 2000. 
[11] Kohonen, T., Self-Organizing Maps, Series in Information Sciences, 
second edn. 1997, Springer, Heidelberg 
 
 
Volumn 2
