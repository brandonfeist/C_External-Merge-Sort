Grounding Symbols: 
Labelling and Resolving Pronoun Resolution with fLIF Neurons 
Fawad Jamshed and Christian Huyck 
Middlesex University – London, UK 
f.jamshed@mdx.ac.uk, c.huyck@mdx.ac.uk 
 
 
Abstract 
 
If a system can represent knowledge symbolically, and 
ground those symbols in an environment, then it has 
access to a vast range of data from that environment.  The 
system described in this paper acts in a simple virtual 
world.  It is implemented solely in fatiguing Leaky 
Integrate and Fire neurons; views the environment; 
processes natural language commands; plans; and acts.  
Visual representations are labeled, using a Hebbian 
learning rule, thus gaining associations with symbols. The 
labelling is done using simultaneous presentation of the 
label and a corresponding visual item. These grounded 
symbols can be useful in reference resolution. Both 
experiments perform perfectly on all tests. 
 
 
1. Introduction 
 
A major hurdle in the development of an artificial 
intelligent agent is the symbol grounding problem (SGP) 
[6], [16]. A symbol can be defined as an association with 
an object due to a social convention and usually has an 
arbitrary shape with no resemblance to its referent.  Each 
symbol is a part of a wider and more complex system 
[16], [18].  Any symbol is meaningless to its user unless, 
somehow, it is given some meaning. Once a symbol gets 
its meaning, it is grounded. How an artificial agent can 
develop the meanings of symbols autonomously is the 
SGP [3], [4], [7], [8]. 
 The SGP is one of the most important open 
questions in the philosophy of information [20]. 
Manipulating meaningless symbols into other meaningless 
symbols is not intelligence [15]. Most artificial agents do 
not understand the meanings of the symbols they are 
processing and are just processing information according 
to predesigned algorithms [19]. Instead of defining 
symbols in the form of other ungrounded symbols, a 
system can derive the meaning from sensory-motor 
interaction with the environment [1], [2], [17]. 
 
2. Theoretical Background & Previous Work 
 
The SGP has been in existence for hundreds of years. As 
knowledge about human cognition has advanced, more 
candidate symbol grounding solutions have been 
proposed. Since the development of connectionist 
systems, there have been more ideas and solutions to 
address the SGP. While progress has been made, the SGP 
remains open.  This paper presents simulations that begin 
to address the SGP.  The simulations are based on 
fatiguing Leaky Integrate and Fire (fLIF) neurons [13].  
They make use of the cell assembly (CA) concept [9].  A 
brief description of CAs and fLIF neurons is given below. 
fLIF neurons are a relatively simple model of 
biological neurons [12][13]. The model used in this paper 
makes use of discrete cycles.  Each neuron has some 
activation, which it receives from other neurons. If a 
neuron has enough activation at the end of a cycle, it will 
fire, spread activation to connected neurons, and lose all 
its energy. Neurons are connected to other neurons with 
unidirectional, weighted connections.  A firing neuron  
passes the activation of the weight of the connection.  If a 
neuron’s activation is less than the threshold, it will not 
fire but will lose some of its activation as it leaks away. 
fLIF neurons also fatigue just like biological neurons [13]. 
If a neuron fires regularly it becomes harder to fire.   
As neurons fatigue, they become more difficult 
to fire again. This is modelled by increasing the threshold 
of a neuron as describe in equation 1. 
T(t) = T(t-1) + Fc. (Equation 1) 
Where T is the threshold at time t and Fc is fatigue 
constant. If a neuron does not fire the threshold associated 
with that neuron decreases using the fatigue recovery 
constant Fr as shown in equation 2. The threshold never 
goes below the base activation threshold. 
T(t) = T(t-1) + Fr. (Equation 2) 
2009 International Conference on Machine Learning and Applications
978-0-7695-3926-3/09 $26.00 © 2009 IEEE
DOI 10.1109/ICMLA.2009.97
791
If a neuron does not fire at a given time, some of its 
energy leaks away but it still integrates energy from the 
surrounding active neurons. This is modelled by 
calculating the activation as describe in equation 3. 
A(t) = A(t-1)/D + C. (Equation 3) 
Where A(t) is the activation at  time t and is sum of 
activation A at t-1 time, reduced by a decay constant D, 
and C, the sum of incoming activation of all active 
neurons that are connected to a given neuron and fired at 
time t-1. The value of C is determined by multiplying the 
incoming activation on all connected links with the 
associated weights of those links. 
CAs were proposed by Hebb sixty years ago [9] 
and  explain how the human brain learns, stores and 
accesses concepts. A single neuron does not represent a 
memory but a large number of neurons represent each 
concept. The learning of a CA is done by Hebbian 
learning, the connection strength between two neurons is 
related to how frequently they fire simultaneously. 
The repeated presentation of input increases the 
strength of the connection between simultaneously active 
neurons while decreasing the connection strength between 
other neurons. The set of neurons with increased synaptic 
strength forms a CA. CAs are reverberating circuits. 
Initial firing of some neurons in the CA can lead to further 
firing of other neurons in the CA due to high connection 
strength.  This then can lead to a cascade of firing called 
CA ignition [11], [13], [ 21]. 
The Cell Assembly roBot version 1 (CABot1) 
[13] was an agent in simulated neurons that took natural 
language as input and interacted with the environment. By 
interacting with the environment, it is hoped that it can 
learn the semantics of the environment sufficiently well to 
improve language processing.  A total of 21 sub-networks 
are used to subdivide the tasks of vision, natural language 
parsing, planning, action and system control. 
The important subnets for the purposes of this 
paper are the vision nets and the word nets.  There are 
three vision subnets, a simulated retina, a primary visual 
cortex and a secondary visual cortex (V2).  These systems 
were hard coded, so there was no learning. Visual input 
was in the form of a bitmap representation of a view of the 
game from the agent’s perspective.  In particular, the 
secondary visual cortex subnet was set to recognize 
pyramids and stalactites.  If one of these was present in 
the game, a CA in V2 ignited. Similarly, the parsing 
component had CAs for words.  In the game, the user 
issues natural language commands to the agent.  The noun 
subnet is used during parsing and the instance subnet 
stores semantic roles during parsing.  Both noun and 
instance subnets had CAs for both pyramid and stalactite. 
 
3. Proposed Work 
 
The names of different objects (labels) are naturally 
correlated with the visual appearance of the corresponding 
objects obtained from the visual field. Once this labeling 
is done, machines can demonstrate many human like 
behaviors [5].  Labelling is a simple but necessary form of 
symbol grounding [22].  There is an existing system, 
CABot1, that contains semantics CAs and label CAs.  An 
association between the semantic and label CAs is 
learned.   These labels provide a form of reference 
resolution in a relatively simple task, a proof of concept.  
One theory states that a concept is represented by 
a semantic pole and a phonological pole [14]. A CA for 
the category represents the semantic pole, and a different 
CA for the label the phonological pole (word). If a system 
has a semantic CA, and a label CA, it can attach them to 
each other, which means the symbol is now grounded. The 
system has attached a name to a category.  
Symbol grounding can be used to address the 
reference resolution problem. Reference resolution is a 
common problem in natural language. For example in the 
sentence we saw a doll with a black jacket on and it was 
quite big. The pronoun it can refer to either doll or to the 
jacket. If the system can decide which, it is resolving the 
pronoun.  In resolving the pronoun, the system could 
ignite both the semantic CA and the label CA associated 
with the item to which the pronoun is resolved. 
 
4. Simulations 
The simulations described below are an extension of 
CABot1 [13].  CABot1 does no real learning.  The first 
simulation shows how learning allows the attachment of 
labels.  The second shows how the now labelled semantic 
CAs can be used for reference resolution. 
 
4.1 Labelling Experiment 
 
The labelling simulation associates label CAs with 
semantic CAs. Initially pictures and labels are presented at 
the same time so the weights between the semantic and 
label categories can be adjusted. Pictures of different 
instances of pyramid and stalactite were used. These 
pictures were taken from a virtual 3D environment. The 
connections between visual CAs and label CAs are 
learned using Hebbian learning. According to Hebbian 
learning, the weights of the connections are increased 
when both the pre and the post synaptic neurons fire, and 
when the pre but not the post synaptic neuron fires, the 
weights are decreased. The learning is bi-directional with 
792
weights from V2 to the label net and weights from the 
label net to V2 being learned at the same time.  
Each shape is represented by a CA of 2500 
neurons in the V2 net, and each label is by a CA of 150 
neurons. Every 10th neuron of a visual shape in V2 has 10 
random connections with stalactite and pyramid CAs in 
the instance net. Each neuron of a label instance has 10 
random connections with stalactite and pyramid shape 
CAs in V2. The initial weights between labels and visual 
input are low. The other parameters were selected by a 
trial and error method. For V2 decay rate of 1.1, fatigue of 
1.0, fatigue recovery of 3.0, learning of 0.1 and activation 
threshold of 5 is used and for the instance net, decay rate 
of 1.5, fatigue rate of 0.4, fatigue recovery rate of 1.2, 
learning rate of 0.1 and activation threshold of 4 is used.  
The correlatory rule was used for learning connections 
[11]. The complete code for the experiments can be found 
at www.cs.mdx.ac.uk/research/PhDArea/fawad1/labelling.  
During testing, different pictures are presented 
while the label input to the instance net is switched off to 
test the connection efficiency between V2 and the instance 
net. At the end, V2 is turned off and different labels are 
presented to see the connection efficiency between the 
Instance net and V2. Figure 1 and figure 2 show an 
instance of pyramid and an instance of stalactite 
respectively as visual input to CABot1. 
 
    
              Figure 1    Figure 2 
 
The result is calculated using the number of 
neurons fired at the 49th step of presenting every picture or 
label. Thirty eight percent of the images were used for 
training and the remainder for testing. Each picture was 
given 50 CABot steps for training and testing purpose. 
Individual results for an instance of pyramid and stalactite 
are produced after the 49th cycle. 
The test runs for 2000 steps. In the first 600 
steps, 6 different pictures of pyramid and stalactite are 
presented. Then for the next 1000 steps, 10 different 
pictures of pyramid and stalactite are presented while the 
instance net receives no external input.  For the next 398 
steps, there is no visual input to the V2 net and input to 
the instance net is turned on, rotating between pyramid 
and stalactite labels after every 50 steps.  
Different instances of visual pyramid and 
stalactite were used. On all 28 tests, the correct 
association between shapes and their labels was learned.   
 
4.2 Pronoun Resolution 
 
For the pronoun resolution experiment, the connection 
weights are set within CAs of the instance net (from the it 
CA to all other CAs in the instance net) and from the V2 
net to the instance net, the later reflecting those weights 
learned in the labelling experiment. The connections from 
the pronoun it in the noun net to the it CA in the instance 
net are also set. Input from both the V2 net and the 
instance it CA in the instance net is needed to ignite the 
stalactite or pyramid instance CAs in the instance net. 
Each shape in V2, label in the instance net and 
words in the noun net are represented by a CA of 500 
neurons. Every 11th neuron of a shape CA in the V2net 
and of the instance it CA has 3 random connections with 
stalactite and pyramid CAs in the instance net with the 
weight of 0.7 and 0.6 respectively. Every 5th neuron of the 
it CA in the noun net has 3 random connections to the it 
CA in the instance net with the weight of 1.2. The other 
parameters were selected by a trial and error method. The 
instance net had a decay rate of 1.4, fatigue of 0.5, fatigue 
recovery of 1.4 and activation threshold of 3.8.  
In a pronoun resolution experiment, a sentence 
containing pronoun ambiguity [10] and a shape to which 
the pronoun is referring to was presented to the system. 
The activation of the CAs of instance it or CAs of shapes 
from V2 can not ignite stalactite and pyramid CAs 
instances on its own. A combined activation from the 
visual field and the noun field is able to ignite the symbol 
label. The pronoun it gets linked to the presented shape 
dynamically each time a different shape is presented.  
 
 
Figure 5. 
 
Figure 5 shows a run of the pronoun ambiguity resolution 
experiment. Each square represents a neuron. A filled 
square represents a fired neuron. In this run, a pyramid is 
presented to the system as shown in the Visual Input net 
causing the ignition of the pyramid CA in V2. When a 
sentence is presented to the system, it gets parsing causes 
words in the noun net ignite. In this run, a sentence 
containing it is presented to the system igniting the it CA 
in the instance net. The label pyramid instance CA is 
ignited by the combination of V2 and the it instance CA. 
793
For 1000 cycles, the system is tested by 
presenting different shapes as input to the system and 
presenting the system with a sentence containing an 
ambiguous it pronoun. While the system is presented with 
the pronoun it, if the matching shape CA turns on in the 
instance net, then the system has associated the pronoun it 
dynamically with the presented shape and hence has 
resolved the pronoun ambiguity.  
The CAs of the word instances both receive 
connections from the it instance and the corresponding 
visual CAs; the word instance is only ignited when it gets 
activation from both of the nets. The experiment was run 
20 times and each time the ambiguous pronoun was 
successfully dynamically associated with the visual item 
presented to the system at that time.  
 
5. Conclusions and Future Work 
 
The results of the above experiments are promising. The 
labelling experiment learns the correct association 
between shapes and their corresponding labels on all 28 
experiments. The label experiment is a small but 
important step towards the solution of the SGP. Labelling 
is an essential aspect of symbol grounding because it 
attaches symbols to sub symbolic representations 
(semantic CAs).  As compared to other models [19], [22], 
this model is simpler and more generic in nature.  
The pronoun resolution experiment creates a 
dynamic association between ambiguous pronouns and 
shape categories. Pronoun resolution is not required to 
ground symbols, but the experiment shows one of the 
many benefits of symbol grounding. The promising results 
of these experiments show that Hebbian learning can be 
used effectively to ground semantic symbols and indicates 
that the model and the technique used can be used 
effectively in solving other aspects of symbol grounding.  
Other aspects of the SGP need to be addressed in 
order to fully ground symbols. These include symbolic 
theft and functional symbol grounding. Symbolic theft is 
to makes new categories by modifying old categories from 
symbolic instruction. For example, by combining stripes 
with horse, a new category, zebra, can be created. 
Functional symbol grounding depends on the context in 
which the symbols are used. The use of the symbols is 
domain and situation specific [20]. By improving symbol 
grounding,  the accuracy of the system can be enhanced.  
6. References 
[1] C. Breazeal,"Sociable Machines: Expressive Social 
Exchange between Humans and Robots". Dissertation, 
Department of EECS, MIT (2000). 
[2] A. Cangelosi, “Evolution of Communication and Language 
Using Signals, Symbols and Words”, IEEE Transaction in 
Evolution Computation, 5, pp. 93-101, (2001). 
[3] A. Cangelosi, A. Greco S. Harnad, “From Robotic Toil to 
Symbolic Theft: Grounding Transfer from Entry-Level to 
Higher-Level Categories”, Connection Science, 12, pp. 143-
162, (2000). 
[4] A. Cangelosi, A. Greco  S. Harnad, “Symbol Grounding and 
the Symbolic Theft Hypothesis”, in Simulating the Evolution 
of Language, A. Cangelosi and D. Parisi, Eds., London, 
Springer,  pp.191-210, (2002). 
[5] P. Davidsson, “Toward a General Solution to the SGP: 
Combining Machine Learning and Computer Vision“, in 
AAAI Fall Symposium Series, Machine Learning in 
Computer Vision: What, Why and How? pp. 157-161 (1993). 
[6] S. Harnad, “The SGP”, Physica D, pp. 335-346, (1990). 
[7] S. Harnad, “Symbol Grounding in an Empirical Problem: 
Neural Nets are just a Candidate Component”, in 
Proceedings of the Fifteenth Annual Meeting of the 
Cognitive Science Society, (1993). 
[8] S. Harnad, Grounding Symbols in the Analog World with 
Neural Nets, a Hybrid Model, Psychology,  pp12-78, (2001). 
[9] D. Hebb. The Organization of Behavior. John Wiley and 
Sons, New York (1949). 
[10] D. Hindle, Mats Rooth. “Structural Ambiguity And Lexical 
Relations”  Meet. Assoc. Computational Linguistics (1993). 
[11] C. Huyck. “Overlapping CA from correlators”. 
Neurocomputing 56:435–9 (2004). 
[12] C. Huyck. “Creating hierarchical categories using CA”. 
Connection Science (2007). 
[13] C.Huyck, “ CABot1: a Videogame Agent Implemented in 
fLIF Neurons” IEEE Systems, man and Cybernetics Society, 
London. pp 115-120 (2008). 
[14] R. Langacker.  Foundations of Cognitive Grammar. Vol. 1. 
Stanford, CA. Stanford University Press (1987). 
[15] J. Searle, “Minds, Brains, and Programs”, Behavioral and 
Brain Sciences, 3, pp. 417-458, (1980). 
[16] L.Steels “The Symbol Grounding Problem has been solved. 
So what’s next?” Symbols, Embodiment and Meaning, 
Oxford University Press,  (2007). 
[17] M. Mayo, “Symbol Grounding and its Implication for 
Artificial Intelligence”, in Twenty-Sixth Australian 
Computer Science Conference , pp. 55-60 (2003). 
[18] R. Sun, “Symbol Grounding: A New Look at an Old Idea”, 
Philosophical Psychology, 13, pp. 149-172, (2000). 
[19] D. Roy. Grounded Spoken Language Acquisition: 
Experiments in Word Learning. IEEE Transactions on 
Multimedia, 5(2): 197-209, (2003). 
[20] M. Taddeo
 
and L. Floridi Solving the Symbol Grounding 
Problem: a Critical Review of  15 Years of Research (2003). 
[21] T. Wennekers and G. Palm "Cell Assemblies, Associative 
Memory and Temporal Structure in Brain Signals", in Time 
and the Brain, pp 251-274, (2000). 
[22] C. Yu and D.  H. Ballard, "A Multimodal Learning Interface 
for Grounding Spoken Language in Sensory Perceptions", 
ACM Transactions on Applied Perception, 1, 57-80, (2004). 
794
