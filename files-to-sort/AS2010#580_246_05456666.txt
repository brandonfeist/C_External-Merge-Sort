2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics 
978-1-4244-5194-4/10/$26.00 ©2010 IEEE                                                                  CAR 2010 
Massive Data Mining Based on Item Sequence Set
Grid Space
Lijuan Zhou
Information Engineering College
Capital Normal University
Beijing, China
Zlj87@tom.com
Zhang Zhang
Information Engineering College
Capital Normal University
Beijing, China
sherrytangtang@gmail.com
Mingsheng Xu
Information Engineering College
Capital Normal University
Beijing, China
xumingsheng@gmail.com
Abstract—According to the stored mode of massive data in 
the relational database, this paper proposed a fast mining 
algorithm to find maximum frequent item sets based on item 
sequence set grid space. The traditional methods for mining 
association rules generate frequent item sets from small to 
large. These approaches are either time consuming or 
computationally expensive, and often generate a large number 
of redundant candidates or frequent item sets, which is fatal
for controlling mining speed as data to mass-level. The goal of 
this paper is first to use a self-defined structure linked list to 
storage item sequence then to find the frequent item sets from 
large to small. Several applications of association rules mining 
using item sequence set grid space has a good performance but 
it demonstrated inefficiency in massive data mining. The 
problem involves time spent on sub item sets finding.
Experimental results will be presented to show that the fast 
mining algorithm ISSDL-DM proposed in this paper use much 
less time than the similar existing algorithm ISS-DM for 
achieving the same outcomes.
Index Terms—massive data mining, item sequence set grid 
space, maximum frequent item, data structure
I. INTRODUCTION
Massive Data Mining is extracting the hidden, unknown 
information and knowledge, which has potential application 
value, from massive database of a large number of original 
data according to interest, and thus also known as KDD 
(Knowledge Discovery in Database), is considered as the 
one of the current effective solution to “data explosion“ and 
“the date rich and information poor”. Association rules is an 
important data mining issue for describing the existing
relationship among data items in the database. Association 
rules can reflect the complex and interesting links between 
the data in the database, digging out the useful links between 
data, for improving the practical work of great help. And the 
frequent item sets generation algorithm is the key to 
determine the efficiency of association rules mining. This 
paper presented a fast mining algorithm to generate
maximum frequent item sets based on item sequence set grid 
space and used the self-defined linked list store item 
sequence for adopting its property to expedite the mining 
process.
The traditional approach Apriori algorithm to find the 
maximum frequent item sets is to first generate i candidate
Ci and get their support count by scanning database and then 
select the item sets whose support count greater than or equal 
the mini-support count to generate i frequent item sets Li 
from 1 to k. It is clear there are two fatal performance 
bottlenecks. One is multiple scan the transaction database 
requires a lot of I / O load. For every k cycle, each element 
of candidate Ck must be scanned by scanning the database 
once to verify its adherence to Lk. The other one is may 
generate a large number of candidates.
[1]
Because of this, lots of improved methods of Apriori 
algorithm had been proposed, among which the maximum 
frequent item sets generation algorithm based on the
operation of item sequence set is more efficient with one 
pass to the database and without large candidates generated 
and stored than Apriori. With mining large-scale databases it 
is a more smart strategy to reduce data capability than 
current one like Apriori. But when in the massive data 
mining, its speed is still need to improve. This is the kernel 
issue to be resolved in this paper.
[2]
II. ITEM SEQUENCE SET GRID SPACE
The algorithm proposed in this paper is based on the 
item sequence set of improved algorithms for generating 
maximum frequent item set, depending on the item
sequence set grid space and its operation. So we need make 
a clear definition of several related models of the existing 
basic algorithm ISS-DM before improving:
Definition 1 (item sequence set grid) an item sequence 
set grid space can be triples (I, S, p) to characterize, in
which the following meaning:
?Item domain I: I=(i1, i2, ... , im
?Item sequence set variable set S: Each item sequence 
set variable in S is in the form of ISS=(IS
) is the definition scope 
of the reference items; 
1, IS2, ..., ISn
?2SHUDWLRQ SThe operation set about item sequence
set variable on the S.
), 
where ISi (i=1,2, ..., n) is item sequence defined on the I; 
Definition 2 (Association rule mining space) association 
rule mining space is defined as a five-triple W=(I, D, O, U, 
R), in which the following meaning:
?,=(i1, i2, ..., im
? '=(t
), is the entire items involved in W;
1, t2, ..., tn), is the transaction database W is 
based on. This paper considers the transaction database 
contains two basic attributes; a globally unique transaction 
number TIDi of a transaction ti and the corresponding items 
sequence ISi
? 2=(o
(i=1,2, ..., n);
1, o2, ..., ok), is the operation set about the 
elements on D in W;

2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics 
978-1-4244-5194-4/10/$26.00 ©2010 IEEE                                                                  CAR 2010 
Massive Data Mining Based on Item Sequence Set
Grid Space
Lijuan Zhou
Information Engineering College
Capital Normal University
Beijing, China
Zlj87@tom.com
Zhang Zhang
Information Engineering College
Capital Normal University
Beijing, China
sherrytangtang@gmail.com
Mingsheng Xu
Information Engineering College
Capital Normal University
Beijing, China
xumingsheng@gmail.com
Abstract—According to the stored mode of massive data in 
the relational database, this paper proposed a fast mining 
algorithm to find maximum frequent item sets based on item 
sequence set grid space. The traditional methods for mining 
association rules generate frequent item sets from small to 
large. These approaches are either time consuming or 
computationally expensive, and often generate a large number 
of redundant candidates or frequent item sets, which is fatal
for controlling mining speed as data to mass-level. The goal of 
this paper is first to use a self-defined structure linked list to 
storage item sequence then to find the frequent item sets from 
large to small. Several applications of association rules mining 
using item sequence set grid space has a good performance but 
it demonstrated inefficiency in massive data mining. The 
problem involves time spent on sub item sets finding.
Experimental results will be presented to show that the fast 
mining algorithm ISSDL-DM proposed in this paper use much 
less time than the similar existing algorithm ISS-DM for 
achieving the same outcomes.
Index Terms—massive data mining, item sequence set grid 
space, maximum frequent item, data structure
I. INTRODUCTION
Massive Data Mining is extracting the hidden, unknown 
information and knowledge, which has potential application 
value, from massive database of a large number of original 
data according to interest, and thus also known as KDD 
(Knowledge Discovery in Database), is considered as the 
one of the current effective solution to “data explosion“ and 
“the date rich and information poor”. Association rules is an 
important data mining issue for describing the existing
relationship among data items in the database. Association 
rules can reflect the complex and interesting links between 
the data in the database, digging out the useful links between 
data, for improving the practical work of great help. And the 
frequent item sets generation algorithm is the key to 
determine the efficiency of association rules mining. This 
paper presented a fast mining algorithm to generate
maximum frequent item sets based on item sequence set grid 
space and used the self-defined linked list store item 
sequence for adopting its property to expedite the mining 
process.
The traditional approach Apriori algorithm to find the 
maximum frequent item sets is to first generate i candidate
Ci and get their support count by scanning database and then 
select the item sets whose support count greater than or equal 
the mini-support count to generate i frequent item sets Li 
from 1 to k. It is clear there are two fatal performance 
bottlenecks. One is multiple scan the transaction database 
requires a lot of I / O load. For every k cycle, each element 
of candidate Ck must be scanned by scanning the database 
once to verify its adherence to Lk. The other one is may 
generate a large number of candidates.
[1]
Because of this, lots of improved methods of Apriori 
algorithm had been proposed, among which the maximum 
frequent item sets generation algorithm based on the
operation of item sequence set is more efficient with one 
pass to the database and without large candidates generated 
and stored than Apriori. With mining large-scale databases it 
is a more smart strategy to reduce data capability than 
current one like Apriori. But when in the massive data 
mining, its speed is still need to improve. This is the kernel 
issue to be resolved in this paper.
[2]
II. ITEM SEQUENCE SET GRID SPACE
The algorithm proposed in this paper is based on the 
item sequence set of improved algorithms for generating 
maximum frequent item set, depending on the item
sequence set grid space and its operation. So we need make 
a clear definition of several related models of the existing 
basic algorithm ISS-DM before improving:
Definition 1 (item sequence set grid) an item sequence 
set grid space can be triples (I, S, p) to characterize, in
which the following meaning:
?Item domain I: I=(i1, i2, ... , im
?Item sequence set variable set S: Each item sequence 
set variable in S is in the form of ISS=(IS
) is the definition scope 
of the reference items; 
1, IS2, ..., ISn
?2SHUDWLRQ SThe operation set about item sequence
set variable on the S.
), 
where ISi (i=1,2, ..., n) is item sequence defined on the I; 
Definition 2 (Association rule mining space) association 
rule mining space is defined as a five-triple W=(I, D, O, U, 
R), in which the following meaning:
?,=(i1, i2, ..., im
? '=(t
), is the entire items involved in W;
1, t2, ..., tn), is the transaction database W is 
based on. This paper considers the transaction database 
contains two basic attributes; a globally unique transaction 
number TIDi of a transaction ti and the corresponding items 
sequence ISi
? 2=(o
(i=1,2, ..., n);
1, o2, ..., ok), is the operation set about the 
elements on D in W;


The core idea of this algorithm is join operation and 
there are mainly two conditions.
(1)A new item sequence point joining to list: it firstly 
determined which level is it in and then split the item 
sequence for locating to insert.
(2)An existed item sequence point appears: it plus 1 to 
the support count of this point and judging for joining to 
frequent item sequence list.
Both two conditions need judge sub item sequence to be 
pruned or to join frequent item sequence list. The main 
algorithms describe after defining some symbols as 
following.
IS: item sequence
ISL: item sequence list
ISP: item sequence point
FISL: frequent item sequence list
FISP: frequent item sequence point
SIS: sub item sequence
SISP: sub item sequence point
Algorithm 1: ISSDL-DM
(1) Input(minisup_count);
(2) ISL=null; FISL=null;
(3) FOR all IS?D DO BEGIN//scan database once
(4) ISP=join(IS,ISL);
(5) IF ISP!=null THEN make_fre(ISP,ISL,FISL);
(6) END
Algorithm 2: join(IS,ISL)
(1) FISP=find(IS,FISL);
(2) IF FISP!=null THEN BEGIN //IS is frequent
(3) FISP->count++;
(4) ELSE
(5) ISP=find(IS,ISL);
(6) IF ISP!=null THEN BEGIN //IS has appeared but is 
not frequent now
(7)     ISP->count++;
(8) ELSE //IS appears for the first time
(9)     ISP=new ItemSeqPoint;
(10)     ISP->IS=IS; 
(11)     ISP->count=1;
(12)     insert(ISP,ISL);
(13) END
(14) END
(15) return ISP;
Algorithm3: make_fre(ISP,ISL,FISL)
(1) IF ISP->count > minisup_count THEN return;
(2) IS=ISP->IS;
(3) IF ISP->count==minisup_count THEN BEGIN //IS is 
frequent just now
(4) FOR all SIS? sub
(5)     SISP=find(SIS,ISL);
{IS} DO BEGIN
(6) SISP->count=0;
(7)     prune(SIS,FISL);
(8) END
(9) FISP=new ItemSeqPoint;
(10) FISP->IS=IS;
(11) FISP->IS=ISP->count;
(12) insert(FISP,FISL);
(13) prune(ISP,ISL);
(14) ELSE
(15) FOR all SIS?  sub
(16)     SISP=find(SIS,ISL);
{IS} DO BEGIN
(17)     IF SISP==null THEN BEGIN
(18)       SISP=new ItemSeqPoint;
(19)       SISP->IS=SIS;
(20)       SISP->count=1;
(21)       insert(SISP,FISL);
(22)     ELSE
(23)     SISP->count++;
(24)       IF SISP->count==minisup_count THEN 
BEGIN
(25)         FSISP=new ItemSeqPoint;
(26)         FSISP->IS=SIS;
(27)         FSISP->count=SISP->count;
(28)         insert(FSISP,FISL);
(29)         SISP->count=0;
(30)       END
(31)     END
(32) END
(33) END
Algorithm 4: prune(IS,L)
(1) ISP_pre=find_pre(IS,L);
(2) ISP=ISP_pre->next;
(3) IF IsHeadType(ISP_pre) THEN BEGIN
(4) ISP_pre->ISP=ISP->next;
(5) ELSE
(6) ISP_pre->next=ISP->next;
(7) END
(8) free(ISP);

The core idea of this algorithm is join operation and 
there are mainly two conditions.
(1)A new item sequence point joining to list: it firstly 
determined which level is it in and then split the item 
sequence for locating to insert.
(2)An existed item sequence point appears: it plus 1 to 
the support count of this point and judging for joining to 
frequent item sequence list.
Both two conditions need judge sub item sequence to be 
pruned or to join frequent item sequence list. The main 
algorithms describe after defining some symbols as 
following.
IS: item sequence
ISL: item sequence list
ISP: item sequence point
FISL: frequent item sequence list
FISP: frequent item sequence point
SIS: sub item sequence
SISP: sub item sequence point
Algorithm 1: ISSDL-DM
(1) Input(minisup_count);
(2) ISL=null; FISL=null;
(3) FOR all IS?D DO BEGIN//scan database once
(4) ISP=join(IS,ISL);
(5) IF ISP!=null THEN make_fre(ISP,ISL,FISL);
(6) END
Algorithm 2: join(IS,ISL)
(1) FISP=find(IS,FISL);
(2) IF FISP!=null THEN BEGIN //IS is frequent
(3) FISP->count++;
(4) ELSE
(5) ISP=find(IS,ISL);
(6) IF ISP!=null THEN BEGIN //IS has appeared but is 
not frequent now
(7)     ISP->count++;
(8) ELSE //IS appears for the first time
(9)     ISP=new ItemSeqPoint;
(10)     ISP->IS=IS; 
(11)     ISP->count=1;
(12)     insert(ISP,ISL);
(13) END
(14) END
(15) return ISP;
Algorithm3: make_fre(ISP,ISL,FISL)
(1) IF ISP->count > minisup_count THEN return;
(2) IS=ISP->IS;
(3) IF ISP->count==minisup_count THEN BEGIN //IS is 
frequent just now
(4) FOR all SIS? sub
(5)     SISP=find(SIS,ISL);
{IS} DO BEGIN
(6) SISP->count=0;
(7)     prune(SIS,FISL);
(8) END
(9) FISP=new ItemSeqPoint;
(10) FISP->IS=IS;
(11) FISP->IS=ISP->count;
(12) insert(FISP,FISL);
(13) prune(ISP,ISL);
(14) ELSE
(15) FOR all SIS?  sub
(16)     SISP=find(SIS,ISL);
{IS} DO BEGIN
(17)     IF SISP==null THEN BEGIN
(18)       SISP=new ItemSeqPoint;
(19)       SISP->IS=SIS;
(20)       SISP->count=1;
(21)       insert(SISP,FISL);
(22)     ELSE
(23)     SISP->count++;
(24)       IF SISP->count==minisup_count THEN 
BEGIN
(25)         FSISP=new ItemSeqPoint;
(26)         FSISP->IS=SIS;
(27)         FSISP->count=SISP->count;
(28)         insert(FSISP,FISL);
(29)         SISP->count=0;
(30)       END
(31)     END
(32) END
(33) END
Algorithm 4: prune(IS,L)
(1) ISP_pre=find_pre(IS,L);
(2) ISP=ISP_pre->next;
(3) IF IsHeadType(ISP_pre) THEN BEGIN
(4) ISP_pre->ISP=ISP->next;
(5) ELSE
(6) ISP_pre->next=ISP->next;
(7) END
(8) free(ISP);

Algorithm 5: find(IS,L)
(1) level=GetLevelNum(IS,L);
(2) lh=GetLevelHead(level);
(3) split(IS,&ph); //split IS to find the head of sub list it is 
in
(4) FOR all ISP in ph DO BEGIN
(5) IF ISP->IS==IS THEN return ISP;
(6) END
(7) return null;
IV. EXPERIMENT RESEARCH
In order to illustrate performance of our algorithm, we 
carry out a simulation experiment, and the result shows, the 
ISSDL-DM is better than ISS-DM. The reasons are:
(1)When the same item sequence into ISS-DM need to 
travel whole item sequence set for linear structure storage, 
while ISSDL-DM locate the sub list which it is in and then 
only travel this sub list to count.
(2)In insertion and deletion ISS-DM need do much 
moving operations while ISSDL-DM not.
The experimental performance comparison of ISS-DM 
and ISSDL-DM is shown as figure 2.
0
5
10
15
100 200 300 400 500 600 800 1000
Number of item sequence
T
i
m
e
ISS-DM ISSDL-DM
Figure 2? experimental performance comparison of ISS-DM and 
ISSDL-DM
It can be seen from the experimental performance 
comparison that the ISSDL-DM algorithm performs more 
significant advantages than ISS-DM as the number of item 
sequence increases.
V. CONCLUSION
In this paper, it firstly analyzed the frequent item sets 
generation algorithm which is the key to determine the 
efficiency of association rules mining. Then it introduced 
the basic algorithm ISS-DM and indicated the advantages 
and disadvantages for pointing out its bottlenecks of mining 
speed controlling as data increases to mass-level. At last, 
according to the defect it proposed an improved algorithm 
ISSDL-DM for developing finding speed by designing a 
self-defined structure linked list. Through experimental 
performance comparison of the ISS-DM and ISSDL-DM, it 
proved the fast mining algorithms used less mining time and
the superiority is more significant as data size enlarged.
This algorithm not only has a strict theoretical basis, but 
also a efficient algorithm of generating maximum frequent 
sequence set. Its advantage is using self-defined linked list, 
which organized items orderly, greatly improve the speed of 
search and simplify the insertion and deletion operations, 
and timely pruning to improve the memory utilization.
ACKNOWLEDGMENT
This work was supported by Beijing Educational 
Committee science and technology development plan 
project?KM200810028016?, Capital Normal University 
project and Beijing Information project.
REFERENCES
[1] Zhu Jiaxian. “A Mining Algorithm of Association Rule Based on 
Linked List”. Journal of Shaoxing University, 2004,8(24):19-22,59.
[2] Mao Guojun, Duan Lijuan, Wang Shi, Shi yun. Data Mining Theory 
and Algorithm. Tsinghua University Press, 2005.
[3] Zhang Lei, Liu Zhongjie, Liu Huiwei. “Association Rules’ Mining 
Architecture Based on Operating Theory of Itemsequences Set”.
Journal of tanzhou Polytechnic College, 2005,4(12):20-24.
[4] Wang Yifu, Chen Songqiao, Chen An. “The Designing of Prediction
Model on Huge Database and the Analysis of Case Study”.
Computer Engineering and Applications, 2005,19(41):170-173. 
[5] Bao Zhengyi, Wang Zhoujing. “MLCI Algorithm for Mining Lower 
Closed Itemsets”, Computing Technology and Automation, 
2005.12,4(24):73-76.
[6] Washio T, Nakanishi K, Motoda H. “Association rules based on 
levelwise subspace clustering”, In: Proceedings. of 9th European 
conference on principles and practice of knowledge discovery in 
databases,2005, Heidelberg ,LNAI, vol 3721, pp. 692–700 Springer.
[7] Yang Qiang, Wu Xindong. “10 Challenging Problems in Data 
Mining Research”, International Journal of Information Technology 
& Decision Making, 2006,4(5):597-604.
[8] Zhu Xiaoyu, Wang Lidong, Wang Guangyang. “An Improvement of 
Apriori Algorithm for Mining Association Rules”, Computer 
Technology and Development, 2006.12,12(16):89-90.
[9] Han Wang, Lingfu Kong, "A Constrained Maximum Frequent 
Itemsets Incremental Mining Algorithm", Network and Parallel 
Computing Workshops, IFIP International Conference on, pp. 
743-747, 2007 IFIP International Conference on Network and 
Parallel Computing Workshops (NPC 2007), 2007.
[10] Wu Xindong, Vipin Kumar, J. Ross Quinlan, Joydeep Ghosh, Yang 
Qiang, Hiroshi Motoda, Geoffrey J. McLachlan, Angus Ng, Liu 
Bing, Philip S. Yu, Zhou Zhihua, Michael Steinbach, David J. Hand, 
Dan Steinberg. “Top 10 algorithms in data mining”, Knowl Inf Syst 
(2008) 14:1–37.

Algorithm 5: find(IS,L)
(1) level=GetLevelNum(IS,L);
(2) lh=GetLevelHead(level);
(3) split(IS,&ph); //split IS to find the head of sub list it is 
in
(4) FOR all ISP in ph DO BEGIN
(5) IF ISP->IS==IS THEN return ISP;
(6) END
(7) return null;
IV. EXPERIMENT RESEARCH
In order to illustrate performance of our algorithm, we 
carry out a simulation experiment, and the result shows, the 
ISSDL-DM is better than ISS-DM. The reasons are:
(1)When the same item sequence into ISS-DM need to 
travel whole item sequence set for linear structure storage, 
while ISSDL-DM locate the sub list which it is in and then 
only travel this sub list to count.
(2)In insertion and deletion ISS-DM need do much 
moving operations while ISSDL-DM not.
The experimental performance comparison of ISS-DM 
and ISSDL-DM is shown as figure 2.
0
5
10
15
100 200 300 400 500 600 800 1000
Number of item sequence
T
i
m
e
ISS-DM ISSDL-DM
Figure 2? experimental performance comparison of ISS-DM and 
ISSDL-DM
It can be seen from the experimental performance 
comparison that the ISSDL-DM algorithm performs more 
significant advantages than ISS-DM as the number of item 
sequence increases.
V. CONCLUSION
In this paper, it firstly analyzed the frequent item sets 
generation algorithm which is the key to determine the 
efficiency of association rules mining. Then it introduced 
the basic algorithm ISS-DM and indicated the advantages 
and disadvantages for pointing out its bottlenecks of mining 
speed controlling as data increases to mass-level. At last, 
according to the defect it proposed an improved algorithm 
ISSDL-DM for developing finding speed by designing a 
self-defined structure linked list. Through experimental 
performance comparison of the ISS-DM and ISSDL-DM, it 
proved the fast mining algorithms used less mining time and
the superiority is more significant as data size enlarged.
This algorithm not only has a strict theoretical basis, but 
also a efficient algorithm of generating maximum frequent 
sequence set. Its advantage is using self-defined linked list, 
which organized items orderly, greatly improve the speed of 
search and simplify the insertion and deletion operations, 
and timely pruning to improve the memory utilization.
ACKNOWLEDGMENT
This work was supported by Beijing Educational 
Committee science and technology development plan 
project?KM200810028016?, Capital Normal University 
project and Beijing Information project.
REFERENCES
[1] Zhu Jiaxian. “A Mining Algorithm of Association Rule Based on 
Linked List”. Journal of Shaoxing University, 2004,8(24):19-22,59.
[2] Mao Guojun, Duan Lijuan, Wang Shi, Shi yun. Data Mining Theory 
and Algorithm. Tsinghua University Press, 2005.
[3] Zhang Lei, Liu Zhongjie, Liu Huiwei. “Association Rules’ Mining 
Architecture Based on Operating Theory of Itemsequences Set”.
Journal of tanzhou Polytechnic College, 2005,4(12):20-24.
[4] Wang Yifu, Chen Songqiao, Chen An. “The Designing of Prediction
Model on Huge Database and the Analysis of Case Study”.
Computer Engineering and Applications, 2005,19(41):170-173. 
[5] Bao Zhengyi, Wang Zhoujing. “MLCI Algorithm for Mining Lower 
Closed Itemsets”, Computing Technology and Automation, 
2005.12,4(24):73-76.
[6] Washio T, Nakanishi K, Motoda H. “Association rules based on 
levelwise subspace clustering”, In: Proceedings. of 9th European 
conference on principles and practice of knowledge discovery in 
databases,2005, Heidelberg ,LNAI, vol 3721, pp. 692–700 Springer.
[7] Yang Qiang, Wu Xindong. “10 Challenging Problems in Data 
Mining Research”, International Journal of Information Technology 
& Decision Making, 2006,4(5):597-604.
[8] Zhu Xiaoyu, Wang Lidong, Wang Guangyang. “An Improvement of 
Apriori Algorithm for Mining Association Rules”, Computer 
Technology and Development, 2006.12,12(16):89-90.
[9] Han Wang, Lingfu Kong, "A Constrained Maximum Frequent 
Itemsets Incremental Mining Algorithm", Network and Parallel 
Computing Workshops, IFIP International Conference on, pp. 
743-747, 2007 IFIP International Conference on Network and 
Parallel Computing Workshops (NPC 2007), 2007.
[10] Wu Xindong, Vipin Kumar, J. Ross Quinlan, Joydeep Ghosh, Yang 
Qiang, Hiroshi Motoda, Geoffrey J. McLachlan, Angus Ng, Liu 
Bing, Philip S. Yu, Zhou Zhihua, Michael Steinbach, David J. Hand, 
Dan Steinberg. “Top 10 algorithms in data mining”, Knowl Inf Syst 
(2008) 14:1–37.

