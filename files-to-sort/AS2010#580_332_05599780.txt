Hierarchical Multi-Label Associative Classi?cation (HMAC)
Using Negative Rules
Sawinee Sangsuriyun
Computer Engineering Department,
Faculty of Engineering,
Kasetsart University, Thailand
Email: csnsns@ku.ac.th
Sanparith Marukatat
Image Laboratory,
NECTEC,
Thailand
Email: sanparith.marukatat@nectec.or.th
Kitsana Waiyamai
Computer Engineering Department,
Faculty of Engineering,
Kasetsart University, Thailand
Email: fengknw@ku.ac.th
Abstract—Hierarchical Classi?cation is a very important clas-
si?cation task for arranging data in a hierarchical structure.
Hierarchical arrangement of data is one of the best methods to
achieve better understanding of complex data. In this paper, we
propose the HMAC method to perform Hierarchical Multi-label
Associative Classi?cation. This method uses multiple and negative
rules to predict class-set and to ?lter exceptional cases in order
to improve both accuracy and explanatory ability of the resulting
classi?er. Redundant rule pruning method for negative rules and
rule ranking method for hierarchical associative classi?cation
are developed. Moreover, we propose a rule evaluation measure,
Sim, that tread-off between F-measure and Jaccard’s coef?cient to
encode hierarchical structure meaning of actual and predicted
node collections. We show that Sim is robust and simple rule
evaluation measure. Experimental results show that HMAC im-
proves accuracy and explanatory ability of hierarchical classi?ers
compared with various rule ranking and pruning techniques.
Index Terms—Data mining; Associative classi?cation; Hier-
archical classi?cation; Negative rule; Multiple rule; Multi-label
classi?cation; Rule ranking
I. INTRODUCTION
Association rule mining has been used effectively to build
classi?cation models (classi?ers), known as Associative Clas-
si?cation (AC) [1, 2]. [2–4] show that AC often builds more ac-
curate classi?ers than traditional classi?cation techniques and
many of the rules found by AC methods cannot be discovered
by traditional classi?cation algorithms. This paper, we focus
on three aspects of associative classi?cation, which are 1. the
number of classes to be predicted for each transaction (single-
label vs. multiple-label classi?cation), 2. the particular type
of structure over labels (?at vs. hierarchical structure) and 3.
presence or absence of items and classes in the representation
of rules (positive vs. negative).
Traditional single-label classi?cation algorithms such as
CBA [2] and CMAR [5] refer to classi?cation tasks that
predict only one label. These basic algorithms are generally
known as single-label classi?cation. The algorithms are not
suitable for the data structures found in real world applications.
For example, in medical diagnosis, a patient may be suffering
from diabetes and prostate cancer at the same time [6]. Hence,
multi-label classi?cation algorithms such as MCAR [7] and
MMAC [8] algorithms are preferred. These algorithms have
been used to predict more than two labels for classi?cation
tasks.
Most of the existing algorithms in AC have been developed
for ?at structure over labels [2, 4–8]. However, these algo-
rithms do not cover many signi?cant real world classi?cation
tasks involve a large number of categories, which are arranged
in a hierarchical structure; for example, classifying documents
into subject categories under the Library of Congress scheme,
classifying World Wide Web documents into topic hierarchies,
or classifying proteins by gene ontology which annotate them.
For this reason, hierarchical classi?cation has been proposed
to support hierarchical structures [9–12]. Little research has
focused on hierarchical AC. Itskevitch [9] built COMAR
that applies AC to e-mail classi?cation using multiple rules.
In additional, the author proposed rule cohesion and phase
cohesion measures for rule ranking in hierarchical AC, prob-
abilistic hierarchical accuracy for evaluation of hierarchical
class. However, this method focused only on single-label
classi?cation.
Negative AC, classi?cation using negative rules, has been
investigated by [13–16] proposed. Antonie [13] and Bala [16]
focused on rule generation. Antonie [13] uses the correlation
coef?cient between an item and the set of class labels to
generate and prune rules. [16] uses lift instead of correlation
coef?cient. A positive association rule is produced with a lift
value greater than 1 and a lift value of less than 1 implies a
negative association rule. Another work focuses on classi?er
building, [14, 15] use negative rules to improve accuracy and
explanatory ability. However, these methods cannot classify
multi-label classi?cation and the negative rule form cannot
represent some complex cases in applications; for instance,
prevention or diagnosis of new infectious diseases such as
swine ?u.
This paper aims to improve the prediction accuracy and
explanatory ability of a Hierarchical Multi-label Associa-
tive Classi?cation (HMAC) method using multiple and neg-
ative rules such as rules of positive class-set, x1¬x2 ?
c1c2, to predict class-set, and rules of negative class-set,
x1¬x2¬(x4x5) ? ¬(c1c2), to ?lter exceptional cases in
order to improve explanatory ability of rule based classi?er.
This paper proposes three improvements to hierarchical AC
algorithms. First, we extend the pruning of redundant negative
rules. Second, we introduce a rule ranking method based
on estimated accuracy to add more tie-breaking conditions.
Lastly, we propose a corresponding evaluation measure, Sim
Proc. 9th  IEEE  Int. Conf. on Cognitive  Informatics  (ICCI’10) 
F. Sun, Y. Wang, J. Lu, B. Zhang, W. Kinsner & L.A. Zadeh (Eds.) 
978-1-4244-8040-1/10/$26.00 ©2010 IEEE

Fig. 1. Associative classi?cation steps
that presents relation between hierarchical class-sets.
The rest of this paper is organized as follows. Section II re-
views background knowledge; Section III descries the HMAC
approach; Section IV describes evaluation measures for hierar-
chical classi?cation; Section V show the experimental results.
Conclusions and future work are presented in Section VI.
II. BACKGROUND KNOWLEDGE
This section gives background information about associative
classi?er building, hierarchical structure of ontology, hierarchi-
cal associative classi?cation, and negative association rules.
A. Associative Classi?cation
Associative classi?cation (AC) is a technique relying on
a special type of association rule called Class Association
Rules (CARs) [2]. The rhs of a CAR contains only a class
label. This section presents the main steps in building the AC
model, shown in Figure 1. The ?rst step is CAR generation,
the second step is rule selection, and the last step is classi?er
creation from the selected rules. In Step I, itemsets whose
support is higher than a threshold are selected. Then, the CARs
are generated from these frequent itemsets; only CARs whose
con?dence level is higher than a threshold are retained.
The rules derived from Step I can be redundant or erroneous.
Several rule pruning techniques [3, 5, 8, 13, 17] have been
proposed in order to create a more effective and accurate
classi?er. In this pruning step, a commonly used measure is
Pearson’s correlation coef?cient between left hand side (lhs)
and the right hand side (rhs) of the rules [13, 15, 16].
The other pruning methods try to discard speci?c rules with
lower con?dence values than general rules. In this redundant
rule pruning [3, 5, 13], A ? c is considered as more general
than A? ? c if A ? A?. This pruning method reduces the size
of the resulting classi?ers and minimizes rule redundancy.
In order to build a classi?er from the selected rules, ranking
plays an important role. Indeed, the rank of rules indicates
which rule is to be applied ?rst. Highly ranked rules are
then used more frequently in predicting test data. The rule
ranking is usually based on several parameters including
support, con?dence, and rule antecedent cardinality [2, 5]. In
some cases, tie breaking conditions are required. For example,
[7, 8] propose two tie breaking conditions based on class
distribution frequency and favors rules that are associated
with the most representative class (ActOccr). Note that, the
above-mentioned algorithms focus on ?at (non-hierarchical)
classi?cation methods.
Fig. 2. A hierarchial ontology
In Step III, a classi?er is formed by the ranked CARs
which are selected incrementally. Only rules that cover at least
one training data not covered by previous selected rules are
kept for further classi?cation. This database coverage method
was created by the CBA and subsequently adopted by other
algorithms, including those in [5, 7, 18].
B. Hierarchical Structure of Ontology
De?nition 1 (Hierarchy H(S,?)): [19] Let S be a par-
tially ordered set under ordering ?. We say that an ordering
 de?nes a hierarchy for S if the following three conditions
are satis?ed: (1) x  y ? x ? y;?x, y ? S. We say (S,?) is
better than (S,?),
(2) (S,?) is a re?exive, transitive closure of (S,?),
(3) No other ordering  satis?es (1) and (2).
Example: Let S = {Plant, Fruit, Orange}. We can de?ne a
partial ordering ? on S according to the is-a relationship. For
example, Fruit is a Plant, Orange is a Fruit, and Orange also
is a Plant. In addition, everything is a itself. Thus, (S,?)
= {(Plant, Plant), (Fruit, Fruit), (Orange, Orange), (Fruit,
Plant), (Orange, Fruit), (Orange, Plant)}. The re?exive, tran-
sitive closure of ? is the set: (S,) = {(Fruit, Plant), (Orange,
Fruit)}, which is the only hierarchy associated with (S,?).
Figure 2 shows an ontology including the hierarchy asso-
ciated is-a and part-of relationships. Indeed, an ontology is
often used by domain experts to encode domain knowledge.
It is represented as a directed acyclic graph in which each node
represents a concept, and links between nodes represent some
relation between them. For a given relation, the ontology’s sub-
graph is described by a hierarchy associated with that relation.
In this paper we focus only on the is-a relation in hierarchical
structure of ontology.
C. Hierarchical associative classi?cation
Hierarchical associative classi?cation (HAC) is a task in
which class labels are assigned a hierarchical structure, as
given by De?nition 1. An associative classi?er is composed of
class association rules that can be used to predict hierarchical
class. Therefore, a rule that predicts ’Fruit’ when an input
image is indeed a ’Grape’ should not be considered as totally
in error. Compared with traditional associative classi?ers that
work with ?at structure, HAC, should take into account the
class hierarchy in rule pruning and rule ranking phases.
Further, a class association rule that contains more than one
class on the rhs is called multi-label associative classi?cation.

Fig. 3. Steps in HMAC method
Thus, a HAC that supports multi-label classi?cation is called
hierarchical multi-label associative classi?cation.
D. Negative association rule
Note that not only the presence of attributes can be used
to predict class, but their absence is also a useful indicator in
some cases. Following the derivation in [20], let X denote a
positive itemset meaning that X contains only items possessing
some attributes, N denote a negative itemset containing items
absent the attributes, and NP is negation of positive itemset
denoting the non-simultaneous presence of attributes. For
example, ¬x1 is of type N , and means that x1 must be
absent. If ¬(x1x2) is of type NP , it denotes non-simultaneous
presence of x1 and x2. This means that x1 or x2 can still be
present but not simultaneously. To simplify the discussion, let
Pa denote the lhs of CARs.
In an analogous manner, the rhs of CARs can be separated
in three types, C, NC, and NPC. Let C be the positive class-
set denoting the presence of class C; NC be the negative
class-set denoting the absence of the class; and NPC be the
negation of positive class-set denoting the non-simultaneous
presence of classes such as ¬(c1c2) and ¬(c1c3c4). In the
following, let Pc denote the rhs of CARs. Then, a negative
association rule is of the form Pa ? Pc. Note that Pa is
a conjunction of three patterns X , N , and NP , while Pc is
either C, NC, or NPC. We will call all CARs for which
Pc = C the rules of positive class-set (RPC), and all CARs
for which Pc = NC or Pc = NPC the rules of negative
class-set (RNC).
III. HMAC: HIERARCHICAL MULTI-LABEL ASSOCIATIVE
CLASSIFICATION
In this section we present a new Hierarchical Multi-label
Associative Classi?cation method called HMAC, using mul-
tiple and negative rules. An overview of HMAC is shown in
Figure 3. The RPC are generated in Step I. Pruning strategies
to reduce the number of generated rules are applied in Step II.
The rule precedence is an important concept to use appropriate
conditions to decide which rules are better. In Step III, the
classi?er builder for HMAC that uses rule pruning based on
database coverage is vital for selecting a subset of high quality
rules for the classi?cation step. Finally, a classi?cation step,
for given testing data object obj, HMAC extracts a subset of
rules matching the obj and predicts the class label of the obj
by analyzing this subset of rules.
A. Rules Pruning
In Step II a subset was selected to form the classi?er, mainly
focused on avoiding redundant rule that would mislead the
prediction process in testing data. HMAC uses two pruning
strategies to reduce the size of RPC.
1) Pearson’s correlation coef?cient: For each Positive
Class-set rule RPC, we calculate Pearson’s correlation coef?-
cient ? between the lhs and the rhs and prune the rules whose
correlation is below a user-speci?ed threshold. If ? = 0, the
lhs and rhs of the rule are independent; ? = +1 and ? = ?1
mean the lhs and rhs of the rule are perfectly positively and
negatively correlated, respectively.
2) Redundant rules pruning: The rules in the resulting
classi?ers may share lhs and there could be several speci?c
rules containing many general rules. Redundant rule pruning
discards speci?c rules that have a lower rank than general
rules. In this study, the redundant rule pruning method for the
negative rules is as follows. Once the rule generation process
is ?nished, the negative rules are classi?ed by the lhs of each
rule in four clusters: X , X ?N , X ?NP , and X ?N ?NP .
Then, an evaluation step is performed to prune all rules for
each cluster, such as Pa? ? Pc, from the set of generated
rules, where there is some general rule Pa ? Pc of a higher
ranking and Pa ? Pa? as de?ned in de?nition 2.
De?nition 2: A set of itemsets Pa ? Pa? if (X ? X ?) ?
(N ? N ?) ? (NP ? NP ?).
For example, rule r1 : x1¬x2¬(x4x5) ? c1c2 and rule
r2 : x1¬x2¬x3¬(x4x5)¬(x6x7) ? c1c2. Moreover, both
of them have the same rhs pattern of classes and rule r1
is higher than rule r2. The X component of r1 and r2
is x1 and x1, respectively, then {x1} ? {x1}. Next, the
N component of r1 and r2 is x2 and x2, x3, respectively,
then {x2} ? {x2, x3}. The last component, NP itemsets,
r1 and r2 are (x4x5) and (x4x5), (x6x7), respectively, then
{(x4x5)} ? {(x4x5), (x6x7)}. Therefore, the rule r1 ? r2,
hence r2 is discarded.
B. Rule Ranking
Traditional rankings are based on ?at non-hierarchial clas-
si?cation. In this study we focus on hierarchical classi?cation,
so the HMAC ranking method proposed as shown in Figure 4
is used to rank RPC only. The rule ranking based on several
parameters that order rules by priority, which are F-measure,
Jaccard, support, ActOccr, and speci?c rule. HMAC ranking
replaces con?dence parameter with two measures, the ?rst is
F-measure (FM), which is given in Equation 1. This measure
has a high value if two node collections exactly match. The
second measure is weighted Jaccard’s coef?cient, Jaccardw,
that encodes hierarchical structure meaning to evaluate the
strength of the semantic link between two groups of concepts
from the difference or same hierarchical structure (this paper
focuses on the same hierarchical structure). Jaccardw is given
in Equation 4. Section IV describes details of these measures.
Moreover, we rank the rules that have more conditions in the
lhs higher than the others.

Fig. 4. HMAC rule ranking method
C. HMAC Classi?er
We propose an algorithm to create HMAC classi?er in Phase
III, HMAC algorithm uses multiple and RNC to ?lter the
exceptional case for the following RPC (see Figure 5). HMAC
algorithm can be summarized as follows:
Step I. Rule sorting: RPC are sorted by rule precedence in
descending order as shown in Figure 4 (line 1).
Step II. Classi?er building: Each rule rpci is considered
from top to bottom. If rcpi match at least one training
transaction, we will create a classi?er, else consider the next
rpci (line 4). In classi?er building, all RNCi are generated
from rpci (line 5), then mark all training transactions tj that
are matched rpci and unmatched RNCi (line 6). Next, default
class-set (Def ) is created (line 7-9). We also choose a default
class-set, which is the majority class-set in the training data
T
?. Then in line 10-11 the new classi?er (Clnew) is created.
Step III. Classi?er selection: After the measure of Clnew
accuracy is calculated in line 11, a classi?er is selected (line
12-15). If Clnew is selected, then we will remove all marked
tj , else all tj are unmarked.
Repeat Step II-III until there is no more transactions or rules
remaining. Remaining rules are appended to the classi?er in
the accuracy decreasing order. Figure 6 shows an example set
of classi?cation rules that compose HMAC classi?er.
D. Classi?cation
In classifying an unseen data obj, shown in Figure 7, obj is
compared with the rule-sets in classi?ers from top to bottom.
If it matches a rpci without any RNC, then the RPC classi?es
it (line 7). If the matching rpci has RNC, we examine each
rules in RNC and attempt to match each of them (line 5). If
RNC does not match the obj, then the RPC classi?es it (line
6). Otherwise, if prediction is cannot be made, we move on to
the next rule-set and repeat the process (line 8). If prediction is
cannot be made, then default class-set is predicted (line 9-10).
IV. EVALUATION MEASURES
A. Traditional similarity measures
In order to evaluate our task of hierarchical multi-label
classi?cation, keep in mind that the system predicts not a
single class but several classes containing in the class-set.
Fig. 5. HMAC classi?er builder algorithm for selecting rules based on
database coverage
Fig. 6. An example for HMAC classi?er. RPC are ordered by Sim.
RNC ?lter the exceptional cases for the following RPC, and as a result
the RPC makes more accurate predictions.
These classes are related to each other by the relation given in
the considered hierarchy. Indeed, within the given hierarchy, a
class corresponds to a node and a class-set corresponds to
a node collection. Thus evaluation measure could be built
upon the similarity between the predicted nodes collection
and the actual nodes collection. Some traditional set similarity
measures like F-measure or Jaccard’s coef?cient could be then
Fig. 7. Classifying a test instance is compared with the rule-set that
have a rule of positive class-set rpci and many rules of negative class-
set RNC for a set of rule.

used.
1) F-measure: is a common evaluation measure in informa-
tion retrieval task. It is indeed the harmonic mean of precision
and recall. Precision is the fraction of predicted nodes that
are actual nodes while recall is the fraction of actual nodes
which are predicted. This measure can be extended to take into
account hierarchical structure by considering ancestor nodes
of both predicted and actual nodes. Let A = (a1, a2, ..., am)
and P = (p1, p2, ..., pn) be the actual node collection and
the predicted node collection respectively. We shall denote
by AncA and AncP the set of ancestor nodes of A and
P respectively. Using this notation, the normal F-measure
(FM(A,P )) and the modi?ed F-measure (FMAnc(A,P )) are
de?ned by
FM(A,P ) = 2
|A ? P |
|A|+ |P |
(1)
FMAnc(A,P ) = 2
|AncK ?AncP |
|AncK |+ |AncP |
(2)
Note that after some calculation FMAnc(A,P ) is exactly
the same as Dice’s coef?cient [21].
2) Jaccard’s coef?cient: Another measure of set similarity
is Jaccard’s coef?cient (Jaccard), that is given by
Jaccard(AncA, AncP ) =
|AncA ? AncP |
|AncA ? AncP |
(3)
B. Our similarity measure
One may expect the FMAnc(A,P ) or
Jaccard(AncA, AncP ) to be suitable for evaluate our
hierarchical multi-label classi?cation problem. However,
by further analyzing, we can see that these 2 measures
fail to distinguished between predicted node collections if
they both contain nodes on the same path. For example,
in Figure 8 FM(AncA, AncP1) = FM(AncA, AncP2) =
0.89 and Jaccard(AncA, AncP1) = Jaccard(AncA, AncP2)
= 0.80. The normal F-measure does not suffer from this
problem since it focuses on exact match between nodes in
collections. Hence, we propose a new similarity measure,
Sim(A,P ), to estimate the accuracy of classi?er to predict
the hierarchical classi?cation. Our evaluation measure is
based on a similarity measurement that trades off between
exact match and the relational between nodes in hierarchical
structure. Jaccardw(AncA, AncP ) and Sim(A,P ) are
computed by
Jaccardw(AncA, AncP ) =
?
?i?(AncA?AncP )
wi?
?j?(AncA?AncP )
wj
(4)
Sim(A,P ) = ?·FM(A,P )
+ (1? ?)·Jaccardw(AncA, AncP ) (5)
where 0 ? ? ? 1. Thus, in Figure 8, let ? = 0.50 and ?wi =
?wj = 1, then Sim(A,P1) = 0.735 and Sim(A,P2) = 0.65.
In this paper, the weight of nodes involving in the calcula-
tion of weighted Jaccard’s coef?cient (Equation (4)) is com-
Fig. 8. Graph a), b) and c) in an ontology graph, let A =
{c3, c4, c6, c8, c9} be an actual node collection and AncA =
{c0, c1, c2, c3, c4, c5, c6, c7, c8, c9} be an ancestor node of A. Next,
P1 = {c2, c3, c4, c9} and P2 = {c2, c3, c9} be a predicted
node collection of P1 and P2, respectively. AncP1 = AncP2 =
{c0, c1, c2, c3, c4, c5, c7, c9} be an ancestor node of P1 and P2.
puted as function of its information content. The information
content of a node c, IC(c), is de?ned by IC(c) = ?log[P (c)]
where P(c) corresponds to the occurrence probability of c or
one of its directly or indirectly subsumed concepts [22].
V. EXPERIMENTAL RESULTS
The dataset containing 15,088 protein sequences, 1,353
PROSITE motifs and 849 molecular functions were down-
loaded from the PROSITE database (release 20.22, of
November 14, 2007), ftp://au.expasy.org/databases/prosite/,
and the Gene Ontology Annotation (GOA) database from
http://archive.geneontology.org/latest-lite/ in November 19,
2007. Experiments were conducted using strati?ed 5-fold cross
validation [23].
Following is the list of parameters together with their values
used in respectively rule generation and pruning steps. For rule
generation step: support(%): 12, 14, 16, 18, 20; con?dence: 50.
For rule pruning step: Pearson’s correlation coef?cient: 0.5;
alpha(?): 0.5. Table I shows experimental results on different
ranking methods with respect to different support values.
Experimental results show a signi?cant improvement of the
HMAC rule ranking method (p < 0.01) over six rule ranking
methods which are (conf (CBA), conf (MMAC), FM, Jiang &
Conrath’s Dist, Lin’s Sim and Resnik’s Sim. Conf (CBA) and
conf (MMAC) are based on respectively CBA and MMAC.
Resnik’s Sim [24], Jiang & Conrath’s Dist [25] and Lin’s
Sim [26] are the measures used in Gene Ontology evaluation.
Moreover, the proposed rule ranking method has a signi?cant
improvement (p < 0.05) over Jaccard rule ranking method
at 16% and 18% minimum support thresholds. HMAC rule
ranking method gives the best results (in bold) in improving
the predictive power of the resulting classi?ers.
Table II shows the robustness of the alpha parameter (?)
over the accuracy of HMAC. We observe no signi?cant dif-
ference for various values of alpha (?) parameter. Thus, the
proposed Sim(A, P) in Equation 5 is simply measure to utilize.
4
TABLE I
IMPACT OF THE TEN RULE RANKING METHOD ON THE ACCURACY OF
HMAC ALGORITHM
Supp. (%)
Ranking Method
12 14 16 18 20
HMAC 45.17 43.25 41.38 39.96 39.75
JaccardIC 44.04 42.39 40.51? 38.89? 38.97
Jaccard 44.15 42.28 40.71 39.12 38.99
FMAnc 44.15 42.28 40.71 39.12 38.99
FM 37.66?? 36.43?? 35.18?? 33.84?? 32.32??
conf(CBA) 38.18?? 35.10?? 34.47?? 33.35?? 33.47??
conf(MMAC) 37.56?? 35.66?? 35.15?? 33.19?? 28.65??
Resnik?s Sim 35.53?? 33.73?? 32.60?? 31.59?? 31.76??
Lin?s Sim 37.59?? 36.47?? 35.14?? 3.83?? 32.32??
Jiang&Conrath?s 37.57?? 36.46?? 35.15?? 33.83?? 32.32??
Dist
1** 0.01 signi?cant level 2* 0.05 signi?cant level
TABLE II
IMPACT OF THE ALPHA PARAMETER (?) ON THE ACCURACY OF HMAC
ALGORITHM
? 0.0 0.2 0.4 0.6 0.8 1.0
accuracy (%) 45.13 45.15 45.16 45.18 45.19 45.21
VI. CONCLUSIONS AND FUTURE WORKS
In this paper, HMAC method can improve accuracy and
explanatory ability of rule-based classi?er using multiple and
negative rules. HMAC has the following features over other
existing associative classi?cation techniques:
• Negative redundant rule pruning: We extend pruning
negative redundant rule in complex form that can improve
explanatory ability of complex data in real world.
• Appropriate rule ranking method for hierarchical associa-
tive classi?cation: HMAC rule ranking uses combination
of two scoring methods: (1) FM , (2) Jaccard. Moreover,
the experimental results show that HMAC can improve
the predictive power of the resulting classi?ers.
• Robust rule evaluation measure for hierarchical classi-
?cation: Sim evaluation measure is a tread-off between
F-measure and Jaccard. Experimental results show that
Sim is a robust evaluation measure bounded [0, 1].
In our future work, we are going to improve explanatory ability
of HMAC by proposing a better representation of classi?cation
rules.
ACKNOWLEDGMENT
Thanks to J.E. Brucker for his reading and comments of
this paper.
REFERENCES
[1] K. Ali, S. Manganaris, and R. Srikant, “Partial classi?cation using
association rules,” in Proc. 3th Int. Conf. on KDD, 1997, pp. 115–118.
[2] B. Liu, W. Hsu, and Y. Ma, “Integrating classi?cation and association
rule mining,” Knowledge Discovery and Data Mining, pp. 80–86, 1998.
[3] M. Antonie, O. Za?¨ane, and A. Coman, “Associative classi?ers for
medical images,” Lecture Notes in Computer Science, vol. 2797, pp.
68–83, 2003.
[4] X. Yin and J. Han, “CPAR: Classi?cation based on predictive association
rules,” in Proceedings of the third SIAM international conference on data
mining. Society for Industrial & Applied, 2003, pp. 208–217.
[5] W. Li, J. Han, and J. Pei, “CMAR: Accurate and Ef?cient Classi?cation
Based on Multiple Class-Association Rules,” in ICDM ’01: Proceedings
of the 2001 IEEE International Conference on Data Mining. Washing-
ton, DC, USA: IEEE Computer Society, 2001, pp. 369–376.
[6] G. Tsoumakas and I. Katakis, “Multi-label classi?cation: An overview,”
Int J Data Warehousing and Mining, vol. 2007, pp. 1–13, 2007.
[7] F. Thabtah, P. Cowling, and Y. Peng, “MCAR: multi-class classi?cation
based on association rule,” 2005, pp. 33–.
[8] ——, “MMAC: a new multi-class, multi-label associative classi?cation
approach,” Nov. 2004, pp. 217–224.
[9] J. Itskevitch, “Automatic hierarchical e-mail classi?cation using associ-
ation rules,” Master’s thesis, Simon Fraser University, 2001.
[10] J. Fan, Y. Gao, H. Luo, and R. Jain, “Mining multilevel image seman-
tics via hierarchical classi?cation,” Multimedia, IEEE Transactions on,
vol. 10, no. 2, pp. 167–187, Feb. 2008.
[11] N. Cesa-Bianchi, C. Gentile, and L. Zaniboni, “Hierarchical classi?ca-
tion: combining bayes with svm,” in ICML ’06: Proceedings of the 23rd
international conference on Machine learning. New York, NY, USA:
ACM, 2006, pp. 177–184.
[12] J. Fan, Y. Gao, and H. Luo, “Hierarchical classi?cation for automatic
image annotation,” in SIGIR ’07: Proceedings of the 30th annual
international ACM SIGIR conference on Research and development in
information retrieval. New York, NY, USA: ACM, 2007, pp. 111–118.
[13] M. Antonie and O. Za?¨ane, “An associative classi?er based on positive
and negative rules,” in DMKD ’04: Proceedings of the 9th ACM
SIGMOD workshop on Research issues in data mining and knowledge
discovery. New York, NY, USA: ACM, 2004, pp. 64–69.
[14] J. Li and J. Jones, “Using multiple and negative target rules to make
classi?ers more understandable,” Knowledge-Based Systems, vol. 19,
no. 6, pp. 438 – 444, 2006.
[15] G. Kundu, M. Islam, S. Munir, and M. Bari, “ACN: An Associative
Classi?er with Negative Rules,” July 2008, pp. 369–375.
[16] P. K. Bala, “A technique for mining negative association rules,” in
COMPUTE ’09: Proceedings of the 2nd Bangalore Annual Compute
Conference on 2nd Bangalore Annual Compute Conference. New York,
NY, USA: ACM, 2009, pp. 1–4.
[17] G. SNEDECOR and W. COCHRAN, “Statistical methods. ames: Iowa
state university, 1989. 503p,” Links.
[18] B. Liu, Y. Ma, and C. Wong, “Classi?cation using association rules:
weaknesses and enhancements,” Data mining for scienti?c applications,
2001.
[19] P. Bonatti, Y. Deng, and V. Subrahmanian, “An ontology-extended
relational algebra,” in IEEE International Conference on Information
Reuse and Integration, 2003. IRI 2003, 2003, pp. 192–199.
[20] M. Gan, M.-Y. Zhang, and S.-W. Wang, “One extended form for negative
association rules and the corresponding mining algorithm,” vol. 3, Aug.
2005, pp. 1716–1721 Vol. 3.
[21] L. Dice, “Measures of the amount of ecologic association between
species,” Ecology, pp. 297–302, 1945.
[22] E. Blanchard, M. Harzallah, H. Bri, P. Kuntz, and R. C. Pauc, “A
typology of ontology-based semantic measures,” in in proc of EMOI-
INTEROP’05 workshop, at CAiSE’;05, 2005, pp. 13–14.
[23] I. Witten and E. Frank, “Data mining: Practical machine learning
tools and techniques with java implementations,” in COMPUTE ’09:
Proceedings of the 2nd Bangalore Annual Compute Conference on 2nd
Bangalore Annual Compute Conference, San Francisco, CA: Morgam
Kaufmann, 2000.
[24] P. Resnik, “Using information content to evaluate semantic similarity in
a taxonomy,” in International Joint Conference on Arti?cial Intelligence,
vol. 14. Citeseer, 1995, pp. 448–453.
[25] J. Jiang and D. Conrath, “Semantic similarity based on corpus statistics
and lexical taxonomy,” Arxiv preprint cmp-lg/9709008, 1997.
[26] D. Lin, “Using syntactic dependency as local context to resolve word
sense ambiguity,” in Annual Meeting-Association for Computational
Linguistics, vol. 35. Association for Computational Linguistics, 1997,
pp. 64–71.

