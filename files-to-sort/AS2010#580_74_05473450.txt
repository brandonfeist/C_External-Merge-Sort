 A Study of Improving Apriori Algorithm  
 
Libing Wu 
School of Computer 
 Wuhan University 
Wuhan, China 
wu@whu.edu.cn 
 
Kui Gong 
School of Computer 
Wuhan University 
Wuhan, China 
 
 
Yanxiang He 
School of Computer 
Wuhan University 
Wuhan, China  
 
 
Xiaohua Ge 
School of Computer 
Wuhan University 
Wuhan, China 
 
 
 Jianqun Cui 
Department of 
Computer Science 
Huazhong Normal 
University 
Wuhan, China  
Abstract—The Apriori algorithm is one of the most influential 
apriori for mining association rules. The basic idea of the Apriori 
algorithm is to identify all the frequent sets. Through the 
frequent sets, derived association rules, these rules must satisfy 
minimum support threshold and minimum confidence threshold. 
This paper presents improved algorithms, mainly through the 
introduction of interest items, frequency threshold, to improve 
the mining efficiency, dynamic data mining to facilitate the needs 
of users. Confirmed by many experiments, this algorithm is 
better than traditional algorithms in time and space complexity. 
Keywords- Apriori algorithm; dynamic mining; interest item; 
frequency threshold 
I.  INTRODUCTION  
With the development of artificial intelligence, database 
technology and mathematical statistics, the transaction database 
for mining association rules is an important research direction 
for data mining. Association rule is an important research in the 
knowledge discovery research. In large amounts of data, some 
interesting correlation would find in itemsets or related 
links[1,2].  
The mainly technology of data mining is association rules, 
clustering, rough sets, neural networks, genetic algorithms and 
so on. Association rules are a group of objects in the database 
which associated with the relationship between the rules. It is 
widely used in data mining. It can be divided into two sub-
problems [3,4].One is to find the frequent item sets which meet 
the minimum support. The other one is using the frequent item 
sets to generate association rules, according to the minimum 
credibility. The first problem is the overhead of time and space, 
so most of current association rule mining algorithms are 
committed to improving the efficiency to find frequent item 
sets. There are some ways to extend the association rules, such 
as the numeric association rules [5], multi-level association 
rules [6]. 
A large number of mining association rules algorithm has 
proposed. In this rules, Apriori algorithm is the most classical 
algorithms. This article is based on the Apriori algorithm by 
introducing the number of interest items and frequency 
threshold to reduce the times of database search. Dynamic 
mining can be well positioned to meet customer’s need, and 
improved the efficiency of the algorithm. 
 
II. ASSOCIATION RULES 
Association rules derived from analyzing the problem of 
supermarket shopping. Using this rules to detect the link 
between different commodities in the database. These links 
reflect the patterns of customer buying behavior. Found such a 
link can be applied to analyze customer shopping, directory 
design, commercial advertising mail. The area of research in 
data mining for association rules mining was more in-depth 
research. It has carried out a number of association rules 
mining algorithm. At present, the association rule mining has 
been successfully applied in various related areas. The data 
mining is one of the most mature, most important and most 
extensive research details [7, 8] 
A. Related Concepts 
In order to facilitate description of our algorithm, we 
hereby agree: i in this transaction database is a 
property, }...,,{ 21 niiiI =  is a collection of all attributes in this 
transaction database, )}(,...,,{ 21 nmiiiT m ?= is a transaction, 
},...,,{ 21 nTTTD = is a transaction database, D  is indicated the 
number of transaction database transactions. In this place, the 
elements in },...,,{ 21 nTTTD = can be repeated. In order to 
avoid duplication of transactions are covered .In this article, we 
give a unique mark to each of transaction in the transaction 
database TID. 
Supportive degree of the itemset )(XSup is the proportion 
how much transaction X included in the entire database D. 
Confidence )( BAConf ?  of association rule BA?  is the 
conditional probability that itemset B occurred in the condition 
that itemset A have occurred. Minimum support threshold 
Supmin  is the minimum one which item sets must be met in 
the mining process. Minimum confidence threshold Confmin  
is the minimum one which association rule must be met. 
Itemsets whose supportive degree are greater than or equal to 
Supmin  are defined as frequent itemsets. 
B. The introduction of traditional Apriori algorithm 
Firstly, we need dig out the frequent 1-itemsets, then, 
continue to use the recursive way to mining frequent k-itemsets 
(k> 1).Specific practices is to dig out the candidate frequent k-
itemsets, according to the smallest minimum confidence 
Supported by National Natural Science Foundation of China (Grant No. 60773008), Key Laboratory of Aerospace Information Security and Trust Computing 
of Ministry of Education., National Science Foundation for Post-doctoral Scientists of China, Natural Science Foundation of Hubei Province and “Dawn” Program 
of Wuhan (No. 200950431183). 
978-1-4244-5874-5/10/$26.00 ©2010 IEEE
 threshold Supmin  to filter some candidate, to get frequent k-
itemsets. Finally, combine all of the frequent k-itemsets(k>0). 
The rule's confidence is greater than given minimum 
confidence. In this step, firstly, you need start from the frequent 
itemsets, to dig out all the association rules, and then to get the 
frequent association rules. 
C. The example illustrates the Apriori algorithms 
Transaction database as shown in Table I, Supmin =50%, 
Confmin =70%. Request the frequent association rules in 
transaction database D. 
TABLE I.  TRANSACTION DATABASE  
Tid Itemsets 
1 A B C D E 
2 A B C 
3 C D E F 
4 A B E 
 
The implementation process is as follows: 
The first step: Find the frequent itemsets 
1) Frequent 1 - itemsets{{A}?{B}?{C}?{D}?{E}}. 
2) Frequent 2 - itemsets{{AB}?{AC}?{AE}?{BC}?
{BD}?{CD}?{CE}}. 
3) Frequent 3 - itemsets{ABC}. 
4) Summary 321 LLLL ??= ={{A}? {B}? {C}? {D}?
{E}?{AB}?{AC}?{AE}?{BC}?{BD}?{CD}?{CE}?
{ABC}}. 
The step two: seeking association from {ABC} 
Only {AC} ? {B},{BC} ? {A},{A} ? {B},{B} ? {A} 
meet the requirements. Confidence level is 100%. 
III. THE DESCRIPTION OF IMPROVED ALGORITHM 
A. Introduction of Improved algorithm 
From the above process, we see that some disadvantages in 
the traditional data mining. Firstly, the process of scanning 
database is too frequently. Secondly, the definition of Supmin  
and Confmin  cannot be changed. If we want to change 
Supmin or Confmin , we need re-excavation. It is 
inconvenience to users. Thirdly, we are not interested in EF, so 
it should not be start to operate on EF. 
Property1. If A B? exists in the association, then 
?AB Countmin .so if T < Countmin , Then, the 
relationships composed of any subset of T not meet the 
minimum confidence. 
Property2. If A B? exists in the association, then A and 
B are frequent itemsets, but AB is not a necessarily frequent 
itemsets. 
Definition1: Interested Item I is a collection of items which 
are interested in some users. It is also a key objective of the 
excavation. 
Definition2: Item frequency refers to a subset of items 
from the interest in the composition of the items set in the 
transaction database number. 
Definition3: Support the frequency threshold 
SupCountmin  is a minimum number of items in association 
rules. 
SupCountmin = D * Supmin  
Definition4: Frequency threshold Countmin  is the 
minimum number in the association rule of BA? . 
Countmin = SupCountmin * Confmin  
B.  Algorithm Steps 
To sum up the three inadequate in traditional mining 
algorithms and the two properties, we have improved Apriori 
algorithm as follow: 
The first step: This paper presents the various items of 
interest in a subset of items of frequency. 
1) Enter interest items and mining transactional database 
2) Scan the transaction database 
3) Records each sub-set of items in the database. You can 
record frequency and the total number of articles D . Save the 
subset. 
The second step: find the association 
1) Enter Supmin and Confmin .Put Supmin  into 
SupCountmin  
2)  Scan the subset of items of interest which you have 
saved. Find out frequent itemsets and delete some subset 
whose frequency is less than Countmin . 
3) Find each association rule whose confidence is greater 
than Confmin .Output the rules. 
C. The improved algorithm pseudo-code 
Step 1: Find the item frequency of all the subsets of 
interested items. 
Input: Transaction database (D); Interested items (I) 
Output: Item frequency of all the subsets of interested items 
and record item numbers in the database. 
For each candidate Ii ?  Do // traversing each Interested 
items 
Count++         // Record numbers of interested items 
End for                         
sumI = )(Isubset   // Find all the subsets of Interested items  
For each log Dd ?  Do   
For each candidate di ?  Do // traversing each 
Interested items 
        If ( Ii ? )    // if this item belongs to Interested items 
         idi =?   // Find all the Interested items in this record 
        End if 
       )( id dsubsetI =   
   End for 
   For each Item in dI  // traverse each item in the collection 
    ++countItems.     // each item add 1 in the collection 
    End for 
    Count++         // record the item numbers in the database 
End for 
Pseudo-code of )(Isubset  as follows: 
);;1( . ++<= icountIiifor  
Return  sumI =? countiiiii IIIIII ...... 11 ++ ??  
End for     
Step 2: Find the association in sumI  
Input: Minimum support threshold ( Supmin ); Minimum 
confidence threshold ( Confmin ) 
Output: The AR to meet the requirement and credibility 
SupCountmin =Count* Supmin * Confmin  
For each candidate sumII ?  Do 
    )min( .. SupCountcountItemsIif <  
        Delete I  // if the frequency of I is smaller 
than SupCountmin , delete it from sumI  
    Else 
       )min( .. CountcountItemsIif ?  
          IL =?  // Save I as a frequent item into L, if its 
frequency is greater than Countmin   
           Count1++   // record the numbers of frequent items 
        End if 
     End if 
End for 
For each candidate LI ?  Do // traversing all the items of L 
   );1;1( ++<= icountiifor  // traversing each element of L 
     )..( ItemsLItemsLif ki ?  // if the items in iL  and kL  are 
different 
       ))..(( sumki IItemsLItemsLif ??   // if the union of 
items in iL  and kL belongs to sumI  
)min
..
)...(( Conf
countItemsL
countItemsLItemsLif
i
ki ?
?  
                    return ItemsLi . ItemsLk .? ? 
countItemsL
countItemsLItemsL
i
ki
..
)...( ?  
           End if 
        End if 
     End if 
End for 
End for 
Time complexity analysis of the algorithm: the record 
number in database (m) is always very large. Actually, constant 
n, the items which user interested is smaller. The complexity of 
the algorithm is O ( )12(* ?nm ). 
IV. EXPERIMENT AND EXPERIMENTAL ANALYSIS 
A. The improved algorithm flowchart 
At the beginning, input the target data forms and interested 
items. Scan all the item collections in the database, and save 
the frequency in the list-L. Input the threshold of support 
degree and credibility, judge whether they are legal, then scan 
L, delete items whose frequencies are smaller than the 
frequency threshold, mine AR according to the related rules. At 
last, need further mining or not. If so, keep inputting new 
threshold of support and credibility to continue mining. 
Otherwise exit from the program. The flowchart of the 
improved algorithm is shown in Fig.1. 
 
Figure 1.  The improved algorithm flowchart 
B. Experiment examples of improved algorithm 
All data and parameters have listed on the Table I, 
interested item is ABC. 
 1) frequencies of A?AB?AC?ABC?B?BC?C are 3
?3?2?2?3?2?3 
2) The frequent items are {A?AB?AC?ABC?B?BC
?C} 
3) Candidate association relations are on the list: 
{A} ? {BC}?{B} ? {AC}?{C} ? {AB}?{AB} ? {C}?
{AC} ? {B}? {BC} ? {A}? {A} ? {B}? {A} ? {C}?
{B} ? {A}? {B} ? {C}? {C} ? {A}? {C} ? {B}. The 
credibility are as follows?67%?67%?67%?67%?100%
?100%?100%?67%?100%?67%?67%?67%. 
4) As a result, only these items {AC} ? {B}?{BC} ? {A}
? {A} ? {B}? {B} ? {A}meet the requirement? their 
credibility have reached to 100%. 
V. PERFORMANCE EVALUATION OF IMPROVED APRIORI 
ALGORITHM 
At first, the minimum support of degree and credibility are 
changeable in the algorithm provided in this paper, which 
greatly facilitate the customer's requirements. Secondly, the 
advanced mining algorithm has explicit object, improves the 
mining efficiency, reduce the time and space complexity. The 
author have test the traditional algorithm and the advanced one 
based on the same situation that all the data are from Table I, 
and lead to the results showed in Fig. 2(a). 
Fig. 2(a) showed that improved algorithm improved a lot 
on time. When it comes to the case that the transaction 
database is huge and the number of interested items is much 
smaller, the improved algorithm runs much better. As shown in 
Fig. 2(b), we set that each storage object accounted for 3 bytes. 
      
(a)                                                              (b)  
Figure 2.  Performance results of improved apriori algorithm 
VI. CONCLUSION 
The paper do some research on the Apriori algorithm, it 
showed that the biggest challenge of the Apriori algorithm 
faced is the computational efficiency issue. We reach a 
conclusion after an analysis on Apriori algorithm: reduce the 
frequency we scan the database; reduce the item collection that 
impossibly become a mining relationship; improved the 
flexibility to be a user-friendly mining algorithm; the above 
measures can make the algorithm efficient. The algorithm 
provided in this paper can get the target to improve the 
efficiency. 
For the future research and development, association rules 
mining can take these important aspects into consideration, 
such as, how to improve mining efficiency of association rule 
especially in the situation that processing large amount of data; 
how to set multiple supportive degree and creditable in multi-
dimensional multi-layer database that user interested in order to 
mine more valuable association rule; how to mine related 
valuable rare item collection in a more efficient methods [9, 
10]. 
REFERENCES 
[1].WANG Li-Zhen, ZHOU Li-Hua, et al. Data warehouse and data 
mining principles and applications. Beijing, Science Press, 2005. 
[2] T.Uno, M.Kiyomi,and H.Arimura. Lcm ver.2:Efficient mining 
algorithms for frequent/closed/maximal itemsets. In B. Goethals,M. 
J. Zaki,and R.Bayardo,editors, Proceedings of the IEEE ICDM 
Workshop on Frequent Itemset Mining Implementations (FIMI’04), 
volume 126 of CEUR Workshop Proceedings, Brighton, UK, 2004. 
[3]B.R'acz.nonordfp:An FP-growth variation without rebuilding the 
FPtree .In B.Goethals, M.J.Zaki,and R.Bayardo, editors, 
Proceedings ofthe IEEE ICDM Workshop on Frequent Itemset 
Mining Implementations (FIMI’04), volume 126 of CEUR 
Workshop Proceedings, Brighton, UK, 2004. 
[4]Adhikari A?Rao P R?A framework for synthesizing arbitrary 
Boolean expressions induced by frequent itemsets[C]?3rd Indian 
Intemat Conference on Artificial Intelligence?2007? 
[5] M.Kuramochi and G.Karypis.Frequent subgraph discovery. In 
Proceedings of the first IEEE International Conference on Data 
Mining, pages313–320, 2001. 
[6].M. Elhadef, K. Abrougui, S. Das, Nayak, A parallel Probabilistic 
system- level fault diagnosis approach for large multiprocessor 
systems, Processing Letters, 1(2006),63~79. 
[7]. Eberhart R C,Dobbins R W.Neural Network PC Tools:A Practical 
Guide[M].Academic Press,1990. 
[8].Wu X,Wu Y,Wang Y,et al.Privacy-aware market basket data set 
generation:A feasible approach for inverse frequent set 
mining[c].SIAM Internat Conference on Data Mining,2005. 
[9].Adhikari A,Rao P R.A framework for synthesizing arbitrary 
Boolean expressions induced by frequent itemsets[C].3rd Indian 
Internat Conference on Artificial Intelligence,2007. 
[10]A. Inokuchi,T.Washio,and H. Motoda.An apriori-based algorithm 
for mining frequent substructures from graph data.In Proceedings 
of the 4th European Conference on Principles of Data Mining and 
KnowledgeDiscovery, pages13–23. Springer-Verlag, 2000. 
 
