 
Figure 1.  A sample XML document with its tree 
XML Document Clustering Based on Common Tag Names Anywhere in the 
Structure 
 
 
 Mohamad Alishahi Mehdi Ravakhah Baharak Shakeriaski Mahmud Naghibzade 
 Islamic Azad Islamic Azad Islamic Azad Ferdowsi university  
 University Mashhad University Mashhad University Ramsar of Mashhad 
 Branch Branch Branch Computer Department 
 alishahi@ymail.com ravakhah@gmail.com emino.a@gmail.com naghibzade@um.ac.ir 
 
 
Abstract 
 
One of the most effective ways to extract knowledge 
from large information resources is applying data 
mining methods. Since the amount of information on 
the Internet is exploding, using XML documents is 
common as they have many advantages. Knowledge 
extraction from XML documents is a way to provide 
more utilizable results. XCLS is one of the most 
efficient algorithms for XML documents clustering. In 
this paper we represent a new algorithm for clustering 
XML documents. This algorithm is an improvement 
over XCLS algorithm which tries to obviate its 
problems. We implemented both algorithms and 
evaluated their clustering quality and running time on 
the same data sets. In both cases, it is shown that the 
performance of the new algorithm is better. 
Keywordsüdata mining, clustering, XML documents, 
level structure, level similarity 
1. Introduction 
 
Nowadays the World Wide Web is a huge platform 
of data and this data is created, stored and transferred 
incrementally. XML (eXtensible Markup Language) 
documents are one of the best tools for representing 
and transferring data because of their flexibility and 
self description, and many of the information resources 
use them. Since XML tags describe the structural and 
semantic concepts of information in texts, these 
documents are known to be semi-structured. This semi 
structure and irregularity causes problems for 
knowledge extraction from this kind of documents. So 
we need data mining techniques such as clustering, 
classification and association rules to extract 
knowledge. One of the most important advantages of 
data mining techniques is improving the speed and 
accuracy of the XML based search engines. We can 
refer to IEEE paper collection as an example and so 
searching a specific term in these papers has better 
results [1-4]. 
XML data exists in two forms: XML documents 
and XML schemas. XML schema defines structure 
while XML document defines data [5]. We can say that 
XML documents are instances of a XML schema and 
this schema includes acceptable elements, attributes, 
number of element occurrence and other constraints. 
We have to pay attention that among large number of 
XML documents only the ones that correspond to 
correct schemas are valid. There are many languages to 
describe the structure and content of these documents 
such as DTD (Document Type Definition) and XSD 
(XML Schema Definition). XSD has more capabilities 
than DTD [2]. Representing and modeling XML 
documents is one more subject to be considered. There 
are three methods for this act: tree structure, graph and 
time series. Among these, the tree structure is most 
common as XML documents have hierarchical 
organization defined by the provider and this 
organization more naturally corresponds to tree 
structure. Figure 1 shows an XML document and its 
corresponding tree structure. In this paper we focus on 
methods that use this structure. Section 2 is related 
works for XML clustering and in section 3 we briefly 
describe how XCLS algorithm that incrementally 
clusters XML documents works. In section 4 we 
978-1-4244-4262-1/09/$25.00 ©2009 IEEE
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
588
represent our algorithm and evaluate and compare it 
with XCLS in section 5. Section 6 is conclusion and 
future works. 
 
2. Related works 
 
Clustering XML data is more complicated than 
common text data as XML allows inserting structural 
and conceptual aspects into document content. A XML 
document includes tags and data. Tags describing 
names of elements contain concepts as text data. 
Besides document structure, tags also show the 
relationship between elements [1]. There are two types 
of algorithms for specifying XML documents 
similarities. First are structure-based algorithms and 
second are structure and content-based algorithms. In 
[4] there is a classification of the methods that have 
been used in XML document clustering so far. Current 
methods are usually implemented using models based 
on neural networks, vector, and similarity. The 
foundation of neural network based models is recursive 
neural networks and self organizing map. Vector based 
models use converting XML document format to 
vector and similarity based models define a similarity 
criterion between documents to cluster them [4]. Using 
similarity based model is more common because of its 
generality. So [2] demonstrates this model in two 
ways: structure level and element level. 
Similarity in structure level measures and describes 
three set of data: 
1- Structure and level similarity between 
documents 
2- Structural similarity between documents and 
schemas 
3- Structure and level similarity between 
schemas 
In similarity checking we study how similar is a 
document to other documents and schemas. But in 
element level we check the similarity between the 
elements of the two schemas. Element level uses XML 
document schemas for clustering. Generally the main 
difference between these two methods is that element 
level specifies the similarity between tree elements 
(particularly the similarity in the name structure) 
whereas structure level studies the similarity of the 
whole tree and ignores the elements details [2].  
In this paper we divide XML document clustering 
algorithms into two groups: 
• Pair wise methods 
• Incremental methods 
Pair wise based algorithms are more common which 
first create a similarity matrix for each pair of 
documents. This matrix is initialized by a criterion for 
measuring similarity between two documents. Finally 
after completing the matrix we can use a general 
clustering algorithm such as K-means to locate a 
document in its proper cluster. For incremental 
method, we specify the similarity to each existing 
cluster for each entering document and if the similarity 
is more than a threshold then it is placed in the 
corresponding cluster. Else a new cluster is created and 
the document is placed in it. Generally the main 
differences between pair wise and incremental 
algorithms are time complexity and application. In the 
best case, pair wise algorithms are from order of two 
but incremental algorithms work in linear time and are 
useful for online environments. In the next subsection 
we briefly introduce pair wise clustering algorithms 
and in next section we describe an incremental 
algorithm with details because our algorithm presented 
in this paper is an improvement for this algorithm. 
 
2.1. Pair wise algorithms for clustering XML 
documents 
 
It is common for pair wise algorithms to use tree 
edit distance to calculate the similarity between two 
XML documents. The problem is to calculate the 
minimum distance between two trees T1 and T2 while 
using insert, delete and edit operations for each node of 
the tree. We consider a cost for each of these 
operations that are computed depending on the node 
tags. So in order to specify the similarity between two 
XML documents, it suffices to calculate the minimum 
cost of converting T1 tree to T2 tree by a sequence of 
operations [2]. In other words, we calculate how many 
operations are required to convert T1 to T2. This cost 
is the similarity between T1 and T2.  
The technique we mentioned above is the basis for 
indicating the similarity between XML documents. But 
we must pay attention to the time complexity and high 
cost of this method when we have to cluster many 
XML documents as we must compute the distance 
between each pair of documents.  
In order to solve the problem above, many 
algorithms are designed that try to decrease the cost. 
Some of them are mentioned below: 
• In [7] a method is represented to summarize 
the XML tree. So by decreasing the number of 
repetition and nested elements and defining a 
new criterion for structural distance, a better 
performance is achieved.  
• In [8] using S-graph theory to represent XML 
documents and suggesting a new criterion for 
distance, an improvement on clustering is 
accomplished. The reason of this claim is 
encrypting S-graph to a bit string which is 
simple to be used in clustering. 
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
589
 
Figure 2.   A sample XML document with its level structure
 
3. XCLS incremental algorithm 
 
XCLS (XML Clustering by Level Structure) 
algorithm tries to cluster XML documents by 
considering their structures. Of course this algorithm 
represents XML structure in a new way called level 
structure. Level structure only uses the elements or tags 
of the XML document and ignores their contents and 
attributes. Using a global criterion for computing 
similarity is a considerable point in incremental 
methods. Comparing the entering document with 
existing clusters necessitates having a global criterion. 
This global criterion uses level structure. Level 
structure acquired from tree representation shows the 
existing nodes of each level [1].  
Figure 2 shows the level structure of a XML 
document. In level structure we re-label nodes to 
integers for ease. The formula (1) is used to specify the 
similarity between two objects (an object can either be 
a document or a cluster) and focuses on common nodes 
on each level of two objects.  
( ) ( )
( ) ZrN
rCNrCN
LevelSim
L
k
kLk
L
i
L
j
jLjiLi
×¹¸
·
©¨
§
×
××+××
=
¦
¦ ¦
?
=
??
?
=
?
=
????
>?
1
0
1
1
0
1
0
1
2
1
1
21
5.05.0
(1) 
 The parameters used in formula 1 are: 
• Z Size of the cluster, i.e., the number of 
documents within the cluster 
• 
iCN1  Sum of occurrences of every common 
element in the level i of the object 1  
• 
jCN2  Sum of occurrences of every common 
element in the level j of the object 2  
• Nk Number of elements in level k of the 
document 
• r Base Weight: the increasing factor of 
weight. This is usually larger than 1 to 
indicate that the higher level elements have 
more importance than the lower level 
elements. 
• L   Number of levels in the document  
 
In other words, the LevelSim mentioned in (1) is 
based on common nodes in different levels of objects. 
In next subsections we explain clustering by comparing 
objects according to level similarity. 
 
3.1. The steps of matching the elements of two 
objects 
 
1. Start with searching for common elements in the 
first level of both objects. If at least one common 
element is found, mark the number of common 
elements with the level number in object 1 ( 01CN ) and 
the number of common elements with the level number 
in object 2 ( 02CN ), then go to step 2. Otherwise, go to 
step 3.  
2. Move both objects to next level (level i++, level 
j++) and search for common elements in these new 
levels; if at least one common element is found, mark 
the number of common elements with the level number 
in object 1 ( iCN1 ) and the number of common 
elements with the level number in object 2 ( jCN2 ), 
then go to step 2. Otherwise, go to step 3.  
3. Only move object 2 to next level (level j ), then 
search for common elements in the original level (i) of 
object 1 and the new level ( j) of object 2. If at least 
one common element is found, mark the number of 
common elements with the level number in object 1 
( iCN1 ) and the number of common elements with the 
level number in object 2 ( jCN2 ), then go to step 2. 
Otherwise, go to step 3. 
4. Repeat the process until all levels in either object 
have been matched. 
We can calculate the similarity between two objects 
by above stages and then cluster accordingly. Figure 3 
shows an example for calculating the level similarity 
between two documents. The calculated measure by 
the given formula is always between zero and one. If 
there is no common element between two objects in the 
current level then it proceeds to the next level of the 
second object. So the level similarity LevelSim1?2 
differs from LevelSim2?1. We must calculate both 
cases and consider the greater value as the similarity 
between two objects. 
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
590
 
Figure 3.   An example for calculating the similarity
 
Figure 5.   An example for the problem of the XCLS 
algorithm 
 
Figure 4.   XCLS clustering algorithm 
3.2. Clustering by level similarity 
 
The general procedure for clustering is that the first 
document enters and forms the first cluster. The next 
document enters and the similarity between the two 
existing documents is computed. If the calculated 
number is greater than the user provided threshold then 
the entering document is placed in the existing cluster. 
Pay attention that in this case two documents with 
possibly different structures are located in the same 
cluster. So we should merge their structures to keep the 
algorithm incremental. To merge the documents we 
congregate the elements of the same levels into a new 
level structure called cluster level structure. In fact the 
level structure of a cluster is the representative of the 
existing documents in that cluster. But if the computed 
similarity is less than the user provided threshold then 
the entering document forms a new cluster. This 
procedure is repeated and for each entering document 
we compare it with existing clusters. If the maximum 
calculated similarity is greater than the user provided 
threshold then the document is placed in the most 
similar cluster, otherwise it forms a new cluster. 
Finally, this procedure is performed for the last 
document when the clustering task is finished. Two of 
the advantages of this algorithm are its linear time and 
its quality of clustering. But one of its disadvantages is 
specifying the threshold by user as different threshold 
may cause different results. Also the sequence of 
entering the documents is the other problem that may 
cause different clustering results. To obviate the latter 
problem a reassignment phase is used. In this phase 
some of the documents are selected randomly and are 
assigned to the clusters, again. This task is repeated 
until there is no improvement in placing documents in 
two consecutive iterations. Figure 4 shows the 
clustering algorithm [1] with the reassignment phase. 
 
4. XCLS+ 
 
As we studied the XCLS algorithm in more details 
we observed some problems that are XCLS's 
deficiency. Figure 5 shows an example for which the 
process of matching the elements of two objects by 
XCLS algorithm is unable to find all common elements 
of the two objects, consequently the real similarity 
cannot be obtained. In this example there are six 
elements in each object with five of them being 
common but the similarity that is calculated by XCLS 
is equal to zero. This is not reasonable. 
Thus in this paper we try to suggest a new algorithm 
named XCLS+ and this algorithm uses a new method 
for matching the common elements between two 
objects. As we described XCLS we see that XCLS 
orders the elements by level and in each level tries to 
find the common elements and fill the iCN1  and 
jCN2  
parameters, but in XCLS+ we try to order the elements 
by tag names and according to algorithm 1 in Figure 6 
we are able to find all common elements. 
Note that we store all the XML documents as data 
base tables and we can easily order them by tag name 
or level. Figure 7 is an example of a XML document 
that is stored by data base tables. By storing the tag 
names, their levels, and their parents we can easily 
retrieve the original documents. 
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
591
Algorithm 1   The steps of matching the elements of two objects in 
XCLS+ 
Input: 
O1,O2: Two Novel Level Structure represented as Table which 
Ordered by   TagName, Level 
OL1 : the number of rows of O1 in { OL11, OL12, …, OL1w } 
OL2 : the number of rows of O2 in { OL21, OL22, …, OL2z } 
 
Output: CN1[1..w] as number 
              CN2[1..z] as number 
 
Method: 
(1) Repeat 
(2) Compare each row i of O1 with each row j of O2  
(3) if (O1.TagName = O2.TagName) 
         {  
           CN1[OL1i] ++ ; 
           CN2[OL2j]++; 
           Go to the next rows of both object O1,O2; 
         } 
(4) if (O1.TagName > O2.TagName) 
         Go to the next row of just O2 
(5) else 
         Go to the next row of just O1 
(6) until all rows of both objects checked 
Figure 6.   The XCLS+ matching process algorithm 
 
Figure 7.   An XML document and its corresponding table 
 
Figure 8.  An example for the steps of XCLS+ algorithm 
The description of algorithm 1 is as follow: we 
order the tables by tag names then we try to find the 
common tag names disrespectful of levels of matched 
tags. For each pair of matched tags found, the iCN1  
and jCN2  parameters are computed by using the level 
attribute of the tags. Since we first find all possible 
matched tags and then consider the levels of the 
matched tags to compute iCN1  and
jCN2 , all possible 
pairs of equal tag names of the two objects are found. 
However, based on XCLS only matched tags of 
matched levels are found. Figure 8 shows the 
difference between XCLS and XCLS+. 
 
5. Experimental evaluations  
 
In order to show the improvement in XCLS+ we try 
to compare it with XCLS algorithm under similar 
circumstances. All the experiments for both algorithms 
are done on the same data sets which are consisting of 
heterogeneous XML documents. These data sets are 
standard and are usually used for XML clustering 
algorithm’s evaluation. We compare both algorithms 
from the aspects of quality of clustering and running 
time.  
Both XCLS and XCLS+ algorithms and also the 
evaluation criteria were implemented with Microsoft 
visual studio 2008 platform using C# language and all 
documents of data sets were stored as tables in a 
Microsoft SQL server 2005 data base. All the 
experiments were done in a machine with 3.2GHZ 
Intel Celeron CPU and 1GB of RAM. In the next two 
subsections we describe the data sets and the 
evaluation criteria which measure the quality of 
clustering and finally the results will be discussed. 
 
5.1. Data set 
 
The data used in experiments are (1) the XML Files 
data set obtained from [9, 10]; and (2) the MovieDB 
corpus obtained from [11]. The XML files data set 
contains 460 XML documents. The documents are 
from various domains which are shown in table 1. The 
number of tags varies from 10 to 100 in these sources. 
The nesting level varies from 2 to 15. Majority of these 
domains contains a number of different documents that 
have structural and semantic differences. Hence, even 
though documents are from the same domain, they 
might not be considered similar enough to be grouped 
into the same clusters. The MovieDB corpus has 11 
thematic and 11 possible structure classes. The 
MovieDB collection is derived into many versions (m-
db-s-0, m-db-s-1 and m-db-s-2) after a series of 
transformation for adding the complexity in the 
clustering process making each later version more 
difficult than former. Each movie set contains 4800 
XML files. The MovieDB corpuses have 190–200 
distinct tags [1]. 
 
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
592
5.2. Evaluation Criteria 
 
The evaluation criteria for XML documents 
clustering are categorized in two groups: the first one is 
internal cluster quality evaluation criteria and the 
second one is external cluster evaluation criteria. 
Internal evaluation criteria have no information about 
the data sets and try to determine how similar the 
documents are. But here, the problem is that in XCLS 
the similarity between documents is measured by 
comparing corresponding levels while in XCLS+ a 
new similarity algorithm is suggested. So, as we used 
two different similarity measures it is not reasonable to 
compare these two algorithms based on internal 
evaluation criteria. Consequently, in this article we use 
the external evaluation criteria which are based on the 
comparison of clusters’ classes to known external 
classes. Entropy, purity, and FScore are used as 
external evaluation criteria in this article, which are 
taken from [1, 12], described as follow. 
The entropy measure looks at how the various 
classes of documents are distributed within each 
cluster. Given a particular cluster Ci of size ni, the 
entropy of a cluster is defined as: 
¦
=
=
k
r i
r
i
i
r
i
i n
n
n
n
k
CE
1
log
log
1)(
 
 Where k is the number of classes in the dataset, and 
r
in   is the number of documents of the rth class that 
are assigned to the ith cluster. The entire clustering 
solution’s entropy is the sum of the individual cluster 
entropies weighted according to the cluster size. The 
formula is given here: 
¦
=
=
k
i i
i CE
N
nEntropy
1
)(
 
A perfect clustering solution will be the one that 
leads to clusters that contain documents from only a 
single class, in which case the entropy will be zero. In 
general, smaller the entropy value, the better the 
clustering solution is. 
Purity measures the extent to which each cluster 
contains documents primarily from one class. The 
formula of purity of a cluster is: 
)max(1)( ri
i
i nn
CP =
 
The purity of entire clustering solution is obtained 
as a weighted sum of the individual cluster purity: 
¦
=
=
k
i i
i CP
N
nPurity
1
)(
 
In general, larger the value of purity, the better the 
clustering solution is. 
FScore is a combination of precision and recall. 
Precision defines the rate of correct matches in the 
generated solution, and Recall defines the rate of 
correct matches in the model solution. 
Given an XML document category Zr with the nr 
number of similar XML documents, and a cluster Ci 
with the ni number of similar XML documents 
categorized by the clustering algorithm. Let rin  be the 
number of documents in cluster Ci belonging to Zr. 
Precision (correctness) is defined as: p(Zr ,Ci ) = 
r
in /ni 
Recall (accuracy) is defined as: r (Zr ,Ci ) = rin /nr . 
The FScore combining precision and recall with 
equal weights is defined as: 
ri
r
i
irir
irir
ir nn
n
CZrCZp
CZrCZpCZF
+
=
+
×
=
2
),(),(
),(),(),(
 
Table1. Data set of various domains with amount of 460 XML 
files. 
No. Class
74 Movie
22 University
207 Automobile
16 Bibliography
38 Company
24 Hospitality message
10 Travel
10 Order
4 Auction
2 Appointment
15 Document page
2 Bookstore
20 Play
12 Club
2 Medical
2 Nutrition
 
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
593
 
Figure 9.  Comparing running time of XCLS and XCLS+ 
The FScore value of a category Zr is the maximum 
FScore value attained in any cluster of the clustering 
solution. Hence, the FScore of the overall clustering 
solution is defined as the sum of the individual class 
FScores weighted differently according to the number 
of documents in the class: 
N
CZFn
FScore
k
r irr¦ =
=
1
),(
 
where k is the number of clusters. A good clustering 
solution has the FScore value close to one. 
 
5.3. Quality evaluation 
 
Table 2 shows all the experiments and assessments 
about the quality of clustering. As shown in table, we 
tried to compare the algorithms under different 
circumstances and each time we run the algorithms 
with different parameters and record the results. The 
results declare that XCLS+ clusters the documents 
with better quality. 
 
5.4. Running Time Evaluation 
 
The time complexity for both algorithms XCLS and 
XCLS+ is equal because the basis of both algorithms is 
equal and the difference is the way they use to find the 
common elements between two documents. Thus as 
the XCLS algorithm assert time complexity is linear 
but the running time is different because as explained 
previously XCLS+ algorithm is able to find all 
common elements just by one iteration but XCLS 
needs two iterations. According to recent explanation 
our algorithm must have better running time than the 
XCLS. After calculating the running time for one of 
our data sets Figure 9 proves our claim. 
 
6. Conclusion and future works 
 
We presented an algorithm for clustering XML 
documents based on the XCLS algorithm. We 
compared our algorithm with the XCLS algorithm and 
perceived that it works better than XCLS or in the 
worst case it performs like XCLS. Although this 
Table2. The experiments and assessments about the quality of clustering. 
Data set Algorithm r factor Threshold Entropy Purity FScore Cluster No.
XML Files 
XCLS 
2 0.75 0.06 0.86 0.88 21
2 0.6 0.07 0.83 0.84 21
1.5 0.75 0.08 0.85 0.86 21
XCLS+ 
2 0.75 0.04 0.94 0.96 22
2 0.6 0.04 0.93 0.94 22
1.5 0.75 0.05 0.91 0.92 22
m-db-s-0 
XCLS 
2 0.75 0.21 0.73 0.75 11
2 0.6 0.20 0.73 0.73 11
1.5 0.75 0.20 0.72 0.73 11
XCLS+ 
2 0.75 0.18 0.79 0.80 11
2 0.6 0.17 0.78 0.79 11
1.5 0.75 0.18 0.75 0.78 11
m-db-s-1 
XCLS 
2 0.75 0.26 0.69 0.71 11
2 0.6 0.24 0.68 0.70 11
1.5 0.75 0.26 0.68 0.69 11
XCLS+ 
2 0.75 0.17 0.72 0.72 11
2 0.6 0.17 0.71 0.71 11
1.5 0.75 0.18 0.72 0.71 11
m-db-s-2 
XCLS 
2 0.75 0.31 0.66 0.67 11
2 0.6 0.30 0.66 0.68 11
1.5 0.75 0.32 0.65 0.66 11
XCLS+ 
2 0.75 0.28 0.69 0.71 11
2 0.6 0.27 0.68 0.70 11
1.5 0.75 0.28 0.69 0.71 11
 
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
594
algorithm solves some of the problems of the XCLS 
algorithm but one of its remained problem is 
specifying the threshold that may affect its 
performance remarkably. Future works for this paper 
can be: specifying the threshold by the algorithm 
automatically, considering the concepts of elements for 
clustering, designing a two phases algorithm for 
clustering as in one phase using pair wise algorithms 
and in another using incremental algorithms. Finally, 
as the role of XML documents becomes more 
important, we hope our algorithm would be useful for 
clustering XML documents especially in search 
engines that search huge resources of the World Wide 
Web. 
 
7. References 
 
[1] R. Nayak, "Fast and effective clustering of XML data 
using structural information", Knowl. Inf. Syst. 14(2), 2008, 
pp. 197-215. 
 
[2] R. Nayak, "XML Data Mining: Process and 
Applications", in Song, Min and Wu, Yi-Fang, Eds, Idea 
Group Inc. /IGI Global, 2008. 
 
[3] R. Nayak, T. Tran, "A Progressive Clustering Algorithm 
to Group the XML Data by Structural and Semantic 
Similarity", IJPRAI 21(4), 2007, pp. 723-743. 
 
[4] L. Denoyer, P. Gallinari, "Report on the XML mining 
track at INEX 2005 and INEX 2006: categorization and 
clustering of XML documents", SIGIR Forum 41(1), 2007, 
pp. 79-90. 
 
[5] S. Abiteboul, P. Buneman and D. Suciu, "Data on the 
Web: From Relations to Semistructured Data and XML", 
Morgan Kaumann, CA, 2000. 
 
[6] S. Flesca, G. Manco, E. Masciari, L. Pontieri and A. 
Pugliese, "Fast detection of XML structural similarities", 
IEEE Trans. Knowl. Data Engin. 7(2), 2005, pp. 160–175. 
 
[7] T. Dalamagas, T. Cheng, K. Winkel, T. K. Sellis, "A 
methodology for clustering XML documents by structure", 
Inf. Syst. 31(3), 2006, pp. 187-228. 
 
[8] W. Lian, D. W. Cheung, N. Mamoulis, S. Yiu, "An 
Efficient and Scalable Algorithm for Clustering XML 
Documents by Structure", IEEE Trans. Knowl. Data Eng. 
16(1), 2004, pp. 82-96. 
 
[9] The Wisconisn’s XML data bank. Accessed from: 
http://www.cs.wisc.edu/hiagara/data.html. Cited sept 2004. 
The XML data repository. Accessed from: 
http://www.cs.washington.edu/research/xmldatasets/. Cited 
Sept 2004. 
 
[10] INEX (2005) Document mining track. Accessed from: 
http://inex.is.informatik.uni-duisburg.de/2005. 
 
[11] Y. Zhao, G. Karypis, "Criterion functions for document 
clustering: Experiments and analysis", Department of 
Computer Science, University of Minnesota, Minneapolis, 
2001. 
Proceedings of the 14th International CSI Computer Conference (CSICC'09)
595
