VIDEO SEMANTIC CONCEPT DETECTION VIA ASSOCIATIVE CLASSIFICATION
Lin Lin, Mei-Ling Shyu, Guy Ravitz
Department of Electrical and
Computer Engineering
University of Miami
Coral Gables, FL 33124, USA
l.lin2@umiami.edu, {shyu,ravitz}@miami.edu
Shu-Ching Chen
School of Computing and
Information Sciences
Florida International University
Miami, FL 33199, USA
chens@cs.fiu.edu
ABSTRACT
Associative classification (AC) has been studied in the areas of
content-based multimedia retrieval and semantic concept de-
tection due to its high accuracy. The traditional AC algorithm
discovers the association rules with the frequency count (min-
imum support) and ranking threshold (minimum confidence)
while restricted to the concepts (class labels). In this paper,
we propose a novel framework with a new associative clas-
sification algorithm which generates the classification rules
based on the correlation between different feature-value pairs
and the concept classes by using Multiple Correspondence
Analysis (MCA). Experimenting with the high-level features
and benchmark data sets from TRECVID, our proposed algo-
rithm achieves promising performance and outperforms three
well-known classifiers which are commonly used for perfor-
mance comparison in the TRECVID community.
Index Terms— Associative Classification, Multiple Cor-
respondence Analysis, Concept Detection.
1. INTRODUCTION
The ability to automatically detect high-level semantic con-
cepts from multimedia databases and to narrow the gap be-
tween such concepts and the low-level features has been in-
vestigated by many researchers. The motivations to extract
objects, concepts, or events from images and videos lie in the
fact that it could immensely improve the performance of ap-
plications such as search engines, video/audio recommenders,
and video summarizers.
Classification using Association Rule Mining [1] takes
advantages of its high accuracy and ability to handle large
databases [2]. However, this comes with some challenges [3]
such as rule ranking and rule overlapping. One new technique
for concept detection, called Association Rule Classification
(ARC) or Associative Classification (AC), has been utilized in
content-based multimedia retrieval and concept/event detec-
tion in recent years. In [4], an image classification approach
was presented by using multiple-level association rules based
on objects in the images. In our previous work [5], we
proposed a framework that discovered three semantic con-
cepts from news TV broadcast using traditional associative
classification. Initially, low-level audio-visual features were
extracted from the broadcast. Following that, pure positive
and pure negative association rules were generated for each
concept. Finally, a classifier with a different classification
rule ranking strategy was developed for each concept.
One of the first associative classification algorithms in-
troduced in the literature was Classification Based on Asso-
ciations (CBA) [6]. It generated the association rules with
certain support and confidence values based on the Apriori
algorithm. Since then, three main research aspects for asso-
ciative classification have emerged. One is to improve the
support and confidence measurements themselves [7][8]. An-
other one is to use other evaluation criteria such as lift, cov-
erage, leverage, and conviction [1]. The last one is to use an
integrated algorithm to generate association rules. For exam-
ple, in [9], the Classification based on Predictive Association
Rules (CPAR) combined the advantages of both associative
classification (with high accuracy) and traditional rule-based
classifiers named First Order Inductive Learner (FOIL) with
less computational cost. CPAR adopted a greedy algorithm
to generate more rules directly from the training data, used
an expected accuracy to evaluate each rule, and the best k-
rules were used in prediction. In our previous study [10], we
have utilized the Multiple Correspondence Analysis (MCA)
methodology as the rule generation mechanism in associative
classification. MCA is an extension of standard correspon-
dence analysis to more than two variables [11]. Considering a
multimedia database, the columns represent the features and
classes, and the rows represent the instances. Using MCA,
the correspondence between the features and classes could
be captured. Although the classification rules were based on
only 1-feature-value pairs in [10], the approach was able to
help the classifiers to detect more positive instances in the
testing data set without misclassifying too many negative in-
stances of the investigated concepts, especially for the imbal-
anced data sets.
418978-1-4244-4291-1/09/$25.00 ©2009 IEEE ICME 2009
In this paper, we propose a novel framework which ex-
tends MCA to identify the correlation between 2-feature-
value pairs and concepts, and use both 1-feature-value pair
rules and 2-feature-value pair rules as the rule set for asso-
ciative classification. By using those rules captured by MCA,
we perform classification (concept detection). To evaluate
our proposed framework, we used the concepts and data from
TRECVID 2007 and 2008 [12], and compared the perfor-
mance of our proposed framework to that of the well-known
decision tree classifier (DT), support vector machine classi-
fier (SVM), and traditional association rule classifier (ARC).
The reasons we compared with these three classifiers are
(i) DT is the traditional rule-based classifier and the most
frequently used one in event/concept detection; (ii) SVM is
the most popular classifier for comparison using TRECVID
datasets; and (iii) ARC is our initial motivation of improving
associative classification. Overall, our proposed framework
performs 10% or higher on accuracy evaluation (F1-score)
than the three compared classifiers for nine concepts.
This paper is organized as follows. In Section 2, the
proposed framework and detailed discussions on its different
components are presented. Section 3 discusses our experi-
ments as well as our observations. This paper is concluded in
Section 4.
2. THE PROPOSED VIDEO SEMANTIC CONCEPT
DISCOVERY FRAMEWORK
We propose a novel video semantic concept detection frame-
work with the following steps. First, a set of 28 low-level
audiovisual features is extracted from the video data and nor-
malized. Second, the data is split into training and testing
data sets and discretized to generate the association rules.
Next, the feature-value pairs from the discretization stage are
evaluated and MCA is utilized to get the correlation between
feature-value pairs and classes. Finally, classification using
the generated rules measured by the correlation is performed.
2.1. Framework Architecture
Our proposed framework is shown in Figure 1. After extract-
ing the audio-visual features (numerical features), each fea-
ture is normalized for each video. Next, the whole data set is
split into the training data set (two thirds of the data) and the
testing data set (one third of the data). In order to implement a
3-fold cross-validation experiment, the positive instances (in-
stances with the target concept label) and negative instances
(instances with non-concept labels) are split into three equal
parts separately. Two parts of the positive instances and two
parts of the negative instances are used as the training set, and
the remaining part of the positive instances and the remaining
part of the negative instances are used for testing. By doing
this, we could ensure that each instance in the data set would
be tested at least once.
Due to the facts that associative classification requires the
input data to be nominal and all our features are numerical,
the features need to be discretized in the next stage. First, the
training data was discretized and then the same partitions are
used for discretizing the testing data. Next, MCA is applied to
calculate the angle between each candidate feature-value pair
and each class for the training data. Those 1-feature-value
pairs whose corresponding angles are smaller than the first
threshold value will be kept. Those selected 1-feature-value
pairs are then used to generate the candidate 2-feature-value
pairs by pairing every two 1-feature-value pairs that are from
different numerical features. These candidate 2-feature-value
pairs will apply MCA and those whose corresponding angles
are smaller than the second threshold value would be kept.
Both threshold values are determined by using the training
data. Finally, classification is performed using the associative
rules generated by the selected 1-feature-value and 2-feature-
value pairs.
Fig. 1. The proposed framework.
2.2. Associative Classification
An association rule is a relation among items (feature-value
pairs in this study) [1]. Let D be a multimedia database con-
sisting of N instances/rows (Dn where n=1 to N ), F be a
feature set consisting of M numerical features (Am where
m=1 to M ), and C be a class set consisting of J discrete
classes/concepts (Cj where j=1 to J). The data instances in
D are characterized byM+1 low-level features/columns (i.e.,
M numerical values and 1 nominal class label Cj).
After discretization which converts each numerical fea-
419
ture into discrete bins, each feature Am has Km nominal
feature-value pairs (Aim where i=1 toKm), and the total num-
ber of feature-value pairs (i.e., the sum of all Km) is equal
to K. Then each Dn can be described as the feature-value
pairs Aim and the class Cj . For instance, A17 is the fea-
ture of the pixel changes, which is converted to 3 bins (i.e.,
K17 = 3), and A117, A217, and A317 represent the feature value
ranges [0, 0.32865], (0.32865, 0.5044], and (0.5044, 1], re-
spectively. Applying some pruning strategy, only a subset
of the 1-feature-value pairs will be kept and each 1-feature-
value pair forms an associative classification rule denoted as
Aim ? Cj . Unlike the traditional AC that the itemsets and
rules are pruned based on the frequency count (support) and
accuracy (confidence) respectively, our MCA-based associa-
tive rules are generated based on some measure of the corre-
spondence (to be discussed next).
2.3. Multiple Correspondence Analysis (MCA)
Multimedia data is projected into a new space using the first
and second principle components [10]. The pseudo-code for
generating the 1-feature-value pair rules is presented as fol-
lows, where J is the total number of classes, K is the total
number of 1-feature-value pairs, and R is the final rule set.
1-FEATURE-VALUE PAIR RULE GENERATION
1 R ? ?;
2 for j ? 1 to J
3 for k ? 1 toK
4 anglek = cos?1
<pairk,classj>
||pairk||?||classj ||) ;
5 if anglek < threshold1
6 then R ? R ? {pairk ? classj}.
In our proposed framework, the inner product of the
feature-value pairs and classes are used to represent the sim-
ilarity, and the angle between the feature-value pairs and
classes is used as a measurement [10]. In addition, the
feature-value pairs whose corresponding angle values were
smaller than the angle threshold were selected for classifi-
cation rules. In this paper, a different method is developed
to determine the threshold for angles. Rather than comput-
ing the average angle values in certain ranges, we evaluate
the rules by applying different thresholds to the training set
and determine the threshold1 value which yields the highest
accuracy.
After 1-feature-value pairs are generated, 2-feature-value
pairs are generated by pairing the 1-feature-value pairs.
However, unlike the traditional AC, the pairing depends
on whether both of the 1-feature-value pair rules have been
generated for the same class. The pseudo-code for generat-
ing a 2-feature-value pair rule is as follows. Here, J is the
total number of classes and Sj is the total number of selected
1-feature-value pairs for class Cj . The value of threshold2 is
determined similar to threshold1 based on the training set.
2-FEATURE-VALUE PAIR RULE GENERATION
1 for j ? 1 to J
2 for s? 1 to Sj ? 1
3 for t? s + 1 to Sj
4 if pairs and pairt do not belong to
the same feature then
5 anglest = cos?1 <{pairs,pairt},classj>||{pairs,pairt}||?||classj ||) ;
6 if anglest < threshold2 then
7 R ? R ? {pairs ? pairt ? classj}.
3. EXPERIMENTS AND RESULTS
Our proposed framework is evaluated with the sampled
TRECVID 2007 and 2008 videos. We use all the positive
instances in our database, and randomly choose the neg-
ative instances. The concepts used include hand, urban,
crowd, person, two-people, outdoor, building, vegetation,
and road, whose descriptions could be found in [12]. The
reason we selected these concepts only because there are
sufficient amounts of instances to build useful training and
testing sets in our database. The precision, recall, and F1-
score metrics are used under the 3-fold cross validation ap-
proach as explained earlier. To show the efficiency of our
proposed framework, its performance is compared to the De-
cision Tree classifier (DT), Support Vector Machine classifier
(SVM), and Association Rule Classification (ARC) available
in WEKA [1]. Note that we use the default values for param-
eters of three classifiers WEKA has provided. The average
precision (Pre), recall (Rec), and F1-score (F1) values ob-
tained over the three folds are presented in Tables 1 and 2,
where columns 2 to 4 provide the performance of WEKA’s
DT, SVM, and ARC, respectively, and the last column pro-
vides the performance of our proposed framework.
Hand DT SVM ARC MCA
Pre 0.33 0.46 0.28 0.40
Rec 0.06 0.31 0.20 0.80
F1 0.10 0.37 0.24 0.53
Urban DT SVM ARC MCA
Pre 0.53 0.51 0.49 0.45
Rec 0.25 0.41 0.41 0.76
F1 0.34 0.46 0.43 0.57
Crowd DT SVM ARC MCA
Pre 0.78 0.54 0.40 0.41
Rec 0.03 0.32 0.41 0.83
F1 0.06 0.40 0.39 0.55
Person DT SVM ARC MCA
Pre 0.61 0.54 0.49 0.45
Rec 0.32 0.39 0.32 0.71
F1 0.42 0.45 0.39 0.55
Table 1. Performance evaluation for four concepts
420
Two people DT SVM ARC MCA
Pre 0.00 0.51 0.14 0.37
Rec 0.00 0.19 0.09 0.86
F1 0.00 0.27 0.11 0.51
Outdoor DT SVM ARC MCA
Pre 0.59 0.59 0.42 0.47
Rec 0.37 0.39 0.60 0.73
F1 0.46 0.47 0.47 0.57
Building DT SVM ARC MCA
Pre 0.55 0.57 0.45 0.43
Rec 0.27 0.34 0.34 0.83
F1 0.36 0.42 0.38 0.57
Vegetation DT SVM ARC MCA
Pre 0.54 0.51 0.48 0.41
Rec 0.14 0.35 0.35 0.81
F1 0.21 0.42 0.41 0.54
Road DT SVM ARC MCA
Pre 0.59 0.58 0.49 0.43
Rec 0.35 0.34 0.48 0.87
F1 0.44 0.42 0.47 0.58
Table 2. Performance evaluation for five concepts
As can be seen from both tables, our proposed concept
detection framework achieves promising results compared to
DT, SVM, and ARC. In fact, our recall values outperform the
other three classifiers, and our F1-scores can achieve at least
10% higher than the ones obtained by the other three classi-
fiers. This demonstrates that the proposed novel associative
classification algorithm with MCA is effective in video con-
cept detection.
4. CONCLUSIONS
In this paper, a novel associative classification algorithm us-
ing MCA for video concept detection is proposed. MCA is
utilized to measure the correlation between different feature-
value pairs and classes to infer the high-level concepts from
the extracted low-level features. Nine concepts from the
TRECVID 2007 and 2008 data are used to validate our pro-
posed framework. The experimental results demonstrate that
our proposed framework achieves promising concept detec-
tion results. Furthermore, we are able to show an increased
overall performance over some well-known classifiers.
5. REFERENCES
[1] I. H. Witten and E. Frank, Data Mining: Practical Ma-
chine Learning Tools and Techniques, Morgan Kauf-
mann, second edition, June 2005.
[2] I. Bouzouitz and S. Elloumi, “Integrated generic associ-
ation rule based classifier,” in IEEE International Con-
ference on Database and Expert Systems Applications
(DEXA07), September 2007, pp. 514–518.
[3] F. Thabtah, “Challenges and interesting research di-
rections in associative classification,” in IEEE In-
ternational Conference on Data Mining Workshops
(ICDMW06), December 2006, pp. 785–792.
[4] V. S. Tseng, M.-H. Wang, and J.-H. Su, “A new method
for image classification by using multilevel association
rules,” in IEEE International Conference on Data Engi-
neering (ICDE05), April 2005, pp. 1180–1188.
[5] L. Lin, G. Ravitz, M.-L. Shyu, and S.-C. Chen, “Video
semantic concept discovery using multimodal-based as-
sociation classification,” in IEEE International Confer-
ence on Multimedia and Expo (ICME07), July 2007, pp.
859–862.
[6] B. Liu, W. Hsu, and Y. Ma, “Integraing classifica-
tion and association rule mining,” in International
Conference on Knowledge Discovery and Data Mining
(KDD98), August 1998, pp. 80–86.
[7] C. S. Kanimozhih Selvi and A. Tamilarasi, “Association
rule mining with dynamic adaptive support thresholds
for associative classification,” in IEEE International
Conference on Computational Intelligence and Multi-
media Applications (ICCIMA07), December 2007, pp.
76–80.
[8] P. Vateekul and M.-L. Shyu, “A conflict-based confi-
dence measure for associative classification,” in IEEE
International Conference on Information Reuse and In-
tegration (IRI08), July 2008, pp. 256–261.
[9] X. Yin and J. Han, “CPAR: Classification based on pre-
dictive association rules,” in SIAM International Con-
ference on Data Mining (SDM03), May 2003, pp. 369–
376.
[10] L. Lin, G. Ravitz, M.-L. Shyu, and S.-C. Chen,
“Correlation-based video semantic concept detection
using multiple correspondence analysis,” in IEEE Inter-
national Symposium on Multimedia (ISM08), December
2008, pp. 316–321.
[11] N. J. Salkind, Ed., Encyclopedia of Measurement and
Statistics, Thousand Oaks, CA: Sage Publications, Inc,
2007.
[12] A. F. Smeaton, P. Over, andW. Kraaij, “Evaluation cam-
paigns and TRECVid,” in ACM International Workshop
on Multimedia Information Retrieval (MIR06), October
2006, pp. 321–330.
421
