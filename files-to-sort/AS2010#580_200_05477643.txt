On Developing an Effectual Progressive Sampling-Based Approach for Association 
Rule Discovery
  
V.Umarani 
Sri Ramakrishna College of Arts &Science for Women  
Coimbatore, India. 
v_umarani@yahoo.com                                                          
 
 
M.Punithavalli 
Director and Head, Department of Computer Science 
Sri Ramakrishna College of Arts &Science for Women 
Coimbatore, India 
                     mpunitha_srcw@yahoo.co.in 
Abstract— Association rule discovery from large databases is 
one of the most challenging tasks in data mining. The process 
of frequent itemset mining, the first step in the mining of 
association rules, is a computational and I/O intensive process 
necessitating repeated passes over the entire database. 
Sampling has often been suggested as an effectual tool to 
reduce the size of the dataset operated at some cost to 
accuracy. Data mining literature presents with numerous 
sampling based approaches to speed up the process of 
Association Rule Mining (ARM). In our earlier research [29], 
we presented a proficient progressive sampling-based 
approach for mining association rules from massive databases. 
In this article, we validate our earlier approach with different 
empirical variations and also present an analysis on the 
validations using synthetic datasets. The approach starts with 
an initial sample selection process based on the temporal 
characteristics and size of the database. Subsequently, the 
frequent itemsets and the negative border are mined from the 
initial sample using Apriori algorithm. The patterns in the 
negative border are then sorted based on their support and the 
midpoint itemset in the sorted negative border is scanned in 
different variations (sizes) of the database to check its 
frequency. If the support of the midpoint itemset is greater 
than the support threshold, the sample size is progressively 
increased to a larger size. The aforesaid process is repeated 
until an optimal sample size is met and then association rules 
are mined from the optimal sample determined. The empirical 
validation also results the appropriate database size for 
conducting the midpoint itemset scan.  
Keywords- Data mining; Frequent Patterns; Association 
Rule Mining (ARM); Sampling; Progressive sampling; 
Temporal characteristics; Apriori; Negative border; Midpoint 
itemset.  
I. INTRODUCTION   
Data Mining is an area of contemporary research and 
development in Computer Science. Of late, data mining has 
emerged as a field of extensive research from a wide range 
of diverse groups of people. Formally, data mining is 
defined as "The non-trivial extraction of inherent, previously 
unknown, and potentially valuable information from data" [2, 
3, 4]. Commonly, data mining includes an assortment of 
algorithms: Clustering, Classification, ARM [15] and more. 
Of all data mining tasks [22], ARM is considered as the 
most significant and well researched data mining techniques. 
Ever since its introduction by Agrawal et al. [14] in 1993, 
the task of ARM has received an immense deal of attention. 
ARM techniques are being extensively applied in marketing 
and retail communities besides many other diverse fields [20] 
ARM algorithms aim at extracting interesting 
correlations, frequent patterns, associations or casual 
structures that satisfy a predefined minimum support and 
confidence, among items present in transaction databases or 
other data repositories [6]. The association rules illustrate a 
relational association between selected attributes in the 
database [5]. An association rule will be of the form YX  , 
that means for every instance of X  that is true, Y  is also true, 
where X  and Y  are itemsets in the transaction databases. 
Generally, the significance of an association rule is defined 
by two indicators, support and confidence. 
Starting from Agrawal’s [14], a number of researchers 
have made significant contributions to improve association 
rule mining. Some noteworthy accomplishments in the field 
of ARM include, approaches that improve the effectiveness 
of computing the frequent patterns from massive datasets 
[21, 24], approaches that apply constraints to identify 
interesting patterns [24,25,26], and approaches that purges 
irrelevant association rules by making use of some 
interestingness measures [23]. The ARM process generally 
consists of two steps:  
 Frequent itemset generation and  
 Discovery of association rules using the frequent 
itemsets [17].  
The first step of ARM, frequent itemset mining, has been 
shown to dictate the computational and I/O requirements 
requiring repeated passes over the whole database [17]. In 
spite of the numerous algorithms available for ARM, Apriori 
has been the most renowned and widely used owing to its 
effectiveness in knowledge discovery [21]. But, the Apriori 
algorithm itself suffers from two bottlenecks,  
 Complex frequent itemset generation that requires 
intensive time, space and memory requirements and  
 Multiple scans of the database [5].  
Executing traditional ARM algorithms on massive real-
time databases can take hours or even days, and in the years 
to come, the problem would only turn out to be even worse. 
Lately, researchers have attempted to devise proficient 
approaches that minimize the I/O and computational 
requirements of the ARM techniques. Among the various 
research efforts undertaken to improve the effectiveness of 
ARM, sampling has proved to be capable of minimizing the 
_____________________________________ 
978-1-4244-5265-1/10/$26.00 ©2010 IEEE
I/O traffic involved in such data-intensive applications [8]. 
Sampling in ARM can be defined as the process of reducing 
the volume of the data to be analyzed [1, 9, 10]. Sampling is 
a popular data reduction technique that has been effectively 
applied to a variety of data mining algorithms so as to 
reduce intensive computational overhead incurred. Sampling 
speeds up the ARM process by more than an order of 
magnitude via reducing the I/O costs and radically shrinking 
the number of transactions to be considered [10]. Generally, 
the validity of a sample is determined by two significant 
characteristics namely,  
 Sample size and  
 Quality of the sample.  
In the context of statistical sampling techniques, the term 
quality refers to appropriateness of the sample to capture the 
definite characteristics of the original database [18].  
In the "standard" association-rule mining perspective, the 
mining studies that were formerly infeasible due to the 
enormous time requirements were achievable by the use of 
sampling. Sampling facilitates rapid discovery of 
preliminary association rules that would help the user in 
directing the data mining process by refining the criterion 
for “interesting” rules [8] ,[17]. Especially, when the data to 
be processed instigates as a stream flowing at a faster rate, 
the only possible choice is sampling [27]. In addition to the 
primary advantages of sampling, considering factors like 
transaction length and transaction frequency [13] in sample 
selection can appreciably improve the quality of the sample 
chosen for ARM.  
Suppose if the rules mined from a sample were 
unsatisfactory, the sample size is increased in most general 
cases and the mining process is repeated again. The process 
of increasing the size of the sample continues as an iterative 
procedure until interesting rules are found [7].The chief 
limiting factor in devising sampling-based algorithms stems 
from the fact that the support of an itemset in a sample 
usually deviates from the support in the whole database. 
These luck-of-the draw fluctuations can either leave out 
itemsets that were frequent in the database but not in the 
sample and false itemsets that are frequent in the sample but 
not in the database [8].  Considering the above scenario, it 
becomes obvious that a fitting sample size is the chief factor 
influencing the success of the sampling technique [11]. In 
order to determine the optimal sample size speedily, 
researchers have recently turned to progressive sampling. 
Progressive sampling aims at starting with a smaller sample 
and then increasing it progressively given that model 
accuracy improves considerably [1].  
 As with the other ARM algorithms, progressive 
sampling for association rule mining also suffers 
from two problems.  
 The model accuracy of each sample size can be 
measured either by executing ARM algorithms on 
the samples [1] or on the complete database [12], 
which is, nevertheless, very costly. 
 To meet efficiency considerations, previous 
algorithms usually determine the model accuracy of 
a sample size by executing association rules only on 
a sample with this size, and thereby neglecting the 
phenomenon of randomness [28] that is to be 
considered for sample selection [11].  
We have employed progressive sampling in the proposed 
approach to decide on an optimal sample size for achieve 
desirable number and quality association rules. A number of 
researches have been proposed for ARM based on sampling 
and progressive sampling [1, 10-13, 19]. The motivation 
behind this research is that, incorporating the temporal 
characteristics of data and progressing sampling based on 
negative border for sample selection will end up with better 
results.  
In our earlier research [29], we presented an efficient 
progressive sampling-based approach for effectual discovery 
of association rules from large databases. In this article, we 
perform an extensive validation of our former approach with 
different empirical variations and also present an analysis on 
the validations using synthetic datasets. The approach 
discovers an optimal sample size that will result in all 
possible association rules that hold in the actual database. 
First of all, an initial sample of certain size is selected 
relevant to the actual size of the database. The individual 
transactions in the sample are chosen by considering the 
temporal characteristics of the data items in the database. 
Then, a renowned association rule mining algorithm, Apriori, 
is applied to the initial sample to determine the frequent 
itemsets with the aid of a minimum support level. Based on 
the frequent itemsets generated, we calculate the negative 
border of the initial sample. Then, the calculated negative 
border is sorted based on their support levels. The itemset 
corresponding to the midpoint of the sorted negative border 
is scanned in different variations of the concrete database to 
check if it satisfies the minimum support level. If it satisfies, 
the sample size chosen initially is progressively increased 
and the above process is repeated until the support of the 
midpoint itemset in the sorted negative border is less than 
the minimum support level. Else, the sample chosen is opted 
as an optimal choice and association rules are mined from 
the sample. Lastly, we determine a fitting database size for 
effectual midpoint itemset scan, so as to reduce 
computational overhead further.  
II. NOVEL Progressive Sampling-Based Approach for 
Effective Association Rule Mining 
The innovative progressive sampling-based approach 
and the different empirical variations proposed for 
determining a fitting sample of a massive database has been 
presented in this section. The proposed approach aims to 
fasten and produce acceptable accuracy in association rule 
mining. The concept of progressive sampling has been made 
use of in the proposed approach for identifying a fitting 
sample of a large database. The task of ARM comprises of 
two steps:  
Frequent itemset generation using support threshold and  
Association rules generation using confidence threshold.  
It has long been identified that the first step of 
association rule mining, frequent itemset generation, 
dominates the computational and I/O requirements. 
Sampling can be thought of as an obvious source for 
considerably reducing the computational and I/O 
requirements incurred in frequent itemset generation [24]. In 
data mining, sampling has been suggested as a powerful data 
reduction tool operated at some cost to accuracy. Sampling-
based approaches can reduce the computational cost and I/O 
overhead of mining remarkably, as the mining algorithms 
has to deal with only a small dataset compared to the 
original database. Time and again, samples proffer good 
enough accuracy with far less computational cost. However, 
the choice of the right sample size for ARM is hardly ever 
known [16]. So as to determine an appropriate sample size, 
researchers have moved onto progressive sampling. 
Progressive sampling works as follows, it starts with an 
initial sample of data and then progressively increases the 
size of the sample until an acceptable accuracy (or other 
performance measure) is achieved [14]. 
One another important concern in sampling large 
databases is the random selection of samples without 
considering any of the characteristics of the database. As so 
ever, it has also been difficult to determine an optimal 
sample size for effectively mining association rules. The 
solution proposed for the above stated problems in the 
presented approach are,  
1) Sample Selection based on the temporal 
characteristics of the original database.  
2) Progressive sampling based on an estimated negative 
border.  
The proposed approach is likely to yield considerable 
reduction in computational time with some cost to accuracy 
(Optimality between accuracy and time). It would be worth-
mentioning if we could further reduce the computational 
overhead involved in the proposed approach. The possible 
improvement that can be effected to the proposed approach 
is,  
3) Determining a suitable database size (m) for 
scanning the midpoint itemset in the negative border, rather 
than performing the entire database scan.       
The primary motivation behind the proposed research is 
that, progressive sampling based on negative border will 
speed-up and facilitates the process of discovering an 
optimal sample size for effective ARM. The steps involved 
in the proposed innovative progressive sampling-based 
approach are as follows:  
1) Selection of initial sample iS  (systematic sampling) 
of size ‘ n ’, based on the temporal characteristics of 
Database D . 
2) Generation of frequent itemsets and negative border 
using Apriori algorithm. 
3) Sorting of the negative border based on the support 
level of itemsets.   
4) Selection of the midpoint itemset in the sorted 
negative border. 
5) Single scan on the left behind records of the database 
1D  of size ‘( nd  )’ to determine the support of the 
midpoint itemset, where iSDD 1  
6) If the support computed for the midpoint itemset is 
less than the specified support, the selected sample is 
optimal and association rules are mined from it. Else, the 
sample size ‘ n ’ is increased and steps 2-5 are performed 
progressively until an optimal sample size is achieved.  
7) After determining the optimal sample, we analyze 
with different percents of database 1D  to identify a suitable 
database size ‘ m ’ for performing midpoint itemset scan. 
Based on the analysis results, we determine ‘m ’ such that, 
)( ndm  . 
III. EXPERIMENTAL RESULTS 
This section describes the results obtained from the 
experimentation on the proposed progressive sampling-
based approach for ARM. The experiments are conducted in 
order to assess the practical feasibility of using samples for 
finding frequent itemsets. The proposed progressive 
sampling-based approach is implemented in Java (jdk 1.6). 
The experimentation is performed using synthetic dataset 
consists of 30K transactions with 13 items in each 
transaction. Apriori, the most renowned association rule 
mining algorithm, has been chosen as the benchmark to 
evaluate the performance i.e. accuracy and time complexity 
of the proposed sampling approach. The notion of model 
accuracy for a particular dataset varies sensitive to relevant 
interaction parameters (e.g. support, confidence, important 
items to the user) as well as the inherent properties of the 
dataset in question. Here, we describe accuracy as the 
number of association rules discovered for different support 
thresholds by the proposed approach in comparison to 
Apriori algorithm rather than the similarity among the 
individual rules. The number of association rules discovered 
by the Apriori algorithm and the corresponding results are 
plotted in Figure 1. The results show that there has not been 
so many rules left mined by the proposed approach when 
compared to Apriori and obviously with increased 
thresholds (more significant patterns), the proposed 
approach almost achieves the model accuracy of the 
classical Apriori algorithm.   
 
Figure1.Accuracy graph 
The need for sampling in ARM was aggravated to the 
fact that association rule algorithms require multiple passes 
over the whole database, and subsequently the database size 
is by far the most influential factor of the execution time for 
very large databases.  So, one important measure that 
illustrates the effectiveness of the sampling-based 
approaches is the timing incurred to complete ARM. We 
have measured the time incurred by the Apriori algorithm 
and the proposed approach to mine association rules from 
the same database for different support thresholds. The 
results obtained are plotted in Figure 2. Clearly, we could 
see an appreciable reduction in the timing required for ARM 
using Apriori and the proposed approach.  
 
Figure 2. Time graph 
 
The above two results clearly demonstrate the 
effectiveness of the proposed approach to mine a good 
number of association rules with appreciable reduction in the 
processing time.  
 Analysis on empirical variations: 
The results obtained on the application of empirical 
variations to the former approach are presented in this sub- 
section. Here, we attempt to reduce the computational 
overhead incurred for performing a midpoint itemset scan on 
the concrete database D . Clearly, we could eliminate the 
records in the sample iS  during the midpoint itemset scan 
because it is does not reflect the true state of the database. 
So, in the proposed empirical variation, we perform database 
scan over iSDD 1 of size nd   .  The results shown in 
Figure 3 clearly show that the proposed approach achieves 
considerable reduction in the processing time merely by 
reducing the database size for the midpoint itemset scan.  
 
Figure 3. Processing time reduced by Empirical variation (d-n) 
The empirical variation achieves significant reduction in 
the processing time incurred for the database scan and 
ultimately the overall processing time. 
The next empirical variation is aimed at reducing the 
computational overhead further. After determining the 
optimal sample, we analyze with different percents of 
database 1D  to identify a suitable database size ‘ m ’ for 
performing midpoint itemset scan. Based on the analysis 
results, we determine ‘m ’ such that, )( ndm  . The results 
obtained for different ‘ %m ’ of the databases for a fixed 
support of 40% is presented in figure (Figure 4) below.   
0
0.05
0.1
0.15
0.2
0.25
30 60 90
Percentage of Remaining database
P
ro
ce
ss
in
g 
tim
e 
in
 s
ec
 
Figure 4. Processing time recorded for different database sizes 
Also, to identify a suitable database size ‘ m ’ for 
performing midpoint itemset scan, we evaluate the support 
of the midpoint itemset on different ‘ %m ’ of the databases. 
The figure 5 shows the graphical depiction of the different 
supports obtained for the midpoint itemset on different 
‘ %m ’ of the databases.  
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
30 60 90
Percentage of Remaining database
M
id
 i
te
m
's
 s
u
p
p
o
rt
 
Figure 5. Support thresholds determined for different database sizes 
From the results, it is obvious that there is considerable 
variation in the support values computed for say 60%, 30%. 
Here, we identify a suitable database size ‘ %60m ’ for 
performing midpoint itemset scan.   
IV. CONCLUSION 
In this paper, we present an innovative progressive 
sampling-based approach that determines an optimal sample 
for effectual mining of association rules from a massive 
database. Firstly, we have selected a preliminary sample of 
some size proportional to the size of the database and 
dependant on the temporal characteristics of the data items 
in the database. Secondly, the negative border of the selected 
sample is generated using the Apriori algorithm. Thirdly, 
based on the support of the midpoint itemset in the sorted 
negative border, the sample size was either progressively 
increased or association rules are mined by regarding it as an 
optimal sample. Fourthly, we have determined an optimal 
database of some fitting size for effectual midpoint itemset 
scan, so as to reduce computational overhead further.  
REFERENCES 
[1] Srinivasan Parthasarathy, "Efficient Progressive Sampling for 
Association Rules", in Proceedings of the 2002 IEEE International 
Conference on Data Mining, pp.354,2002. 
[2] Frawley, W., Piatetsky-Shapiro, G., Matheus, C. (1992) Knowledge 
Discovery in Databases: An Overview. AI Magazine, Fall 1992, pp. 
213-228. 
[3] Jeffrey W. Seifert, "Data Mining: An Overview", in proceedings of 
CRS Report for Congress, 2004. 
[4] Fayyad U, “Data Mining and Knowledge Discovery in Databases: 
Implications from scientific databases,” in Proceedings of the 9th 
International Conference on Scientific and Statistical Database 
Management, Olympia, Washington, USA, pp. 2-11, 1997. 
[5] Sotiris Kotsiantis and Dimitris Kanellopoulos, "Association Rules 
Mining: A Recent Overview", GESTS International Transactions on 
Computer Science and Engineering, vol.32, no.1, pp. 71-82, 2006. 
[6] Jiming Liu, Yiuming Cheung and Hujun Yin, "Intelligent data 
engineering and automated learning", in proceedings of the 4th 
International Conference, IDEAL 2003, Hong Kong, China,  
Springer, 2003 
[7] P. J. Haas. “Techniques for Online Exploration of Large Object-
Relational Datasets,” In Proceedings of the 11th International 
Conference on Scientific and Statistical Database Management, pp. 
4–12. IEEE Press, 1999. 
[8] Bin Chen Exelixis, Peter Haas, Peter Scheuermann, "A new two-
phase sampling based algorithm for discovering association rules", in 
Proceedings of the eighth ACM SIGKDD international conference 
on Knowledge discovery and data mining, pp: 462 - 468, 2002. 
[9] H. Toivonen, “Sampling large databases for association rules”, in 
Proceedings of the 22nd International Conference on Very Large 
Data Bases, pp. 134 – 145, 1996. 
[10] M.J. Zaki, S. Parthasarathy, Wei Li, and M. Ogihara, “Evaluation of 
sampling for data mining of association rules”, in proceedings of the 
International Workshop on Research Issues in Data Engineering, 
pp.42, 1997. 
[11] Kun-Ta Chuang, Ming-Syan Chen, and Wen-Chieh Yang, 
"Progressive Sampling for Association Rules Based on Sampling 
Error Estimation", Lecture Notes in Computer Science, vol.3518, pp. 
505-515, 2005. 
[12] F. Provost, D. Jensen and T. Oates, “Efficient progressive sampling”, 
In Proceedings of the fifth ACM SIGKDD international conference 
on Knowledge discovery and data mining, pp. 23 - 32 , San Diego, 
California, United States, 1999. 
[13] Basel A. Mahafzah, Amer F. Al-Badarneh and Mohammed Z. 
Zakaria "A new sampling technique for association rule mining," in 
Journal of Information Science, Vol. 35, pp. 358-376, 2009.   
[14]    R.Agrawal, T.Imielinski, and A. Swami, “Mining association rules 
between sets of items in large databases”, in proceedings of the ACM 
SIGMOD Int'l Conf. on Management of data, pp. 207-216, 1993.  
[15] R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with 
item constraints. In KDD, pages 67–73, 1997.  
[16] Tsau Young Lin, "Sampling in association rule mining", Conference 
on Data mining and knowledge discovery: Theory, Tools, and 
Technology VI, vol. 5433, pp.161-167, 2004.  
[17] Venkatesan T. Chakaravarthy, Vinayaka Pandit and Yogish 
Sabharwal, "Analysis of sampling techniques for association rule 
mining", In Proceedings of the 12th International Conference on 
Database Theory, Vol. 361, pp. 276-283, 2009. 
[18] Y. Zhao, C. Zhang and S. Zhang, “Efficient frequent itemsets mining 
by sampling”, in Proceedings of the fourth International Conference 
on Active Media Technology (AMT), pp. 112-117, 2006. 
[19] Wontae Hwang, Dongseung Kim, "Improved Association Rule 
Mining by Modified Trimming," Sixth IEEE International 
Conference on Computer and Information Technology (CIT), pp.24, 
2006. 
[20] F. Bodon, “A Fast Apriori Implementation”, In Proceedings of the 
IEEE ICDM Workshop on Frequent Itemset Mining Implementations, 
vol. 90, Melbourne, 2003. 
[21] Agrawal. R and Srikant. R., “Fast algorithms for mining association 
rules”, In Proceedings of 20th International Conference on Very 
Large Data Bases, pp. 487-499, 1994. 
[22] Yanbo J. Wang , Qin Xin  and Frans Coenen, "Mining Efficiently 
Significant Classification  Association Rules", Studies in 
Computational Intelligence, Springer Berlin / Heidelberg,  Vol. 118, 
pp.443-467, August 2008.  
[23] B. Liu, W. Hsu, S. Chen, and Y. Ma. Analyzing the subjective 
interestingness of association rules. IEEE Intelligent Systems, 15:47–
55, 2000. 
[24] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without 
candidate g R. Srikant, Q. Vu, and R. Agrawal. Mining association 
rules with item constraints. In KDD, pages 67–73, 1997.eneration. In 
SIGMOD, pages 1–12, 2000. 
[25] R. Ng, L. Lakshmanan, J. Han, and A. Pang. Exploratory mining and 
pruning optimizations of constrained association rules. In SIGMOD, 
pages 13–24, 1998. 
[26] R. Bayardo, R. Agrawal, and D. Gounopolos. Constraint-based rule 
mining in large, dense databases. In ICDE, pages 188–197, 1999. 
[27] Yanrong Li and Raj P. Gopalan, "Effective Sampling for Mining 
Association Rules", Lecture Notes in Computer Science, vol. 3339, 
pp: 391-401, 2005. 
[28] R. L. Scheaffer, W. Mendenhall and R. L. Ott, “ Elementary Survey 
Sampling”, Duxbury Press, 1995. 
[29] V Umarani and M Punithavalli, "Developing Novel and Effective 
Approach for Association Rule Mining Using Progressive Sampling", 
The 2nd International Conference on Computer and Electrical 
Engineering (ICCEE 2009), Dubai, UAE, December 28-30, 
2009(accepted for publication). 
