 The Application of Association Rules Algorithm on Web Search Engine 
 
Lu Nan1, Zhou Chun-Guang2, Cui Lai-Zhong3  
1College of Computer and Software Shenzhen University, China 
2Jilin University, China 
3Tsinghua University, China 
lunan@szu.edu.cn, cgzhou@jlu.edu.cn, cuilaizhong@gmail.com 
 
Abstract 
 
Aiming at the prevalently concerned mining 
problem about constructing concept search in current 
Web search engine area, especially applying the 
Vector Space Model VSM to web search mining 
based on the association rules, this paper provides a 
highly efficient mining algorithm EARS. The EARS 
algorithm implements the association rules pruning 
based on VSM via constructing association library 
and computing similarity. The EARS stores the 
frequent itemsets via multi-dimensional linked lists 
and utilizes the recurrence relation among the 
frequent itemsets in order to effectively obtain the 
association rules. We verify the extended function of 
retrieving and querying on the web and the results of 
these experiments indicate that our method is 
effective and feasible. 
 
1. Introduction 
 
With the rapid development of Internet, Web has 
been a major information source. Due to the huge and 
mass information involved, it becomes more and 
more difficult that find out useful information fast 
and accurately. Although the search engine based on 
key words is widely used, its precision ratio and 
recall-precision are hot issues of all time. For this 
reason, the concept-based retrieval [1] is proposed, 
which is an outcome combining data mining 
technology with search engine mechanism and also is 
one of realizing intelligent information retrieval 
methods. 
Concept-based retrieval expand the users’ query 
requests in form of concepts via the transformation of 
association between concepts, namely the 
transformation associated library, and then submits 
them to retrieval systems, outputting the query results 
eventually. Since concept-based retrieval understood 
and dealt with the users’ requests from the level of a 
word’s conceptual meaning, breaking through the 
defect that keyword matching is restricted to 
appearance form, it can effectively eliminate the 
difference between query requests expressed by the 
users and the query results by the system executing, 
thus increasing precision ratio and recall-precision of 
the system [2]. The two key technologies are the 
transformation of semantic library and query 
expansion. 
The transformation of associated library making 
use of association rules mining algorithm, 
automatically mines the association between words 
form the text to structure, in favor of query expansion 
and adjustment. Currently, there are two major 
methods to structure associated library:  
x using manual method to structure associated 
library, demanding domain experts to accomplish. 
It is a rather time-consuming project and the 
associated library can not reflect the change 
between concepts in time. 
x automatically extracting concepts and words from 
the text set and then discovering the correlation 
between the concepts and the words, structuring 
the associated library finally. 
Query expansion is based on the association 
library and conducts the correlation query expansion 
according to correlation and degree of correlation. 
Therefore, association rules mining technology has 
been an important step of realizing intelligence 
search for query expansion [3, 4]. Based on the 
associated library, the query requests of the users will 
be correspondingly expanded, to make retrieval 
Copyright © 2009 by the Institute of Electrical and Electronics Engineers, Inc. All rights reserved.
 intelligent and increasing the precision ratio and 
recall-precision. 
Due to the knowledge discovery in mass data, the 
quality and efficient of mining algorithm are always 
the bottleneck in the application and extension of 
association rules. A lot of researchers conduct a great 
of research about the topic of association rules 
mining, expecting to improve and optimize the 
original algorithm for better efficiency of algorithm. 
The representative algorithm are Apriori [6]?
DHP[7]?Partition[8]?Sampling[9] and so on. 
This paper proposes an improved association 
rules mining technology, which can automatically 
export the correlation between concept and word 
from the text. This method applies the vector space 
model (VSM) to the association rules mining 
algorithm, in order to discover the correlation 
between concept and word in the text., according to 
which structuring the associated library. The 
associated library can effectively solve the problem 
of query expansion to achieve the purpose of 
increasing precision ratio and recall-precision. 
 
2. Web vector space and association rules 
 
The major task of concept searching is building 
feature extraction and Vector Space Model formed by 
the term frequency count and applying the 
association rules and correlation process to establish 
the feature words association library. 
 
2.1 Vector Space Model VSM 
 
Since the VSM [5] has strong computability and 
operability, it has been widely applied to many 
applications in information retrieval areas as text 
retrieval?automatic abstraction?keyword automatic 
extraction? text classification and search engine, 
achieving good effects. In VSM, a document space is 
regard as a vector space consisting of a orthogonal 
word vector set, in which each document d represents 
a standardizing eigenvector: 
V(d)=(i1,w1(d); … ;ij,wj(d); … ;im,wm(d)) 
ij is word item, wj(d) is the weight value of ij in d, 
which is generally defined as a function of tfj(d), the 
frequency of ij ’s occurrences in d, namely 
wj(d)=?(tfj(d)). tfj(d) represents the frequency of 
characteristic item ij ’s occurrences in d. There are 
many patterns of ?, in which the classic and widely 
used computable function is TF·IDF. Its form is as 
follows:  
? = tfj (d)?log[N/nj] 
In which, N is the amount of all the documents and 
nj is the amount of documents including word item ij. 
2.2 The calculation of similarity degree 
 
We compute the similarity degree based on the 
cosine distance which can be formally defined as: 
     (1) 
2.3 The transformation of associated library 
The construction of the association library is a 
crucial step in realizing concept searching, aiming at 
automatically extracting concepts and words from 
document sets and finding out the correlations among 
them. 
 
2.3.1 The concept of association rules 
In association rules, itemset I={i1,i2, …, in} 
represents a set consisting of n different data items. 
For a given transaction database D, each transaction 
T is a subset of itemset I. The implication of 
association rules is X?Y, in which X?I,Y?I and 
X?Y=?, and its support and confidence are 
respectively defined as: 
support(X?Y) = P(X?Y)   (2) 
confidence(X?Y) = P(Y|X)      (3) 
The task of association rules mining is find out all 
strong association rules, making support larger than 
the given support’s threshold and confidence larger 
than the given confidence’s threshold. From (2), we 
can see that support reflects the frequency of the 
implication X?Y’s occurrences in transaction T and 
the itemset whose frequency is larger than the given 
threshold is defined as frequent itemset. The 
 generation of frequent itemset indicates that there is a 
certain similarity between corresponding objects. In 
VSM, a document is regard as an object and a word is 
regard as an object item. If some object items always 
in some documents, we think that these document 
items have a certain similarity. Through (3), we can 
compute the confidence between document items and 
then make sue the similarity between document 
items. 
2.3.2 The pruning of association rules 
If the association rules mined by current 
association rules algorithm are directly added into 
associated library for query expansion, it will be 
found out that there are a lot of useless rules in the 
mining results. Once these rules are added into the 
associated library, some errors will occur in the 
process of query expansion and it also decrease the 
precision ratio and recall-precision. In order to make 
the rules in associated library more meaningful and 
convenient for query expansion, we make some limits 
in the process of mining as follows: 
(1) Support threshold value limit. Support reflects 
the itemsets in the database are whether universal 
laws or not. In order to make sure the frequent 
itemsets with more universal laws, we demand the 
frequency of frequent itemsets’ occurrences must be 
larger than 20 in the database with 1000 items, 
namely the least support threshold value is 0.02. You 
can certainly increase the support threshold value to 
make the frequent itemset more meaningful. 
(2) Confidence threshold value limit. If the 
confidence threshold value is set too small, the rules 
with too small confidence will also be mining out. 
And if these rules are added into associated library, it 
will make the query expansion set too large and 
decreasing the precision ratio, simultaneously 
increasing the retrieval cost. In this paper, the least 
confidence threshold value is set as 0.7. 
(3) Constraints limit. In general, the number of left 
and right in the association rules is not limited. When 
retrieving, query string is generally 1-2 words, and as 
in query expansion, only 1-2 will be expanded. So, 
we needn’t generate the rules with the number of left 
and right lager than 2. Adding number constraint 
condition in mining algorithm not only increases the 
efficiency of algorithm but also eliminates the invalid 
rules. 
(4) Correlation interest threshold value limit. 
Though we can eliminate invalid rules via above 
limits, we must make out whether the rules with high 
support and high confidence is really valid or not and 
reflect the real correlation between words or not. To 
solve the problem, we introduce the interest threshold 
of association rules to judge the association rules. For 
a given transaction set D, the interest of association 
rule X ?Y in D is defined as: 
     (4) 
According to (4), if interest is small than 1, it 
indicates more interest in this rule, namely its 
practical value lager in use. If interest is equal to 1, it 
indicates that X and Y are mutually independent and 
this rule should be eliminated. Through above steps’ 
process, the association rules mined out are basically 
in accord with the reality and they could be added 
into the associated library. 
2.3.3 The structure of associated library 
The associated library includes two structure tables, 
hierarchy relationship table and correlation 
relationship table. Hierarchy relationship describes 
hierarchical relation between words and its basic 
element is word node. The attribute of word node is 
described as follows: 
struct Concept { 
char itemid[]; //hierarchy number which a node in  
char itemname[]; //name of a word node  
double psweight; //the weight value from father  
     node to the node itself 
double spweight; //the weight value from the node 
itself to its father node  
struct concept *son; //a point to a array of child  
nodes  
} 
 The correlation relationship table describes the 
correlation between words, specific representation as 
following: 
struct Relationship { 
char itemstring1[]; // word string 
char itemstring2[]; //word string 
double weight[]; //weight value of confidence 
} 
In the expression, itemstring1 and itemstring2 
could be a string consisting of multiple words. 
3. The architecture of web search engine 
based on association rules 
The structure of web search engine based on 
association rules usually includes two parts: query 
service in client and background processing in server, 
which are shown as in the figure 1.The query service 
in client includes three parts consisting of the user’s 
query request, concept associative spread and pattern 
match. The background processing includes four 
parts consisting of document collection, feature 
extraction, transformation of associated library and 
adjustment of associated library. 
  
Figure1. The Architecture of Web Search Engine  
Based On Concept Retrieval  
 
3.1 The background processing in server 
 
The major process is building document library, 
VSM [5] and feature word associated library. The 
document library could be constructed using the 
information acquisition tool to collect document files 
including original documents and their URLs. VSM 
storing each document’s major feature words and 
word frequency is a word frequency matrix formed 
by feature word extracting and the word frequency 
counting for the documents in the document library. 
The feature word associated library is build up after 
the process of association rules mining algorithm, 
mining the correlation between feature words in 
VSM. 
3.2 The foreground query request in client 
When a user submits a query request, the system 
will find out the corresponding feature words from 
the feature words associated library and process the 
concept expansion to form a string of related 
concepts. They are regarded as query request 
submitted to the system for pattern matching and the 
documents meeting conditions will be submitted to 
the user. If system doesn’t find out the feature words 
corresponding with the query request, system will 
re-mining the corresponding feature words from the 
VSM, do the expansion process and adjust the 
associated library. 
4. The improved mining algorithm EARS 
The key points of increasing association mining 
efficiency are usually including the followings: ? 
decreasing the amount of scanning database and 
reducing the I/O load ? generating small candidate 
frequency set ? making rational use of relationship 
between back and forth items solving the 
sub-problems in the process of generating association 
rules ?optimizing implementation code to reduce the 
space complexity as far as possible. We provide an 
improved mining algorithm called EARS to do these. 
The main idea is that we use a multi-dimensional list 
structure to store the Tid set of each frequency set in 
database and recursion relations between levels of 
each frequency set and effectively obtain association 
rules via list operation and set operation at last. 
4.1 Correlation theory 
For any two itemsets X, Y, if X?Y, X is the father 
itemset of Y and Y is the child itemset of X. If X?Y 
and |X|+1=|Y|, Y is the proper sub-itemset. The proper 
sub-itemset is a special child itemset. If Y, the proper 
sub-itemset of X, is a frequency set, Y is the proper 
sub frequency set of X. Let D be the number of 
records in database, Tid be the identifier of a record 
in database; Lk be the set of  frequency set in level k, 
 usually called large k-itemset, Lk,m be the m-th of the 
set consisting of large k-itemsets, Lk,m[i] be the i-th 
item of the m-th element of large k-itemset, |X| be the 
number of elements that X includes, X.Set be the set 
of all items composing the itemset X, X.Set[i] be the 
i-th item of itemset X, in which i?0, X.SupTidSet be 
the i-th Tid number of itemset X’s support Tid set, 
X.sup be the supports of itemset X, namely the 
number of elements belonging to X.SupSet, X.Tid be 
the Tid number which records X in database, X.Level 
be the level number, namely |X|, X.NearOffspring be 
the proper sub frequency set nodes queue of X. 
Theory 1: X is any a k-itemset and Y, Z are two 
different itemsets. If Y,Z?X?Y???Z???there are 
Y Z=X, X.SupTidSet =Y.SupTidSet ? Z.SupTidSet. 
Theory 2: If the frequency sets in k-1 level are in 
ascending order, all the items included by the every 
frequency set will also be in ascending order. When 
the frequency itemsets in k level are found, we use 
dual cycle to matching mine the two itemsets in k-1 
level from small to large. The generated items 
included by the frequency sets sort ascending and 
then the large itemset Lk in k level will sort ascending. 
Theory 3: For nonempty itemset, X and Y, the 
number of both X.set and Y.set’s items is m, and 
X?Y??, X.Set[1]<X.Set[2]<…<X.Set[m]? Y.Set[1] 
<Y.Set[2]<…<Y.Set[m]. If the same item, ?, is deleted 
from (or inserted into) X and Y simultaneously, 
obtaining X’ and Y’, the size relationship of X’ and Y’ 
is the same as the size relationship of X and Y. 
4.2 Data structure 
The core data structure of the algorithm is a multi 
dimensional list. The vertical list stores the frequency 
set nodes. Each node includes X.Set?X.SupTidSet?
X.Sup?X.Level?X.NearOffspring. The horizontal list 
consists of queues pointed by each frequency set 
node’s NearOffspring, each node of which store a 
pointer pointing to a proper sub frequency set node of 
X.Set. These pointers re-point to frequency set in the 
vertical list and the node store three fields: 
Rules-Route?Off-Set and Con-Set. Rules-Route is a 
path pointer, generating rules. When mining rules, we 
depend on breadth-first search to expand the queue to 
deduce all the rules. Off-Set stores extra items that 
proper sub frequency set Y is bigger than current 
frequency set X. Con-Set stores rule’s consequent of 
association rules, namely the conclusion part. The 
major structure of the list is shown in Figure 2. 
Where, L1,1?L1,2, … ,L1,m?L2,1?L2,2, … ,L2,n?
L3,1, … ,L3, represents respectively frequency set node 
from each level, composing vertical queue. (X) 
expresses the pointer pointing to node X. 
 
Figure 2. The Structure of Multi Dimensional List 
The feature of data structure is that each frequency 
set node is adjacent to its proper sub frequency 
itemset sequence, and through the widely used list 
operation, breadth-first search, we can conveniently 
get all the child frequency set of any a frequency set. 
As breadth-first search is used, the obtained child 
frequency set sequence has been arranged as from 
low to high level, of which we can make use to 
increase the efficiency of algorithm in the course of 
algorithm design. 
4.3 Algorithm description 
 Let Tid number of a record in database be unique 
in the whole database and the records in database sort 
ascending as Tid. In this condition, the algorithm 
EARS can be parted into three steps: 
Step1: By scanning database once, it generates all 
the order frequency set L1 and X.SupTidSet and X.Sup 
are recorded. If we set minsup to 0.5, the process of 
L1‘s generation is shown as table 1 and table 2.  
Step 2: By multiple cycles based on L1 , it 
generates all the large itemset Lk in level k(k?2). 
 
 
 
 Table 1.  Database Table 
Tid Items 
001 a c d 
002 b c e 
003  a b c e 
004 b e 
Table 2. The List Structure After Big Itemset of Level L1 Is Obtained 
X?XL1? X.Sup X.SupTidSet 
{a} 2 001 003 
{b} 3 002 003 004 
{c} 3 001 002 003 
{e} 3 002 003 004 
In this process, it matching mine two large itemsets 
in k-1 level from small to large via dual cycles. For 
any two frequency sets Lk-1,m and Lk-1,n(m<n) in level 
k-1,if the conditions are satisfied that Lk-1,m[1]=Lk-1,n[1]?
Lk-1,m[2]=Lk-1,n[2],…,Lk-1,m[k-2]=Lk-1,n[k-2] ? Lk-1,m[k-1]<Lk-1,n[k-1], 
X.Set=Lk-1?m.SetLk-1?n.Set is respectively a k-itemset. 
According to theory 1, there is X.SupTidSet= 
Lk-1,m.SupTidSet?Lk-1,n.SupTidSet.IfX.Sup?minsup*D in 
which X.Sup belongs to k-itemset X, X is frequency 
set in level k, otherwise, X is a weak itemset. 
We can use theory 2 to accelerate dual cycle 
scanning for this process. For any a frequency in 
level k, it can be obtained by matching the least two 
frequency sets in level k-1 consisting of k-1 elements 
from Lk,x, namely Lk-1,m={Lk-1,1?Lk-1,2?…?Lk-1,k-3?
Lk-1,k-2} and Lk-1,n={Lk-1,1?Lk-1,2?…?Lk-1,k-3?Lk-1,k-1}.  
When deducing frequency set in level k, if the first 
k-2 items of Lk-1, m and Lk-1,n are different, the smaller 
frequency needn’t to match the following other 
frequency sets, in other words, the inner cycle can be 
stopped. After deducing a frequency set Lk,x by using 
Lk-1,m and Lk-1,n(m<n), Lk,x is added into the vertical list 
and the support set and support number of Lk,x are 
written into corresponding domain. The pointer node 
pointing to Lk,x is added into the proper sub nodes 
sequences pointed by respective NearOffspring of 
frequency Lk-1,m and Lk-1,n and the item obtained from 
Lk,x-Lk-1,m is recorded into the off-set domain of proper 
sub node newly added into Lk-1,m meanwhile, the item 
obtained from Lk,x-Lk-1,n is recorded into the off-set 
domain of proper sub node newly added into Lk-1,n. It 
searches the frequency sets which also regard Lk,x as 
its proper sub frequency set in the frequency sets 
sequence at level k-1 after Lk-1,n. Table 3 describes the 
storage structure of multiple list generated by 
example1 through step2.  
Table 3. The Storage Structure of Ultiple List Generated By Example 
L X. Sup X. SupTidSet X. NearOffspring 
{a} 2 001 003 [ ({a c}) ,c] 
{b} 3 002 003 004 
[ ({b c}) ,c] 
[ ({b e}) ,e ] 
{c} 3 001 002 003 
[ ({a c}) ,a ] 
[ ({b c}) ,b] 
[ ({c e}) ,e ] 
{e} 3 002 003 004 
[ ({b e}) ,b] 
[ ({c e}) ,c] 
{a c} 2 001 003  
{b c} 2 002 003 [ ({b c e}) ,e ] 
{b e} 3 002 003 004 [ ({b c e}) ,c] 
{c e} 2 002 003 [ ({b c e}) ,b] 
{b c e} 2 002 003  
Step 3: By using the information of current data 
structure, it gets the association rules meeting the 
minconf. In other words, it regards any a frequency 
set in vertical list as the antecedent of association 
rules, and then mines out the conclusion meeting 
minconf, namely the rule’s consequent. When 
frequency set X is a rule’s antecedent, first, the next 
pointer of each node in NearOffspring is copied into 
Rules-Route pointer of current node and the value of 
Off-Set is copied into Con-Set, forming an initial 
Rules-Route which generates rules. Through scanning 
this list to get a node, the Con-Set value Y of this 
node is the rule’s consequent and the support of 
corresponding frequency set Z can be obtained from 
the pointer of this node, in which according to the 
generation process, we know that Z=X? Y. If 
confidence (X?Y)= (Z.Sup/X.Sup)?minconf, it is a 
strong rule meeting the requirement, otherwise, it’s a 
weak rule. If confidence (X?Y) is a weak rule, 
apparently the child nodes of Z don’t combine with X 
to generate a strong rule. Otherwise, the 
NearOffspring list of Z is scanned. If it is not null, 
each node in the list is fetched one by one and Y is 
copied into the Con-Set domain of the node in the list. 
Simultaneously, the item of Off-Set domain is 
inserted into Con-Set, making the item of Con-Set 
sort ascending to form rule’s consequent M. 
 Comparing M with rule’s consequent N of the last 
node in Rules-Route, if |N|<|M| or |N|=|M| and 
N<M(Theory 3), this node will be linked to the end of 
Rules-Route. Scan the next node of Rules-Route and 
repeat the above process until to the last node. When 
example 1 uses frequency set {c} as rule’s antecedent, 
Table 4 lists the Rules-Route queue and its 
corresponding association rules generated by the 
derivations. As long as the minconf is given, it could 
judge which are the strong rules meeting the 
requirement.  
 
Table 4. The Rules-Route Queue And Its Association Rules 
The node point  
to freq-set 
Off- 
Set 
Con- 
Set 
Sup.of 
freq-set 
Asso. 
Rules Conf. 
({a c}) A a 2 c?a 0. 667 
({b c}) B b 2 c?b 0. 667 
({c e}) E e 2 c?e 0. 667 
({b c e}) E b e 2 c?b e 0. 667 
 
5. The results and analysis of experiment  
 
To verify the efficiency of EARS’s expansion 
function in searching and retrieval, we test on a 
computer with CPU 2.4G, Memory 2GB and 
Windows XP operating system. The original 
documents are from the TREC-7 document set 
downloaded from the Internet, including 23251 
documents. Choosing ten thousand words as feature 
word, the documents are carried on the feature 
extraction and word frequency counting, forming 
word frequency matrix stored in the Oracle9i 
database. When minsup=0.04, minconf=0.4, the 
number of records in the database increases from 
2,000 to 10,000 and the execute efficiency of EARS 
and Apriori is shown as Figure 3.From Figure 3, we 
can see that as records increasing, both of the runtime 
are prone to increase, while, from the perspective of 
data, the increment speed of EARS’ runtime is slower 
than Apriori’s. In addition, the runtime of EARS is 
less than Apriori’s at any time. 










7LPHV

1XPEHURIUHRUGV
?
?
?
?
?
?
?
?
?
?










	?????????????????????????????
?
?
??????

 
Theoretically speaking,  
x EARS scans the database once only when 
discovering the large 1-itemset in the whole 
process of mining, which solves the problem 
about the heavy load of I/O. 
x With the help of Tid sets recorded in the memory, 
the algorithm doesn’t generate candidate large 
itemset Ck.  
x The advantage of using the data structure, 
multiple dimensional pointers, is that when 
generating association rules, the expenditure of 
matching time is decreased as much as possible 
by making the best use of previous work.  
x The design of the algorithm makes use of the 
ordered data structure and set operations. 
Therefore, the execute efficiency of EARS is 
improved effectively. 
6. Conclusion 
In the current developing process of network 
search engine technology, how to using web data 
mining technology is a key point. In the research 
process of the web search engine technology, this 
paper analyses in depth on the query expansion 
technology based on the association rules. We 
propose an association rules mining algorithm EARS 
based on multiple dimensional list. The results of 
experiment indicate that the efficiency of EARS is 
higher than Apriori’s and the runtime of EARS varies 
within a small range, namely having a good 
flexibility. It thus is concluded that EARS is an 
effective and scalable association rules algorithm, 
which can be widely used to query expansion in web 
information retrieval. 
 
 7. Reference  
 
[1] Fetzer C,Hagstedt, K,Felber P. “Automatic Deteciton 
and Masking of Non-Atomic Exception Handling” 
International Conference On Dependable Systems and 
Networks, (DSN2003), 110-116. 
 
[2] Yen S J, Lee Y S. “Mining Interesting Association Rules 
and Sequential Patterns”. International Journal of Fuzzy 
Systems, 2004-6 (4), 78-84. 
 
[3] Alasffar A H, Deogun J S. “Concept-based Retrieval 
with Minimal Term Sets”. Foundations of Intelligent 
Systems: 11th Int’l Symposium, Springer, Poland, 2004: 
114- 122. 
 
[4] Qiu Yonggang,Frei H P. Concept Based Query 
Expansion[C].SIGIR’03,2003:160-169. 
 
[5] Saltom G, Wong A, Yang C S. “A Vector Space Model 
for Automation Indexing”. Communications of the ACM, 
2005, 18(5): 613-620. 
 
[6] Agrawal R, Srikant R. “Fast Algorithm for Mining 
Association Rules in Large Databases.” Proceedings of the 
20th International Conference on Very Large DataBases , 
Santiago , Chile , 2004 
 
[7] Park J S. “Using A Hash-Based Method with 
Transaction Trimming forMining Association Rules.” IEEE 
Transactions on Knowledge and Data Engineering, 2007. 
 
[8] Savasere A, Omiecinski E, Navathe S. “An Efficient 
Algorithm for Mining Association Rules in Large 
Databases.” Proceedings of the 21st International 
Conference on Very large Database, Switzerland, 2002. 
 
