2010 Second International conference on Computing, Communication and Networking Technologies
Classification Ensemble for Mammograms Using 
Ant-Miner
Roselin  .R#1   &  Thangavel. K*
2
#Assistant Professor of  Computer Science,
Sri Sarda College for Women (Autonomous),
Salem  636 016,Tamil Nadu, India.
1rose_line_r@yahoo.co.in
*Prof & Head , Department of Computer Science,
Periyar University, Salem 636 011, Tamil Nadu,  India.
2drktvelu@yahoo.com
Abstract— This paper proposes a new classification method 
based on association rule mining. This association rule-based 
classifier is experimented on a real dataset; a database of 
medical images from MIAS database. The proposed system 
employs Ant-Miner metaheuristic algorithm for extracting 
knowledge in the form of decision rules using texture features 
extracted with the help of co-occurrence matrices. These rules 
are used to predict unseen mammogram. The experimental 
results show that the method performs with greater accuracy.
Keywords— Ant-Miner, Data mining, Mammogram,
GLCM Matrix, Metaheuristic
I.  INTRODUCTION
Breast Cancer is one of the most common cancers, leading 
to cause of death among women, especially in developed 
countries. There is no primary prevention since cause is still 
not understood. So, early detection of the stage of cancer 
allows treatment which could lead to high survival rate. The 
accuracy with which tumors are detected, when large 
volumes of images are to be read by radiologists tends to 
decrease, and hence an automated mechanism for reading of 
digital mammograms is always preferable. However with the 
use of proper computer aided systems, we could reduce the 
number of unnecessary biopsies being conducted. Wavelet-
based subband image decomposition for detecting 
microcalcification in digital mammograms is presented in [1]. 
Tumor detection using Markov Random field is proposed in 
[2]. In this technique, detection of tumor in digital 
mammography is performed in two steps, segmentation and 
classification. Classification of medical images using neural 
networks is presented in [3, 4]. Osmar R. Zaine et. al [5] have 
classified medical images using Association Rule based 
Classifiers by Category (ARCBC). A study of the breast 
cancer using data mining techniques has been presented in 
[6].
978-1-4244-6589-7/10/$26.00 ©2010 IEEE
Metaheuristics are generally applied to problems for which 
there is no satisfactory problem-specific algorithm or 
heuristic; or when it is not practical to implement such a 
method. Most commonly used metaheuristics are targeted to 
combinatorial optimization problems, but of course can 
handle any problem that can be recast in that form, such as 
solving boolean equations. In this research, the Ant-Miner 
metaheuristic algorithm has been used to generate rules for 
classification purpose.  A voting scheme algorithm has been 
proposed to classify an unknown case which is not classified 
under one particular angle. A similar technique has been 
proposed by Andrew Kusiak et al. [7] in predicting survival 
time for kidney dialysis patients.
This paper is organized as follows: Section II explains the 
concepts and importance of datamining. Section III elucidates 
Ant Colony-Based Association Rule Miner, Section IV gives 
out the proposed algorithm using voting scheme. Section V 
reports the computational results and discussions.
II. DATA MINING
Mining information and knowledge from large database 
has been recognized by many researchers as a key research 
topic in database system and machine learning and by many 
industrial companies as an important area with an opportunity 
of major revenues. One of the data mining tasks gaining 
significant attention is the classification rules extraction from 
databases. The goal of this task is to assign each case (object, 
record, and instance) to one class, out of a set of predefined 
classes, based on the values of some attributes for the case. 
There are different classification algorithms used to extract 
relevant relationship in the data as decision trees which 
operate performing a successive partitioning of cases until all 
subsets belong to single class [8] (Quin-lan,1986).This 
operating way is impracticable except for trivial data sets. 
There are many other approaches for data classification, such 
as statistical and roughest approaches (Ziarko,1994) and 
neural networks(Lu et al.,1995).Though these classification 
techniques are algorithmically strong they require significant 
expertise to work effectively and do not provide intelligible 
rules. The classification problem becomes very hard when the 
number of possible different combinations of parameters is so 
high that algorithms based on exhaustive searches of the 
parameter space rapidly become computationally infeasible. 
The metaheuristic algorithms based on nature, such as genetic 
algorithms (GA), neural networks, immune algorithm, are 
extremely appealing for the tasks of data mining. This paper 
deals with Ant-Miner metaheuristic algorithm. In the context
of the classification task of data mining, discovered 
knowledge is often expressed in the form of
IF-THEN rules, as follows:
IF <conditions> THEN < class>.
The rule antecedent (IF part) contains a set of conditions, 
usually connected by a logical conjunction operator (AND).
A. Data Pre-processing
Pre-processing is always a necessary whenever the data is 
to be mined in noisy, inconsistent or incomplete and pre-
processing significantly improves the effectiveness of the 
data mining techniques [10]. Mammogram images are noisy 
and inconsistent to interpret in their raw form. To produce a 
reliable representation of the breast anatomy we need to pre-
process the mammograms. There are basically two steps 
involved in processing the mammogram images and they are 
noise reduction and enhancement of image. Many images 
have existing artifacts like written labels that need to be 
eliminated and this can be done by cropping the images. The 
pruning of images removes nearly all background noise. The 
second step is image enhancement. In the process of image 
generation, transmission and transformation, with the
influences of different external and internal factors, the 
quality of images would be decreased. The purpose of image
enhancement is to use special techniques to improve the
quality of image or change the images to other formats that 
are more suitable for processing afterwards. Usually there are 
two categories of image enhancement techniques: space 
domain and frequency domain. Histogram equalization 
technique is an algorithm of gray level enhancement 
performed in space domain. The distribution of the histogram 
of an image with low contrast will normally aggregate in a 
relatively small region. For images after equalization, the 
different gray levels will have similar occurring rate. In the 
above situation, the entropy of the image is the largest and 
contains the most information. In this paper, we choose the 
widely used histogram equalization technique to enhance the 
images. Noise removal should be performed first in order not
to enhance the noise simultaneously. The results after noise
removing and histogram equalizing are shown in Fig 1.
       
  a. Original Image            b. After Noise Removal  and         
                                                Histogram  Equilization
Fig1 The Preprocessing stage
B. Grey level co-occurrence matrices features (GLCM).
The GLCM is a well-established robust statistical tool for 
extracting second order texture information from images [11,
12]. The GLCM characterizes the spatial distribution of grey 
levels in an image. Specifically, an element in the GLCM, 
Pd, (i,j), represents the probability of occurrence of the pair of 
grey levels (i,j) separated by a distance d at direction . In this 
study, four GLCMs are computed, corresponding to three 
different directions (  = 0°, 45°, 90° ) and one distance(d = 1 
pixel). Haralick 14 features [11] are derived from each 
GLCM: Angular second moment, Contrast, Correlation, 
Variance, Inverse second different moment, Sum Average, 
Sum Variance, Sum Entropy, Entropy, Difference Variance, 
Difference Entropy, Measure of Correlation 1, Measure of 
Correlation 2, and Local Mean. 
C. Discretization of Numerical Attributes
In order to perform data mining by decision tree algorithm
or Ant-miner algorithm, numerical attributes should be 
discretized first, i.e. continuous attribute values should be 
divided into multiple segments. For some attributes, if 
doctors have had existing dividing points, we can adopt it 
directly. For example, patients’ weight can be divided to thin, 
common and heavy; their age can be divided into under age, 
youth and the elderly; Medical test results can be said to be 
normal and abnormal. But for extracted image feature value, 
there is no existing threshold. Previous research indicated that 
supervised discretization methods are better than 
unsupervised methods [13]. In this research, entropy-based 
binning via binarization has been used. It intuitively, find best 
split so that the bins are as pure as possible and formally 
characterized by maximal information gain [14].
III. ANT COLONY-BASED ASSOCIATION RULE MINER
Ant Colony-Based is proposed by Parpinelli et al [9] as an 
association rule mining algorithm. An Ant Colony 
Optimization algorithm (ACO) is essentially a system based 
on agents which simulate the natural behavior of ants, 
including mechanisms of cooperation and adaptation. In 
solving the optimization problems with ACO we have three 
major functions. Choosing these functions appropriately 
helps the algorithm to get faster and better results. The first 
function is a problem-dependent heuristic function (? ) which 
measures the quality of items that can be added to the current 
partial solution. The heuristic function stays unchanged 
during the algorithm. A rule for pheromone updating, which 
specifies how to modify the pheromone trail (?), and a 
probabilistic transition rule based on the value of the heuristic 
function and on the contents of the pheromone trail that is 
used to iteratively construct a solution In Ant-Miner 
algorithm the author refer to each rule condition as a term, so 
that the rule antecedent is a logical conjunction of terms in 
the form: IF term1 AND term2 AND ... Each term is a triple 
<attribute, operator, value>, such as <Gender = female>. The 
rule consequent (THEN part) specifies the class predicted for 
cases whose predictor attributes satisfy all the terms specified 
in the rule antecedent. From a data mining viewpoint, this 
kind of knowledge representation has the advantage of being 
intuitively comprehensible for the user, as long as the number 
of discovered rules and the number of terms in rule 
antecedents are not large.
ACO algorithms involve simple agents (ants) that 
cooperate with one another to achieve an emergent, unified 
behavior for the system as a whole, producing a robust 
system capable of finding high-quality solutions for problems 
with a large search space. In the context of rule discovery, an 
ACO algorithm has the ability to perform a flexible, robust 
search for a good combination of terms (logical conditions) 
involving values of the predictor attributes.
In ACO algorithm each ant incrementally 
constructs/modifies a solution for the target problem. In the 
proposed model the target problem is the discovery of 
classification rules for mammogram classification.
A. Pheromone Initialization 
All cells in the pheromone table are initialized equally as 
per the following equation: 
                                  
?
=
== a
i
i
ij
b
t
1
1)0(?       
where a is the total number of attributes, and bi is the number 
of possible values that can be taken on by attribute Ai. The 
rule is constructed by the ant incrementally by adding one 
term at a time. The term selection is based on the probability 
as given by the following equation:
? ?
= =
= a
i
b
j
ijiji
ijij
ij i
tx
t
P
1 1
))(.(.
)(.
??
??
where ?ij is the value of a problem-dependent heuristic 
function for termij, the higher the value of ?ij the more 
relevant for classification the termij is, and so the higher its 
probability of being chosen. a is the total number of 
attributes. xi is set to 1 if the attribute Ai was not yet used by 
the current ant, or to 0 otherwise. bi is the number of values in 
the domain of the ith attribute.
B.  Heuristic value 
In traditional ACO, a heuristic value is usually used in 
conjunction with the pheromone value to decide on the 
transitions to be made. In Ant-Miner, the heuristic value is 
taken to be an information theoretic measure for the quality 
of the term to be added to the rule. The quality here is 
measured in terms of the entropy for preferring this term to 
the others, and is given by the following equation: 
))|(.log).|(()|( 21 ijiij
K
W iiji
VAWPVAWPVAWH ==?== ? =
where W is the class attribute (i.e., the attribute whose 
domain consists of the classes to be predicted).k is the 
number of classes. P(W|Ai=Vij) is the empirical probability of 
observing class W conditional on having observed Ai=Vij. The 
higher the value of H(W|Ai=Vij), the more uniformly 
distributed the classes are and so, the smaller the probability 
that the current ant chooses to add termij to its partial rule. 
The information-theoretic heuristic function is:   
? ?
= =
=?
=?
=
a
i
b
j
ijii
iji
ij i
VAWHkx
VAWHk
1 1
2
2
)|((log.
)|(log
?                  
where a, xi, and bi have the same meaning as in term 
selection equation. Immediately after the ant completes the 
construction of a rule, pruning is undertaken to increase the 
comprehensibility and accuracy of the rule. After the pruning 
step, the rule may be assigned a different predicted class 
based on the majority class in the cases covered by the rule 
antecedent. The rule pruning procedure iteratively removes 
the term whose removal will cause a maximum increase in 
the quality of the rule. The quality of a rule is measured using 
the following equation:
                         
TNFP
TN
FNTP
TPQ
++
= .
where TP(true positives) is the number of cases covered by 
the rule that have the class predicted by the rule, FP (false 
positives) is the number of cases covered by the rule that 
have a class different from the class predicted by the rule, FN 
(false negatives) is the number of cases that are not covered 
by the rule but that have the class predicted by the rule, TN 
(true negatives) is the number of cases that are not covered by 
the rule and that do not have the class predicted by the rule.
C.  Pheromone Update Rule 
After each ant completes the construction of its rule, 
pheromone updating is carried out as per the following 
equation:                                  
Qttt ijijij ).()()1( ??? +=+           Rji ?? ,        
where R is the set of terms occurring in the rule 
constructed by the ant at iteration t. In Ant-Miner, pheromone 
evaporation is implemented in an indirect way. More 
precisely, the effect of pheromone evaporation for unused 
terms is achieved by normalizing the value of each 
pheromone ? ij. This normalization is performed by dividing 
the value of each ? ij by the summation of all ? ij.
D.  Ant-Miner Parameter Setting
  The parameters used to achieve the results             
   Number of ants =  100
   Minimum cases per rule =   10
   Maximum uncovered cases = 10
   Number cases for rules converge = 10
E. A high-level description of Ant-Miner Algorithm
TrainingSet = {all training cases};
DiscoveredRuleList = [ ]; /* rule list is initialized with an 
empty list */
WHILE (TrainingSet > Max_uncovered_cases)
t = 1; /* ant index */
j = 1; /* convergence test index */
Initialize all trails with the same amount of pheromone;
REPEAT
Ant t starts with an empty rule and incrementally constructs a 
classification rule Rt by adding one term at a time to the
current rule;
Prune rule Rt;
Update the pheromone of all trails by increasing pheromone 
in the trail followed by Ant t (proportional to the quality of 
Rt) and decreasing pheromone in the other trails (simulating 
pheromone evaporation);
IF (Rt =  Rt – 1) /* update convergence test */
    THEN j = j + 1;
    ELSE j = 1;
END IF
t = t + 1;
UNTIL (i < No_of_ants) OR (j <  No_rules_converg)
Choose the best rule Rbest among all rules Rt constructed by 
all the ants;
Add rule Rbest to DiscoveredRuleList;
TrainingSet = TrainingSet - {set of cases correctly covered 
by Rbest};
END WHILE
F.  Comparative study 
The metaheuristic Ant-Miner algorithm has been 
compared with standard C4.5 algorithm. The experimental 
results show that Ant-Miner classifies the mammogram 
region with greater accuracy and with less number of rules 
than C4.5. Another observation made is the default rules used 
for classification in both the algorithm decreases the 
accuracy. Ten-fold cross validation has been done on the 
features extracted in the mammogram region by constructing 
coocurrence matrices at three different angles namely 0, 45
and 90.  Experimental results reveal that some of the cases 
which are misclassified by the default rule in one particular 
angle could be classified by the rules generated in other 
angles.
IV. THE PROPOSED DECISION MAKING ALGORITHM
 To the author’s knowledge there are studies focus on 
extracting features from co-occurrence matrix at different 
angles and combing all features to form feature set and then 
build classification models. There is only one study using 
mean and range of different features at different Angles 
namely (? = 00,450, 900,1350)[15].
The Ant-Miner algorithm has been applied to generate 
classifiers for the features generated over the co-occurrence 
matrix at different angles namely (? = 00,450, 900). These 
classifiers are used to make predictions of tumor as benign or 
malignant. Each classifier can be considered as a digital 
expert. If all digital experts generate the same outcome, then 
this would be the confident prediction. The predictions 
generated by all classifiers are often not identical, and 
therefore a decision making algorithms is needed.
A simple voting scheme has been used with each classifier 
having one vote. Thus the decision outcome with maximum 
number of votes is the predicted outcome. To be conservative 
if there is tie or no classifier can classify a particular case the 
outcome will be Unknown instead of giving any approximate 
classification using default rule. Figure 2 shows the 
diagrammatic representation of proposed decision making 
scheme.
Fig 2  Diagrammatic Representation of Proposed Decision-making 
Scheme
V. COMPUTATIONAL RESULT
Initial experiment was conducted to classify the 
mammogram region as normal and abnormal (abnormal 
includes benign and malignant).  The result shows the 
accuracy reaches 99% for the proposed method. In the second 
level the experiment has been extended to classify the region 
of abnormality as benign and malignant.  Since it is very 
difficult to interpret the region as benign and malignant there 
is a drop in the classification rate.
A.  Sample Rule Set
The rule set for Fold 3 at Angle 0 is given below
Number of Rules = 2
Rule  : 1
(Contrast   = low)  and  (Entropy  = high)  and  (MC1  = low) 
and  (SE = high)  : Malignant
Rule  : 2
(Contrast  = low)   and (Correlation = low)   and  (LM = low) 
and  (ASM =  low)  and  (MC2 = low)   :  Benign
Where 
MC1 – Measure of Correlation 1
SE- Sum Entropy
LM – Local Mean
ASM – Angular Second Moment
MC2 – Measure of Correlation 2
Table I reports the prediction given in various angle classifier 
and the voting scheme prediction.
TABLE 1
PREDICTION RESULTS AND OVERLAP ANALYSIS
B – Benign    A – Malignant   UK – Unknown  
For an independent angle analysis some of the 
mammograms remains unclassified that can be classified by 
the default class that decreases the classification accuracy. 
The Classification percentage, which is improved by the 
proposed algorithm  is illustrated in Table II.
TABLE II
CLASSIFICATION PERCENTAGE AT DIFFERENT ANGLES AND 
PROPOSED ALGORITHM (10 FOLDS)
The Classifier at different angles and the classification 
percentage is given in Table III.
TABLE III
AVERAGE CLASSIFICATION PERCENTAGE FOR 10 FOLDS
The results show that the cases which are not classified in 
one particular angle could be classified by the proposed 
algorithm with the greater accuracy. The graphical 
representation of the improvement in classification 
percentage is shown in Figure 3.
Fig  3  Classification Accuracy
VI. CONCLUSION
The result shows the significance of data mining in image 
processing. This system gives us more accurate result 
compared with the co-occurrence matrix constructed by 
independent angle. Also the malignancy which could not be 
classified under particular angle of co-occurrence matrix can 
be classified by the features extracted in other angles.  This 
paper proposes the decision making tree that considers the 
result in three different angles. The further study can be made 
to improve the classification accuracy using different feature 
set as an additional expert of the proposed algorithm.
REFERENCES
[1] T. Wang and N. Karayiannis, “Detection of Microcalcifications in 
Digital  Mammograms using Wavelets”, IEEE transactions on 
Medical Imaging, 1998, pp. 498-509.
[2] H. D. Li, M. Kallergi, L. P. Clarke, V. K. Jain, and R. A. Clark, 
“Markov Random Field for Tumor Detection in 
DigitalMammography”, IEEE Transactions on Medical Imaging, 
14(3), 1995, pp. 565-576.
[3] Maria-Luzia Antonie, Osmar R. Zaiane, and Alexandru Coman, 
“Application of Data Mining Techniques for MedicalImage 
Classification”, Proceedings of the Second International 
Workshop on Multimedia Data Mining (MDM/KDD `2001) in 
conjunction with Seventh ACM SIGKDD, USA, 2001, pp. 94-
101.
[4] Ioanna Christoyianni, Evalgelos Dermatas, and George 
Kokkinakis. “Fast Detection of Masses in Computer-Aided 
Mammography”, IEEE Signal Processing Magazine, 2000, pp. 
54-64.
[5] Osmar R. Zaine, Maria-Luzia Antonie, and Alexander Conman, 
“Mammography Classifications by an Association Rule Based 
Classifier” Proceedings of the Third International Workshop on 
Multimedia Data mining (MDM/KDD’2002) in conjunction with 
Eighth ACM SIGKDD, USA, 2002, pp. 62- 69.
[6] Vibha L, Venugopal K. R., and L. M. Patnaik, “A Study of Breast 
Cancer Using Data Mining Techniques”, Technical Report, 
University Visvesvaraya College of  Engineering, Bangalore 
University, August 2003.
PredictionsCase 
No. 00 450 900
Final
 Prediction Result
Mdb252 M M M M Match
Mdb253 B B UK B Match
Mdb256 M M M M Match
Mdb264 M M UK M Match
Mdb265 UK UK UK UK -
Mdb267 M M M M Match
Mdb270 B B UK B Match
Mdb271 M UK UK M Match
Mdb274 B B UK B Match
Mdb290 M M M M Match
Classification Percentage
Training 
Data Angle 
00
Angle 
450
Angle 
900
Proposed 
Algorithm
Fold 1 10% 10% 100% 100%
Fold 2 30% 60% 60% 100%
Fold 3 100% 60% 60%     100%
Fold 4 30% 40% 80% 90%
Fold 5 40% 30% 80% 50%
Fold 6   30% 10% 50% 100%
Fold 7 10%    30% 30% 30%
Fold 8 30% 70% 30% 100%
Fold 9 10% 50% 60% 70%
Fold 10 90% 80% 40% 90%
Classifier at 
different Angles
Average Classification 
Percentage for 10 Folds
Angle 0 38%
Angle 45 44%
Angle 90 59%
Proposed 
Algorithm 83%
[7] Andrew Kusiak, Bradley Dixon, Shital Shah, Predicting survival 
time for kidney dialysis patients : a data mining approach, 
Computers in Biology and Medicine 35 (2005) 311-327.
[8] Quinlan,J.R.: Simplifying decision trees  International Journal of 
Man-Machine   Studies, 27, 221-234, 1987.
[9] R. S. Parpinelli, H. S. Lopesand A. A. Freitas, “Data Mining with 
an Ant Colony Optimization Algorithm”, IEEE Transactions on 
Evolutionary Computing, Vol. 6, No. 4, 321-332, August 2002. 
[10] Jiawei Han and Micheline Kamber. Data Mining,Concepts and 
Techniques. Morgan Kaufmann, 2001.
[11] Haralick RM, Shanmugam K, Dinstein I. Textural features for 
image classification. IEEE Trans Syst Man Cybern 1973;SMC-
3:610–21. 
[12] Breiman,Friedman,Olshen,Stone, Classification and Decision 
Trees Wadsworth International Group, 1984.
[13] Dougherty J, Kohavi R, Sahami M. Supervised and unsupervised 
discretization of    continuous features. In: Proceedings of the 
12th international conference on machine learning.San Francisco: 
Morgan Kaufmann; (1995) pp 194–202.
[14] H. Liu, F. Hussain, C.L. Tan, and M. Dash, Discretization: An 
Enabling Technique. DMKD 6 (2002) 393-423. 
[15] A Karahaliou, S Skiadopoulos,  Boniatis, , P    Sakellaropoulos, 
P, E Likaki, , G Panayiotakis, and L Costaridou, Texture analysis 
of tissue surrounding microcalcifications on mammograms for 
breast cancer diagnosis, British Journal of Radiology , 80 (2007) 
648-656
