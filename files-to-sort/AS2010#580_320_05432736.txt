Efficiently Using Matrix in Mining  Maximum Frequent Itemset 
Liu Zhen-yu 
School of Traffic and Transportation 
Beijing Jiaotong University  
Beijing , China 
08114207@bjtu.edu.cn 
 
Xu Wei-xiang  
School of Traffic and Transportation 
Beijing Jiaotong University 
Beijing, china 
xu_weixiang@163.com 
Liu Xumin 
School of Information Engineering 
Capital Normal University 
Beijing, china  
liuxumin@126.com 
 
 
Abstract—an efficient way to discover the maximum 
frequent itemset can be very useful for mining association 
rules, correlations, episodes patterns, etc. Most existing work 
focuses on the technique for mining candidate maximal 
frequent itemset and ignores the technique for MFI 
checking. However the efficient of a MFS mining algorithm 
lies on these two parts. In this paper, a new MFI checking 
method is presented based on the optimizing of the former 
called MaxMatrix and an additional constraint for 
association rules generating is discussed to save mining time. 
In order to understand the process of MaxMatrix easily, an 
example is provided in detail. 
Keywords-maximum Frequent itemset; MFI checking; 
MaxMatrix; Association Rules 
I.  INTRODUCTION  
Frequent itemset mining has been recognized as a 
fundamental and essential problem in many data mining 
tasks including association rules mining, sequential 
patterns mining, correlations, and multi-dimensional 
patterns et al. A frequent itemset is a set of items appearing 
together in a number of database records meeting a user-
specified threshold. 
Starting with the pioneering work in [1,2], itemset 
mining algorithm has been studied extensively by 
researchers. Many of the proposed itemset mining 
algorithms are a variant of Apriori, which employs a 
bottom-up level-wise search in the itemset lattice that 
enumerates every possible single frequent itemset. This 
implies candidate k+1-itemsets are generated only after all 
k-itemsets have been generated. For each level, all 
candidate itemsets are tested for frequency by scanning the 
database. 
The drawback of mining all frequent itemsets is that in 
order to produce a frequent itemset of length l, all l2 of its 
subsets must be enumerated, which is computationally 
unfeasible. Thus there has been recent interest in exacting 
only the maximal frequent itemset, because the set of all 
maximum frequent itemsets is orders of magnitude smaller 
than the set of all frequent itemsets. An itemset is maximal 
frequent if it has no superset that is frequent. Wherever 
there are very long patterns (pattern contains many items) 
are presented in the data, it is often impractical to generate 
the entire set of frequent itemsets [3]. Also, in some 
situations it is sufficient to mine the maximal frequent 
itemsets rather than all the frequent itemsets. We will use 
MFS to denote the set of the maximal frequent itemsets, 
and MFI to denote one maximal frequent itemset.  
Therefore, many algorithms [3,4,5,6,7] have been 
proposed for generating MFS directly instead of all the 
frequent itemsets to “shortcut” the process. In general, a 
MFS mining algorithm includes two main parts. The first 
is the techniques to find candidate maximal frequent 
itemset efficiently, and the second is the methods used to 
perform fast MFI checking to eliminate non-maximal 
itemsets. However, the second part MFI checking hasn’t 
drawn adequate attention. This paper is written with the 
primary aim of developing a method for fast maximality 
checking. 
In this paper a new method is proposed called 
MaxMatrix which uses the pseudo-projection matrix of the 
MFS matrix to do MFI checking. It can not only test fast, 
but also significantly save resources. Because only logical 
operation is used to delete the related ranks of the matrix 
for testing the candidate MFI in algorithm MaxMatrix, it 
does not need to allocate new memory space for pseudo-
projection matrix. An all-confidence constraint is also used 
to facilitate the further generation of association rules from 
MFS if necessary. 
A. Related Work 
There are considerable researches on methods for 
generating the set of maximal frequent itemsets. 
Lin and Kedem [4] proposed an algorithm called 
Pincer-search for mining maximal frequent itemsets. It 
combines both the bottom-up like Apriori and top-down 
directions to maintain and update the maximal frequent 
candidate set which do not contain any known infrequent 
itemset. This method can help in reducing the number of 
database scans by eliminating non-maximal set early. But 
the overhead of maintaining the candidate maximal 
frequent set can be very high. 
MaxMiner [3] also mines only maximal elements. It 
abandons a strict bottom-up traversal of the search space, 
and instead always attempts to “look ahead” in order to 
quickly identify maximal frequent itemsets. i.e., if a node 
with all its extensions can be determined to be frequent, 
there is no need to further process that node. It also 
employs item order based on support instead of the 
lexicographic order to keep the search space as small as 
possible. Though these strategies reduce the search time 
dramatically, MaxMiner still needs many passes over 
datasets to get all maximal frequent itemsets. 
DepthProject [5] finds long patterns by using depth-
first search on a lexicographic tree of itemsets. It uses 
bitvector and hierarchical projections to make the process 
of support counting more efficient. A bitvector contains 
the information about transactions which contain the 
itemset for a node as a subset. By using hierarchical 
projections, it can reuse the information from counting k-
itemset to count (k+1)-itemsets. It also uses an effective 
2010 Third International Conference on Knowledge Discovery and Data Mining
978-0-7695-3923-2/10 $26.00 © 2010 IEEE
DOI 10.1109/WKDD.2010.27
50
lookahead strategy in order to avoid creation of those 
subtrees of the lexicographic tree which contain only non-
maximal itemsets. 
MAFIA[6] also uses the depth-first search strategy for 
mining maximal frequent itemsets from transactional 
database like DepthProject. It integrates a variety of old 
and new algorithmic ideas to improve performance, such 
as three type of pruning ideas to trim the tree including 
PEP, FHUT(also used in MaxMiner and DepthProject) and 
HUTMFI, dynamic reordering the children of each node 
and a compression form of vertical bitmap representation 
for the database. 
In general, these methods are all trying to improve the 
performance for mining maximal frequent itemset and 
have varying performance depending on the database 
characteristics mainly the distribution of maximal frequent 
patterns by length. While they all maintain a superset of 
the MFI and would require post-pruning, it is not clear 
how these algorithm would do maximality checking 
efficiently.  
GenMax [7] uses a novel technique called progressive 
focusing to perform maximality checking and diffset 
propagation to perform fast frequency computation in the 
process of mining to mining exact MFI. But it needs to 
construct a list of local maximal frequent itemsets which is 
most relevant superset of candidates. G.Grahne and J.Zhu 
proposed a MFI-tree in [8,9] to store all MFI, which is 
constructed like FP-tree [10] and returns all and only the 
maximal frequent itemsets. However, for large datasets, 
the MFI-tree will be quite large, so one itemset may need 
thousands of comparisons for subset testing. 
In this paper, the algorithm MaxMatrix will integrates 
pruning of non-maximal itemsets in the process of mining 
using matrix of MFS to maintain an exact set of maximal 
frequent itemset, which is proved to be an efficient 
method. 
B. Overview 
The organization of the rest of the paper is as follows. 
Section 2 discusses the conceptual ideas of the MFS 
mining problem and the principle of MFI checking of 
MaxMtrix. In section 3, we provide a pseudo-code 
description of MaxMatrix and implementation details 
about how it uses pruning techniques to restrict the search 
space. Section 4 discusses the integration of all-confidence 
constrains into the generation of association rules from 
MFS. The algorithm is illustrated with an example in 
section 5. Section 6 discusses the conclusions and 
summary. 
II. PRELIMINARIES 
A. Terminology Defining 
Let { }miiiI ,,, 21 "=  be a set of m distinct items. A 
database D  is a set of transactions that are sets over item 
domain I . Each transaction is associated with a unique 
identifier, called TID . A set of items is more succinctly 
called an itemset. An itemset with k  items are referred as 
k -itemset. The support of an itemset IX ? , denoted 
)sup(X , is the fraction of the transactions in D  that contains 
all items of X . An itemset is frequent if its support is 
above or equal to the minimum support(minsup) 
predefined by the user. Otherwise, it is infrequent. 
We will use generic set-enumeration tree search 
framework [3] to search each MFI. The idea is to expand 
sets over an ordered and finite item domain as illustrated in 
figure1, where five items { }EDCBA ,,,, are denoted by 
their position in the ordering. We assume that a lexical 
ordering exists among the items in the database. The item-
name is replaced with item-number in order to facilitate 
the construction and pseudo mapping of MFS-matrix 
(defined in section 2.3). MaxMatrix constructs the set 
enumeration tree mainly in depth-first order for finding the 
exact MFI. Figure1 also shows the itemset frequency 
testing order in the process of MFS mining by the number 
on the top-right side of the itemset. 
 
 
A candidate group 2g is employed to represent each 
node in the set-enumeration tree like [3] at the initial step 
of algorithm MaxMatrix. A candidate group 2g  consists of 
head )( 2gh  and tail )( 2gt . )( 2gh represents the itemset 
enumerated by the node and )( 2gt is an lexical ordered set 
containing all items not in )( 2gh which can potentially 
appear in )( 2gh ’s sub-node. 
B. Initialization 
Figure 1 shows the tree does not grow in pure depth-
first order. A hash technique of the DHP [11,12] is used to 
initialize the step of group. A direct-addressing hash table 
H2 and hash function ??
=
??+?=
1
1
1)()(),(
x
i
xyiNyxh , are 
illustrated in figure2. N is the amount of the item and 
5=N  in figure 2. 
 
item- 
name
A 
B 
C 
D 
E 
item- 
number
1 
2 
3 
4 
5 
itemset 
2H hash address
1,2 0 
1,3 1 
"  "
3,5 8 
4,5 9 
 
Figure2. Example of H2 generation 
C. MFS Checking Based Matrix 
First we need to construct a MFS-matrix, each row of 
which represents a frequent item ordered according to 
lexical sequence. Every determined MFI will be added in 
the matrix as a new column, of which the element 
corresponding to item included in MFI will be set to 1 and 
??
=
+?=
1
1
)(),(
x
i
iNyxh  
     1)( ?? xy  
{}0 
11 21 31 41 
1,21 1,31 1,41 2,31 2,41 3,41 
1,2,32 1,2,42 1,3,46 1,3,56 
1,2,3,43 
Figure 1.  set enumeration tree for searching 
51
1,51 2,51 3,51 
1,2,52 1,4,58 2,3,49 2,4,511 3,4,512
4,51
1,2,3,53 1,2,4,55 1,3,4,57 2,3,4,510 
1,2,3,4,54
2,3,59 
51
others set to 0, so each column represents a MFI. For each 
candidate MFI X , pseudo projection is operated on MFS-
matrix to check whether it has a superset in MFS-matrix. If 
item Xi ? , the columns of MFS-matrix is shielded, of 
which the ith element equal to 0. Iterating the shield 
process from the last item to the first one of X , a pseudo 
projection matrix ? of the original MFS-matrix will be 
obtained. If ? = ? , it verifies there is not a superset of X , 
and if X is frequent then X is a MFI, X will be added to 
the original MFS-matrix; otherwise X is not a MFI, the 
iteration will be continued until no candidate MFI is 
produced.  
Since the mapping is based on the designated ranks, it 
does not require new memory space to storage new matrix. 
It just needs to establish a vector to shield the 
corresponding ranks in MaxMatrix, which can save 
memory greatly. 
III. PSEUDO-CODE FOR MAXMTRIX 
MaxMatrix consists of four parts as follows. 
1) In the first round, scan the database D to count the 
support of all 1-item sets and build a hash table H2; 
2) Generate L1 and L2 
3) Geberate first-level and second-level nodes of 
search tree; 
4)  MFS-searching algorithm and MFI checking. 
The pseudo-code of MaxMatrix algorithm is given 
below: 
 
MaxMatrix Algorithm() 
 Begin 
 //generate the initial candidate node 2g  
1 for each itemset 
2Fxx ji ?  generate a new candidate 
group 2g  
2    let ji xxgh =)( 2  
3       =)( 2gt { ,2Fxxk ki ? k follows j in the ordering} 
 //invoke as MFI-search( 2,, 22 CI ) for current node 2I  
4 for each 2gx ?  
5  Let )(.2 xhxI = , )(.2 xtxP =  
6  
2C =Tail-gen ( 22 , PI ) 
7  MFI-search( lCI ll ,, ) 
//function MFI-search( lCI ll ,, ) until ?=lC  
8 MFI-search( lCI ll ,, ) 
9 for each lCx ?  
10   }{1 xII ll ?=+  
11   }{1 xyandCyyP ll >?=+  
12    While flag=0 do 
13   {If 11 ++ ll PI ? has a superset in MFS-marix 
14         return// all subsequent branches pruned} 
15     =+1lC Tail-gen( 11, ++ ll PI ) 
16           if 1=C and flag=1 
17               {put 11 ++ ll CI ?  in MFI 
18                  let ?=lC } 
19           if 1=C and flag=0 
20           if 11 ++ ll CI ? has a superset in MFS-matrix 
21                 return// all subsequent branches pruned 
22            put 11 ++ ll CI ?  in MFS-matrix  
23                    return// all subsequent branches pruned 
24           if 0=C  
25            if 1+lI has no superset in MFS put 1+lI in 
MFS-matrix  
26        else MFI-search( 1,, 11 +++ lCI ll ) 
//can 1+lI joint with other item in lC  
27 Tail-gen( 11 , ++ ll PI ) 
28 ?=C  0=C  flag=1 
29  for each 1+? lPy  
30     if sup( }{1 yI l ?+ ) ? minsup 
31        if sup( }{1 yI l ?+ )=sup( 1+lI )   
32          }{11 yII ll ?++ =  
33        else{ yCC ?=  
 34             1+= CC } 
 35     else flag=0 
End 
 
MaxMatrix employs PEP (lines 30-32) and HUTMFI 
(lines 12-14) pruning strategies. PEP has the biggest effect 
of the pruning method on the performance gains proved in 
[6]. HUTMFI proposed also in [6] determines whether a 
superset of the HUT is in the MFS, and thus it ensures the 
exact MFI generated without post-pruning and can prune 
some branches early to reduce search space. If a superset 
does exist, then the HUT must be frequent and the subtree 
rooted at the node can be pruned away.  
Many algorithms adopt support increasing order to 
dynamically reorder the children of each node, such as, 
MaxMiner, MAFIA, GenMax etc. There are also 
algorithms adopting support descending order [9,10]. 
While ordering strategy isn’t always an effective means of 
cutting down the search space, since the effect of item 
ordering is very much dependent upon the characteristics 
of the data sets. Here, MaxMatrix constructs search tree 
based on lexical order in order to facilitate the MFI 
checking with MFS-matrix. 
To avoid redundancy generated during each recursive 
superset checking, items’ count C  of 1+lC and a status flag 
are used. If flag is true, it implies no items are deleted 
from 1+lP . That is, ll PI ?  of current node is the same 
as 11 ++ ll PI ? , so superset checking do not needed to operate 
again (lines 12-14). If flag is true and C =1, we can inset 
11 ++ ll CI ?  into MFS directly and end current lI ’s extension 
(lines 16-18). If flag is false and C =1, 11 ++ ll PI ? will be 
performed superset checking subsequently without the 
need to return to MFI-search() (lines 19-23). 
IV. FURTHER CONSTRAINT FOR ASSOCIATION RULE 
MINING 
Though the frequent patterns themselves are often of 
interest to the decision maker, they often need to be 
transformed further before being presented for 
understanding. The problem of mining association rules is 
to generate all rules that have support and confidence 
greater than some user specified minimum support and 
 
52
minimum confidence thresholds respectively. The 
confidence of a rule YX ? is defined as the 
ratio )sup(/sup( XYX ? . So in order to find those 
association rules with high confidence, another database 
pass is required after finding all maximal frequent itemsets 
to obtain the supports of all frequent itemsets for 
producing association rules. If some frequent itemsets are 
long, this step will be very costly [3]. To solve this 
problem, we incorporate an additional constraint called 
all_confidence into MaxMatrix for association rules 
searching from MFS. This constraint is quite powerful 
since all_confidence ensures a lower bound on confidence 
for any rule of an itemset by which we can further reduce 
the number of subset of MFI to be counted.  
All_confidence is defined as the minimum confidence 
of all the association rules that can be derived from the 
itemset X , which is formulated as follows [13]. 
})max{sup(
)sup()(
Xii
XXallconf
jj ??
=
                         (1) 
A pattern that has all_confidence of no less than a 
given minimum confidence threshold? , indicates a high 
correlation among all the items in the pattern. This is 
because all association rules derived from the pattern have 
confidence of no less than? , as implied by (1). 
All_confidence has a desirable property for the 
efficient mining of all association rules from MFS. The 
property called the downward closure property [13] can be 
directly adapted as effective pruning tools for mining 
association rules, which is formally stated as follows. 
Property1. (Downward closure property of 
all_confidence) 
Given two itemsets, X  and Y , if YX ?  
then )()( YallconfXallconf ? . 
By property 1, we are able to perform the following 
pruning: if a pattern X  has an all_confidence value no less 
than? , then the all-confidence of all its subset will greater 
than? , so we can get the association rules directly without 
counting the supports of these subset.   
V. EXAMPLE 
The process of MaxMatrix is given in figure3 with 
minsup=2, ? =0.5 and initial MFS-matrix= ? . The fist 
time scanning of D returns 1C and 2H . Comparing 
1C and 2H with minsup, 1F and 2F can be determined. Based 
on the items in 2F , itemgroup 2g can be acquired. Then the 
MFS search tree for the database D  is constructed like 
figure 1, in which itemsets painted with sloping line are 
MFIs and itemset below dashed line are infrequent 
itemsets. MFS searching starts from the second level. For 
example, when =2I 1,2 and =2P 3,4,5, through the Tail-
gen(), 5,4,32 =C .Though the first calling of the function 
     
 
 MFS-search(), 3,2,13 =I  and 5,43 =P is produced. 
5,4,3,2,133 =PI ? is checked subsequently whether it has a 
superset in MFS. As MFS-matrix= ? , 
5,4,3,2,133 =PI ? doesn’t have a superset in MFS and 
53 =C from Tail-gen ( 33 ,PI ). In this phase, =C 1 and 
flag=0, so 5,3,2,133 =CI ?  will be checked whether it has 
a superset in MFS. Similarly, it doesn’t have a superset in 
MFS. 5,3,2,133 =CI ? will be added in MFS-matrix as a 
Figure3   the mining process of MaxMatrix 
53
MFI. The node 3,2,13 =I extension is finished. Then the 
function MFS-search( lCI ll ,, ) will be called repeatedly 
until all the nodes are checked or ?=lC .  
The checking process with MFS-matrix is showed in 
figure4 when 5,3,233 =PI ? . First, starting from the last 
item 5 of 33 PI ? , the column of the original matrix 
figure4(a) with the fifth element equal to 0 is shielded, 
then the matrix figure4(b) is obtained. Second, to the 
second item 3 from back to front of 33 PI ? , the column 
with the third element equal to 0 is shielded and matrix 
figure4(c) is generated. Third, to the last item from back to 
front, the column is shielded with the second element 
equal to 0 and matrix figure4(d) is produced, which is the 
final pseudo projection matrix ? . Because ? ?? , 
5,3,233 =PI ?  is not a MFI. 
 
 
??
??
??
?
?
??
??
??
?
?
0
1
1
1
0
1
1
0
1
1
1
0
1
1
1
5
4
3
2
1
 
5
3
2
   
??
??
??
?
?
??
??
??
?
?
1
1
0
1
1
1
0
1
1
1
5
4
3
2
1
 
5
3
2
   
??
??
??
?
?
??
??
??
?
?
1
0
1
1
1
5
4
3
2
1
 
5
3
2
     
??
??
??
?
?
??
??
??
?
?
1
0
1
1
1
5
4
3
2
1
 
5
3
2
 
a                         b                    c                      d 
 
Figure4  MFS-matrix pseudo projection based 5,3,233 =PI ?  
 
Through the iteration calling of the function MFS-
search() and MFI checking with MFS-matrix, MaxMatrix 
can get all the exact MFI without post-pruning. In this 
example, MFS  is ( ) ( ){ }4,3,2,5,4,2,1),5,3,2,1( . 
If we need to get all the association rules of the 
database D , we could compute all_confidence of every 
MFI in MFS firstly. For example, 33.0)5,3,2,1( =allconf , 
50.0)5,4,2,1( =allconf , and 33.0)4,3,2( =allconf  from 
the formula (1). Since 50.0)5,4,2,1( =allconf ? ? , all the 
association rules exacted from the pattern are interesting 
and it does not need to count the supports of its subset. 
VI. CONCLUSION 
This paper present an efficient MFI mining algorithm 
MaxMatrix based on the analysis of the previous work, 
which mainly relies on a depth-first search technique to 
construct the lexical set enumeration tree of itemsets. The 
algorithm is optimum through hash technique at initial 
stage, node pruning with PEP and HUTMFI and some 
means avoiding redundancy. At the same time, it uses 
MFS-matrix to do superset and MFI checking during the 
hole searching process efficiently. An additional constraint 
for discovering association rules from MFS is also 
discussed, which can save a lot of time for counting the 
support of the subset of MFI. MaxMatrix can reduce both 
the time the exact MFI is generated and the number of 
subset considered for association rule mining. 
ACKNOWLEDGMENT 
The authors gratefully acknowledge the editor and 
anonymous reviewers for their valuable comments and 
constructive suggestions. This research was supported by the 
Beijing Municipal Science & Technology Commission key 
project (Z090506006309011) and the Beijing Educational 
Committee science and technology develop plan key 
project (KZ200710028014). It was partially supported by 
the MOE key Laboratory for Transportation Complex 
Systems Theory and Technology School of Traffic and 
Transportation Beijing Jiaotong University. 
REFERENCES 
[1] R. Agrawal, T. Imielinski, A. Swami. Mining Association Rules 
between Sets if Items in Very Large Database. ACM SIGMOD 
Conference Proceedings, pages 207-216, 1993. 
[2] R. Agrawal, R. Srikant. Fast Algorithms for Mining Association 
Rules. VLDB Conference Proceedings, pages 487-499, 1994. 
[3] R. J. Bayardo. Efficiently Mining Long Patterns from Databases. 
ACM SIGMOD Conference Proceedings, pages 85-93, 1998. 
[4] D. Lin, Z. M. Kedem. Pincer-search: A New Algorithm for 
Discovering the Maximum Frequent set. The Six European 
Conference Proceedings on Extending Database Technology, Mar, 
1998. 
[5] R. Agrawal, C. Aggarwal, and V. Prasad. Depth First Generation 
of Long Patterns. ACM SIGKDD Conference Proceedings, Aug. 
2000. 
[6] D. Burdick, M. Calimlim, and J. Gehrke. MAFIA: A Maximal 
Frequent Itemset Algorithm for Transactional Databases. In Intl. 
Conf. on Data Engineering, Apr. 2001. 
[7] K. Gouda, M.J. Zaki. Efficiently Mining Maximal Frequent 
Itemsets. In 1st IEEE International Conference on Data 
Mining(ICDM), pages 163-170, San Jose, Nov. 2001. 
[8] G. Grahne and J. Zhu. High Performance Mining of Maximal 
frequent itemsets. In SIAM’03 Workshop on High Performance 
Data Mining: Pervasive and Data Stream Mining, May 2003. 
[9] G. Grahne and J. Zhu. Efficiently Using Prefix-trees in Mining 
Frequent Itemsets. First workshop on Frequent Itemset Mining 
Implementation (FIMI’03), Melbourne ,FL,2003 
[10] J. Han, J. Pei, and Y. Yin. Ming Frequent Patterns without 
Candidate Generation. In Proceeding of Special Interest Group on 
Management of Data, pages 1-12, Dallas, TX, May 2000. 
[11] J. S. Park, M. S. Chen, and P. S. Yu. Using a Hash-based Method 
with Transaxtion Trimming for Mining Association Rules. IEEE 
Trans on Knowledge and Data Engineering, pages 813-825, 1997, 
9(5). 
[12] Zhang Min-cong, Yan Cun-liang, and Zhu Kai-yu. A New Hybrid 
Algorithm for Association Rule Mining. Journal of Donghua 
University, Vol. 24, No. 5, 2007. 
[13] E. R. Omiecinski. Alternative Interest Measures for Mining 
Associations in Databases. IEEE Trans on Knowledge and Data 
Engineering, pages 57-69, 2003, 15(1). 
 
54
