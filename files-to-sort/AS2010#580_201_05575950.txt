Efficient Algorithm for Discovering Potential Interesting Patterns with 
Closed Itemsets 
 
Raj Singh 
School of Science &  Comp. 
Engineering 
Univ. of Houston Clear Lake, 
Houston, TX 77058 
singhr@uhcl.edu
Tom Johnsten 
School of Comp. & Informa-
tion Sciences 
Univ. of South Alabama 
Mobile, AL 36688 
tjohnsten@usouthal.edu
Vijay Raghavan 
Center of Advanced Computer 
Studies 
Univ. of Louisiana at La-
fayette, LA 70504 
raghavan@louisiana.edu 
Ying Xie 
Dept. of Computer Science & 
Information Systems 
Kennesaw State Univ. 
Kennesaw, GA 30144 
yxie2@kennesaw.edu
 
 
Abstract 
 
A pattern discovered from a collection of data is usual-
ly considered potentially interesting if its information 
content can assist the user in their decision making 
process. To that end, we have defined the potential 
interestingness of a pattern based on whether it pro-
vides statistical knowledge that is able to affect one’s 
belief system. In previous work, we proposed two novel 
algorithms, Discovering All Potentially Interesting 
Patterns (DAPIP) and All-Confidence Discovery of 
Potentially Interesting Patterns (ACDPIP), designed to 
discover potentially interesting patterns from a collec-
tion of data. Results of experimental investigations 
show that the application of these two algorithms is 
limited to non-dense datasets.  
In response, we propose a new algorithm, referred to 
as ACDPIP-Closed, designed to discover potential 
interesting patterns from dense datasets. We show em-
pirically that ACDPIP-Closed is able to effectively and 
efficiently discover potentially interesting patterns 
from dense datasets. Additional contributions provided 
by the paper include a definition of a frequent closed 
itemset based on an all-confidence threshold and a 
theorem stating that, under the assumption of a partic-
ular ordering of items, an itemset is support based 
closed if and only if it is all-confidence based closed. 
 
1. Introduction 
 
We previously proposed two algorithms, Discovering 
All Potentially Interesting Patterns (DAPIP) and All-
Confidence Discovery of Potentially Interesting Pat-
terns (ACDPIP) which are designed to discover two 
types of potentially interesting patterns from a collec-
tion of data [7]. These two types of patterns, referred to 
as positive and negative patterns, provide statistical 
knowledge that is able to affect one’s belief system 
[9].In other words, if a pattern changes a user’s belief 
system, then it has the potential to guide the user into 
acting differently in the future. The DAPIP algorithm is 
a non-heuristic search algorithm that ensures the dis-
covery of all positive and negative patterns satisfying a 
given set of constraints. Its application requires the 
specification of relatively small support thresholds for 
generating itemsets and therefore its use is limited to 
small, non-dense datasets. The ACDPIP algorithm, 
unlike DAPIP, generates itemsets based on an all-
confidence threshold instead of a support threshold.  
The all-confidence value of an itemset, I, represents the 
minimum confidence of a rule (pattern) that can be 
generated from the itemsets in I [5]. This measure has 
the desirable anti-monotonic property: if an itemset I 
does not satisfy a given all-confidence threshold, then 
no super itemset of I will satisfy the threshold. Results 
of experimental investigations show that ACDPIP sig-
nificantly outperforms DAPIP in terms of execution 
time and provides adequate levels of coverage with 
respect to the discovery of positive and negative pat-
terns. Unfortunately, the investigations also showed 
that its application is limited to non-dense datasets. For 
example, when applied to the dense datasets such as 
mushroom and breast cancer
1
 its performance is unac-
ceptable in terms of execution time and completeness 
of positive and negative patterns discovered.  
The current state of the art in discovering positive 
and negative patterns parallels the early history of as-
sociation rule mining in which the discovery process 
was limited to non-dense datasets. More recently pro-
posed association rule mining algorithms have over-
come this limitation, in part, through the developed 
concepts of frequent maximal and closed itemsets.  
In this paper, we propose an alternative form of the 
ACDPIP algorithm, referred to as ACDPIP-Closed that 
generates non-redundant positive and negative patterns 
from a set of frequent closed itemsets. We show empir-
ically that ACDPIP-Closed can successfully discover 
positive and negative patterns from dense datasets. 
Additional contributions of the work include a defini-
tion of a frequent closed itemset based on an all-
                                                                                       
1
 http://archive.ics.uci.edu/ml/datasets.html 
2010 IEEE International Conference on Granular Computing
978-0-7695-4161-7/10 $26.00 © 2010 IEEE
DOI 10.1109/GrC.2010.55
414
confidence threshold and a theorem stating that, under 
the assumption of a particular ordering of items, an 
itemset is support based closed if and only if it is all-
confidence based closed. The rest of this paper is orga-
nized as follows. Section 2 highlights the unique con-
tributions of our work by comparing it to related work. 
Section 3 develops the theoretical foundation that faci-
litates the discovery of non-redundant positive and 
negative patterns. Section 4 presents the details of the 
ACDPIP-Closed algorithm and Section 5 presents the 
results of experiments conducted to assess its perfor-
mance. Finally, Section 6 provides a summary of the 
work. 
 
2. Related Work 
 
In [9] we have considered the problem of discovering 
potentially interesting patterns (rules) from a dataset D 
consisting of N transactions {t1, t2, …, tN}, where each 
transaction ti ? I and I is a set of items {i1, i2, …, ik} 
over which the transactions are defined. We assume the 
standard definition for the support (supp) of an itemset 
and for the confidence (conf) of a rule.  
We define a binary relation ? on I, such that for any 
pair of itemsets Qi, Qj ? I, we have Qi ? Qj ? Qi,= Qj ^ 
i, where i ? I. The itemset Qi is referred to as the parent 
of Qj whenever Qi ? Qj. Finally, given a rule Q?A 
where Q, A? I, the quantity supp(Q) = n is referred to 
as the noise controller. 
 
Definition 2.1 Potentially Interesting Pattern 
Let Q ? I, A ? I and Q ? A = ?.  
A rule Q?A is called a positive pattern if one of the 
following two conditions holds: 
1. conf(Q ?A) – supp(A) ? s, given: Q ? I, |Q| > n, 
and 0 ? s ? 1. 
2. conf(Q?A) – max1?i?j [conf(Pi ?A)] ? s, given: 
Q ? I, |Q| > n, itemsets P1, P2, …, Pj are all the 
parent itemsets of Q, and 0 ? s ? 1 
 
A rule Q?A is called a negative pattern if one of the 
following two conditions holds: 
1. supp(A) - conf(Q?A) ? s, given: Q? I, |Q| = n, 
and 0 ? s ? 1. 
2. min[conf(Pi ?A)] – conf(Q ? A) ? s, given: Q ? 
I, |Q| > n, itemsets P1, P2, …, Pj are all the parent 
itemsets of Q, and 0 ? s ? 1. 
 
The parameter s is called the significance controller 
and it intuitively represents the minimum degree of 
statistical change that a pattern must provide in order 
for it to be classified as potentially interesting. Both 
positive and negative patterns represent potentially 
interesting information. For example, a pattern with 
confidence of 30% will typically be deemed uninterest-
ing. However, consider the following situation: the 
conf(B?A) is 1% or 80% and conf(B^C?A) is 30%, 
where A is some kind of disease; B denotes some popu-
lation and B^C is a subpopulation of B. Now one may 
conclude that the latter pattern is potentially useful. 
The work by Bayardo et al. [3] on the concept of a 
minimum improvement constraint is very similar to the 
notion of a positive pattern. However, their proposed 
algorithm requires the consequent of a rule to be speci-
fied in advance. The existing algorithms DAPIP and 
ACDPIP and the proposed algorithm ACDPIP-Closed 
do not have this constraint. 
Several published papers have reported on work re-
lated to the discovery of potentially interesting, de-
scriptive rules from a collection of data. The previous 
work most closely related to the work presented in this 
paper includes the notion of exception rules [4, 8] and 
peculiarity rules [10]. Specifically, the definition of a 
positive pattern includes peculiarity rules, but also in-
cludes other potentially interesting patterns that are not 
instances of such a rule. Likewise, the definition of a 
negative pattern can be viewed as a generalization of 
an exception rule. 
The use of frequent closed itemsets to generate asso-
ciation rules has been studied by a number of research-
ers [2, 6]. The primary focus of their work has been to 
use frequent closed itemsets to produce generating sets 
of association rules. A generating set represents a non-
redundant collection of interesting association rules 
from which all other interesting rules can be derived. In 
the next section, we present a formal framework that 
provides the basis for the discovery of non-redundant 
positive and negative patterns. Generally speaking, a 
positive (or negative) pattern will be considered non-
redundant if its confidence is sufficiently larger (or 
smaller) than the confidence of patterns (rules) belong-
ing to a corresponding reference set.  
 
3. Problem Formulation 
 
Researchers have improved the efficiency of discover-
ing association rules through the use of frequent closed 
itemsets. Unfortunately, the discovery of positive and 
negative patterns is limited when itemsets are generated 
based on a support threshold. This fact has lead to the 
design of the ACDPIP algorithm which generates item-
sets based on a given all-confidence threshold. Hence, 
an interesting research question is the following: Can 
the efficiency of ACDPIP be improved, without sacri-
ficing its effectiveness, through the use closed item-
sets? The answer to this question is yes and the expla-
nation is provided in the remaining sections. To that 
end, we present a set of formal definitions, an impor-
415
tant theorem, and the design of an efficient algorithm 
that discovers positive and negative patterns through 
the generation of all-confidence based frequent closed 
itemsets. 
 
Definition 3.1 Parent rule 
If  X ^ Y  Z is an interesting rule then  X  Z and Y 
 Z are parent rules of X ^ Y  Z. 
 
Definition 3.2 Frequent Closed Itemset (Support-
Based)  
An itemset X is called a closed itemset if there exists no 
itemset X’ such that  
1. X’ is a proper superset of X, and  
2. sup(X’) = sup(X). 
If condition (1) and (2) hold for X’, then X’ can be a 
closed itemset. A closed itemset X is a closed frequent 
itemset (CFI) if it is frequent; that is, if sup(X) ? supp, 
the minimum support threshold. 
We now define a novel approach to generate closed 
itemsets. We defined a new approach to generate fre-
quent itemset with all-confidence [7]. Similarly we can 
generate closed itemsets.  
 
Definition 3.3 All-confidence based Frequent Closed 
Itemset 
An itemset X is called a closed itemset if there exists no 
itemset X’ such that  
1. X’ is a proper superset of X, and  
2. all-conf(X’) = all-conf(X). 
If condition (1) and (2) hold for X’, then X’ can be a 
closed itemset. A closed itemset X is an all-confidence 
closed frequent itemset (ACFI) if it is frequent accord-
ing to minimum all-confidence threshold; that is, if all-
conf(X) ? all-conf-supp. 
 
Definition 3.4 Redundant rule 
A rule or a pattern is considered redundant if its confi-
dence is not sufficiently different (by having a confi-
dence value that is different by the significance thre-
shold value, s) from that of its parent rule(s). 
 
Definition 3.5 Positive LHS redundancy 
A pattern P1 is positive LHS redundant if the differ-
ence of its confidence from the MAX of its parent 
rules’ confidences is <= s. 
 
Example 3.1 Given frequent itemsets {A,B,C,D}, 
{A,E,C,D}, and {B,E,C,D} that are not closed, sup-
pose that there is a frequent closed super-itemset 
{A,B,C,D,E}. 
Compare the confidence (s) of the following pat-
terns. 
a. (A^B)   (C^D)      (generated from {A,B,C,D}) 
b. (A^E)  (C^D)       (generated from {A,E,C,D}) 
c. (B^E)  (C^D)       (generated from {B,E,C,D}) 
d. (A^B^E)  (C^D)  (generated from  {A,B,C,D,E}) 
From definition 2.1, pattern P1 (d) is a positive pat-
tern if: [C^D | A^B^E] – MAX ([C^D | A^B], [C^D | 
A^E], [C^D | B^E]) > s. 
Hence, the use of closed itemset generates a positive 
rule P1 having sufficiently larger confidence with re-
spect to rules whose LHS are parents of itemset 
{A,B,E}. In particular, if Support({A,B,C,D} =  Sup-
port({A,B,C,D,E}, then the increase  in confidence is 
0, which is < s. In this case, if only closed frequent 
itemsets are kept at the itemset generation stage, then 
itemset {A, B, C, D} will not get generated. However, 
the rule (A^B)   (C^D) will be generated from the 
closed frequent itemset {A,B,C,D,E} during the rule 
generation step. 
 
Definition 3.6 Cegative LHS redundancy 
A pattern P2 is negative LHS redundant if the differ-
ence of its confidence from the MIN of its parent rules’ 
confidences is < = s. 
 
Example 3.2 Given frequent itemsets {A,B,C,D}, 
{A,B,C,E}, and {A,B,E,D} that are not closed, sup-
pose that there is a frequent closed super-itemset 
{A,B,C,D,E}. 
Compare the confidence (s) of the following patterns. 
a. (A^B)   (C^D)      (generated from {A,B,C,D}) 
b. (A^E)  (C^D)       (generated from {A,E,C,D}) 
c. (B^E )  (C^D)      (generated from {B,E,C,D}) 
d. (A^B^E)  (C^D)  (generated from  {A,B,C,D,E}) 
From definition 2.1, pattern P2 (d) is a negative pat-
tern if:  
MIN ([C^D | A^B], [C^D | A^E], [C^D | B^E]) – [C^D 
| A^B^E] > s. 
Hence, the use of closed itemsets generates negative 
rule P2 having sufficiently smaller confidences with 
respect to rules with LHS are parents of itemset {A, B, 
E}. In particular, if Support({A,B,C,D} =  Sup-
port({A,B,C,D,E}, then the decrease  in confidence of 
P2 (from its parents) is 0, which is < s. In this case, if 
only closed frequent itemsets are kept at the itemset 
generation stage, then itemset {A, B, C, D} will not get 
generated. A potential negative pattern that will be 
generated from the closed frequent itemset 
{A,B,C,D,E} is {A,B}  {C,D,E}, provided its confi-
416
dence is not smaller than that of the pattern {A,B}  
{C,D} by more than s. 
We now present a theorem that establishes an equi-
valence relationship between support based closed 
itemsets and all-confidence based closed itemsets.  
Theorem 3.1 
Suppose that the items in ? are ordered such that Sup-
port ( ji ) ?  Support ( ki ), for nkj ???1 . Then, an 
itemset is all-confidence based closed iff it is support 
based closed. 
Proof: Let T is a transaction table with C transactions. 
Only If-part 
Let X = {i1, i2… ij} be a all-confidence based frequent 
itemset and there exist a all-confidence based closed 
frequent itemset X’ = {i1, i2… ik}, where 1< j < k. 
We know from definition 3.3, if X’ all-confidence 
based closed then, 
all-confidence (X’) = all-confidence (X)        -- (1) 
and X’ is proper superset of X         -- (2) 
 
Now from all-confidence definition[5],  
all-confidence(X) =   
}|)({
)(
XiiSupportMAX
XSupport
jj ??   
-- (3) 
all-confidence(X’)= 
}'|)({
)'(
XiiSupportMAX
XSupport
kk ??  
-- (4) 
From the fact that MAX is monotonically non-
decreasing function, with the addition of another item, 
it must be true that, 
MAX{|{i1}|, |{i2}|, …, |{ij}|} ?  MAX{|{i1}|, |{i2}|, …, |{ik}|}. 
From (1) & (2), we obtain Support (X) has to ? Sup-
port (X’) and that the all-confidence values are equal, 
which imply that, 
MAX{|{i1}|, |{i2}|, …, |{ij}|} ?  MAX{|{i1}|, |{i2}|, …, |{ik}|}. 
Therefore, we can conclude that, 
MAX{|{i1}|, |{i2}|, …, |{ij}|} = MAX{|{i1}|, |{i2}|, …, |{ik}|}. 
Thus, 
Support(X) = Support (X’)                                -- (5) 
(2) and (5) satisfies the definition 3.2 and thus X’ is 
support based closed. 
If-Part 
From the fact that MAX is monotonically non-
decreasing function, with the addition of another item, 
it must be true that, 
MAX{|{i1}|, |{i2}|, …, |{ij}|} ?  MAX{|{i1}|, |{i2}|, …, |{ik}|}. 
From the assumption that items in ? are ordered in 
non-increasing value of their supports, we conclude, 
MAX{|{i1}|, |{i2}|, …, |{ij}|} ?  MAX{|{i1}|, |{i2}|, …, |{ik}|}, 
implying that the denominators in (3) & (4) are equal.  
Since we are given Support(X) = Support (X’), we con-
clude that, 
}|)({
)(
XiiSupportMAX
XSupport
jj ??  
= 
}'|)({
)'(
XiiSupportMAX
XSupport
kk ??
 
Thus, we conclude that, 
all-confidence (X’) = all-confidence (X).           
Based on the above theorem redundant positive and 
negative patterns can be eliminated through the genera-
tion of all-confidence based frequently closed itemsets. 
4. Algorithm 
 
We have extended the ACDPIP algorithm to discover 
non-redundant LHS positive and negative patterns from 
all-confidence based frequent closed itemsets. The re-
sulting algorithm, called ACDPIP-Closed, is shown in 
Figure 4.1.  
 
Algorithm ACDPIP-Closed: Algorithm generates 
closed frequent itemsets using an all-confidence thre-
shold with algorithm in figure 4.2 and positive and 
negative patterns with closed itemsets. 
Input: dataset D; significant controller s, noise control-
ler n, all-confidence threshold t. 
Output: set of positive patterns PP and the set of nega-
tive patterns P. 
[1] Generate closed frequent itemsets CFI with 
all_confidence > t with modified apriori algorithm. 
[2] for each itemset fin ?CFI generate all possible 
rules from fin and place in AP 
[3]     for each Pai ?  AP  
     //When P is an atomic concept        
[4]        if (conf (Q?A) – supp(Q) ? s) 
[5]             add Pai  to PP 
[6]       else  
[7]       if (supp(Q)–conf(P?Q) ? s) and(supp(P)? n) 
[8]             add Pai to P 
   //When P is a composite concept   
[9]  if (conf (Q?A) – max1?i?j [conf (Pi?A)]),     
?Pi?parents (P) 
[10]           add Pai  to PP 
[11]    else if (min1?i?j [conf (Pi?A)] – conf (Q?A)), 
      ?Pi ? parents(P) and [parent(Pai)] ? n 
[12]         add Pai to P. 
Figure 4.1: Algorithm ACDPIP-Closed 
 
The steps of the algorithm are as follows: 
417
• Generate all frequent closed itemsets FCI from a 
given dataset D using a minimum all-confidence > t.  
• For each frequent closed itemset, generate all possi-
ble association rules. 
• For each association rule determine if it represents 
either a positive or negative pattern. In particular, if a 
rule satisfies the definition of a positive pattern then 
evaluate the next rule. If it does not then determine if 
the rule represents a negative pattern.  
We have modified the Apriori algorithm [1] to gen-
erate all-confidence based frequent closed itemsets 
from a dataset D. Specifically, the algorithm finds fre-
quent closed itemsets using a bottom-up procedure in 
which candidate itemsets of size k are generated by 
joining the frequent itemsets of size k-1. If any superset 
of an itemset I has an all-confidence equal to the all-
confidence of I then it is not returned as part of the 
result set. The algorithm terminates when the frequent 
closed itemsets of a given size is equal to zero. 
 
5. Experiments 
 
We compared the performance of ACDPIP and ACD-
PIP-Closed. The specific objectives were to compare 
the coverage level and execution time of both algo-
rithms.  
 
5.1 Experimental Setup 
 
The experiments were performed on a PC with Intel(R) 
Core(TM) Duo CPU, E6750 @ 2.66GHz, and 3 GB of 
RAM. The noise control threshold, n, and the signific-
ance threshold, s, used in all experiments were .02, and 
0.1, respectively. Three real-life dense datasets, chess, 
mushroom, and adult were used in the experimental 
investigation. These datasets were obtained from the 
UCI ML repository
2
. 
 
5.2 Experimental Results 
 
The experimental results show that ACDPIP-Closed 
out performed ACDPIP on the selected datasets. Spe-
cifically, ACDPIP-Closed outperformed ACDPIP with 
respect to the number of generated itemsets, the num-
ber of generated redundant patterns, and the execution 
time. 
Figure 5.1 shows the number of itemsets generated 
by ACDPIP and ACDPIP-Closed with an all-
confidence threshold value equal to 0.06  The reduc-
tion obtained by ACDPIP-Closed for the chess dataset 
                                                                                       
2
 http://archive.ics.uci.edu/ml/datasets.html 
was approximately 27%, for the mushroom dataset it 
was 48%, and approximately 33% for the adult dataset.  
 
 
Figure 5.1: Redundant itemset reduction with closed 
itemsets 
 
Figures 5.2 - 5.4 provide a comparison of the number 
of patterns discovered by ACDPIP and ACDPIP-
Closed with respect to the chess, mushroom, and adult 
datasets, respectively. The additional patterns discov-
ered by ACDPIP represent LHS redundant positive or 
negative patterns.  The level of redundancy in the con-
text of the chess datasets is approximately13%, 37% in 
the context of the mushroom dataset, and 28% in the 
context of the adult dataset. 
 
 
Figure 5.2: Redundant patterns reduction with closed 
itemsets for Chess dataset. 
 
 
Figure 5.3: Redundant patterns reduction with closed 
itemsets for Mushroom dataset. 
 
418
 
Figure 5.4: Redundant patterns reduction with closed 
itemsets for Adult dataset. 
 
 
Figure 5.5: Percent execution time improvement with 
closed itemsets 
 
Figure 5.5 shows the execution time for ACDPIP and 
ACDPIP-Closed for all three datasets with all-
confidence threshold value equal to 0.06. The results 
shown in this figure clearly illustrate that ACDPIP-
Closed outperformed ACDPIP with respect to all three 
datasets. 
 
6. Conclusion 
 
In our previous work we show with the help of experi-
mental results that when dataset is dense, the number of 
frequent itemsets generated is very large. This affects 
the performance of the interesting patterns discovery 
algorithms. We improved the performance by using all-
confidence measure. Even though all-confidence based 
algorithm outperformed the support based algorithm 
we discover that there is still need for further improve-
ment. In this paper we show that the performance can 
be improved with the help of closed itemsets by reduc-
ing redundant itemsets. We propose changes to ACD-
PIP algorithm by introducing closed itemset generation 
and we refer it ACDPIP-Closed. Experimental results 
show that we are able to improve the performance of 
ACDPIP with closed itemsets. ACDPIP-Closed outper-
forms ACDPIP in terms of redundant itemset reduc-
tion, redundant patterns reduction, and improved ex-
ecution time. 
 
7. References 
 
[1] Agrawal, R, and Srikant, R. “Fast Algorithms for Min-
ing Association Rules.” In Proceedings of 20th Int’l 
Conf. on Very Large Databases, 1994.  
[2] Bastide, Y, Pasquier, N, Taouil, R, Stumme, G, and 
Lakhal, L. “Mining Minimal Non-Redundant Associa-
tion Rules Using Frequent Closed Itemsets.” In Pro-
ceedings of 1st Int’l Conf. on Computational Logic, 
2000. 
[3] Bayardeo, R, Agrawal, R, and Gunopulos, D. “Con-
straint-Based Rule Mining in Large, Dense Databases.” 
In Proceedings of 15th Int’l Conf. on Data Engineering, 
1999. 
[4] Hussain, F., Liu, H., Suzuki, E., and Lu, H. “Exception 
Rule Mining with a Relative Interestingness Measure”. 
In Proceedings of PAKDD, 2000. 
[5] Omiecinski E. “Alternative interest measures for 
mining associations.” IEEE Trans. Knowledge and 
Data Engineering, vol.15, no. 1, pp. 57 - 69, 2003. 
[6] Pasquier, N, Bastide, Y, Taouil, R, and Lakhal, L. 
“Closed Set Based Discovery of Small Covers for 
Association Rules.” Cetworking and Information 
Systems Journal, vol. 3, no. 2, 2000. 
[7] Singh, R, Johnsten, T, Raghavan, V, and Xie, Y. “An 
Efficient Algorithm for Discovering Positive and Nega-
tive Patterns.” In Proceedings of IEEE Int. Conf. on 
Granular Computing, Nanchang, China, 2009. 
[8] Suzuki, E. Undirected Discovery of Interesting Excep-
tion Rules. Int. Journal of Pattern Recognition and Ar-
tificial Intl.16:1065-1086, 2002. 
[9] Xie, Y, Johnsten, T, Raghavan, V.V, and Ramachan-
dran, K. “On Discovering “Potentially Useful” Patterns 
from Databases.” In Proceedings of IEEE Int. Conf. on 
Granular Computing, 2006. 
[10] Zhong, N, Yao, Y.Y., Ohshima, M. Peculiarity 
Oriented Multidatabase Mining. IEEE Trans. On 
Knowledge and Data Engineering, 15:952-960, 2003. 
419
