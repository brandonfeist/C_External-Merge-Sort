2010 Second IITA International Conference on Geoscience and Remote Sensing
978-1-4244-8515-4/10/$26.00 ©2010 IEEE                                                   GRS2010
Application of Data Mining Techniques in Resources 
Evaluation
Hai-dong Meng, Yu-chen Song 
Inner Mongolia University of Science and Technology  
Baotou 014010, China 
haidongm@imust.edu.cn 
Dinil Pushpalal 
Department of International Resources Policy 
Graduate School of International Cultural Studies 
 Tohoku University, Sendai 980-8576, Japan 
Abstract—Due to the complexity of geoscientific data, such as 
geochemical data, geophysical data and digital remote sensing 
data, traditional data mining methods, such as cluster analysis 
and association analysis, have limitations in resources evaluation. 
In this paper, a clustering algorithm is presented which has the 
ability to handle clusters of arbitrary shapes, sizes and densities. 
For association analysis, quantitative association rules aims to 
deal with the relationships among continuous attributes of 
geoscientific data objects in resources evaluation. An association 
analysis algorithm based on the distances between clusters 
projected on attributes is presented. Applications indicate that 
the algorithms are effective in real world applications. 
Keywords- Data mining; Cluster analysis; Association analysis; 
Geoscientific data; Spatial data mining 
I. INTRODUCTION
In many application domains, such as resources evaluation, 
clusters of data objects are of arbitrary shapes, sizes and 
densities, and the number of clusters is unknown. In such 
scenarios, traditional clustering algorithms, including 
partitioning methods, hierarchical methods, density-based 
methods and grid-based methods, cannot identify clusters 
efficiently or accurately. Obviously, these are critical 
limitations or weaknesses of clustering methods. In order to 
solve these problems, many algorithms have been proposed by 
many researchers, such as Ertöz, Steinbach and Kumar [1], 
Ayad and Kamel [2], Ng and Han [3], Ester and Kriegel [4, 5], 
and Zhang, Ramakrishnan and Livny [6]. 
 Algorithms for discovering classical association rules 
make different assumptions about the type of datasets to be 
mined. In general, the dataset is a relational table. The domains 
of the attributes are restricted to boolean domains. The 
databases in most business and scientific domains have many 
types of attributes, including quantitative, categorical or 
boolean attributes. The classical association analysis algorithms 
for boolean attributes can not mine quantitative association 
rules from databases with continuous attributes, and may yield 
very unintuitive results when applied to continuous attributes. 
Srikant and Agrawal [7], Miller and Yang [8], and Aumann 
and Lindell [9] proposed algorithms to create quantitative 
association rules.
The rest of the paper is organized as follows. We present a 
novel clustering algorithm based on density and adaptive 
density-reachable in section 2. In section 3, the creation of 
quantitative association rules based on distance is proposed. 
The applications of the algorithms are presented in section 4. 
Section 5 concludes with a summary. 
II. CLUSTERING ALGORITHM BASED ON DENSITY AND 
ADAPTIVE DENSITY-REACHABLE
In many application domains, clusters of data objects are of 
arbitrary shapes, sizes and densities, and the number of clusters 
is unknown. In order to solve the problem, we proposed a 
clustering algorithm which has the abilities to find clusters of 
arbitrary shapes and sizes, to handle clusters and noise of 
varying densities, and to identify outliers effectively. The 
algorithm is called CADD (Clustering Algorithm based on 
Density and adaptive Density-reachable, CADD) [10, 11]. 
A. Relevant Definitions of the Clustering Algorithm 
(1)The density of data points: Given N d-dimensional data 
points in dataset D: {Xi} where i = 1, 2,…, N. The density of 
data points models the overall density of a set of points in 
dataset D as the sum of influence function associated with each 
point: 
 
 
¦
 

 
N
j
XXd
i
ji
eXDensity
1
2
,
2
2
V
 
   
 
Here, Gaussian influence function 2
2
2
,
X, V
ji XXd
jiGuass eXf

 
CoefRDmeanR 
indicates the density influence of each data points to the 
density of point Xi, and ? is density adjustment parameter 
which is analogous to the standard deviation, and governs how 
quickly the influence of a point drops off. 
(2)Local density attractors: Local density attractors are the 
data points at which the values of density function Density(X)
are local maximum. 
(3)Density-reachable distance: Density-reachable distance 
is used to determine a circular area of data points x, labeled as 
?={X| 0<d(Xi, Xj)?R}, and the data points in the circular area 
are belong a same cluster. The definition formula is: 
)( 
Here, 2/121
1 1
))(1()( i
N
i i
XX
1N
Dmean 

 ¦    is the mean distance 
between all data points in dataset D, and CoefR (0<CoefR<1)
510
is named as the initial adjustment coefficient of density-
reachable distance. 
(4)Density-reachable: Density-reachable means that if there 
is a chain of objects p1, p2,?,pn=q, q is a local density attractor, 
and pn-1 is density-reachable from q, then for pi?D,(1?i<n-1) 
and d(pi,pi+1)?R, we define that object pi,(1?i<n-1) is density-
reachable from q.
(5)Adaptive density-reachable distance: In handling the 
clusters of varying densities, it is important to adjust the 
density-reachable distance R step by step during clustering. The 
adaptive adjustment is carried out through multiplying the 
original density-reachable distance R with an adjustment 
coefficient ?:
RRAdap D 
Here, RAdap is adaptive density-reachable distance, and ? is 
defined as: 
)(
)( 1
i
i
AttractorDensity
AttractorDensity  D
)()( 10 AttractorDensityAttractorDensity  
)()( 1 ii AttractorDensityAttractorDensity t
i

This is because that when the density value of local density 
attractor of a cluster is greater , the distance between objects in 
the cluster is smaller, and on the contrary, when the density 
value of local density attractor of a cluster is smaller, the 
distance between objects in the cluster is larger. When i=1, let 
. Because 
, so ??1. It is necessary 
to point out that adaptive adjustment coefficient ? may also be 
other value of function which can adjust the density-reachable 
distance effectively. 
X
B. The Clustering Algorithm 
According to the definitions we design and implement the 
clustering algorithm as below:  
Algorithm Clustering Algorithm based on Density and 
adaptive Density-reachable, CADD 
Input: Adjustment coefficient of density- reachable 
distance CoefR, density adjustment parameter ?.
Output: Number of clusters, the members of each cluster, 
outliers or noise points. 
1: Compute the densities of each data points and initial 
density-reachable distance. 
2:  i?1
3:  Repeat
4: Seek the maximum density attractor ODensityMaxi in the 
original dataset of clustering objects as the cluster 
centroid of Ci.
5: Assign the data objects which are density reachable 
within adaptive density-reachable distance from 
ODensityMaxi to cluster Ci, and delete the clustered objects 
from original dataset. 
6:  i?i+1 
7:  Until Original dataset is empty. 
8:  Make the clusters which have few objects (such as less 5 
or 7) into outlier or noise group. 
III. DISTANCE-BASED QUANTITATIVE ASSOCIATION RULES
Association rules that contain continuous attributes are 
commonly known as quantitative rules. There are various 
methodologies for applying association analysis to continuous 
data. The types of methods mainly fall into three broad 
categories: (1) discretization-based methods, (2) statistics-
based methods, and (3) non-discretization methods. The 
quantitative association rules derived using these methods are 
quite different in nature. 
The main concept for creating distance-based association 
rules is to cluster data objects and mine association rules 
among these projected clusters according to the distances 
between the clusters.  
A. Clustering 
It is necessary to point out that if there are a number of 
clusters in a data space, the strong association rules among 
attributes just exist in each cluster. Therefore, the creation of 
association rules just focuses in each cluster. The notion 
proposed in this section can make the process of quantitative 
association analysis more simple, efficient and effective. 
We use the clustering algorithm CADD to group the data 
points in a dataset. For a specific set of attributes, restrictions 
are placed on the properties of these data points when projected 
on X. For this reason, when a cluster is projected on X, the 
cluster is denoted as CX. Given N d-dimensional data points 
{
&
}, (i=1,…,N) in CX, the Clustering Feature [6] is defined 
as:
),,( 0 RXN ?????????????????????????????                CF ??
Here, N is the number of data points in CX,
¦   
N
i i
X
N
X
10
1 is the centroid of CX, and 
2/12
01
))(1( XX
N
R N
i i
 ¦   is the average distance from 
member points to the centroid or the radius of CX. According 
the clustering feature CF, the relationships among clusters 
projected on attributes are determined as presented later. 
B. The Association Rules 
For a cluster, if association rules exist among the attributes: 
X={x1,…,xx} and Y={y1,…,yy}, the definition of association 
rules is x1?Cx1[x1],…,xx?Cxx[xx]? y1 ?Cy1[y1], …,yy?
Cyy[yy]. The clusters are labeled with the attributes on which 
they are projected. For abbreviation, the rule is presented as 
Cx1,…,Cxx?Cy1,…,Cyy, where all the attributes X={x1,…,xx}
and Y={y1,…,yy} are disjoint. The rule Cx1,…,Cxx? Cy1,…,Cyy
holds with confidence c if |(?iCxi) ?(?jCyj)|/|?Cxi|?c. The 
rule holds with support s, if |(?iCxi) ?(?jCyj)|?s.
For distance-based association rules, the confidence c is 
determined by the distances among the images of clusters 
Cx1,…,Cxx and Cy1,…,Cyy, and the support s is dominated by 
the numbers or densities of clusters. In this paper, we use the 
511
Euclidean distance metric to measure the distance between data 
points.  
According to the notion proposed by R. J. Miller and Y. 
Yang [8], the definitions of distance-based association rules are 
as follows:  
Let x1,x2,…,xx and y be pairwise disjoint sets of attributes. A 
N:1 distance-based association rule (DAR) is a rule of form R:
Cx1,…,Cxx?Cy, where each Cxi is a cluster projected on xi and 
Cy a cluster on Y. R holds with degree of association D0 if: 
xiDYCxYCyD i ddd 1])[],[( 0 
jidXCxXCxD ixjjii zd 0])[],[(
])[],[( YCxYCyD i
||/|][| DsYCyS  
])[],[( YCxYCy

Here, we emphasize that Cy[Y] indicates the Cy?Cxi, Cxi[Y] is 
the image of all data points in the range of Cxi projected on Y,
and  is the distance between centroids of 
Cy[Y] and Cxi[Y]. In real applications, the value of D0 is 
determined by the radius of the cluster. Because the creation of 
association rules is in each cluster, it is unnecessary to calculate 
Equation (7). We define the support S of the association rule as: 

Here, |Cy[Y]| is the number N of data points in the cluster, and 
|Ds| indicates the number of all data points in the data space. 
The degree of association replaces the traditional notion of 
confidence and the density threshold (or the number of data 
points in a cluster) replaces the notion of support. 
In this paper, we focus our research to the N:1 distance-
based association rules. N:1 distance-based association rules 
have a number of important applications. Often in data mining, 
we are interested in discovering which attributes determine one 
of a specific set of target attributes. For example, in 
geochemical applications, there are many chemical elements 
which are measured in the field, and we have to determine the 
relationship between a target element and a specific set of 
elements so as to solve some geochemical problems. Another 
example is that in medical domain we also have to research the 
relationships between a specific symptom and other symptoms, 
and so on.  
C. The Association Algorithm 
The algorithm presented in this section is a modification of 
the algorithm proposed in [8], and it includes three phases:  
z In first phase, clusters in the data space are identified 
using normal clustering algorithms, such as K-means or 
CADD [10,11], and the clustering features are calculated.  
z In second phase, the distances D i  are 
calculated in a cluster which holds support S, here, Y is 
the target attribute chosen by domain experts interactively 
and X={x1,…,xx
0])[],[( DYCxYCyD i d ||/|][| DsYCyS  
hist, shallow particle rock, and griotte.
} are the other attributes of data points in 
the data space. 
z In third phase, the rule is formed by combining the 
clusters projected on attribute Y which holds 
 and .
IV. APPLICATIONS
In the real world application of data mining techniques, we 
use cluster analysis and association analysis to research the 
regional geochemical characteristics in a region of western 
China. The sampling area is 80*72 Km2, the distance between 
sampling points and lines is 2 Km, and the number of sampling 
points is 1517. The lithological distribution pattern in the 
region is shown in Figure 1: (1) the pale yellow area indicates 
humus, anemoarenyte and diluvium in Quaternary; (2) the 
yellow area is sandy and carboniferous dark gray-colored slate 
and silty mudstone with siltstone in Dyas; (3) the dark yellow 
area represents clastic rock, dark gray-
colored conglomerate, graywacke, and silty slate with silty 
mudstone in Dyas; (4) yellow and yellowish-brown-
colored granite porphyry, hornblende granite porphyry, and 
masanophyre in Yanshanian magmatism distribute in the pale 
pink area; (5) the pink area is flesh and red-colored granitello 
and medium-grain granite in Yanshanian magmatism; (6) the 
blue area indicates gray and sage green-colored rhyolite, 
rhyolitic tuff with breccia in Jurassic; (7) the purple area is 
dimgray-colored medium and coarse-grain quartz diorite 
and gneissic quartz diorite in Variscan magmatism; (8) the 
green area is sage green and pale-gray-yellow-colored biotite 
plagioclase gneiss with amphibole plagioclase gneiss, 
quartz sc
Figure 1. Lithological distribution pattern in the sampling region. 
The purposes of clustering analysis and association analysis 
are to research the characteristics of regional geochemical 
anomalies, to determine the distribution of anomaly source, and 
to analyze the type of mineral resources according to the 
relationship among the geochemical elements. 
A. Cluster Analysis 
There are 1443 samples actually in the geochemical 
measurement region, and for each sample 17 kinds of chemical 
elements are measured which are Ag, Al, As, Au, Cd, Co, Cu, 
Fe, Hg, K, Mn, Mo, Pb, Sb, Sn, W, Zn. The sampling points 
constitute a spatial dataset in which each data point has 17 
attributes, i.e., Ag, Al, As, Au, Cd, Co, Cu, Fe, Hg, K, Mn, Mo, 
Pb, Sb, Sn, W, Zn. The clustering result of CADD is shown in 
Figure 2. There are four clusters: Cluster1, Cluster2, Cluster3, 
Cluster4 and Outliers found in the spatial dataset. The 
512
distribution pattern of the clusters is consistent with the 
lithological distribution pattern in the region, which can 
indicate the characteristics of geochemical anomaly. The 
distribution area of Cluster1 reflects the geochemical 
characteristics of the dimgray-colored medium and coarse-
grain quartz diorite and gneissic quartz diorite in Variscan 
magmatism (the purple area). 
Figure 2. Clustering result of geochemical samples. 
B. Association Analysis 
Geological survey in the field indicates that mineral 
occurrences of W and Pb or Cu exist in the area of Cluster1. 
According to the geochemical theory [12], the geochemical 
characteristics of a geological unit can be evaluated using the 
association rule of the chemical elements. In this section, we 
use association analysis to analyze the relationship among the 
chemical elements so as to determine the characteristics of a 
geological unit, and provide useful knowledge for mineral 
resource survey.  
Because the chemical elements Cd and Sb are important 
indicator elements for the evaluation of mineral resources, we 
research the relationships Cd and Sb with other chemical 
elements using the distance-based association analysis. For 
Cluster1, when D0=0.005, the quantitative rules are as follows:  
(1)The association rule of Cd with other elements: 
As?[1.4,45], Ag?[0.01,0.29], Au?[0.3,1.1],  
Hg?[1.0,120], Mo?[0.02,4.7], Pb?[5.0,56],  
Sb?[0.03,2.78], Sn?[0.1,14], W?[0,8.7] 
? Cd?[0.01,0.22], D0=0.005, S=33.6%. 
(2)The association rule of Sb with other elements: 
Ag?[0.01,0.29], As?[1.4,45], Au?[0.3,1.1], 
Hg?[1.0,120], Mo?[0.02,4.7], Pb?[5.0,56],  
Sn?[0.1,14], W?[0,8.7.0] ? Sb?[0.03,2.78], 
D0=0.005, S=33.6%. 
The association rules indicate that Cd and Sb are related 
with Ag, Au, Hg, Mo, Pb, Sn and W under certain degree of 
association and support. According to geochemical theory [12] 
we can conclude that the mineral resources in the region are 
related with Ag, Au, Hg, Mo, Pb, Sn and W. The conclusion is 
consistent with the real characteristics of mineral resources in 
the region. 
V. CONCLUSIONS
The research results may provide new methods and 
techniques for comprehensive interpretation of geoscientific 
data, and minimize the uncertainness and ambiguity of 
geoscientific data interpretation in resources evaluation. Along 
with the development of geosciences, more and more data are 
collected, and data mining techniques have evolved important 
methods to process huge amounts of geoscientific data and to 
discover useful geoscientific knowledge efficiently and 
effectively. 
ACKNOWLEDGMENT
The materials are based on work supported by National 
Natural Science Foundation of China under Grant No. 
40762003, National Chunhui Project under Grant No. Z2009-
1-01041, and Natural Science Foundation of Inner Mongolia 
under Grant No. 200711020814. 
REFERENCES
[1] L. Ertöz, M. Steinbach, and V. Kumar. Finding Clusters of Different 
Size, Shapes and Densities in Noisy High Dimensional Data. In Proc. of 
the 3rd SIAM International Conference on Data Mining: pp.47-58, 2003. 
[2] H. Ayad, and M. Kamel. Finding Natural Clusters Using Multi-cluster 
Combiner Based on Shared Nearest Neighbors. In Proceedings of the 4th 
International Workshop on Multiple Classifier Systems (MCS 2003),
Springer Berlin, LNCS 2709: pp.159-175, 2003.  
[3] R. T. Ng and J. Han. CLARANS: A Method for Clustering Objects for 
Spatial Data Mining. IEEE Transactions on Knowledge and Data 
Engineering, 14(5): pp.1003-1016, 2002. 
[4] M. Ester, H.-P. Kriegel, and J. Sander, et al.. A Density-Based 
Algorithm for Discovering Clusters in Large Spatial Databases with 
Noise. In Proceedings-The 2nd Intl. Conf. on Knowledge Discovery and 
Data Mining, Portland, Oregon, AAAI Press: pp.226-231, August 1996. 
[5] J.-O. Sander, M. Ester, and H-P. Kriegel, et al.. Density-Based 
Clustering in Spatial Data sets: The Algorithm GDBSCAN and Its 
Applications. Data Mining and Knowledge Discovery 2: pp.169–194, 
1998.  
[6] T. Zhang, R. Ramakrishnan, and M. Livny. An Efficient Data Clustering 
Method for Very Large Databases. In Proc. ACM SIGMOD Conference 
on Management of Data, Montreal, Canada: pp.103-114, 1996. 
[7] R. Srikant and R. Agrawal. Mining Quantitative Association Rules in 
Large Relational Tables, ACM SIGMOD, Volume 25, Issue 2: pp.1-12, 
1996. 
[8] R. J. Miller and Y. Yang. Association rules over interval data, ACM 
SIGMOD, Volume 26, Issue 2: pp. 452-462, June 1997.  
[9] Y. Aumann and Y. Lindell. A Statistical Theory for Quantitative 
Association Rules, Journal of Intelligent Information Systems ,Volume 
20 ,  Issue 3: pp.255 – 283, May 2003.  
[10] H.-D. Meng, Y.-C. Song, and F.-Y. Song. Research and implementation 
of clustering algorithm for arbitrary clusters, In Proceedings - 
International Conference on Computer Science and Software 
Engineering, v 4: pp. 255-258, 2008. 
[11] Y.-C. Song, H.-D. Meng, M. J. O'Grady, and G. M. P. O'Hare. Research 
and Application of Clustering Algorithm for Arbitrary Data Set, In 
Proceedings - International Conference on Computer Science and 
Software Engineering, v 4: pp. 251-254, 2008. 
[12] P.-G. Dai, X.-P. Gu, and J.-L. Yu. Applied Geochemistry, Published by 
Central South University Press, China, 2008.
513
