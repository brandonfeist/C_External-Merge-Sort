Int’l Conf. on Computer & Communication Technology
___________________________________
978-1-4244-9034-/10/$26.00©2010 IEEE               431
A Comparative Study of Four Feature Selection Methods for Associative Classifiers
Kavita Das
SoS in Computer Science and I.T.
Pt. Ravishankar Shukla University
Raipur, C.G., India
mskavitadas@gmail.com
O. P. Vyas
Professor & Program coordinator (S/W Engg.)
Indian Institute of Information Technology
Allahabad, U. P., India
dropvyas@gmail.com
Abstract— Feature Selection is a preprocessing step that has   
optimization effect in data mining. The feature set of a dataset 
generally contains redundant or irrelevant features in order to 
avoid the risk of incomplete description of instances and to 
provide utility to different purposes of the dataset. This may 
lead to an inefficient Classification rule mining process that 
bears with memory and time overhead. Recently developed 
Associative Classifiers like CBA, CMAR and CPAR are almost 
equal in accuracy and have outperformed traditional 
classifiers. CPAR has been found to be most consistently 
generating results with good average accuracy. So, it is selected 
to compare the suitability of four popular feature selection 
methods: GGA, SSGA, LVW and MIFS for classification of 
data.  The Genetic algorithm is found to be the most suitable.
Keywords- feature selection; associative classification; CBA; 
CMAR; CPAR; GGA; SSGA; LVW; MIFS
I. INTRODUCTION
Classification is a Machine Learning technique that 
requires datasets containing many instances. Classification 
approach uses a dataset in two parts as – training set and test 
set. In training set, each instance is defined with many
features (attributes) and a class label. It is used for building 
the classifier. The test set is used to test performance of the 
classifier. A dataset may contain many impurities that affect 
the efficiency of a classifier. Hence, it requires preprocessing
like filtering, transforming, summarizing, etc.
Feature Selection is method of filtering a dataset in which 
a subset of features or attributes are selected out of original 
feature set for reducing the dataset to make it more relevant 
to the concept of classification. While creating a dataset, 
relevant features are generally unknown a priori. There may 
be many candidate features that represent the domain. Hence, 
the feature set may contain many partially or completely 
irrelevant attributes and redundant attributes. Such features 
increase the size of dataset and interfere in the efficiency and 
accuracy of classifier. It also leads to processing cycle and 
time overhead. It also compels generation of large sized test 
sets. 
Feature Selection is important both to speedup learning 
and to improve concept quality. Irrelevant features degrade 
the performance of concept learners both in speed (due to 
high dimensionality) and predictive accuracy (due to 
irrelevant information), especially in large dataset. Feature 
selection methods use various approaches to select a feature 
and test its relevancy to the target concept. Generally a 
features is taken as irrelevant if on removing it, the 
classification accuracy does not decrease significantly or if 
the resulting class distribution is nearly same as the original 
class distribution in the test set. A general Feature Selection 
process is shown in figure 1.
    Original
Feature set
             Subset                    Feature subset           Evaluation for        
           Generation                                                    irrelevance or
                                                                                 redundancy   
                                                             Goodness of
                                                             the subset
                                                                                            
                                                                                          Stopping
                                No                                      Criteria
                                                                           
                                                                                           Yes
                                                                   
                                                                    Validation w.r.t.
                                                                                     other methods
Figure 1.    Feature Selection process
Broadly, Feature Selection approaches can be categorized 
as follows:
Feature Selection Approach
Complete                   Heuristic                        Random
                                 
                                   Filter                             Wrapper    
A Feature Selection approach is called complete if the 
search space is completely searched for an optimal subset. It 
may be an exhaustive search. Heuristic approach searches 
for a nearly best solution in incremental manner based on 
Int’l Conf. on Computer & Communication Technology
432
some simple criteria. Hence they are fast in producing 
results. Random approach selects candidates based on some 
parameter values and its optimality depends on availability 
of the resources. Filter approaches obtain feature subset by 
maximizing or minimizing a criteria function. They do not 
take support of any induction algorithm. Wrapper
approaches are feedback oriented and evaluate feature 
selection using a learning algorithm in terms of predictive 
accuracy. The time required depends on complexity of 
learning algorithm for fitness evaluation.
Feature Selection methods have been studied and 
compared with traditional classification systems, but still 
they have not been tested on higher ended Associative 
Classification systems. In this work, Associative 
Classification approaches CBA [6], CMAR [7] and CPAR 
[8] have been studied and CPAR has been chosen to test the 
accuracy of popular Feature Selection methods GGA [2], 
SSGA [3], LVW [4] and MIFS [5].  Section II describes the 
feature selection methods and the Associative Classifiers are 
described in section III. Section IV gives the comparative 
study of the feature selection methods and section V 
concludes this work.
II. METHODS OF FEATURE SELECTION
Feature selection methods taken into this work are as 
follows:
A. Las Vegas with Probabilistic Wrapper(LVW) Model
This algorithm [4] is a probabilistic and wrapper 
approach version of Las Vegas algorithms.  Las Vegas 
algorithms make use of probabilistic choices to guide them 
more quickly to a correct solution. Las Vegas algorithms, use 
heuristic methods, take long time to reach to decision. LVW 
adopted a modified approach by adopting estimation of error 
rate for each subset. The smallest subset with lowest error 
rate is chosen as the most relevant feature subset for the 
target concept. It computes error of a subset both with 
training set and test set. And then compares with the current 
minimum error rate. LVW outputs every current best. LVW 
produces good solution or an optimal solution if number of 
runs is chosen to be large.
B. Mutual Information for Feature Selection (MIFS)
This method [5] investigates the application of Mutual 
Information criterion to evaluate a set of candidate features 
and to select an information subset for neural network 
classifiers. It uses the problem – given an initial set F with n 
features, find the subset S of set F with k features that 
minimizes conditional entropy H(C/S) i.e. that maximizes 
the mutual information I(C;S).  Shannon’s information 
theory is adopted for suitable formalism of this target. It 
starts with original set of features. It computes mutual 
information I(C;S) for each feature of the selected subset. 
Then it adds the feature f with maximum I(C;S) into the 
subset S. It sets F= F\{f} and S ={f}. Then iteratively MIFS 
selects greedily feature s from F by computing I(f;s), chooses 
f with maximum I(C;S)-	

C. Generational Genetic Algorithm (GGA)
I(f;s)  and sets  F= F\{f} and S 
=SU{f}. S is the selected feature set.
Genetic algorithms (GA) [2] are adaptive search 
techniques based on biological evolution of natural selection. 
Sometimes they may take hours to obtain good feature subset 
on large datasets. To improve this state, GGA adopted filter 
method that selects based on some criteria and reduced 
significantly the   computation time. It used inconsistency 
rate as the filter criteria for a subset of features. It uses 
binary coding that show the presence or absence of features 
in the subset and implements standard genetic operators, 
crossover and mutation.
D. Steady State Genetic Algorithm (SSGA)
This method[3] has been developed for fuzzy rule based 
classification system (FRBCS). FRBCS have a disadvantage 
that there is exponential growth of fuzzy rule search space 
with increase in number of features in training process. 
Hence it has big efficiency degradation with datasets. To 
counter this overhead, this method uses a precision measure 
provided by the k-NN considering only those features that 
are included in the candidate feature subset . Candidate 
subdset is selected with any  GA. It uses integer coding 
scheme with a fixed cardinality. In fact, it combines both 
filter and wrapper approaches in two steps. First it uses filter 
approach to find cardinality for the feature subset with 
minimum number of inconsistencies.Second, the cardinality 
is used as chromosome length for a wrapper based feature 
selection process. It provides a variable subset. It used k-
nearest neighbour estimation which is very sensitive to 
irrelevant variables.  
III. ASSOCIATIVE CLASSIFICATION TECHNIQUES
Associative Classification is the integration of Association 
Rule Mining and Classification Rule Mining by focusing on 
a special subset of association rules whose right-hand-side 
are restricted to the classification class attribute. Associative 
classifiers had been found [8] [9] to be better than C4.5 and 
other traditional classifiers in terms of accuracy and dataset 
coverage. Associative Classification consists of three steps:
1. Generation of frequent item sets or association rules.
2. Selection of all the class association rules (CARs),
3. Building a classifier based on the generated CARs.
Among the associative classifiers: CBA [6], CMAR [7] and 
CPAR [8], CPAR had been found better and have been used 
in this work. But Associative Classifiers are more memory 
and time consuming. The techniques are described as 
follows: 
A. Classification Based on Associations (CBA)
    This approach [6] gives the first algorithm that integrates 
Association rule mining and Classification. It uses the 
apriori approach to discover the association rules. Best
association rules having any of targeted rules are selected 
based on confidence, support and size of antecedent. These 
rules are pruned using “pessimistic error rate”. Finally the 
rule list is generated using a variation of “cover” principle. 
Int’l Conf. on Computer & Communication Technology
433
For prediction of a new case, it uses a set of related rules by 
evaluating the correlation among them.
B. Classification Based onMultiple Association Rules 
(CMAR)
CMAR [7] algorithm uses the FP-growth approach to 
find association rules. The classification rules are stored in a 
prefix tree data structure, known as a CR-tree. CR-tree 
makes effective rule storage and speed retrieval of rules in 
the classifier.  For classifying a new object, the subset of
classification rules matching the new object is observed at 
their class labels. In the case where all rules have a common 
class, CMAR simply assigns that class to the test object. In 
cases the classes of the accumulated rules are not identical, 
the rules are divided into separate groups based on their class 
values and the effects of every group are compared to 
identify the strongest one. The strength of the groups is 
measured by the weighted 2. The class of the strongest 
group is assigned to the test object.
C. Classification Based on Predictive Association Rules 
(CPAR)
It [8] is a greedy associative classification approach. 
The best rule condition is measured by FOILgain [10] of the 
rules generated among the available ones in the dataset. 
FOILgain is used to measure the information gained from 
adding a condition to the current rule. Once the condition is 
identified, the weights of the positive examples associated 
with it are reduced by a multiplying factor, and the process 
repeats until all positive examples in the training data set are 
covered. CPAR generates rules directly from training data 
instead of generating CARs. It generates and tests more 
rules to avoid missing important rules. Whereas other 
approaches select the best rule for prediction, it uses best k 
rules in prediction in order to avoid over fitting. In the rule-
generation process, CPAR is capable of deriving not only 
the best condition but also all similar ones. It includes the 
rules with similar gains.
IV. EXPERIMENT
In order to study empirically the performance of various 
Feature Selection approaches on Associative Classification, 
some easily available Feature Selection methods are 
selected. KEEL [11], a data mining software tool was used 
for discretizing the datasets. The datasets are also available
with this tool. The datasets1 we used are as shown in Table 
1. The methods LVM and SSGA can be directly applied on 
undiscretized dataset whereas GGA and MIFS require 
discretized dataset for their application. Number of features 
to be selected is user-defined in MIFS.
1In each dataset, the data-10-3tra.dat file of data is used in 
the experiment
TABLE I. THE DATASETS
S.no. Datasets Size Classes Attributes
1 Iris 150 3 4
2 Wine 143 3 13
3 Glass 191 6 10
4 cleve 268 5 13
5 Breast 614 2 10
6 Pima 692 2 8
    Associative Classifiers CBA, CMAR and CPAR can be 
applied only on discretized data. MDLP [12] discretization 
approach was adopted on the datasets, either before or after 
feature selection of the datasets depending on the 
requirements of the feature selection methods. The 
performances of the three associative classifiers on different 
datasets with the MDLP discretizer was empirically tested 
[13] with the result obtained as shown in table2.
TABLE II. PERFORMANCE WITH MDLP
Figure 2.   Accuracy with MDLP
    It can be observed that CBA and CMAR are failing to 
generate any rule in some cases. According to current 
observation and [14], the best accuracy seems to swing 
among CBA, CMAR and CPAR with change of dataset. 
CPAR is consistently giving relatively good performance in 
terms of accuracy. Also the number of generated rules by 
Datas
ets
CBA CMAR CPAR
Accurac
y
No. 
of 
Rule
Accurac
y
No. of 
Rules
Accurac
y
No. of 
Rules
Iris 33.33 2 93.33 16 33.33 4
Wine 0 2 74.29 79 47.89 3
Glass 0 0 0 0 36.84 4
cleve 55.97 14 53.14 168 52.24 11
haber
man 54.01 2 53.46 4 73.72 2
Breast 96.42 17 94.46 112 95.77 11
Pima 75.43 10 44.94 28 66.47 11
Aver
age
45.023 59.089 58.037
Int’l Conf. on Computer & Communication Technology
434
CPAR is neither too large nor too small in comparison to 
the other two. CPAR seems to be much balanced with 
respect to number of rules and accuracy. Hence CPAR is 
adopted for our target test.
    On applying the feature selection methods on the datasets 
in table 1, the number of features obtained in reduced 
dataset is shown in table 3.
TABLE III. NO OF FEATURES IN REDUCED SET
    Application of CPAR on the above dataset produced 
classification accuracy as shown in table 4.
TABLE IV. ACCURACIES OF CPAR W.R.T. DISCRETIZERS
Figure 3: Accuracies of CPAR w.r.t. Discretizers
From the above table and corresponding graph, it can be 
observed that GGA is giving best performance with CPAR. 
MIFS is also showing relatively good results.
V. CONCLUSION AND DISCUSSION
This is an investigative work aimed at finding a suitable 
combination of feature selection and classification methods 
in order to get high performance in classification 
applications. Associative classifiers had been found to be 
better than C4.5 and other traditional classifiers in terms of 
accuracy and dataset coverage. Though CBA, CMAR and 
CPAR have been found similar in accuracy and one shows 
superiority from the others with respect to datasets, CPAR 
have been found give little better average accuracy. This 
work also finds a similar trend. Also CPAR is found to be 
more reliable to churn out rules. Along with accuracy, the 
number of rules generated by CPAR is more balanced for 
being applied in problem solutions. But Associative 
Classifiers are more memory and time consuming. 
Feature Selection provides a way to remove irrelevant 
features and reduce the memory and time disadvantage 
considerably. It can also be concluded that in order to 
choose a high performance classifier for obtaining good 
results on some target application dataset, CPAR along with 
Generational Genetic Algorithm (GGA) is providing a 
promising combination for an application oriented project. 
Dataset was applied with four types of feature selection 
approaches: Probabilistic wrapper, Heuristic, Genetic filter, 
Genetic filter-wrapper. Genetic filter method (GGA) is 
showing highest performance (even improved performance) 
with CPAR. It can also be observed that MIFS is also 
providing competitive performance to GGA. But number of 
features to be selected by MIFS is user-defined, so its 
reliability to produce a proper subset of relevant features 
gets questioned. 
As Genetic algorithms are generally slow and Heuristic 
methods are much faster. For a static application, one time 
application of GGA is acceptable. For dynamic applications 
that may deal with classification of many datasets, faster 
method of MIFS may be more suitable for feature selection.  
REFERENCES
[1] M. Dash and H. Liu, “Feature selection for Classisfication”, 
Intelligent Data Analysis 1, 1997, pp. 131-156. 
[2] Pier Luca Lanzi, “Fast feature selection with Genetic algorithms: A 
Filter approach”, in IEEE International Conference on Evolutionary 
Computation, IEEE Press, !997, pp. 537-540. 
[3] J. Casillas, O. Cordon, M. J. Dell Jesus and F. Herrera, “Genetic 
feature selection in a fuzzy rule-based classification system learning 
process for high-dimensional problems”, Information Sciences 136, 
2001, pp. 135-157. 
[4] Huan Liu and Rudy Setiono, “Feature selection and Classification- A
probabilistic Wrapper approach”, To appear in proc. of IEA-AIE96
[5] Roberto Battiti, “Using mutual infoermation for selecting features in 
supervised neural net learning”, IEEE transaction on Neural 
Networks, vol 5, No 4, July 1994.
Data 
sets
Original 
Dataset
Reduced Dataset
GGA SSGA LVW MIFS
Iris 4 1 3 4 3
Wine 13 3 3 7 3
Glass 9 5 3 6 3
cleve 13 8 3 7 3
Breast 9 3 3 5 3
Pima 8 1 3 3 3
Datas
ets
Original 
Dataset
Reduced Dataset
GGA SSGA LVW MIFS
Iris 33.33 33.33 33.33 32.84 33.33
Wine 47.89 47.89 40 40 47.89
Glass 36.84 36.84 36.84 36.84 36.84
cleve 52.24 52.24 52.21 48.53 52.24
Breast 95.77 96.42 91.86 94.46 96.42
Pima 66.47 76.59 62.72 62.72 62.72
Int’l Conf. on Computer & Communication Technology
435
[6] B. Liu, W. Hsu and Y. Ma, “Integrating Classification and 
Association  rule mining”, 
[7]
Proc. of the KDD, 1997, New York, NY, 
pp. 80-86,        1998
Wenmin Li, Jiawei Han and Jian Pei, “CMAR: accurate and efficient        
Classification based on multiple class Association rules”
[8]
, Proc.         
ICDM 2001, pp. 369-376
[9]
Xiaoxin Yin, Jiawei Han, “CPAR: classification based on predictive         
Association Rules”, Proc. of SIAM Int. Conf. on Data Mining         
(SDM’03), San Fransisco, CA, pp.331-335. 
F Thabtah, P Cowling and Y Peng , “A study of predictive accuracy 
for four Associative Classifiers”
[10] J. R. Quinlan and R. M. Cameron-Jones. “FOIL: A midterm report.”
In Proc. European Conf Machine Learning, pp. 3{20, Vienna, 
Austria, 1993 
, Journal Of  Digital Information 
Management, 2005
[11] J. Alcala-Fdez, L. Sanchez, S. Garcia, M. J. del Jesus, S. Ventura, J. 
M. Garrell, et al. ”KEEL: a software tool to assess evolutionary 
algorithms for data mining problems”,  Soft Computing – A Fusion of 
Foundations, Methodologies and Applications: Springer Berlin /
Heidelberg, pp.307-318. Available from anonymous ftp.
[12] U.M Fayyad,  K.B. Irani, “Multi-Interval Discretization of 
Continuous Valued Attributes for Classification Learning”, 13th
[13] Kavita Das, O.P. Vyas, “A suitability study of discretization methods 
for Associative Classifiers”, International Journal of Computer 
Applications (0975-8887) Volume 5-No.10, August 2010, pp. 46-51
IJCAI, vol. 2, Chambery, France, 28.8.-2.9.93, Morgan Kaufmann, 
pp. 1022–1027
[14] F. Thabtah, P. Cowling, Y. Peng, “Multiple labels Associative 
classification”, Knowledge and Information Systems. Vol. 9, No. 1., 
pp. 109-129.
