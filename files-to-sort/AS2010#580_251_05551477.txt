Rule Induction for Identifying Multi Layer Tool 
Commonalities 
 
Alexander Borisov, Igor Chikalov, Eric St. Pierre, Eugene Tuv  
Intel Corporation 
4500 S Dobson Rd 
Chandler, AZ  85248 USA  
 
 
Abstract – A methodology based on association rule concepts is 
given for detecting fab tool commonality of affected lots.  The 
performance of the methodology is then compared to several 
traditional methods such as ANOVA and contingency tables 
using eight actual production cases.  In each case, the offending 
tool is affecting lots at multiple process layers.     
 
I. INTRODUCTION  
 
     Many fab tools are used at more than one process step, 
which poses a challenge for identifying tool commonality of 
yield problems.  For example, a specific wet bench might be 
used for a dozen layers (operation numbers), which makes it 
difficult to find a yield problem caused by the bench if one 
looks only a layer at a time.  Also, it would be desirable to be 
able to identify not only which tool is at fault, but also which 
layers on the tool are at fault and on what dates.  There are 
several existing methods in common use to search for tool 
commonality across multiple layers.  Some are model based 
and rank commonalities using statistical tests, such as 
ANOVA and contingency tables.  Others are simple ranking 
criterions that typically have as their goal to rank the tool 
which processed the most affected lots in the shortest period 
of time at the top of the rank list.  Generally these methods do 
not include time or layer in the model or search criterion.  We 
present a rule induction methodology that efficiently searches 
through tools, layers, and time combinations finding and 
ranking those that are likely responsible for the yield 
problems. We compare   performance of the proposed 
methodology with ANOVA, contingency tables, and most-
lots-in-least-time ranking. 
 
     A multi layer tool commonality is loosely defined as a 
commonality which is best found by looking across all layers 
a fab tool is running, rather than looking a layer at a time.  For 
example, consider Fig. 1.  A single fab tool is running 4 
layers.  Lots with a ‘1’ on the y axis have been categorized as 
“Bad” and lots with a ‘0’ have been categorized as “Good”.  
By looking at all layers at once, it is clear that the problem 
started after Dec. 15th and ended before Dec. 21st.   Contrast 
Fig. 1 with Fig. 2, which shows the same time trend split into 
a separate graph for each layer.  The trend is no longer 
apparent when looking a layer at a time. 
 
0
1
Lo
t C
at
eg
or
y
09
D
ec
20
08
11
D
ec
20
08
13
D
ec
20
08
15
D
ec
20
08
17
D
ec
20
08
19
D
ec
20
08
21
D
ec
20
08
23
D
ec
20
08
Date
A
B
C
D
Layer
 
Fig. 1.  Time trend for single fab tool showing good and bad lots by layer. 
 
0
1
Lo
t
C
at
eg
or
y
18
D
ec
20
08
19
D
ec
20
08
19
D
ec
20
08
20
D
ec
20
08
20
D
ec
20
08
21
D
ec
20
08
21
D
ec
20
08
21
D
ec
20
08
22
D
ec
20
08
22
D
ec
20
08
Date
Scatterplot Matrix Layer=D
0
1
Lo
t
C
at
eg
or
y
17
D
ec
20
08
18
D
ec
20
08
19
D
ec
20
08
20
D
ec
20
08
21
D
ec
20
08
22
D
ec
20
08
Date
Scatterplot Matrix Layer=C
0
1
Lo
t
C
at
eg
or
y
11
D
ec
20
08
13
D
ec
20
08
15
D
ec
20
08
17
D
ec
20
08
19
D
ec
20
08
21
D
ec
20
08
Date
Scatterplot Matrix Layer=B
0
1
Lo
t
C
at
eg
or
y
10
D
ec
20
08
11
D
ec
20
08
12
D
ec
20
08
13
D
ec
20
08
14
D
ec
20
08
15
D
ec
20
08
16
D
ec
20
08
17
D
ec
20
08
18
D
ec
20
08
19
D
ec
20
08
Date
Scatterplot Matrix Layer=A
 
Fig. 2.  Time trend from Fig.1 separated by layer. 
 
 
 
 
 
 
 322978-1-4244-6519-7/10/$26.00 ©2010 IEEE ASMC 2010
II.  METHODOLOGY 
A.  Basic Concept of Association Rules 
     A common application of association rules is searching a 
large database of customer purchases at a retail business. It is 
often referred as “market basket analysis” where rules 
generally have the form of {A,B}=>{C}, meaning that if A 
and B are bought, customers also buy C. Rules are usually 
measured by their support and confidence.  Support measures 
what percent of rows in the database are covered by the rule 
conditions. Confidence measures how often the rule is correct.  
For example, if a rule {A,B}=>{C} has 0.65 support and 0.41 
confidence, this indicates that 65% of the transactions in the 
database contain both A and B and 41% of the {A,B} 
combination results in {C}.   A tool commonality rule would 
look like {fab tool, date range, layers}=.{yield issue}.  Here 
we are more interested in the conditional support, which is the 
number of known bad lots that were processed on a specific 
tool, subset of the corresponding layers, during the date range 
identified by the rule.  Confidence can be thought of as a “hit 
rate”, that is, if a number of lots were sent through the specific 
tool, during the rule date range, and at one of the identified 
layers, how many do we expect would be hit with the yield 
problem.  For more on association rules, interested readers are 
referred to [1]. 
     Using the association rule concepts, we could count the 
number of bad lots that occur on tool, layer, and date 
combinations and the number of times that combination 
results in a bad lot.  Our goal is to put the tool at fault at the 
top of a rank list.  However, calculating every possible rule is 
not usually possible since fabs typically have hundreds of 
tools and operation numbers and analysts usually are looking 
at tens of bad lots across 30 day time periods, so the count of 
possible combinations explodes to an impractical number. In 
[2], we successfully adopted the primary association rule 
induction algorithm, Apriori, for single layer commonality 
analysis targeting spatial patterns in sort wafer maps.   Here 
we look to expand the methodology for multi layer 
commonality. 
B.  Applying the Concept to Ranking Tool Commonality 
     The main limitation of the association rules approach, 
which creates an exhaustive set of rules, is the requirement of 
discrete attributes. It means that time through the tool has to 
be pre-discretized and layers are pre-grouped before the 
Apriori algorithm can be used. That poses a significant 
challenge when a correct rule could have multiple constraints 
on the tool, subset of layers, and the time interval. We address 
these limitations by using a direct search optimization 
technique to solve a 2-target (conditional support and 
confidence) maximization problem. The 2-target problem is 
transformed to a single fitness function optimization task that 
combines a weighted combination of conditional support and 
confidence of the resulting rule. Conditional support and 
confidence are intuitive measures that allow us to rank rules 
by a combination of how many bad lots they contain and their 
hit rate. Rules are sorted by the fitness function, and 
accompanied by insightful, novel visualization.  The algorithm 
is given formally in Algorithm 1. 
ALGORITHM 1 
1. For  t = 1,...,T 
2.    Calculate c* = c(min(Xi3),max(Xi3)) and  
       cs* = cs(min(Xi3),max(Xi3)) 
3.    For k = 1,…,K 
4.       for k>1 
           if(cs(LBk-1,UBk-1) < csmin then go to step 14 
          end for 
5.       for k = 1 
            set IUBk = I and UBk = max(Xi3) 
          end for 
6.       For l = 1,…,IUBk 
            set LBl = xl3 
            calculate f(LBl,UBk) 
          End For l    
7.       select LBk =  f(LBl,UBk) 
8.       set ILBk to row number in XT of LBk 
9.       For u = I,…,ILBk 
            set UBu = xu3 
            calculate f(LBk,UBu) 
          End For u 
10.     select UBk  =  f(LBk,UBu) 
11.     set IUBk to row number in XT of UBk 
12.     for k > 1 
            if f(LBk,UBk) ? f(LBk-1,UBk-1) then go to step 14 
          end for 
13.    End For K 
14.      set LB = LBk and UB = UBk 
15.    End For T 
  
l
maxarg
u
maxarg
 TABLE I 
NOTATION FOR ALGORITHM 1 
 
T  Number of fab tools 
I  Number of occurrences of lots on tool t 
K  Number of user specified iterations 
LB Lower date bound for rule 
UB Upper date bound for rule 
C  Confidence calculated on distinct lots 
CS Conditional support calculated on distinct lots 
CSmin User specified minimum conditional support 
f(LB,UB) Fitness function,  
                  (c(LB,UB) – c*) + ?(cs(LB,UB) – cs*) 
?  User specified trade off between C and CS 
XT [xi,j]i=1,…,I,j=1,…,3 where Xi1=Lot ID, Xi2=Affected           
                    ID (0 or 1), Xi3=Date 
    
 323 ASMC 2010
C. Competing Methods 
     Algorithm 1 will be compared to the methods described 
below.  The goal of each is to rank the tool at fault at the top 
of a rank list, but how this is attempted is much different 
between the methods.  For more background on traditional 
commonality methods, see [3] and [4]. 
i.  ANOVA:   Very common method for detecting 
yield differences between tools.  The mean of the 
failing sort bin(s) that make up the spatial pattern are 
calculated by tool, by operation.  The means of all 
tools at an operation are then compared using a 
statistical test.  Tools are then ranked by the 
statistical significance of the difference between the 
tools at a layer.  This is a layer-at-a-time method 
since means for the tools are calculated by layer.  
This method is commonly automated by fab yield 
analysts where a set number of days back (say 30 
days) of end of line sort data is extracted daily and 
ANOVA is automatically performed.   
ii.  Contingency Tables:  Another common statistical 
model based method for finding tool commonality of 
bad lots.  Here, a table is constructed for each fab 
tool, where all lots in the data set are categorized by 
the user as “Good” or “Bad” and also “Yes” or  “No” 
as to whether they ran on a specific tool.  A 2X2 table 
is then constructed where the columns indicate 
whether lots were affected or not, e.g. 
(“Good”,”Bad”), and the rows indicate whether lots 
ran on the tool or not, e.g.   (“Yes”,”No”).  A 
statistical test is then performed to see if the 
proportion of bad lots for a fab tool exceeds that of 
other tools of its kind.  Tools are then ranked by the 
statistical significance of the test.  This is a multi 
layer approach since the 2X2 tables are constructed 
by tool, NOT by tool, by layer. 
iii.  Most-lots-in-least-time:  An intuitive approach 
which ranks fab tools by the percent of the user 
classified “Bad” lots they ran and the shortest length 
of time required to span all “Bad” lots ran on the tool.   
For example, if Tool A and Tool B each ran 9 of 10 
“Bad” lots, but the minimum time span needed to 
cover the 9 lots was 2 days for Tool A and 3 days for 
Tool B, then Tool A would be ranked above Tool B.  
Is a multi layer approach since the count and time 
span are done by tool, NOT by tool and layer. 
iv.  Single Layer Rule:  An association rule based 
method which uses conditional support and 
confidence to rank rules.  Rules are ranked based 
upon their distance from the pareto bound on the 
conditional support-confidence plane.  The pareto 
bound is defined by points for which there is no other 
point with greater conditional support and 
confidence.  Method is described in detail in [2].  
Similar in concept to Algorithm 1, except this is a 
single layer method since rules are built by tool, by 
layer. 
III.  APPLICATION   
 A.  Data Sets 
     The performance of Algorithm 1 was compared to the 
traditional methods for finding tool commonality, namely, 
ANOVA, contingency tables, and most-lots-in-least-time 
ranking.  The 8 data sets used are production data where the 
tool causing the yield problem is affecting lots at multiple 
operation numbers (layers).  These data sets were selected as 
they are typical of the yield problems seen at a modern 
semiconductor fab with high yields.  Because of the high 
yields, the number of die affected per wafer tends to be small, 
which hurts the ability of mean die per wafer based methods 
like ANOVA of finding the correct tool commonality.  All 8 
yield issues have a spatial pattern.  A summary of the 8 data 
sets is given in Table II.  Note that hit rate is the percent of 
bad lots that ran through the tool during the affected time 
period. 
TABLE II 
DATA SET SUMMARY 
 
 
     Space constraints prevent providing more detail on each of 
these cases, however, the Deposition Tool 2 case will be 
highlighted to provide a good idea of the challenges the 
commonality methods face in identifying the fab tool which is 
at fault.  Fig. 3 shows some of the sort wafer maps for wafers 
affected by the deposition tool.  Note that the spatial pattern is 
a small, approximately square region which rotates around the 
edge of the wafer.   
 
 324 ASMC 2010
 Fig. 3.  Sort wafer maps of a sample of the affected wafers 
 
     There are several challenges presented by this data set to 
any commonality method.  Specifically, only 7 lots are 
affected, the problem is intermittent (hit rate is only 16%), 
only a small number of die per wafer are affected, there are 30 
days of end of line data in the data set, there are approximately 
500 fab tools which could be at fault and many of these tools 
are used at multiple operations.  Some or all of these 
challenges are present in each data set.    
B.  Results 
     Table III provides the summary results of applying each 
method to the data sets.  The value given in the table is the 
rank which was given to the correct tool.  For example, a ‘1’ 
indicates the tool which was at fault was ranked at the top of 
the rank list, a ‘17’ indicates the tool which was at fault was 
ranked 17th in the rank list.  A ‘NR’ means that the method did 
not provide a rank for the correct tool since no difference 
between the tool and its peers was detected.  The median and 
range of the ranks for each method are also provided.  The 
order of the methods in the table are from best to worst at 
consistently finding the correct tool as determined by the 
median and range of the ranks.   
 
TABLE III 
RESULTS SUMMARY 
 
     Algorithm 1 (Layer=Multiple, Method=Rule) in Table III, ranks 
the correct tool at the top of the list for all but one of the data sets, 
where it ranks the correct tool as 2nd.  
     Fig.’s 4-6 show supporting graphics generated for the rules found
by Algorithm 1 for the Deposition Tool 2 data set.  Fig. 4 shows the 
rules list and x y scatter plot of conditional support and confidence 
which allows easy browsing of all competing rules in the rank list.   
Fig. 5 is the time trend plot of all lots that ran on the tool identified at
the top of the rule list.  Multi layer time plots are complicated by a lot 
being able to enter the tool many times, as opposed to a single layer 
time plot where a lot can only enter once.  To reduce clutter, only the 
first and last times a lot enters a tool are charted and a line is drawn 
between these two points to indicate that the lot may have entered the 
tool additional times within that range.  Since we are plotting a bi
response (“Good”,”Bad”), it is necessary to add jitter to the y axis so 
that many points are not drawn on top of each other and become 
unidentifiable.  The “Bad” lots are shown in red and are at the top of 
the graph, the “Good” lots are shown in the bottom of the graph.  Th
symbols on the graph correspond to which operation number the lot 
entered the tool.  Fig. 6 shows other graphs generated which allow 
the user to compare the identifie
 
 
nary 
e 
d tool to others of its kind, compare 
operation numbers, and look at the hit rate versus number of times 
lots passed through a bad tool. 
 
Fig. 4.  Sorted rule list and x y scatter plot of confidence and conditional 
support for the Deposition Tool 2 case, multilayer analysis 
 
Fig. 5.  Time trend for the tool at fault  in the Dep. Tool 2 data set  
 325 ASMC 2010
  
Fig. 6.  Other supporting graphics for the rule identified in Fig. 4. 
 
violated, but that is less critical than say, looking only a layer 
at 
C.  Discussion of Results for Competing Methods 
     In general, these methods fail to consistently rank the 
correct tool at the top of the list for at least one of the primary 
reasons in the list below.  There are secondary reasons as well,
such as some of the assumptions of the statistical tests are 
a time for a multi layer yield signal. 
i.  Method searches a layer at a time.  The ANOVA and 
single layer rule methods look at the data split into a layer 
at a time.  As demonstrated in the simple example in Fig. 1 
 
and 2, this can hide an otherwise obvious signal. 
ii.  Method searches for a difference in the mean number of
bad die (or specific sort fail bins).  This is why ANOVA 
tends to fail on these data sets.  At high yielding factories, 
many of the yield issues affect only a small number of lots 
and only a small number of die per wafer on affected lots.  
Too few lots and die per wafer affected results in a small, if 
any difference, between the correct tools and other tools of 
its kind. 
iii.  Method does not effectively restrict the data set to 
approximately the affected time period only.  ANOVA 
calculates the means for each tool on all data provided.  
This means it mixes unaffected and affected time periods, 
diluting the signal.  Contingency tables also tabulate all the 
data provided, again mixing affected and unaffected time 
 
periods and also diluting the signal. 
iv.  Method uses a statistic for ranking which is sensitive to
widely differing run rates and number of layers processed 
between tool types.  This is the case with the most-lots-in
least-time method.  Both Algorithm 1 and most-lots-in-
least time use conditional support as part of the ranking 
criterion.  However, Algorithm 1 also uses hit rate, which 
normalizes for differences in run rates and layers proc
by dividing by the number of lots during the time period.  
Most-lots-in-least time does not normalize for these 
differences, rather it simply searches for the smallest time 
window that includes the largest number of affected lot
This leaves it vulnerable to ranking tools like wet benches 
consistently near the top of all the data sets  since wet 
benches typically have high run rates and are used at many
layers.  A tool with a high run rate that is in use for many
layers is more likely to
-
essed 
s.  
 
  
 have a small time window for the 
affected lots simply because it can run more lots in less 
time more often. 
 
 in 
 
e time 
d, rather than on constructing a 
sample.  Also, it enables greater efficiency in that more signals 
can be found in less time.   
 
IV.  CONCLUSIONS   
     In [2], we demonstrated how methods based on modern
statistical learning algorithms can greatly reduce the time 
required to do the typical analysis done by yield analysts
fabs.  Here, we have focused specifically on how a modern 
method generally referred to as association rules can be 
adapted to out perform traditional methods for doing multi 
layer tool commonality.  While any of the traditional methods
could perform better with more human intervention, such as 
preparing well groomed data sets with carefully constructed 
“Good” lot lists or time periods to compare against, thes
consuming efforts are made unnecessary by Algorithm 1.   We 
have coded the algorithm to run in seconds on a laptop 
computer against data sets of 500 lots and no time consuming 
sample selection is required from the user in order for the 
method to find the correct tool commonality, just run the past 
n days of data through the algorithm.  The benefit for the 
analyst is that more time can be spent following up on the top 
few commonalities identifie
 
 
 326 ASMC 2010
 , IEEE/SEMI International , vol., no., 
pp.85-89, 21-23 May 1990 
V.  REFERENCES   
[1] T. Hastie,  R Tibshirani, and J. Friedman,  The Elements of Statistical 
Learning,  New York:  Springer-Verlag, 2001. 
[2] St. Pierre, E.R.; Tuv, E.; Borisov, A., "Spatial Patterns in Sort Wafer 
Maps and Identifying Fab Tool Commonalities," Advanced 
Semiconductor Manufacturing Conference, 2008. ASMC 2008. 
IEEE/SEMI , vol., no., pp.268-272, 5-7 May 2008  
[3] Kong, G., "Tool commonality analysis for yield enhancement," 
Advanced Semiconductor Manufacturing 2002 IEEE/SEMI Conference 
and Workshop , vol., no., pp. 202-205, 2002 
[4] Garling, L.K.; Woods, G.P., "Determining equipment performance using 
analysis of variance," Semiconductor Manufacturing Science 
Symposium, 1990. ISMSS 1990.
327 ASMC 2010
