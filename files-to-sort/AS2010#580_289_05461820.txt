An Efficient Online System of Concept Based 
Association Rules Mining  
Hany Mahgoub#1, Arabi Keshk#2, Fawzy Torkey#3, Nabil Ismail*4
#Faculty of Computers and Information, Menoufia University 
Shebin El-Kom, Egypt 
1h_mahgoub,@yahoo.com
2arabikeshk@yahoo.com
3fatorkey@yahoo.com
*Faculty of Electronic Engineering, Menoufia University 
Menouf, Egypt 
4nabil_a_ismail@yahoo.com
 
Abstract— This paper presents a new text mining system for 
extracting association rules based on concepts from online 
textual documents. The system is called developed extracting 
association rules from textual documents. The mathematical 
formula of weighting schema is used for labeling the documents 
automatically and its named fuzzy weighting schema. A new 
algorithm is proposed for generating association rules based on 
concepts and it used a data structure of hash table for the mining 
process. The experiments are applied on a collection of scientific 
documents that selected from MEDLINE for breast cancer 
treatments and side effects. The performance of proposed system 
is compared with the previous Apriori-concept system for the 
execution time and the evaluation of the extracted association 
rules. The results show that the number of extracted association 
rules in the proposed system is always less than that in Apriori-
concept system. Moreover, the execution time of proposed system 
is much better than Apriori-concept system in all cases. 
 
Keywords— Text mining, Data mining, Association rules mining, 
Concept extraction, MEDLINE. 
I. INTRODUCTION
The explosive growth of information in textual documents 
creates a great need of techniques for knowledge discovery 
from text collections. Collecting, analyzing and extracting 
useful information from a very large amount of medical texts 
are difficult tasks for researchers in the medicine who need to 
keep up with scientific advances. Nowadays several domains 
in medical practice, drug development, and health care require 
support for such actives such as bioinformatics, medical 
informatics, clinical genomics, and many other sectors. 
Moreover, the examined textual data are generally 
unstructured as in the case of Medline abstracts in the 
available resources such as PubMed, search engine interfacing 
Medline and medical records [38]. All these resources do not 
provide adequate mechanisms for retrieving the required 
information and analyzing very large amount of text content. 
Text Mining is a tool to support and automate the process of 
finding and extracting interesting information from the 
documents. Selecting features are necessary and sufficient for 
constructing a model that can accurately predict future events 
or describe a problem. The models based on informative 
features will be easier to interpret from the other models, 
which are based on uninformative features. The quality of the 
features must be described in terms of semantic richness. For 
example, breast cancer is a disease occurring in a particular 
part of the body. If a text mining system represented this 
phrase using the two individual features breast and cancer, it 
would not capture the meaning of the phrase breast cancer. 
Thus, the concept feature breast cancer is semantically richer 
than the individual features breast and cancer. Therefore 
increasing the information content or semantic richness of the 
features will increase the plausibility and usefulness of the 
extracted association rules. 
In this paper, we present a new text mining system that 
called developed extracting association rules from textual 
documents (D-EART) for extracting association rules from 
online structured and unstructured documents. The design of 
the D-EART system is based on concepts representation.  D-
EART is designed to overcome the drawbacks of the previous 
EART system that is presented in [24]-[25]. The mathematical 
weighting schema formula that used in the EART system is 
developed and is named fuzzy weighting schema. In addition, 
generation association rules based concept algorithm (GARC) 
is used for the mining process instead of word based as in the 
traditional data mining algorithms. In the D-EART system, 
MEDLINE abstracts are selected for the breast cancer 
treatments and side effects as the main domain of online 
collecting documents. The system is consists of three phases 
that are Text Preprocessing, Association Rule Mining (ARM),
and visualization.  
The reset of this paper is organized as follows. Section 2 
presents the related works. Section 3 presents the D-EART 
system architecture. Experimental results are presented in 
section 4. Section 5 provides conclusions and future work. 
II. RELATED WORKS 
There are several previous works in the field of association 
rules mining from structured documents (XML data) [4], [6], 
[11], [29], [31]-[34].  More precisely the ability to extract 
useful knowledge from XML data is needed because the 
numerous data have been represented and exchanged by 
XML. Thought there are some works to exploit XML within 
the knowledge discovery tasks, and most of them rely on 
legacy relational database with an XML interface. In addition, 
mining knowledge in XML world is faced with more 
challenges than in the traditional well-structured world 
because of the inherent flexibility of XML. Extracting 
association rules from native XML documents called “XML 
association rules” was first introduced by Braga et al in [6]. 
All the previous works in this field are based on the word 
features or structured data, consequently all extracted 
association rules are the relations between words [31]-[34].  
Recently, some works developed tools for extracting 
association rules from XML documents [7]-[35], but both of 
them are approaching from the view point of XML query 
language. This caused the problem of language-dependent 
association rules mining. Ding et. al in [11] developed a 
method to discover all of the possible rules, i.e. generalized 
association rules from XML documents. In this method, all of 
the possible combinations of XML nodes based on their 
multiple nesting are used to generate the relational 
transactions format. This method suffered from some 
shortcomings such as generation of redundant rules. 
Moreover, it ignored the valuable tree structure of the 
documents.  
A model for the effective extraction of generalized 
association rules from a collection of XML document is 
presented in [4]. This method does not used frequent subtree 
mining techniques in the discovery process and not ignored 
the tree structure of data in the final rules. The frequent 
subtrees based on the user that provide support and split to 
complement subtrees to form the rules. From the above 
previous works, we found that all works concentrated on the 
domain of Association Rules Mining (ARM) based on words 
from XML data documents. Therefore this research is 
concentrated on mining of association rules based on concepts 
from native XML text documents and deals with their tags. 
In the field of ARM from unstructured documents, there is a 
large body of previous works. Identifying informative features 
from natural language (text) can be difficult so that the 
problem is that there are many approaches use semantically 
poor features, such as words [3], [14], [21]-[32]. These 
approaches take bag of words as input to the association rule 
mining algorithm such as Apriori algorithm, and finds 
associations among single isolated words. These approaches 
have the advantage of domain independent and easy to 
implement. There are two drawbacks in these approaches: (1) 
some concepts consist of multiple words, these multiple words 
concepts cannot be found as a unit in the association rules, and 
(2) the number of association rules is tremendously large.  
There are some approaches was concentrated on extracted 
association rules based on concepts instead of words as in 
[17], [19], [20], [23], [27], [33]-[37]. The identified problems 
in these approaches are: (1) the ambiguity of the language and 
can be overcome with human interaction. (2) They used the 
Apriori algorithm to generate association rules based on 
concepts. (3) There are many systems based on word features 
representation and do not take into account the synonymy 
problem. These systems could cause a text mining system to 
generate a misleading model of association rules.  
The earlier work of association rules mining from text has 
explored the use of manually assigned keywords [5], [12], 
[13]-[14]. They used keywords as features for generating 
association rules. The drawbacks of these approaches are that:  
(1) It is time consuming to manually assign the keywords.  
(2) The keywords are fixed (i.e., they do not change over the 
time or based on a particular user).  
(3) As the keywords are manually assigned, they are subject to 
discrepancy.  
(4) The textual resources are constrained to only those that 
have keywords.  
Therefore, the work is needed to automate indexing of the 
textual document in order to allow the use of association 
extraction techniques on a large scale. Another research has 
been focused on constructing techniques to improve the 
quality of text-mined association rules. Most of these 
approaches generate a set of rules, and apply ranking 
techniques such as interestingness as in [8], [10], [15], [22]-
[30]. Unlike these approaches, this research is focused on 
extracted the interesting set of the association rules. That rules 
are based on semantically richer representations. In mining 
area, most of previous studies adopt an Apriori for candidate 
set generation and test approach. However, candidate set 
generation is still costly, especially when there are a large 
number of patterns and/or long patterns [18]. Agrawal et al. 
had first introduced the problem of association rules mining 
[2]. Methods for association rules mining from both structured 
and unstructured documents have been well developed. 
Apriori and AprioriTid Algorithms are presented in [1]. These 
Algorithms, which are used for discovering large itemsets, 
make multiple passes over the data. This is the main problem 
of the Apriori algorithm since it reduces the performance of 
the system by increasing the time and generating 
tremendously large association rules where most of them are 
not plausible and useful. 
III. D-EART SYSTEM ARCHITECTURE 
The D-EART system is automatically discovers association 
rules from the collection of online structured and unstructured 
documents as shown in Fig. 1. It is designed to discover three 
types of relations such as: 
(1)  The association rules amongst concepts only.  
(2)  The association rules amongst the words only that are 
remained in the documents after extracted the concepts.  
(3)  Get the relations between the concepts and words in the 
form of complex rules.  
The modifications in the D-EART that overcome the 
drawbacks of the previous EART system in [24]-[25] are as 
follows:  
(1) On-line documents collecting and it accepts all native 
XML documents. 
(2) The system designed for concepts representation, and it 
takes into account the characteristics of the natural 
language such as synonymy. 
(3) The system automatically indexing documents by using 
the developed fuzzy weighting schema without using the 
threshold weight value. 
Visualization Phase 
 
 
(4) The system designed based on a new algorithm for 
extracting association rules based on concepts (GARC). 
The algorithm overcomes the drawbacks of the previous 
algorithms by employing the power of data structure 
called hash table. Furthermore the system has the ability 
to perform different queries on the extracted association 
rules.  
The D-EART system is consists of three main phases beside 
the online documents collection.  The main phases are Text
Preprocessing phase that include transformation, filtration, 
stemming, synonymy and indexing of documents, Association
Rule Mining (ARM) phase that include a new GARC 
algorithm, and visualization phase. 
 
 
         
                Text Preprocessing Phase 
 
 
Fig. 1 The D-EART system architecture 
A. Online Documents Collection 
The D-EART system works online, so it is considered to be 
as a web-based text mining system. The D-EART accepts the 
documents that in XML format (structured) and also the 
unstructured documents. From the interface of the D-EART 
system, the user can online access the MEDLINE link and 
writes the search keywords. The selected documents and their 
tags are automatically loading into the system and the user 
selects the specific part of documents that will work on it. 
B. Text Preprocessing Phase 
The D-EART system has the ability to deal with the native 
XML documents and the unstructured documents. The process 
of concept extraction is done and the documents are filtered,
stemmed and synonym used. Finally, the XML documents are 
automatically indexed by using the fuzzy weighting schema. 
1) Transformation: Once the online XML documents 
download into the system, their tags are automatically 
extracted in a combobox as shown in Fig. 2. The user can 
determine his specific part of the documents (for example the 
abstract part, </Abstract Text>) to work on it. Therefore the 
D-EART system is flexible to work on specific or all parts of 
documents. In the case of the unstructured documents, the D-
EART system transforms them to the XML format.  
 
Fig. 2 Selecting a specific tag of the documents 
2) Concept Extraction: The concept is a single word or a 
group of consecutive words that occurs frequently enough in 
the entire document collection. It is important to appear the 
concepts as a unit in the extracted association rules. The 
process of concept extraction as shown in Fig. 3 can be done 
as follows: (1) Splitting the documents into sentences by using 
the End-of-Sentence Detection Algorithm (ESDA) to 
determine the sentence boundary [36]. (2) Determine each 
concept candidate using n-grams model [9], [16]-[26]. We 
collect all the ordered pairs, or 2-grams, (A, B) such that 
words A and B occur in the same document in this order and 
the pair is frequent in the document collections. (3) Building a 
list of all concepts in the D-EART system, and map the 
concepts from concept list with sentences in documents and 
then estimate their frequencies. (4) Store all concepts with 
their frequencies in XML file. 
3) Filtration: The documents are filtered by removing the 
unimportant words from the documents. A list of unimportant 
words called stopwords is built. The system checks the 
Visualize Association Rules in tables or reports 
format 
Native XML 
documents
Unstructured 
documents 
Online 
MEDLINE Abstracts 
Preprocessed 
documents
 
 
 
 
 
 
Association Rule Mining Phase 
Apply GARC algorithm on the index d documents to 
generate all conceptsets whose support is greater than 
the user specified minimum support (min_support) 
Generate all Association Rules that satisfied a user 
minimum confidence (min_confidence) 
Concepts with 
frequencies 
Stemming
Lexicon
Index documents by using the fuzzy 
weighting scheme Fuzzy TF-IDF for all 
concepts in all documents.   
Filtered XML 
documents 
Filtration
Concepts list Stop words
Synonymy Lexicon
Concepts 
extraction 
using n-grams 
XML file 
Transforme 
Documents 
to XML 
format
documents content and eliminates these unimportant words 
(e.g. articles, pronouns, conjunctions, and common adverbs). 
Moreover, the system replaces special characters, parentheses, 
commas, etc., with distance between words and concepts in 
the documents. 
1. For each document in the corpus 
2. Sentence boundary m End of Sentence Detection 
Algorithm 
3. Concept List  
4. For each concept in the Concepts List 
5. Count=0 
6.     For each sentence in the documents 
7.       N-grams concept in sentence m Concept in 
Concepts List 
8.        Count +; 
9.     End for 
10. End for 
11. Concept File m Each Concept with its frequencies 
 
Fig. 3 Concepts extraction process 
4) Stemming: After the filtration process had done, the D-
EART system automatically do word stemming based on the 
inflectional stemming algorithm which illustrated in [36]. The 
inflectional stemming algorithm consists of both part of rule-
based and dictionary-based. 
5) Synonymy: In the synonymy process, the D-EART 
system matches each concept in the documents with the 
augment synonymous list.  When the system finds a 
synonymy for the concept, it replaces the concept in all 
documents with its synonymy. For example, the phrase hair 
loss is synonymous with the medical concept alopecia. The 
actual times occurs number of this concept is the total number 
of times that hair loss and alopecia occurs in the text. Since a 
concept representation would unify the expression hair loss 
with alopecia and thus account for synonymy. In contrast, the 
systems based on word representation would distribute the 
count between the three features hair, loss, and alopecia. The 
word based count would be smaller than the actual number of 
occurrences of the medical concept alopecia.  
6) Indexing: Mathematical formula of weighting schema in 
D-EART system is developed and used in [24]-[25], and it 
named fuzzy weighting schema. This formula overcomes the 
drawbacks of the standard weighting schema. All weighted 
concepts are store in XML file for using them as input to the 
mining process.    
One of the drawbacks of the previous EART system is that 
the value of the threshold weight is hard. So we developed the 
system to automatically compute the weight value for each 
word and select the actually important concepts without 
entering the threshold weight value M. We developed the 
mathematical formula weighting schema and named it fuzzy 
weighting schema since the threshold weight value is replaced 
with the fuzzy membership value as shown in equation (1) 
)1(10, °¯
°®
­
dd PP where
C
Nt
ji
j
 
Where denotes the number of documents in collection C 
in which occurs at least once (document frequency of the 
term ) and ?C? denotes the number of the documents in 
collection C. Therefore, the fuzzy weighting schema is 
defined as follows: 
jNt
jt
jt
)2(
0,0
1,log,
,),(
2
°°¯
°°®
­
 
t ?
ji
ji
j
ji
tNdif
tNdif
Nt
C
tNd
jijiwFuzzy P  
This formula caused developing in the system since the high 
weighted values were given to the concepts that are more 
occurrences in the documents. Moreover, new concepts 
appeared with high fuzzy weighted values although they are 
disappeared by using the weighing schema. The D-EART 
system automatically eliminates 10% of all concepts that have 
low weighted values. After that the system stores all concepts 
without redundancy with their frequencies in XML file for 
using them as input to the mining process.  
Consider the 6-collection of documents as shown in Fig. 4. 
In the indexing process, the fuzzy weighted values are 
calculated for each concept in the 6 documents. The total 
number of concepts is equal to 21 concepts in all documents. 
We summarized all concepts with their two weighted values 
in Table I.
Collection of Documents
DID Concepts
D1 
D2 
D3 
D4 
D5 
D6 
C1 C2 C1C3 C6 C4
C3 C4 C5 C3 C5 C5 C4
C2 C3C4 C2 C3 C3 C3 C5
C1C5 C4 C1 C5 C1 C5 C5 C5
C3 C4 C5 C3 C4 C5 C3
C2 C5 C4 C5 C2 C5 C2 C5
Fig. 4 The collection of 6 documents  
From Table I, it noticed that a concept C4 has zero weighted 
values so that the system automatically eliminates it from all 
documents. The system resorts the concepts based on their 
weighted values from the highest to the lowest. Table II shows 
all resorted concepts with their TF-IDF values. By choosing 
the threshold weight value M=50%, all concepts that in the 
shaded region had discarded. The system stores all accepted 
concepts without redundancy which are approximately 4 
concepts (C1, C2, C3 and C6) in XML file. Table III shows the 
same resorted concepts but with their Fuzzy TF-IDF values. 
The concepts that appear in the shaded region had discarded, 
since the less important concepts with fewer frequencies 
always exist in the bottom of the table. After that the system 
stores all concepts without redundancy with their frequencies 
which are approximately 4 concepts (C1, C2, C3 and C5) in 
XML file for using them as input in the mining process.  
It noticed that the descending order of the concepts becomes 
different from the order in Table II. The main reasons for the 
difference are:  
 
 
TABLE I 
THE TF-IDF AND FUZZY TF-IDF VALUES FOR EACH 
CONCEPT IN SIX DOCUMENTS 
D
-I
D
C
on
ce
pt
 
Fr
eq
ue
nc
ie
s 
N
o.
 o
f 
do
cu
m
en
ts
 
T
F-
ID
F
Fu
zz
y 
TF
-
ID
F
C1 2 2 0.954 0.318 
C2 1 3 0.301 0.151 
C3 1 4 0.176 0.117 
C6 1 1 0.778 0.129
D1 
 
C4 1 6 0.0 0.0
C3 2 4 0.352 0.235 
C4 2 6 0.0 0.0
D2 
 
C5 3 5 0.237 0.197 
C2 2 3 0.602 0.301 
C3 4 4 0.704 0.469 
C4 1 6 0.0 0.0 
 
D3 
 
C5 1 5 0.079 0.066 
C1 3 2 1.431 0.477 
C4 1 6 0.0 0.0
 
D4 
 C5 5 5 0.395 0.329 
C3 3 4 0.528 0.352 
C4 2 6 0.0 0.0
D5 
 C5 2 5 0.158 0.132 
C2 3 3 0.903 0.452 
C4 1 6 0.0 0.0
 
D6 
 C5 4 5 0.316 0.263 
 (1) The first effect of the fuzzy weighting schema, since the 
high weighted values are given to the concepts that are 
more occurrences in documents. For example, the concept 
C6 is in two different orders as shown in Table II and Table 
III. The weighing schema considered the concept C6 an 
important concept although it occurred only one time in all 
documents.  
(2) The second effect of the fuzzy weighting schema is the 
appearing of new concepts with high fuzzy weighted 
values in the top of the list. For example, in Table II the 
concept C5 does not satisfy the threshold weight value 
although C5 occurred 5 times in D4. In contrast in Table III 
the concept C5 has a high fuzzy weighted value and exists 
in the top of the table.  
C. Association Rule Mining (ARM) Phase 
The D-EART system designed to extract association rules 
based on concepts by using a new GARC algorithm. The 
algorithm overcomes the drawbacks of the Apriori algorithm 
by employing the power of data structure called Hash Table. 
The hashing function h(v) and concepts number (N) 
considered the key factors in hash table building and search 
performance. The GARC algorithm is utilized with dynamic 
hash table.  
1) Generating Association Rules Algorithm Based on 
Concepts (GARC): The proposed GARC algorithm as in Fig. 
5 employs the following two main steps: (1) based on the 
number of concepts (N) in the documents, a dictionary table 
was constructed as shown in Table IV for N = 6 concepts, and 
(2) There are also two main processes for a dynamic hash 
table: the building process, and the scanning process. The 
mining process for GARC algorithm includes the two 
processes (building and scanning process) on the given XML 
file that contains all concepts.  
 
 
 
TABLE II 
THE CONCEPTS WITH THEIR 
TF-IDF.
TABLE III 
 
C
on
ce
pt
 
D
oc
um
en
ts
T
F-
ID
F
C
on
ce
pt
 
D
oc
um
en
ts
Fu
zz
y 
TF
-
ID
F
C1 D4 1.431 C1 D4 0.477 
C1 D1 0.954 C3 D3 0.469
C2 D6 0.903 C2 D6 0.452 
C6 D1 0.778 C3 D5 0.352 
C3 D3 0.704 C5 D4 0.329
C2 D3 0.602 C1 D1 0.318 
C3 D5 0.528 C2 D3 0.301 
C5 D4 0.395 C5 D6 0.263 
C3 D2 0.352 C3 D2 0.235 
C5 D6 0.316 C5 D2 0.197 
C2 D1 0.301 C2 D1 0.151 
C5 D2 0.237 C5 D5 0.132 
C3 D1 0.176 C6 D1 0.129
C5 D5 0.158 C3 D1 0.117 
C5 D3 0.79 
 
C5 D3 0.066 
THE CONCEPTS WITH THEIR 
FUZZY TF-IDF.
 
TABLE IV 
THE DICTIONARY TABLE FOR SIX CONCEPTS IN 
DOCUMENTS 
Dictionary Table 
Concept' s name Abbreviation Location 
Breast Cancer 
Docetaxel 
Tamoxifen 
Methotrexate 
Alopecia 
Fatigue 
C1
C2
C3
C4
C5
C6
0 
1 
2 
3 
4 
5 
 
The hash function h(v) = v mod N, where v is a key 
(location of primary concept) is used to build a primary bucket 
of the hash table. The algorithm scans only the XML file that 
contained all important concepts not the original documents. 
The scanning process is done as follows:  
(1) Make all possible combinations of concepts then 
determine their locations in the dynamic hash table by 
using the hash function h(v).  
(2) Insert all concepts and conceptsets in a hash table and 
update their frequencies, the process continues until there 
is no concept in the XML file.  
(3) Save the dynamic hash table into secondary storage media.  
(4) Scan the dynamic hash table to determine the large 
frequent conceptsets that satisfy the threshold support. 
GARC_algorithm ( ) 
1. Input   minimum support (s), minimum confidence (c ), 
the number of concepts (N) 
2. Build a primary bucket of hash table 
3. IF there is no EOF THEN 
4.      FOR each document  D ( d(1) d(2) ... d(n) ) DO 
5.           Select each concept c(1), c(2), ..., c(N)
6.         Create all combinations of conceptset with their 
occurrences 
7.       Insert all conceptsets with their occurrences in hash 
table by using h(v) 
8.              IF  there is  document D THEN
9.                   Goto line 4 
10.              ELSE 
11.                  Goto line 17  
12.              ENDIF 
13.      ENDFOR   
14. ELSE
15. Goto line 19
16. ENDIF
17. Determine all large frequent conceptsets that satisfies 
the minimum support 
18.  Extract all Association Rules that satisfies minimum 
confidence 
19.  STOP 
Fig. 5 The GARC algorithm 
2) The Advantages of the GARC Algorithm: The advantages 
of the GARC algorithm summarize as follows:  
(1) The algorithm permits the end user to change the threshold 
support and confidence factor.  
(2)   Small size of dynamic hash table, since with changing the 
size of conceptsets the size of dynamic hash table will 
change.  
(3) Less number of conceptsets, since there is no conceptsets 
with zero occurrences will occupy a size in a dynamic hash 
table.  
3) The GARC Algorithm Case Study: The D-EART system 
run on a collection of 100 online XML documents selected 
from MEDLINE by thresholds values: support s=2% and 
confidence c=50%. The number of concepts N= 30 resulted 
from the indexing process and used for building a dynamic 
hash table. Fig. 6 shows the number of all fuzzy weighted 
concepts that labeling each document. Fig. 7 shows the 
number of the resultant association rules with c = 50% which 
is equal to 64 rules.  
The D-EART system can do different queries on the 
extracted association rules. The query supports the medical 
researchers by a model of important relationships within the 
concept features. This model might identify relations between 
the disease and the suitable treatments, and relations between 
a treatment and its side effects. Fig. 8 shows the query screen 
which includes both the categories information and the queries 
result icons. The user can determine which the categories will 
get the relations between them. The query results can be saved 
on the hard disk through the export icon. 
 
Fig.6 The number of fuzzy weighted concepts 
 
Fig. 7 The resultant rules that satisfy c = 50%.  
 
Fig. 8 Query Screen 
The advantages of D-EART system are as follows: 
(1) The user can access XML textual documents online. 
(2) The design of the D-EART system is based on concept 
representation and considers the synonymy as a 
characteristic of the natural language characteristics. 
(3) It is flexible to work on specific or all parts of the 
documents with the same structure. Moreover it is not 
fully domain-independent so we can apply it on other 
domains. 
(4) The proposed GARC algorithm overcomes the drawbacks 
of the previous algorithms.  
(5) It extracts three types of the association rules depending 
on the analysis of relations between the concepts only, 
words only and concepts with words. In addition different 
queries are available on the extracted association rules. 
IV. EXPERIMENTAL RESULTS 
The experiments are performed to compare the 
performance of both D-EART system and Apriori-concept 
system for the number of extracted association rules and the 
execution time. Finally, evaluate the performance of D-EART 
system at the three semantic levels: concepts only, words 
only, and concepts with words.  
The corpus of the PubMed abstracts that used in the 
experiments is consists of 10000 biomedical abstracts with 
keyword search “breast cancer treatments and side effects” 
[38]. All experiments are applied on the 10000 documents 
after divided them into six documentsets 50, 100, 500, 1000, 
5000, and all 10000 documents. The systems are implemented 
by using VS .Net 2005 (C#) and the experiments were 
performed on Intel Core2 Duo, 1.8 GHz system with 
Windows XP and 2 Giga of RAM. 
A large number of association rules can be extracted by 
selecting the values of minimum support and confidence in 
the mining process.  The D-EART system gives the best 
results by using low support and high confidence values. 
Moreover, the number of concepts that entered to the mining 
process is fewer by using the fuzzy weighting schema. Table 
V shows the experiments that are applied on various 
documentsets by different threshold values. It noticed that the 
number of extracted association rules in D-EART system is 
useful and always less than that in Apriori-concept system. 
The reason returns to the strong effect of using the fuzzy 
weighting schema in D-EART system.  
Fig. 9 and Fig. 10 show that the execution time of Apriori-
concept system is increased regularly when the documentsets 
are increased compared to D-EART system. The mining 
process in Apriori-word system takes more time for less 
number of concepts in the documents. The reason is that the 
mining process in Apriori algorithm depends on the size of 
documents rather than the number of concepts. The results 
show that the execution time of Apriori-concept system is 
about seventh fold of D-EART system. The D-EART system 
scans the documents only one time as the number of 
documents increased. Therefore the size of documents does 
not influence in the mining process. Finally, the results reveal 
that the execution time for D-EART system is much better 
than that of the Apriori-concept system in all cases. 
 
TABLE V  
THE NUMBER OF ASSOCIATION RULES FOR APRIORI-
CONCEPT AND D-EART SYSTEMS 
Minimum Support (s),
Minimum Confidence (c)
N
o.
 o
f 
D
oc
um
en
ts
Systems 
s =1%,
c =50% 
3%, 
50% 
7%, 
60% 
10%, 
50% 
50
0 Apriori-concept 
D-EART 
183 
71 
76 
31 
17 
5 
10 
2 
10
00
 Apriori-concept 
D-EART 
227 
86 
91 
34 
11 
4 
8 
3 
50
00
 Apriori-concept 
D-EART 
239
92 
75 
27 
20 
4 
15 
2 
10
00
0 Apriori-concept 
D-EART 
345 
135 
102 
39 
37 
10 
30 
7 
 
D5000
0,00
5,00
10,00
15,00
20,00
25,00
30,00
Apriori-concept D-EART
Ti
m
e 
in
 m
in
ut
es
s=1, c=50 s=3, c=50
s=7, c=60 s=10, c=50
Fig. 9 Execution time of Apriori-concept and D-EART systems at 
D=5000 
D10000
0,00
5,00
10,00
15,00
20,00
25,00
30,00
35,00
40,00
Apriori-concept D-EART
Ti
m
e 
in
 m
in
ut
es
s=1, c=50 s=3, c=50
s=7, c=60 s=10, c=50
Fig. 10 Execution time of Apriori-concept and D-EART systems at 
D=10000 
V. CONCLUSIONS AND FUTURE WORK 
This paper presented a new text mining system for 
extracting association rules based on concepts representation 
from online textual documents. This system overcame some 
of the problems in the previous EART system and the 
drawbacks of the Apriori algorithm by using the data structure 
hash table in the mining process. The results of comparing D-
EART and Apriori-concept systems reveal that the number of 
extracted association rules in D-EART system is always less 
than that in Apriori-concept system. Moreover, the execution 
time for D-EART system is much better than that of Apriori-
concept system in all cases. So concept technique would be 
suitable to apply to any large corpus of medical text such as 
portions of the web. The future work will apply D-EART on 
PDF full text document with figures and images instead of 
using only the abstract part.  
REFERENCES 
[1] R. Agrawal, and R. Srikant, “Fast algorithms for mining association 
rules,” In Jorge B. Bocca, Matthias Jarke, and Carlo Zaniolo, editors, 
Proc. 20th Int. conf. of very Large Data Bases, VLDB, Santigo, Chile, 
1994, pp. 487-499. 
[2] R. Agrawal, T. Imielinski, and A. Swami, “Mining association rules 
between Sets of items in large databases,” In Buneman, Peter and 
Jajodia, Sushil (Eds.), in Proc. of the ACMSIGMOD Int. Conf. on 
Management of Data, Washington, D.C., 1993, pp. 207–216.  
[3] H. Ahonen O. Heinonen, M. Klemettinen, and A. Verkamo, “Applying 
data mining technique for descriptive phrase extraction in digital 
document collections,” in Proc. of IEEE Forum on Research and 
technology Advances in Digital Libraries, Santa Barbra CA, 1998.  
[4] R. AliMohammadzadeh, M. Rahgozar, and A. Zarnani, “A new model for 
discovering XML association rules from XML documents,” in Proc. 3rd
Int. Conf. on Knowledge Mining, ICKM, Prague, Czech Republic, 2006, 
Aug. 25-27, pp. 365-369. 
[5] A. Amir, Y. Aumann, R. Feldman, and M. Fresko, “Maximal association 
rules: A tool for mining associations in text,” Journal of Intelligent 
Information Systems, 25:3, pp. 333-345, 2005.  
[6] D. Braga, A. Campi, M. Klemettinen, and P. L. Lanzi, “Mining 
association rules from XML data,” in Proc. of the 4th  Int. Conf.  on Data 
Warehousing and Knowledge Discovery, Aixen-Provence, France, 
September 4-6, 2002.  
[7] D. Braga, A. Campi, S. Ceri, M. Klemettinen, and P. L. Lanzi, “A tool for 
extracting XML association rules,” in Proc. of the 14th IEEE Int. Conf. on 
Tools with Artificial Intelligence (ICTAI’02), 2002, pp. 57–64.  
[8] S. Balbi, and E. Meglio, “A Text Mining Strategy based on local contexts 
of words,” JADT 2004: 7th Journées internationales d’Analyse statistique 
des Données Textuelles, 2004. 
[9] P. F. Brown, Della Pietra, V. J., deSouza, and P. V. Lai, “Class-based n-
gram models of natural language,” Computational Linguistics, vol. 18, 
pp. 467–479, 1992.  
[10] H. Cherfi, A. Napoli, and Y. Toussaint, “Towards a text mining 
methodology using association rule extraction,” Published online: 31 
May 2005 © Springer-Verlag 2005. 
[11] Q. Ding, K. Ricords, and J. Lumpkin, “Deriving general association rules 
from XML data,” in Proc. of Fourth ACIS Int. Conference on Software 
Engineering, Artificial Intelligence, Networking, and Parallel/ 
Distributed Computing (SNPD'03), Lübeck, Germany, October 16-18, 
2003.  
[12] R. Feldman, and I. Dagan, “Knowledge discovery in textual databases 
(KDT),” in Proc. 1st Int. Conf. on Knowledge Discovery and Data 
Mining, 1995.  
[13] R. Feldman, and H. Hirsh, “Mining associations in text in the presence of 
background knowledge,” in Proc. 2nd Int. Conf. on Knowledge Discovery 
and Data Mining, Portland, USA, 1996.  
[14] R. Feldman and I. Dagan and H. Hirsh, “Mining text using keyword 
distributions,” Journal of Intelligent Systems, 10, pp. 281-300, 1998. 
[15] P. Feng H. Zhang Q. Qiu, and Z. Wang, “PCAR?an efficient approach 
for mining association rules,” 5th Int. Conf. on Fuzzy Systems and 
Knowledge Discovery, IEEE 2008.  
[16] J. Fürnkranz, “A study using n-gram features for text categorization,” 
Austrian Research Institute for Artificial Intelligence Technical Report 
OEFAI-TR-98-30 Schottengasse 3, A-1010 Wien, Austria, 1998. 
[17] Y. Fu, T. Bauer, J. Mostafa, M. Palakal, and S. Mukhopadhyay, 
“Concept extraction and association from cancer literature,” WIDM’02, 
Mclean, Virginia, USA, November 8, 2002.  
[18] J. Han, J. Pei, and Y. Yin, “Mining frequent patterns without candidate 
generation,” In W. Chen, J. Naughton, and P. A. Bernstein, editors, 2000 
ACM SIGMOD Intl. Conf. on Management of Data, ACM Press, 05, 
2000, pp. 1-12. 
[19] W. Jin, R. K. Srihari, and X. Wu, “Mining concept associations for 
knowledge discovery through concept chain queries,” Z.-H. Zhou, H. Li, 
and Q. Yang (Eds.): PAKDD 2007, LNAI 4426, pp. 555–562, 
2007.Springer-Verlag Berlin Heidelberg 2007.  
[20] R. Joshi, X. Li , S. Ramachandaran, and T. Leong (2004). “Automatic 
Model Structuring from Text using BioMedical Ontology,” [Online]. 
Available: http://www.aaai.org/Papers/Workshops/2004/WS-04-
01/WS04-01-013.pdf/   
[21] B. Lent, R. Agrawal, and R. Srikant, “Discovering Trends in Text 
Databases,” in Proc. of KDD, Int. Conf. on Knowledge Discovery, 
NewPort Beach, CA, , August 14-17, 1997, pp. 227-230.  
[22] Y. Liu, S. Navathe, A. Pivoshenko, A. Dasigi, R. Dingledine, and B. 
Ciliax, “Text analysis of Medline for discovering functional relationships 
among genes: evaluation of keyword extraction weighting schemes,” Int. 
J. Data Mining and Bioinformatics, Vol. 1, No 1, 2006.  
[23] S. Loh, L. Wives, and J. Oliveira, “Concept-based knowledge discovery 
in texts extracted from the web,” ACM SIGKDD, pp.29-39, July 2000.  
[24] H. Mahgoub, and D. Rösner, “Mining association rules from 
unstructured documents,” in Proc. 3rd Int. Conf. on Knowledge Mining, 
ICKM, Prague, Czech Republic, Aug. 25-27, 2006, pp. 167-172.  
[25] H. Mahgoub, D. Rösner, N. Ismail, and F. Torkey, “A text mining 
technique using association rules extraction,” Int. J. of Computational 
Intelligence, WASET, Vol. 4, Nr.1, 2007. 
[26] P. Majumder, M. Mitra, and B. Chaudhuri, “N-gram: a language 
independent approach to IR and NLP,” Int. Conf. on Universal 
Knowledge and Language (ICUKL), Goa, India, November 2002.  
[27] H. Murfi, and K. Obermayer (2009). “A two-level learning hierarchy of 
concept based keyword extraction for tag recommendations,” [Online]. 
Available: http://www.kde.cs.uni-
kassel.de/ws/dc09/papers/paper_17.pdf/,  
[28] (2009) National library of Medicine website [Online]. Available: 
http://www.nlm.nih.gov/  
[29] R. Nayak, “Discovering knowledge from XML documents,” In Wong,
John, Eds. Encyclopedia of Data Warehousing and Mining. Idea Group 
Publications, 2005. 
[30] C. Ordonez, “Mining constrained association rules to predict heart 
disease,” in Proc. IEEE Int. Conf. on Data Mining, ICDM 2001, San 
Jose, CA, USA , 2001, pp. 433–440.  
[31] J. Paik, H. Yong Youn, and U. Kim, “A new method for mining 
association rules from a collection of XML documents,” ICCSA 2005, 
LNCS 3481, pp. 936–945, 2005. Springer-Verlag Berlin Heidelberg 
2005.  
[32] G. Paynter, I. Witten, S. Cunningham, and G. Buchanan, “Scalable 
browsing for large collections: a case study,” 5th Conf. digital Libraries, 
Texas, pp.215-218, 2000.  
[33] M. Roche J´erome Az´e, O. Matte-Tailliez, and Y. Kodratoff,, “Mining 
texts by association rules discovery in a technical corpus,” Intelligent
Information Processing and Web Mining, Proc. of the Int. IIS: IIPWM'04 
Conf. held in Zakopane, Poland, May 17-20, 2004.  
[34] J. Shin, J. Paik, and U. Kim, “Mining association rules from a collection 
of XML documents using cross filtering algorithm,” Int. Conf. on Hybrid 
Information Technology (ICHIT'06) IEEE, 2006.  
[35] J. W. W. Wan, and G. Dobbie, “Extracting association rules from XML 
documents using XQuery,” in Proc. of the 5th ACM Int. Workshop on 
Web Information and Data Management (WIDM’03), 2003, pp.94–97.  
[36] S. Weiss, N. Indurkhya, T. Zhang and F. Damerau, TEXT MINING: 
Predictive Methods for Analyzing Unstructured Information. Springer 
Science-business Media, Inc. 2005. 
[37] A. Zhu, J. Li and T. Leong, “Automated knowledge extraction for 
decision model construction: A data mining approach,” AMIA Annual 
Symposium Proc., pp. 758-762, 2003.  
[38] (2009) the PubMed website [Online]. Available: 
http://www.ncbi.nlm.nih.gov/pubmed/ 
