 
 
 
  
Abstract—Since the sole focus can’t capture the high-quality 
image of multi-association plastic gear tooth profile’s flaw detail 
on different end surface, these flaws couldn’t be detected 
simultaneously. When it comes to the two images focused on 
different gear ends, the highly detailed image is required due to 
the large quantity and complex profile of gear teeth. In view of 
the subject above, some fusion rules of multi-focus image, which 
adopt big high-frequency coefficient and mean value of 
low-frequency coefficient, are proposed in this paper based on 
wavelet transformation. Then suitable wavelet coefficient and 
decomposition layers are adopted to fuse the multi-focus image. 
Experimental results show that the fusion image has a high 
quality as well as low calculation and the tooth profile is greatly 
different from the background. So the proposed method shows 
great foreground in real time detection. 
I. INTRODUCTION 
NJECTION molding of small plastic gears more often 
appear together with collapse teeth, missing teeth and 
overflow edges and other defects. At present, 
manufacturers usually detect the flaw by using manual 
methods. But due to the great quantity and variety of product 
with small size, the detection efficiency is very low, and the 
reliability can not be guaranteed[1],[2]. Automatic detection 
using computer vision, based on digital image processing 
technology, can improve the efficiency and accuracy of 
detection considerably. In order to reflect fully and clearly the 
multi-gear tooth flaws in different sections, it is necessary to 
focus and collect two individual images from big and small 
gears respectively, shown in Fig.1. (a), (b). And then two 
individual tests are carried out for big and small gears 
respectively. The above method can achieve automatic 
detecting, but it has a low efficiency. In this paper, using 
image fusion based on wavelet transform, to fuse two pictures 
with different focuses, to reconstruct large and small gear 
teeth are to meet the testing requirements feature an image for 
a gear defect detection can improve the efficiency of 
follow-up testing. 
 
Manuscript received April 8, 2010. This work was supported in part by 
The Natural Science Foundation of Ningbo under Grant (2009A610098).  
Yong-qing Chen is with the School of Mechanical Engineering, Ningbo 
University of Technology, Ningbo 315016, China (phone: 15967803420; 
fax: 0574-87080136; e-mail:arching@163.com).  
Lian-qing Chen is with the School of Mechanical Engineering, Ningbo 
University of Technology, Ningbo 315016, China (e-mail:clq@nbut.cn).  
Hong-jie Gu, is with the School of Mechanical Engineering, Jilin 
University,Changchun 130025, China (e-mail: 604183168@qq.com). 
Kun Wang is with the School of Mechanical Engineering, Jilin 
University,Changchun 130025, China (e-mail: 327713874@qq.com). 
        
(a) Focus large gear                         (b) Focus small gear   
Fig.1.Plastic gear source image 
II. PLASTIC GEAR BASED ON WAVELET TRANSFORM IMAGE 
FUSION RULES 
Image fusion based on wavelet transform method lies in 
determining how to choose the fusion rules and the 
decomposition level of wavelet transform [3]. Fig.1. (a), (b) 
to be integrated in the two source images, F is the fused 
image, based on wavelet transform image fusion of plastic 
gear basic steps: 
1) The registration of the source image has A and B 
respectively wavelet decomposition, the equivalent of 
using a set of high and low pass filter for filtering, 
separating the high frequency and low frequency 
information; 
2)  Decomposition of each layer by high frequency 
information and low frequency characteristics based on 
the information received, adopt a different fusion rules, 
in their respective transform domain feature information 
extraction, were fused; 
3) Using 1) the wavelet transform reconstruction algorithm 
on the processed wavelet coefficients inverse transform 
reconstructed image, you can get the fused image. The 
flow chart shown in Fig. 2.  
Plastic gear source image obtained by wavelet 
decomposition of the low-frequency sub-band transform 
values are positive, reflecting the Gears in the resolution of 
the general picture, does not reflect the edge of the details of 
gear teeth; the high frequency sub-band corresponding to the 
edge of the image detail, reflecting gear tooth profile, 
high-frequency components of fuzzy regions modulus 
smaller, clear high-frequency components of the regional 
model is bigger. 
1)     The low-frequency sub-band of the fusion rule 
Low-frequency wavelet coefficients of fused image 
desirable two source images the mean low-frequency 
wavelet coefficients, it can take a source image of the 
low frequency wavelet coefficients, depending on the 
Technology for Multi-focus Image Fusion Based on Wavelet 
Transform 
Yong-qing Chen, Lian-qing Chen, Hong-jie Gu, and Kun Wang  
I
405
Third International Workshop on Advanced Computational Intelligence 
August 25-27, 2010 - Suzhou, Jiangsu, China
978-1-4244-6337-4/10/$26.00 @2010 IEEE
 
 
 
image and purpose to be. 
2)      High frequency sub-band of fusion rules High 
frequency sub-band of fusion rules can be divided into 
two categories [4]: based on a single pixel and 
region-based fusion method. Here on this article chosen 
integration method based on a single pixel for 
description:  
Fusion method based on a single pixel is to try to model the 
value of high frequency wavelet coefficients larger image 
wavelet coefficients as a fusion, including the maximum 
wavelet coefficient selection method, the weighted average 
method. Select the method to be the maximum first pieces of 
image fusion using wavelet decomposition, respectively, and 
then compare each band corresponding absolute value of 
wavelet coefficients, wavelet coefficients of large absolute 
value as the integration of the wavelet coefficients in a new 
wavelet coefficient map, through the inverse wavelet 
transform to get the final fused image, fusion formula is:  
??
?
?
?
=
),(),(),(
),(),(),(
),(
yxByxAyxB
yxByxAyxA
yxF    (1)  
Where, A (x, y) wavelet coefficients for image A, B (x, y) 
for the image B of the wavelet coefficients, F (x, y) for the 
integration of the wavelet  coefficients. 
Weighted average of the integration formula is: 
),(),(),( yxbByxaAyxF +=     (2) 
here a + b = 1 
Maximum value selection method for high-frequency 
components than the rich, bright, high contrast source images, 
fusion images to retain the basic characteristics of the source 
image, the image contrast and the same source image. 
Weighted average weight adjustable, wide application and 
can remove some noise, low source image information loss, 
but will cause a decline in image contrast.  
Wavelet transform theory shows that the high-frequency 
coefficients of a clear image are much larger than those of a 
blurred image. But the low-frequency coefficients are roughly 
equal [5]. As more small plastic gear, more complex tooth 
profiles, on the details of the higher, therefore, adopt high 
frequency coefficient is large, low-frequency coefficient of 
the average fusion rule, the concrete in three steps.  
1)  using two-dimensional wavelet transform of Mallat 
algorithm, the image is decomposed gear. Set Hr, Hc 
array{ }lkC , ? ( ) 2, Zlk ? , respectively, on the role of 
rows and columns of operator H, the Gr and Gc, 
respectively, acting on the array of rows and columns of 
Operator G. D Mallat decomposition algorithm: 
Jj
CGGD
CHGD
CGHD
CHHC
jcrj
jcrj
jcrj
jcrj
,,1,0
3
1
2
1
1
1
1
"=
???
???
?
=
=
=
=
+
+
+
+
        (3) 
2)      Compare two images in the corresponding position of 
the high frequency wavelet coefficients to retain a large 
factor. Comparing two images is the wavelet 
coefficients of 1jD ? 2jD ? 3jD to retain the greater 
value. Seeking two images and the average 
low-frequency wavelet coefficients as a new 
low-frequency  wavelet coefficients Cj. 
3)   Two-dimensional inverse wavelet transform of Mallat 
algorithm, image reconstruction gear. D Mallat 
reconstruction algorithm is: 
JjDGG
DGGDHHCHHC
jcr
jcrjcrjcrj
,...,1,0~~
~~~~~~
3
1
2
1
1
11
=+
++=
+
+++
      (4) 
 
                                                                       
                                                        
 
                                                    
Fig.2. Image Fusion Based on Wavelet Transform 
III. PLASTIC GEAR IMAGE FUSION EVALUATION 
Integration of image quality evaluation of the main 
objective from the subjective and qualitative analysis and 
quantitative analysis of two aspects. Subjective qualitative 
analysis is a comparative analysis from the visual, mainly 
based on visual resolution and spectral characteristics of 
knowledge to a simple assessment of fusion results; objective 
and quantitative analysis based primarily on quantitative 
analysis of several commonly used formula to calculate the 
corresponding image or source image fusion targets data, 
comparative analysis [6-9]. Small plastic gears on the effect 
of image fusion evaluation, taking into account the evaluation 
of the typical parameters and complexity of the algorithm can 
select the information entropy and the average gradient as the 
result of objective evaluation of integrated indicators. 
1)    The information entropy 
If the fused image entropy the greater the entropy of the 
image that the more integrated the information 
contained in the image richer, better integration of 
quality. For a single image, that the gray value of its 
elements are independent of the sample, then this image 
of the gray distribution 
of { }ni PPPPP "" ,,,, 21= , gray value Pi is equal 
to the number of pixels i and the image ratio of the total 
number of pixels , L is the total number of gray level. 
Image entropy is: 
??
=
?=
1
0
2log
L
i
ii PpE                               (5) 
2)     The average gradient 
The average gradient reflects the image of the small 
details of the contrast, texture variation, and image 
clarity, which is defined as: 
? ?
= =
?+?
×
=?
M
i
N
j
yx IINM
g
1 1
22 2/)(1             (6)  
Fusion 
rules     
Decom
positio
Decom
positioImage A 
Image B 
Inverse
wavelet 
transform  
Image F  
406
 
 
 
Where, z and b, respectively xI?  and yI?  direction of 
the difference. NM ×  is the image size (unit: pixels). In 
general, if the average gradient is larger, the more the image 
level, the higher the image resolution, integration will be 
effective in improving image clarity. Therefore, the fused 
image can be used to evaluate the expression in the small 
details and differences. 
IV. EXPERIMENTAL RESULTS AND EVALUATION OF IMAGE 
FUSION 
Currently based on wavelet transform of multi-focus image 
fusion in wavelet and decomposition level on the choice of no 
uniform standard, which two elements of fusion will have a 
huge impact [10-12]. 
A. Selection of Wavelet 
The most commonly used image processing wavelet are 
Haar, Daubechies orthogonal wavelet bases, Cioflet wavelet, 
Symlets Biorthgonal wavelet and biorthogonal wavelet bases. 
Fused image using Haar wavelet has a relatively small 
average gradient and poor clarity of image detail, though with 
the shortest processing time. DbN series of wavelet entropy 
close to that with the increase in the length of compact 
support, the processing time in turn increase; SymN series on 
all aspects of wavelet parameters are close; CoifN series of 
wavelet, compactly supported length with the increase of 
entropy increases, the processing time required to gradually 
increase; biorthogonal wavelet comprehensive performance 
comparison good. Biorthogonal wavelet bases can be selected 
on the plastic gear images for fusion. The experimental data 
shown in Table I. 
TABLE I 
RESULTS OF DIFFERENT WAVELET FUSION  
Wavelet Image entropy 
Average 
gradient 
Processing 
time (s) 
bior2.2 6.1538 3.225 4.656 
bior2.4 6.1513 3.2215 4.753 
bior4.4 6.1442 3.2114 4.813 
bior5.5 6.1414 3.21 5.031 
bior6.8 6.1466 3.2072 5.719 
Can see from the table, Bior2.2 Wavelet entropy and the 
average gradient value of large, good clarity of image detail, 
less time required for fusion, general properties. 
B. Determination of wavelet decomposition level 
Determine the best decomposition level, need to consider 
the details of the comprehensive, operational time and loss 
and other factors. As the decomposition level increases, the 
fused image entropy increased. This is because the more 
layers of wavelet decomposition, the more extensive 
integration of the frequency range, the more extensive details, 
fused image contains the greater amount of information. 
Decomposition level, but more top-level integration will be 
greater the amount of information loss, and such losses can 
not be restored by inverse transform. Select Bior2.2 wavelet, 
respectively, for 1 to 8 layer decomposition of the integration 
of different decomposition level of the integration effect. The 
objective indicators entropy, average gradient and the time 
evaluation are shown in Table II. The fusion result image is 
shown in Fig. 3. 
TABLE II  
RESULTS OF DIFFERENT DECOMPOSITION LEVEL OF INTEGRATION OF THE 
OBJECTIVE INDICATORS OF EVALUATION FORM 
Decomposition 
level 
Image 
entropy 
Average 
gradient 
Processing 
time (s) 
bior2.2-1 5.9487 2.8182 3.594 
bior2.2-2 6.0288 3.1125 4.391 
bior2.2-3 6.0684 3.2118 4.516 
bior2.2-4 6.1165 3.2234 4.594 
bior2.2-5 6.1538 3.225 4.656 
bior2.2-6 6.2516 3.2248 4.703 
bior2.2-7 6.3171 3.2249 4.766 
bior2.2-8 6.4463 3.222 4.828 
 
 
(a) first                               (b) second 
 
(c) third                               (d) forth 
 
(e) fifth                                (f) sixth 
 
(g) seventh                            (k) eigth 
Fig. 3. Bior2.2 wavelet decomposition level of the fusion of different 
The 5 layers of decomposition level is a critical point. The 
average gradient is 5 level decomposition of the fused image 
big, rich details, good sharpness of the image. While 
continuing to increase as the decomposition level, entropy 
407
 
 
 
and spatial frequency is still increasing, but also increasing 
computation, processing time increases. Tiny plastic gear 
handle on the results of a comprehensive analysis of the 
above indicators, based on Bior2.2 5 Wavelet decomposition 
level image fusion, image-rich detail, clearer images, all 
aspects of general properties. Therefore, in automatic 
detection of computer vision, a wavelet decomposition of 5 
layers Bior2.2 is applied for image fusion of small plastic 
gears, as shown in Fig. 3 (e). 
V. CONCLUSION 
Based on the Focus small multi-joint plastic gear tooth end 
collection of different source images, made high-frequency 
coefficient is large, low-frequency coefficient of the average 
fusion rule, select the appropriate wavelet and decomposition 
level determined to carry out a wavelet transform Multi-focus 
image fusion research, deficiencies in the performance 
characteristics, image quality and processing time to achieve 
satisfactory results, for the realization of computer vision, 
automatic detection of a large and small face gear to provide a 
defect in the male. 
REFERENCES 
[1] G. Li, R.-L. Zeng,R. Li and L.Lin,“Multi-information fusion 
technology of urban traffic control system,” Sensor Technology, vol. 19, 
no. 6. pp. 2707–2711, 2006. 
[2] Y.-B. LI, B.-G. Wang and W.-W. Li,“Based on wavelet transform 
texture feature extraction method and its application,”  Sensors and 
Actuators, vol. 22, no. 9. pp. 1308–1311, 2009. 
[3] M.-S. Chen, H.-W. DI,“Study on optimal wavelet decomposition level 
for multi-focus image fusion,”  Optical electronic engineering, vol. 31, 
no. 3. pp. 64–67, 2004. 
[4] J.-H. Tian,Multi-focus image fusion algorithm,Nanchang: Nanchang 
Aeronautical University, 2007. 
[5] Y. Na, L.-C. Jiao, etc,Based on multiresolution analysis of image fusion 
method, Xi'an: Xidian University Press, 2007. 
[6] L. Guo,H.-H. Li and Y.-S. Bao,Image Fusion , Beijing: Electronic 
Industry Press, 2008. 
[7] Yoo J. H,H. H and Y.-W. J,“Craniomaxillofacial Image Fusion and 
CBCT Incidental Findings,” International Journal of Computer 
Assisted Radiology and Surgery?vol. (Suppl 1), no. 3. pp. 1861–6410, 
2008. 
[8] SEONG G.KONG,“Multi-scale Fusion of Visible and Thermal IR 
Images for Illumination Invariant Face Recognition,” International 
Journal of Computer Vision?vol. 71, no. 2. pp. 215–233, 2007. 
[9] C.-H. Hu, Zh.-X. Ding,“Based on fuzzy multi-focus image fusion 
research,” Sensors and Actuators, vol. 20, no. 4. pp. 885–888, 2007. 
[10] X.-H. Shen,B. Ai and T. Wang,“Multi-focus image fusion small 
selection of wavelet function,”  Rocket, vol. 27, no. 3. pp. 231–234, 
2007. 
[11]  Y.-J. Wang,P. Fu,D.-Q. LI and X.-H. XU,“Multi-focus image fusion 
based on multi-decision,” Optical electronic engineering, vol. 34, no. 8. 
pp. 93–98, 2007. 
[12] Sh. Li, L.-Y. Lin and R.-Y. Chen,“Multi-focus Image Fusion Based on 
Particle Swarm Optimization,” Optical electronic engineering, vol. 36, 
no. 6. pp. 109–114, 2009. 
 
408
