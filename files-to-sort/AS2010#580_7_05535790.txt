Research of Data Mining Based on Apriori algorithm 
in Cutting Database 
 
Guofeng Wang, Xiu Yu, Dongbiao Peng, Yinhu Cui, Qiming Li 
School of Mechanical Engineering 
Tianjin University 
Tianjin 300072, China 
 
Abstract—Cutting data mining is an important method to 
increase efficiency? discover hidden knowledges in cutting 
database, and provide guidance for cutting decisions.This paper 
analyze the Apriori algorithm for association rules mining, and 
make some improvement for this algorithm based on the features 
of cutting database. Apriori algorithm is improved to mine 
association rules in cutting database. The results show that the 
Apriori algorithm can be efficiently used in cutting data mining, 
and improved algorithm can achieve expected effect better than 
traditional algorithm. 
Keywords-data mining; association rules mining; cutting 
database; Apriori algorithm 
I.  INTRODUCTION  
Cutting database appHared after the combination of 
machining technique and database technique which can provide 
effective data information support for machining process. we 
can get higher machining efficiency and economic efficiency if 
the reasonable and optimized cutting data provided by cutting 
database is used [1].However, it is a pity that it can’t derive 
enough more useful information so as to  provide guidance for 
actual machining although large amount of cutting parameters, 
processing knowledges, empirical formulas have been stored. 
In this sense, it can only be called static cutting database, which 
result in “explosive data, however lack of knowledge”. So it is 
important to adopt data mining technique for cutting database 
and discover hidden knowledges from this cutting database. In 
this paper, on studying the properties of cutting database, 
Apriori algorithm is improved before using into cutting data 
mining and the final results shows that some useful knowledge 
can be get from these large amount of cutting data. 
II. ASSOCIATION RULES MINING AND APRIORI ALGORITHM 
Association rules mining is one of the most important 
research methods in data mining which can obtain some useful 
knowledge to describe the association between different 
valuable data items out of a great amount of datas. A lot of 
algorithms about mining association rules have been presented 
recently, among which Apriori algorithm is one of typical 
algorithm. It was introduced in 1993 by Agrawal as a powerful 
method used to find regularities in data trend [2]. Apriori 
algorithm is a width-first search arithmetic in which recursive 
method was adopted. A basic property of “every subset of a 
frequent item sets is still  frequent item set, and every superset 
of a non-frequent item set is not a frequent item set [3]” has 
been used in Apriori algorithm to discover all of the frequent 
item sets. Details and formulas are given as follows: 
C1={candidate 1-itemsets}; 
L1={c?C1/c.count>=minimum support}; 
For (k=2; Lk-1??; k++) { 
Ck=sc_candidate(Lk-1); 
For each transaction t?D { 
              Ct=count_support(Ck,t); 
              For all candidates c?Ct {c.count++} 
           } 
Lk={c?Ck/c.count>=minimum support}; 
} 
Return L=UkLk; 
The notations and definitions are given as follows: 
1) D=set of transactions; each transaction t is included in D;  
2) Lk= set of large k-item sets(set of items having minimum 
support);  
3) Ck= set of candidate k-item sets(items to be counted);  
4) Function of  sc_candidate is aimed at using Lk-1 to get Ck; 
5) Function of count_support is aimed at using Ck and t to get 
all of the candidate k-itemsets that included in t. 
The Apriori algorithm finds only the frequent item sets. In 
order to find the associations rules in the database , we must 
apply the following improved algorithm [4],that is: 
For each frequent item set Lk { 
    Generate all non-empty subsets of  Lk; 
        For each non-empty subset Ls of Lk  { 
        Output-rule: Ls?Lk if 
support(Lk)/support(Ls)>=min-confidence} 
} 
The Above steps can be concluded to the following two 
points: (1) The support of every frequent item sets should be 
larger than the minimum support threshold, and (2) The 
This paper is sponsored by Chinese National Science Fund (50805100) 
and Chinese National Science & Technology Supporting Program 
(2008BAF32B11) 978-1-4244-7739-5/10/$26.00 ©2010 IEEE
confidence of every association rules that derived from 
frequent item sets should be larger than the minimum 
confidence threshold. 
III. THE APPLICATION OF IMPROVED APRIORI ALGORITHM IN 
CUTTING DATABASE 
Since the Apriori algorithm was proposed, many scholars 
have carried on a series of researches and applications. 
Meanwhile, some improvements have been made to reduce the 
time cost of scanning the database [5] and save the time for 
searching frequent item sets [6] which occur when the 
traditional Apriori algorithm is used. But there are still some 
problems in the various kinds of applications more or less. As 
the main target of algorithm Apriori is to find the frequent item 
sets in which the support and the confidence are larger than the 
minimum threshold respectively. If the support is too small, 
many useless rules will be obtained, but if the support is too 
large, there would be some rules missed such as the rules with 
high confidence and not large enough support. In the cutting 
database, the support of cutting data for difficult-to-machine 
material and high-speed cutting is always not very large, but in 
practice, the rules of that kind is requisite due to a lack of 
experience. In that case, the minimum support and the 
minimum confidence need to be set according to various 
circumstances. The method of this paper is to set the minimum 
support, the maximum support, the minimum confidence, the 
maximum confidence based on the principle so that no 
important rules can be missed and the useless rules can be 
reduced according to the limited scale. The steps are listed as 
follows: 
1) Finding out the frequent item sets in which the support is 
larger than the minimum support. 
2) Choosing the frequent item sets primarily which satisfy the 
rule (the attribute of judgment in the left and the attribute of the 
result in the right) as the rough rule. 
3) Judging the confidence of the roughing sets. If the 
confidence is smaller than the maximum confidence and larger 
than the minimum confidence, judge the roughing sets and pick 
out the roughing rule minimum confidence of which is larger 
than maximum support as the eventual output rule; If the 
confidence is bigger than the maximum confidence, then the 
rule is outputted as the eventual rule.
In order to make the process clearly, the flow chart of 
improved algorithm is showed in Fig. 1. 
IV. DATA MINING EXAMPLE OF CUTTING DATABASE 
A. Data Sources 
Parts of milling data are stored in this database, some of 
which are from experimental data [7], and the others are from 
the usual cutting data handbook of metal material written by 
companies such as CPMEC[8]. 
B. Selection of Mining Data Attributes and its Discretization 
Cutting conditions such as cutting speed Vc, feed rate f and 
cutting depth ap are influenced by milling methods, hardness of 
work-piece material, heat-resistance temperature of tool 
material, cutting precision, machine, cutting coolant, heat 
treatment conditions of work-piece material, tool diameter and 
so on. Among the 3 basics of cutting conditions, cutting depth 
is determined by working allowance and surface quality, which 
can be neglected during the mining process. Cutting speed and 
Start
Find frequent 
itemsets which 
suppot>minim
um support
Choose rules which 
confidence>minim
un confidence
Confidence>maximum 
confidence?
Output as final 
rules
Yes
No Compare 
support to 
minimum 
support
Support>maximu
m support
Yes
 
Figure 1.  Flow chart of improved algorithm 
feed rate are onditions in 
C. Data Mining 
are exported from cutting database as XLS 
file, 
be included in the final results. Oppositely, if a lower minimum 
key parameters to evaluate cutting c
machining center. In this paper, cutting precision, work-piece 
material and the other 4 influenced factors are selected as 
regular conditioning attribute, while cutting speed and feed rate 
are selected as regular determined attribute. In order to extract 
the regular conveniently, continuous data should be discretized 
before data mining. Its dividing range and discretized result are 
shown in TABL(?. Additionally, the value of each attribute is 
reflected 1 to 44 respectively so as to facilitate compiling of 
mining program. 
Partial datas 
then 33 data groups are intercepted from it. In order to 
mine by MATLAB, all the datas have to be discretized and 
reflected to 1 to 44 as TABL(? . The selection of the 
minimum support threshold and the minimum confidence 
threshold play an important role in whole process of mining. If 
just one minimum support threshold as 0.1 and one maximum 
confidence as 0.6 thresholds are defined as traditional 
algorithm, we can get the result as TABL(?. As shown in 
TABL(?, although the rules with high support can be got 
from the mining results, some important rules would be missed 
at the same time. For example, the support of frequent item set 
for stainless steel in mining data is not high enough, but the 
association rule got from it can reach 100%, which also has to 
TABLE I. DECARTELIZATION  TABLE  FOR DATA  PROPERTIES 
Machining Classification of Cutting 
Sp ) 
Feed
Ra /z)Precision Work piece Material
Classification of Milling Diameter of Hardness of Work 
Cutter Material Method Cutter(mm) piece(HBS) eed(m/min te(mm
p ) s1( l) 1(Roughing Carbon stee c1(Tool steel) x1(face milling) d1(0-4) h1(125-175) v1(20-25) f1(0-0.02) 
p2(Semi-
finishing) s2(Alloy steel) 
c2(High speed 
steel) 
x2 l f(Peripheramilling) d2(4-8) h2(175-225) v2(25-30) 2(0.02-0.04)
p ) s  3(Finishing 3(Stainless steel) c3(Carbide)  d3(8-12) h3(225-275) v3(30-35) f3(0.04-0.06)
 s4(Cast steel) c4(Ceramic)  d4(12-16) h4(275-325) v4(35-40) f4(0.06-0.08) 
 s5(Aluminum alloy) c5(Diamond)  d5(16-20) h5(325 above) v5(40-100) f5(0.08-0.10)
 S6(Ti ) tanium alloy   d6(20-30)  v6(100-150) f6(0.1-0.15)  
    d7(30-40)  v7(150 above) f7(0 15 .above) 
    d8(40-50)     
    d  9(50 above)     
TABLE II. MINING  WITH  TRADITIONAL  APRIORI  ALGORITHM 
Number Rules Support confidence
1 p1 & s2 & & d4?f5 c2 & x1 18.18% 100% 
2 p1 & s2 & c2 & x1 & d5?f5 18.18% 100% 
3 p1 & s2 & c2 & x1 & d7?f6 18.18% 85.71% 
4 p1 & s2 & c2 & x1 & h1?f6 12.12% 60% 
5 p1 & s2 & c2 & x1 & h2?f6 12.12% 60% 
6 p1 6  & s2 & c2 & x1 & d6 & h1?f 15.15% 100% 
7 p  1 & s2 & c2 & x1 & d6 & h3?v1 &
f6 
12.12% 100% 
 
pport threshold is chosen, a lot of useless rules will derive. 
TABLE III. MINING  WITH  IMPROVED  APRIORI  ALGORITHM 
D. Result Analysis 
TABL(?that the results got from the 
impr
ses, the maximum feed rate for 
m 
V. Conclusion 
In this paper proved based on the 
prop
REFERENCES 
>@ Y. Wan, Z. Q. L G, Development of a cutting 
database system tion and analysis functions, 
Materials Science Forum, vol. 471-472, pp. 32-36, 2004. 
It is shown in 
oved algorithm keep the data information about stainless 
steel with low support and high confidence, which is in 
agreement with expected goal. What’s more, by analyzing the 
rules in TABL(?, some important information about cutting 
can be obtained as follows:  
 1) As cutter diameter increa
rough machining of alloy steel increases correspondingly. 
2)When the carbide cutter whose diameter ranges from 40m
to 50mm is employed, cutting speed between 100m/min and 
150m/min can be used to face mill stainless steel whose 
hardness ranges from 275HBS to 325HBS. But when it is 
used in actual process, some parameters change as actual 
condition, because its support is not large enough at all. 
Besides the above conclusions, the information that the 
cutting speed decrease as the hardness of work-piece increase 
would be derived at the same time, but some rules can’t be 
discovered  because the quantity of data is not big enough, in 
order to get more reliable rules, lots of datas are needed in 
future application. 
 
su
By comprehensive consideration, a minimum support 
threshold as 0.08, a maximum support threshold as 0.1, a 
minimum confidence threshold as 0.6, and a maximum 
confidence threshold as 0.8 is chosen for this mining, then 
carry out data mining with improved algorithm, while the 
mining results is showed in TABL(?.
, Apriori algorithm is imNumber Rules Support Confidence
erties of cutting database, and then it is used in cutting 
data mining. From the results we can conclude that the 
improved algorithm is efficient in cutting database mining. In 
order to get more useful rules efficiently, the future work is to 
get more cutting datas to mine and make further improvement 
on Apriori algorithm. 
1 p1 & s2 &  & d4?f5 c2 & x1 18.18% 100% 
2 p1 & s2 & c2 & x1 & d5?f5 18.18% 100% 
3 p1 & s2 & c2 & x1 & d7?f6 18.18% 85.71% 
4 p1 6  & s2 & c3 & x1 & d8 & h4?v 12.12% 100% 
5 p1 & s2 & c2 & x1 & d6 & h1?f6 15.15% 100% 
6 p  1 & s2 & c2 & x1 & d6 & h3?v1 &
f6 
12.12% 100% 
iu, and X, Ai, J. 
 with predic
>@ Agrawal R, Imielinski T, Swami A. Mining association rules 
between sets of items in large databases. In: Proc. ACM 
SIGMOD Intl. Conf. Management Data, 1993. 
>@ X. Wang, T. F. Xu, and L. Z. Tang, SQL Sever 2005 data, 
mining analysis by living example,Beijing:china press of water 
resources and hydropower research, 2008, pp. 128-131. 
 of the World Congress on Intelligent Control and 
lications, DBA 
03. 
>@ C. Aflori, M. Craus, Grid implementation of the Apriori 
algorithm, Advances in Engineering Software, vol. 38, pp. 295-
300, 2007. 
>@ J. Gao, S. J. Li, and F. Qian, A method of improvement and 
optimization on association rules Apriori algorithm, 
Proceedings
Automation (WCICA), vol. 2, pp. 5901-5905, 
2006[Proceedings of the World Congress on Intelligent Control 
and Automation (WCICA) Language: Chinese]. 
>@ P. Judith, V. Sidney, G. Santiago, Matrix Apriori: Speeding up 
the search for frequent patterns, Proceedings of the IASTED 
International Conference on Databases and App
2006, pp. 75-82, 2006[Proceedings of the IASTED International 
Conference on Databases and Applications, DBA 2006 ]. 
>@ B. Qu, H. Zhou, and C. M. Jiang, Experimental investigation on 
cutting performances of carbide face milling Cutters During 
cutting 0Crl3Ni5Mo, Tool engineering, vol. 37, pp. 3-4, 20
>@ Companies of CPMEC , Shanghai University Of Technology, 
and Tsinghua University, Usual cutting data handbook of metal 
material, Beijing: Press of petroleum industry, June 1995. 
